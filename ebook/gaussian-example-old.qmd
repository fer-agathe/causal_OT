# Gaussian Example {#sec-motivation-gaussian}


:::{.callout-note}

## Objectives

In this page, XXX



:::

```{r package-settings}
#| warning: false
#| message: false
library(tidyverse)
library(mnormt)
```

```{r}
#| warning: false
#| message: false
#| code-fold: true
#| code-summary: Codes for graphical parameters
library(extrafont, quietly = TRUE)
col_group <- c("#1b95e0","#7F170E", "#00A08A")
colGpe1 <- col_group[2]
colGpe0 <- col_group[1]
colGpet <- col_group[3]
loadfonts(device = "pdf", quiet = TRUE)
font_size <- 20
font_family <- "CMU Serif"

path <- "./figs/"
if (!dir.exists(path)) dir.create(path)

theme_paper <- function(...) {
  font_size <- 20
  theme(
    text = element_text(family = font_family, size = unit(font_size, "pt")),
    plot.background = element_rect(fill = "transparent"),
    legend.key = element_blank(),
    panel.spacing = unit(1, "lines"),
    panel.background = element_rect(fill = NA, colour = "black"),
    panel.grid.major = element_line(colour = "grey80"),
    plot.title = element_text(hjust = 0, size = rel(1.3), face = "bold"),
    plot.title.position = "plot",
    strip.background = element_rect(fill = NA, colour = NA)
  )
}
```



```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| file: _myfunctions.R
```

$$
\definecolor{wongBlack}{RGB}{0,0,0}
\definecolor{wongGold}{RGB}{230, 159, 0}
\definecolor{wongLightBlue}{RGB}{86, 180, 233}
\definecolor{wongGreen}{RGB}{0, 158, 115}
\definecolor{wongYellow}{RGB}{240, 228, 66}
\definecolor{wongBlue}{RGB}{0, 114, 178}
\definecolor{wongOrange}{RGB}{213, 94, 0}
\definecolor{wongPurple}{RGB}{204, 121, 167}
\definecolor{colA}{RGB}{255, 221, 85}
\definecolor{colB}{RGB}{148, 78, 223}
\definecolor{colC}{RGB}{63, 179, 178}
\definecolor{colGpe1}{RGB}{127, 23, 14}
\definecolor{colGpe0}{RGB}{27, 149, 224}
$$

## Data Generating Process {#sec-dgp}

We want to simulate potential outcomes in a binary treatment setting, with covariate shift between treatment groups.

Let $n=500$ denote the number of individuals (or unit), and let $\boldsymbol{X}=(X_1,X_2)$ be drawn from bivariate normal distrubtions whose mean vectors and covariance matrices depend on the treatment assignment $A\in\{0,1\}$. 

For `r colorize("untreated individuals", colGpe0)` ($A=\color{colGpe0}0$) the covariates $\boldsymbol{X}^{(0)} = (X_1^{(0)}, X_2^{(0)})$ are sampled from a $\mathcal{N}(\mu_0, \Sigma_0)$, where $\mu_0 = -1$, $\Sigma_0 = \begin{pmatrix} 1 & r_0 \\ r_0 & 1 \end{pmatrix}$ with $r_0 = 0.7$.

For `r colorize("treated individuals", colGpe1)` ($A=\color{colGpe1}1$), covariates $\boldsymbol{X}^{(1)} = (X_1^{(1)}, X_2^{(1)})$ follow a $\mathcal{N}(\mu_1, \Sigma_1)$, where $\mu_1 = +1$, $\Sigma_1 = \begin{pmatrix} 1 & r_1 \\ r_1 & 1 \end{pmatrix}$ with $r_1 = -0.5$. 


The treatment assignment $A$ is randomized with probability $p_1 = 0.5$.

The potential outcomes are linear functions of the covariates: 
$$
\begin{aligned}
Y(0) &= a_1 X_1 + a_2 X_2 + \varepsilon,\\
Y(1) &= a_1 X_1 + a_2 X_2 + a_0 + \varepsilon .
\end{aligned}
$$

where $\varepsilon \sim \mathcal{N}(0, 1)$ and $a_0 = 3$, $a_1 = 2$, $a_2 = -1.5$. 

The observed outcome is 
$$Y = A \cdot Y(1) + (1 - A) \cdot Y(0).$$ 

We will focus on the average treatment effect of the treated:
$$
\begin{aligned}
\text{ATT}
&= \mathbb{E}\bigl[Y(1)-Y(0)\mid A=1\bigr] \\
&= a_0 \\
&= 3.
\end{aligned}
$$

```{r}
set.seed(12345)
# Parameters
n <- 500
mu0 <- -1
mu1 <- +1
r0 <- +.7
r1 <- -.5
a <- 1
a0 <-  3
a1 <-  2
a2 <-  -1.5
p1 <- .5
Mu0 <- rep(mu0, 2)
Mu1 <- rep(mu1, 2)
Sig0 <- matrix(c(1, r0, r0, 1), 2, 2)
Sig1 <- matrix(c(1, r1, r1, 1), 2, 2)

# Draw covariates
X0 <- rmnorm(n, mean = a * Mu0, varcov = Sig0)
X1 <- rmnorm(n, mean = a * Mu1, varcov = Sig1)
# Random noise
E <- rnorm(n)
# Binary treatment
A <- sample(0:1, size = n, replace = TRUE, prob = c(1 - p1, p1))

X <- X0
X[A==1, ] = X1[A==1, ]

df <- tibble(
  X1 = X[, 1],
  X2 = X[, 2],
  A = A,
  Y0 = a1 * X1 + a2 * X2 + E,
  Y1 = a1 * X1 + a2 * X2 + a0 + E,
  Y = A * Y1 + (1-A) * Y0
)
```

We define a function to wrap this DGP.
```{r define-gen_data}
#| code-fold: true
#| code-summary: The `gen_data()`{.R} function.
#' @param n Number of units.
#' @param mu0 Mean of the two covariates in group 0.
#' @param mu1 Mean of the two covariates in group 1.
#' @param r0 Covariance of the two covariates in group 0.
#' @param r1 Covariance of the two covariates in group 1.
#' @parma a Shift parameter for the mean in both groups
#'  (default to 1: no shift). Larger values decreases overlapping.
gen_data <- function(n = 500,
                     mu0 = -1,
                     mu1 = +1,
                     r0 = +.7,
                     r1 = -.5,
                     a = 1,
                     seed = NULL) {
  
  if (!is.null(seed)) set.seed(seed)
  
  a0 <-  3
  a1 <-  2
  a2 <-  -1.5
  p1 <- .5
  Mu0 <- rep(mu0, 2)
  Mu1 <- rep(mu1, 2)
  Sig0 <- matrix(c(1, r0, r0, 1), 2, 2)
  Sig1 <- matrix(c(1, r1, r1, 1), 2, 2)
  # Draw covariates
  X0 <- rmnorm(n, mean = a * Mu0, varcov = Sig0)
  X1 <- rmnorm(n, mean = a * Mu1, varcov = Sig1)
  # Random noise
  E <- rnorm(n)
  # Binary treatment
  A <- sample(0:1, size = n, replace = TRUE, prob = c(1 - p1, p1))
  X <- X0
  X[A==1, ] = X1[A==1, ]
  df <- tibble(
    X1 = X[, 1],
    X2 = X[, 2],
    A = A,
    Y0 = a1 * X1 + a2 * X2 + E,
    Y1 = a1 * X1 + a2 * X2 + a0 + E,
    Y = A * Y1 + (1-A) * Y0
  )
  
  df
}
```


## A Closer Look at Overlapping


When the estimation of the ATT is done using the AIPW estimator, the procedure requires a propensity-score model:
$$e(X) = \mathbb{P}(A = 1 \mid X),$$
and an outcome regression for the untreated potential outcome:
$$\mu_0(\boldsymbol{X}) = \mathbb{E}[Y \mid \boldsymbol{X}, A = 0].$$

The ATT is then estimated as follows:
$$
\widehat{\text{ATT}}_{\text{AIPW}} = \frac{1}{n_1} \sum_{i: A_i = 1} \left[ Y_i - \hat{\mu}_0(X_i) \right] + \frac{1}{n_1} \sum_{i: A_i = 0} \frac{\hat{e}(X_i)}{1 - \hat{e}(X_i)} \left[ Y_i - \hat{\mu}_0(X_i) \right]
$$ {#eq-aipw}

The first term imputes the counterfactual outcome for treated units, whereas the second corrects any residual bias by re-weighting control residuals. 

Consistency holds if either the propensity-score model or the outcome model is correctly specified (known as the estimator's double robustness).

For every covariate pattern represented among treated units, the identification assumption is required:
$$0 < \mathbb{P}(A = 1 \mid X) < 1$$
This assumption ensures an adequate overlap and prevents infinite weights.

In finite samples, extreme estimated propensities ($\hat{e}(\boldsymbol{X})\approx 0$ or $\hat{e}(\boldsymbol{X})\approx 1$) lead to inflated variance. A common practice is then to introduce a trimming rule that discards observations with $\hat{e}(\boldsymbol{X})$ outside a pre-specified interval. Common values are $[0.05;0.95]$ or $[0.01;0.99]$.

Here, we want to have a closer look at what happens when trimming.


Let us consider two examples:

1. Large overlap: $\mu_0=-.5$, $\mu_1=.5$, the rest of the parameters are the same as those presented above.
2. Limited overlap: $\mu_0=-1.5$, $\mu_1=1.5$, the rest of the parameters are the same as those presented above.


```{r}
#| code-fold: true
#| code-summary: Codes to create the Figure.
#| message: false
#| warning: false
#| fig-height: 2.3
#| fig-width: 4.6
#| fig-cap: Level curves of the two densities of $\boldsymbol{X} \\mid A=a$ in the toy example, and associated propensities. The white area correponds to $x$ where the propensity score is in $[1\%,99\%]$. The <span style="color:#1b95e0;">blue area</span> corresponds to $P[A=1 \\mid \boldsymbol{X}] < 1\%$, the <span style="color:#7F170E;">red area</span> corresponds to areas where $P[A=1 \\mid \boldsymbol{X}] > 99\%$.
#| label: fig-level-curves-overlap

# First example
mu0 <- -.5
mu1 <- .5
r0 <- +.7
r1 <- -.5
a <- 1
p1 <- .5
Mu0 <- rep(mu0, 2)
Mu1 <- rep(mu1, 2)
Sig0 <- matrix(c(1, r0, r0, 1), 2, 2)
Sig1 <- matrix(c(1, r1, r1, 1), 2, 2)

u <- seq(-10, 10, length = 161)
dxy <- expand_grid(X1 = u, X2 = u)

d0 <- dmnorm(as.matrix(dxy), mean = a * Mu0, varcov = Sig0)
d1 <- dmnorm(as.matrix(dxy), mean = a * Mu1, varcov = Sig1)

z0 <- matrix(d0, nrow = length(u))
z1 <- matrix(d1, nrow = length(u))

par(mar = c(2.1, 2.1, 0.1, 0.1), mfrow = c(1,2))
x_lim <- c(-3, 3)
y_lim <- c(-4, 4)

plot(NA,NA, 
     xlim = x_lim, ylim = y_lim, 
     xlab = "", ylab = "", pch = NA,
     family = font_family
)
title(xlab = "X1", ylab="X2", line=2, cex.lab=1.2, family = font_family)



# posterior probability of class 1 (using Bayes' theorem)
posterior <- (p1 * d1) / ((1-p1) * d0 + p1 * d1)
# reshape for plotting
post_matrix <- matrix(posterior, nrow = length(u), byrow = FALSE)

lvl <- c(.01, .99)

# contour(
# u, u, post_matrix, levels = lvl, drawlabels = TRUE,
# col = "blue", lty = 3, lwd = 2,
# xlab = "X1", ylab = "X2", main = "Region where 0.01 ≤ P(A|X) ≤ 0.99"
# )

# extract contour lines
contours <- contourLines(u, u, post_matrix, levels = lvl)
param_dens <- 35
cl <- contours
for (i in 1:length(cl)) {
  if (cl[[i]]$x[2] < cl[[i]]$x[1]) {
    cl[[i]]$x <- rev(cl[[i]]$x)
    cl[[i]]$y <- rev(cl[[i]]$y)
  }
}

# Bottom-left
polygon(
  c(cl[[1]]$x, 10, -10, -10),
  c(cl[[1]]$y, -10, -10, 10),
  col=scales::alpha(colGpe0, .9), density = param_dens,
  border = NA
)
# Upper-right
polygon(
  c(cl[[2]]$x, 10, 10, -10),
  c(cl[[2]]$y, -10, 10, 10),
  col=scales::alpha(colGpe0, .9), density = param_dens,
  border = NA
)
# Upper-left
polygon(
  c(cl[[3]]$x, 10, -10, -10),
  c(cl[[3]]$y, 10, 10, -10),
  col=scales::alpha(colGpe1, .9), density = param_dens,
  border = NA
)
# Bottom-right
polygon(
  c(cl[[4]]$x, 10, 10, -10),
  c(cl[[4]]$y, 10, -10, -10),
  col=scales::alpha(colGpe1, .9), density = param_dens,
  border = NA
)

contour_lwr <- cl[sapply(cl, function(x) x$level == lvl[1])]
contour_upr <- contours[sapply(cl, function(x) x$level == lvl[2])]
for (c in contour_lwr) lines(c$x, c$y, col = "gray30", lty = 1)
for (c in contour_upr) lines(c$x, c$y, col = "gray30", lty = 1)

# Add contour lines
contour(u, u, z0, add = TRUE, lwd = 1, col = colGpe0, family = font_family, labcex = 1)
contour(u, u, z1, add = TRUE, lwd = 1, col = colGpe1, family = font_family, labcex = 1)

# Second example
mu0 <- -1.5
mu1 <- 1.5
r0 <- +.7
r1 <- -.5
a <- 1
p1 <- .5
Mu0 <- rep(mu0, 2)
Mu1 <- rep(mu1, 2)
Sig0 <- matrix(c(1, r0, r0, 1), 2, 2)
Sig1 <- matrix(c(1, r1, r1, 1), 2, 2)

u <- seq(-10, 10, length = 161)
dxy <- expand_grid(X1 = u, X2 = u)

d0 <- dmnorm(as.matrix(dxy), mean = a * Mu0, varcov = Sig0)
d1 <- dmnorm(as.matrix(dxy), mean = a * Mu1, varcov = Sig1)

z0 <- matrix(d0, nrow = length(u))
z1 <- matrix(d1, nrow = length(u))

# x_lim <- y_lim <- c(-3.5, 3.5)
x_lim <- c(-3, 3)
y_lim <- c(-4, 4)

plot(NA,NA, 
     xlim = x_lim, ylim = y_lim, 
     xlab = "", ylab = "", pch = NA,
     family = font_family
)
title(xlab = "X1", ylab="X2", line=2, cex.lab=1.2, family = font_family)
# posterior probability of class 1 (using Bayes' theorem)
posterior <- (p1 * d1) / ((1-p1) * d0 + p1 * d1)
# reshape for plotting
post_matrix <- matrix(posterior, nrow = length(u), byrow = FALSE)

lvl <- c(.01, .99)

# contour(
# u, u, post_matrix, levels = lvl, drawlabels = TRUE,
# col = "blue", lty = 3, lwd = 2,
# xlab = "X1", ylab = "X2", main = "Region where 0.01 ≤ P(A|X) ≤ 0.99"
# )

# extract contour lines
contours <- contourLines(u, u, post_matrix, levels = lvl)

cl <- contours
for (i in 1:length(cl)) {
  if (cl[[i]]$x[2] < cl[[i]]$x[1]) {
    cl[[i]]$x <- rev(cl[[i]]$x)
    cl[[i]]$y <- rev(cl[[i]]$y)
  }
}

# Bottom-left
polygon(
  c(cl[[1]]$x, 10, -10, -10),
  c(cl[[1]]$y, -10, -10, 10),
  col=scales::alpha(colGpe0, .9), density = param_dens,
  border = NA
)
# Upper-right
polygon(
  c(cl[[2]]$x, 10, 10, -10),
  c(cl[[2]]$y, -10, 10, 10),
  col=scales::alpha(colGpe0, .9), density = param_dens,
  border = NA
)
# Upper part (wrong but not for the cropped image)
polygon(
  c(cl[[3]]$x, 10, 10, -10),
  c(cl[[3]]$y, -10, 10, 10),
  col=scales::alpha(colGpe1, .9), density = param_dens,
  border = NA
)

contour_lwr <- cl[sapply(cl, function(x) x$level == lvl[1])]
contour_upr <- contours[sapply(cl, function(x) x$level == lvl[2])]
for (c in contour_lwr) lines(c$x, c$y, col = "gray30", lty = 1)
for (c in contour_upr) lines(c$x, c$y, col = "gray30", lty = 1)

# Add contour lines
contour(u, u, z0, add = TRUE, lwd = 1, col = colGpe0, family = font_family, labcex = 1)
contour(u, u, z1, add = TRUE, lwd = 1, col = colGpe1, family = font_family, labcex = 1)

p <- recordPlot()
pdf(paste0(path, "gauss-ex-level-curves-overlap.pdf"), width = 4.6, height = 4.6/2)
replayPlot(p)
dev.off()
```


## Counterfactuals

Let us build counterfactuals for individuals from `r colorize("group 1", colGpe1)`. We will consider the following methods:

- Multivariate Optimal Transport (since we know the parameters of the two Gaussians),
- Sequential Optimal Transport.

### Optimal Transport

```{r lobrary-expm}
library(expm)
```

The optimal transport map $T(x)$ from $\mathcal{N}(\mu_0, \Sigma_0)$ to
$\mathcal{N}(\mu_1, \Sigma_1)$ is:
$$T(x) = \mu_1 + A(x - \mu_0)$$
where:
$$
 A = \Sigma_1^{1/2} 
       \left( \Sigma_1^{1/2} \Sigma_0 \Sigma_1^{1/2} \right)^{-1/2}
      \Sigma_1^{1/2}
$$

We define the function `compute_ot_map()`{.R} to compute the optimal mapping.

```{r define-compute_ot_map}
#' Optimal transport mapping between two Gaussian distributions 
#'  (from \eqn{\mathcal{N}(\mu_0, \Sigma_0)} to 
#'  \eqn{\mathcal{N}(\mu_1, \Sigma_1)})
#'  
#' @param mu0 Means of the bivariate Gaussian in group 0.
#' @param sigma0 Variance-covariance matrix of the bivariate Gaussian in group 0.
#' @param mu1  Means of the bivariate Gaussian in group0.
#' @param sigma1 Variance-covariance matrix of the bivariate Gaussian in group 1.
compute_ot_map <- function(mu0, sigma0, mu1, sigma1) {
  
  sqrt_sigma1 <- sqrtm(sigma1)
  inner <- sqrt_sigma1 %*% sigma0 %*% sqrt_sigma1
  sqrt_inner_inv <- solve(sqrtm(inner))
  A <- sqrt_sigma1 %*% sqrt_inner_inv %*% sqrt_sigma1
  
  list(A = A, shift = mu1 - A %*% mu0)
}
```

We also define the `apply_ot_transport()`{.R} function which uses a transport plan to transport individuals.

```{r define-apply_ot_transport}
#' Function to apply the transport map to simulated data
#' 
#' @param X Observations to transport.
#' @param mapping Optimal transport mapping (from `compute_ot_map()`)?
apply_ot_transport <- function(X, mapping) {
  A <- mapping$A
  shift <- mapping$shift
  t(apply(X, 1, function(x) as.vector(shift + A %*% x)))
}
```


Since we generated the data, we know the exact transport plan to transport individuals from `r colorize("group 0", colGpe0)` to `r colorize("group 1", colGpe1)`.
```{r}
Sigma0 <- matrix(c(1, r0, r0, 1), 2, 2)
Sigma1 <- matrix(c(1, r1, r1, 1), 2, 2)
Mu0 <- rep(a * mu0, 2)
Mu1 <- rep(a * mu1, 2)
ot_map <- compute_ot_map(mu0 = Mu1, sigma0 = Sigma1, mu1 = Mu0, sigma1 = Sigma0)
```

We apply the transport map to the `r colorize("treated units", colGpe1)` (A = 1)

```{r}
X1 <- as.matrix(df[df$A == 1, c("X1", "X2")])
X1_t <- apply_ot_transport(X = X1, mapping = ot_map)
colnames(X1_t) <- c(c("X1", "X2"))
```

Let us visualize the transported individuals. First, we define the function `draw_ellipse()`{.R} which will allow us to plot the 95% confidence ellipse in both groups.

```{r define-draw_ellipse}
#| code-fold: true
#| code-summary: The `draw_ellipse()`{.R} function.
draw_ellipse <- function(mu, 
                         sigma, 
                         col = "black", 
                         lty = 1, 
                         lwd = 1, 
                         level = 0.95, 
                         ...) {
  
  angles <- seq(0, 2 * pi, length.out = 100)
  vals <- sqrt(
    qchisq(level, df = 2)) * t(chol(sigma)) %*% rbind(cos(angles), sin(angles)
    )
  lines(mu[1] + vals[1, ], mu[2] + vals[2, ], col = col, lty = lty, lwd = lwd, ...)
  
}
```

We isolate the observations from `r colorize("group 0", colGpe0)` and from `r colorize("group 1", colGpe1)`.
```{r define-X0}
# Prepare data for the plot
X0 <- df[df$A == 0, c("X1", "X2")]
X1 <- df[df$A == 1, c("X1", "X2")]
```

The initial points and the `r colorize("transported values", colGpet)` are shown in @fig-gaussian-ot

```{r}
#| code-fold: true
#| code-summary: Codes to create the Figure.
#| fig-cap: !expr glue::glue("500 points in each group drawn from bivariates Gaussian distributions and <span style='color:{c2};'>transported values</span> from <span style='color:{c1};'>group 1</span> to <span style='color:{c0};'>group 0</span>, using optimal transport.", c0 = colGpe0, c1 = colGpe1, c2 = colGpet)
#| label: fig-gaussian-ot
#| warning: false
#| message: false
par(mar = c(2.1, 2.1, 0.1, 0.1))
x_lim <- c(-4, 4)
y_lim <- c(-4, 4)

plot(X0, 
     pch = 16, 
     col = adjustcolor(colGpe0, alpha = .3), 
     xlim = x_lim, ylim = y_lim, 
     xlab = "", ylab = "",
     main = "",
     family = font_family
)
title(xlab = "X1", ylab="X2", line=2, cex.lab=1.2, family = font_family)
points(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)
points(X1_t, col = adjustcolor(colGpet, alpha = .3), pch = 17)

# Add arrows from original to transported
arrows(
  x0 = X1$X1, y0 = X1$X2,
  x1 = X1_t[, 1], y1 = X1_t[, 2],
  length = 0.05, col = adjustcolor("gray", alpha = .3)
)

# True mean and covariance (scaled by 'a')
Mu0 <- rep(a * mu0, 2)
Mu1 <- rep(a * mu1, 2)
Sig0 <- matrix(c(1, r0, r0, 1), 2, 2)
Sig1 <- matrix(c(1, r1, r1, 1), 2, 2)

# Covariance of transported points (via OT map)
Sigma1_transport <- ot_map$A %*% Sig1 %*% t(ot_map$A)

# Add ellipses
draw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)
draw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)
draw_ellipse(Mu0, Sigma1_transport, col = colGpet, lty = 2)
```

### Sequential Transport

We will now transport individuals from `r colorize("group 1", colGpe1)` to `r colorize("group 0", colGpe0)` using sequential transport. The results are sensitive to the ordering within the sequence. We will thus consider both ordering here:

- a first marginal univariate optimal transport along the first dimension ($X_1$), then a conditional transport for the second dimension ($X_2 \mid X_1)$: `sequential_transport_12()`{.R},
- a first marginal univariate optimal transport along the second dimension ($X_2$), then a conditional transport for the first dimension ($X_1 \mid X_2)$: `sequential_transport_21()`{.R},


```{r define-sequential_transport_12}
#| code-fold: true
#| code-summary: The `sequential_transport_12()`{.R} function.
#' Sequential transport from N(M_source, S_source) to N(M_target, S_target),
#' along X1, then X2 | X1
#'
#' @param X n x 2 matrix of source observations.
#' @param M_source Mean vector of the source distribution (length 2).
#' @param S_source Covariance matrix of the source distribution (2x2).
#' @param M_target Mean vector of the target distribution.
#' @param S_target Covariance matrix of the target distribution.
sequential_transport_12 <- function(X, 
                                    M_source, 
                                    S_source, 
                                    M_target, 
                                    S_target) {
  
  # marginal univariate transport along the first coordinate (X_1)
  T1x <- qnorm(
    pnorm(X[, 1], mean = M_source[1], sd = sqrt(S_source[1, 1])),
    mean = M_target[1], sd = sqrt(S_target[1, 1])
  )
  
  # conditional parameters for X_2 | X_1
  m_source <- M_source[2] + S_source[1, 2] / S_source[1, 1] * (X[, 1] - M_source[1])
  s_source <- S_source[2, 2] - S_source[1, 2]^2 / S_source[1, 1]
  
  m_target <- M_target[2] + S_target[1, 2] / S_target[1, 1] * (T1x - M_target[1])
  s_target <- S_target[2, 2] - S_target[1, 2]^2 / S_target[1, 1]
  
  # conditional transport for the second coordinate
  T2x <- qnorm(
    pnorm(X[, 2], mean = m_source, sd = sqrt(s_source)),
    mean = m_target, sd = sqrt(s_target)
  )
  
  cbind(T1x, T2x)
}
```


```{r define-sequential_transport_21}
#| code-fold: true
#| code-summary: The `sequential_transport_21()`{.R} function.
#' Sequential transport from N(M_source, S_source) to N(M_target, S_target),
#' along X2, then X1 | X2
#'
#' @param X n x 2 matrix of source observations.
#' @param M_source Mean vector of the source distribution (length 2).
#' @param S_source Covariance matrix of the source distribution (2x2).
#' @param M_target Mean vector of the target distribution.
#' @param S_target Covariance matrix of the target distribution.
sequential_transport_21 <- function(X, M_source, S_source, M_target, S_target) {
  
  # marginal univariate transport along X_2
  T2x <- qnorm(
    pnorm(X[, 2], mean = M_source[2], sd = sqrt(S_source[2, 2])),
    mean = M_target[2], sd = sqrt(S_target[2, 2])
  )
  
  # conditional parameters for X_1 | X_2
  m_source <- M_source[1] + S_source[1, 2] / S_source[2, 2] * (X[, 2] - M_source[2])
  s_source <- S_source[1, 1] - S_source[1, 2]^2 / S_source[2, 2]
  
  m_target <- M_target[1] + S_target[1, 2] / S_target[2, 2] * (T2x - M_target[2])
  s_target <- S_target[1, 1] - S_target[1, 2]^2 / S_target[2, 2]
  
  # conditional transport for X1 | X_2
  T1x <- qnorm(
    pnorm(X[, 1], mean = m_source, sd = sqrt(s_source)),
    mean = m_target, sd = sqrt(s_target)
  )
  
  cbind(T1x, T2x)
}
```


We isolate the observations from `r colorize("group 0", colGpe0)` and from `r colorize("group 1", colGpe1)`, and store them as matrices.
```{r define-X0-mat}
X0 <- as.matrix(df[df$A == 0, c("X1", "X2")])
X1 <- as.matrix(df[df$A == 1, c("X1", "X2")])
```


We then transport from `r colorize("group 1", colGpe1)` to group `r colorize("group 0", colGpe0)` with sequential transport, first transporting $X_1$ then $X_2 | X_1$.


```{r define-X1_st_12}
X1_st_12 <- sequential_transport_12(
  X = X1, M_source = Mu1, S_source = Sig1, M_target = Mu0, S_target = Sig0
)
```

:::{.callout-warning}

Since we want to build counterfactuals for individuals from `r colorize("group 1", colGpe1)` (A=1), the source distribution is indeed that of the units in `r colorize("group 1", colGpe1)` and the target distribution in that of the units in  `r colorize("group 0", colGpe0)`.

:::


We also transport from `r colorize("group 1", colGpe1)` to group `r colorize("group 0", colGpe0)` with sequential transport, first transporting $X_0$ then $X_1 | X_2$.

```{r define-X1_st_21}
X1_st_21 <- sequential_transport_21(
  X = X1, M_source = Mu1, S_source = Sig1, M_target = Mu0, S_target = Sig0
)
```

Again, we can visualize the results on a scatter plot (@fig-gaussian-seq-ot-x1-x2).

```{r}
#| code-fold: true
#| code-summary: Codes to create the Figure.
#| fig-cap: !expr glue::glue("500 points in each group drawn from bivariates Gaussian distributions and <span style='color:{c2};'>transported values</span> from <span style='color:{c1};'>group 1</span> to <span style='color:{c0};'>group 0</span>, using sequential optimal transport, first transporting $X_1$, then $X_2 \\mid X_1$.", c0 = colGpe0, c1 = colGpe1, c2 = colGpet)
#| label: fig-gaussian-seq-ot-x1-x2
#| warning: false
#| message: false
# Prepare data for the plot
X0 <- df[df$A == 0, c("X1", "X2")]
X1 <- df[df$A == 1, c("X1", "X2")]

par(mar = c(2.1, 2.1, 1.8, 0.1), mfrow = c(1,2))
x_lim <- c(-4, 4)
y_lim <- c(-4, 4)

# X1 then X2
plot(
  X0, 
  pch = 16, 
  col = adjustcolor(colGpe0, alpha = .3), 
  xlim = x_lim, ylim = y_lim, 
  xlab = "", ylab = "",
  main = "",
  family = font_family
)
title(xlab = "X1", ylab="X2", line=2, cex.lab=1.2, family = font_family)
title(main = "X1 then X2", line=.5, cex.lab=1.2, family = font_family)
points(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)
points(X1_st_12, col = adjustcolor(colGpet, alpha = .3), pch = 17)

# Add arrows from original to transported
arrows(
  x0 = X1$X1, y0 = X1$X2,
  x1 = X1_st_12[, 1], y1 = X1_st_12[, 2],
  length = 0.05, col = adjustcolor("gray", alpha = .3)
)

# True mean and covariance (scaled by 'a')
Mu0 <- rep(a * mu0, 2)
Mu1 <- rep(a * mu1, 2)
Sig0 <- matrix(c(1, r0, r0, 1), 2, 2)
Sig1 <- matrix(c(1, r1, r1, 1), 2, 2)

# Add ellipses
draw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)
draw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)

# X2 then X1
plot(
  X0, 
  pch = 16, 
  col = adjustcolor(colGpe0, alpha = .3), 
  xlim = x_lim, ylim = y_lim, 
  xlab = "", ylab = "",
  main = "",
  family = font_family
)
title(xlab = "X1", ylab="X2", line=2, cex.lab=1.2, family = font_family)
title(main = "X2 then X1", line=.5, cex.lab=1.2, family = font_family)
points(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)
points(X1_st_21, col = adjustcolor(colGpet, alpha = .3), pch = 17)

# Add arrows from original to transported
arrows(
  x0 = X1$X1, y0 = X1$X2,
  x1 = X1_st_21[, 1], y1 = X1_st_21[, 2],
  length = 0.05, col = adjustcolor("gray", alpha = .3)
)

# Add ellipses
draw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)
draw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)
```

## Causal Effect

Let us now estimate the ATT with different methods. We first generate (again) some data, using the DGP presented in @sec-dgp.

```{r gen-data-2}
df <- gen_data(
  n = 500, 
  mu0 = -1, mu1 = +1, 
  r0 = +.7, r1 = -.5, a = 1, 
  seed = 12345
)
```


### With the AIPW Estimator


Let us create a dataset, `tb`, with only the binary response (Y), the binary treatment (A), and the two covariates.

```{r}
tb <- df[, c("Y", "A", "X1", "X2")]
A_name <- "A"
A_untreated <- 0
Y_name <- "Y"
```

We will estimate the outcome model with a random forest, and the propensity score with a logistic model. We use 5-fold cross-fitting.

```{r}
#| message: false
#| warning: false
library(randomForest)
```

We define a function, `estim_aipw()`{.R} that train the models, computes the ATT and then returns a list with the estimated ATT and the popensity scores.
```{r define-estim_aipw}
#' @param data Dataset with the units.
#' @param Y_name Name of the column with the outcome variable.
#' @param A_name Name of the column with the treatment variable.
#' @param A_untreated Value of the treatment for the untreated units.
#' @param n_folds Number of folds for cross-fitting.
estim_aipw <- function(data,
                       Y_name,
                       A_name,
                       A_untreated,
                       n_folds = 5,
                       seed = NULL) {
  
  if (!is.null(seed)) set.seed(seed)
  
  tb_untreated <- data |> filter(!!sym(A_name) == !!A_untreated)
  tb_treated <- data |> filter(!!sym(A_name) != !!A_untreated)
  
  n_untreated <- nrow(tb_untreated)
  n_treated <- nrow(tb_treated)
  n <- n_untreated + n_treated
  folds <- sample(rep(1:n_folds, length.out = n))
  
  # Init results
  ## outcomes
  mu_untreated_hat <- rep(NA, n)
  mu_treated_hat <- rep(NA, n)
  ## propensity scores
  e_hat  <- rep(NA, n)
  
  for (k in 1:n_folds) {
    idx_valid <- which(folds == k)
    idx_train <- setdiff(1:n, idx_valid)
    tb_train <- data |> slice(idx_train)
    tb_valid <- data |> slice(-idx_train)
    # Outcome models
    mu_untreated_model <- randomForest(
      x = tb_train |> filter(!!sym(A_name) == !!A_untreated) |> 
        select(-!!Y_name, -!!A_name),
      y = tb_train |> filter(!!sym(A_name) == !!A_untreated) |> pull(!!Y_name)
    )
    mu_treated_model <- randomForest(
      x = tb_train |> 
        filter(!!sym(A_name) != !!A_untreated) |> select(-!!Y_name, -!!A_name),
      y = tb_train |> filter(!!sym(A_name) != !!A_untreated) |> pull(!!Y_name)
    )
    
    mu_untreated_hat[idx_valid] <- predict(
      mu_untreated_model, newdata = tb_valid |> select(-!!Y_name, -!!A_name)
    )
    mu_treated_hat[idx_valid] <- predict(
      mu_treated_model, newdata = tb_valid |> select(-!!Y_name, -!!A_name)
    )
    
    # Propensity model
    ps_model <- glm(
      paste(A_name, " ~ ."), data = tb_train |> select(-!!Y_name),
      family = binomial()
    )
    # Propensity scores
    e_hat[idx_valid] <- predict(
      ps_model, newdata = tb_valid, type = "response"
    )
  }
  
  A <- pull(data, !!A_name)
  Y <- pull(data, !!Y_name)
  # Index of treated
  treated_idx <- which(A != A_untreated)
  
  aipw_terms <- A * (Y - mu_untreated_hat) +
    (1 - A) * (e_hat / (1 - e_hat)) * (Y - mu_untreated_hat)
  ATT_aipw <- sum(aipw_terms[treated_idx]) / sum(A == 1)
  ATT_aipw
  
  list(ATT_aipw = ATT_aipw, e_hat = e_hat)
}
```

We can then apply this function to our simulated dataset.
```{r define-aipw_res}
aipw_res <- estim_aipw(
  data = tb, Y_name = Y_name, A_name = A_name, A_untreated = A_untreated, 
  n_folds = 5, seed = 12345
)
```

Let us extract the ATT and the propensity scores:
```{r define-ATT_aipw}
ATT_aipw <- aipw_res$ATT_aipw
e_hat <- aipw_res$e_hat
ATT_aipw
```


Now that we have estimated the propensity scores for each individual, we can have a look at their distribution.

:::{.panel-tabset}

#### Histogram

The distribution of the propensity scores is shown in @fig-prop-scores-hist

```{r}
#| fig-cap: Distribution of the estimated propensity scores.
#| label: fig-prop-scores-hist
#| code-fold: true
#| code-summary: Codes to create the Figure.
par(mar = c(4.1, 4.1, 1.1, 1.1))
hist(e_hat, xlab = "Propensity scores", main = "", family = font_family)
```


#### Estimated Density

We can also have a look at the density estimated with a Beta kernel (@fig-prop-scores-density).

```{r}
#| fig-cap: Estimated density (beta kernel) of the propensity scores.
#| label: fig-prop-scores-density
#| code-fold: true
#| code-summary: Codes to create the Figure.
library(kdensity)
kprop <- kdensity::kdensity(e_hat, kernel = "beta", bw = .05)
par(mar = c(4.1, 4.1, 1.1, 1.1))
plot(
  kprop, xlab = "Propensity Scores", ylab = "Density", main = "",
  ylim = c(0, 6), lwd = 2, family = font_family
)
```

:::

### With IPW

```{r define-estim_ipw}
estim_ipw <- function(data,
                      Y_name,
                      A_name,
                      A_untreated,
                      n_folds = 5,
                      stabilise = TRUE,
                      seed = NULL) {
  
  if (!is.null(seed)) set.seed(seed)
  
  n <- nrow(data)
  folds <- sample(rep(seq_len(n_folds), length.out = n))
  e_hat <- numeric(n)
  
  variables_baseline <- setdiff(names(data), c(Y_name, A_name))
  form_ps <- reformulate(variables_baseline, response = A_name)
  
  # propensity scores with cross-fitting
  for (k in seq_len(n_folds)) {
    idx_train <- which(folds != k)
    idx_valid <- which(folds == k)
    
    ps_mod <- glm(form_ps, data = data[idx_train, ], family = binomial())
    
    e_hat[idx_valid] <- predict(
      ps_mod, newdata = data[idx_valid, ], type = "response"
    )
  }
  
  # ATT with IPW weights
  A <- data[[A_name]]
  Y <- data[[Y_name]]
  treated <- A != A_untreated
  n_treated <- sum(treated)
  pi_hat <- mean(treated)
  
  w <- ifelse(
    treated,
    1,
    e_hat / (1 - e_hat) / if (stabilise) pi_hat else 1
  )
  
  ATT_ipw <- mean(Y[treated]) -
    weighted.mean(Y[!treated], w[!treated])
  
  list(
    ATT_ipw = ATT_ipw,
    e_hat = e_hat,
    w  = w
  )
}
```

Without the mediators

```{r define-ipw_out}
ipw_out <- estim_ipw(
  data = tb[, c(A_name, Y_name)],
  Y_name = Y_name,
  A_name = A_name,
  A_untreated = A_untreated,
  n_folds = 5,
  stabilise = TRUE,
  seed = 12345
)
```

```{r}
(ATT_ipw <- ipw_out$ATT_ipw)
```



### With Optimal Transport

We define a function, `att_counterfactuals()`{.R} to compute the causal effect of $A$ on the outcome $Y$, for the treated individuals.

```{r define-att_counterfactuals}
#' Average treatment on the treated using counterfactuals.
#' 
#' @param data_untreated Dataset with the untreated units only.
#' @param data_treated Dataset with the treated units only.
#' @param data_cf Counterfactuals (treated had they been untreated).
#' @param Y_name Name of the column with the outcome variable.
#' @param A_name Name of the column with the treatment variable.
#' @param A_untreated Value of the treatment for the untreated units.
att_counterfactuals <- function(data_untreated,
                                data_treated,
                                data_cf,
                                Y_name,
                                A_name,
                                A_untreated) {
  
  n_untreated <- nrow(data_untreated)
  n_treated <- nrow(data_treated)
  
  mu_untreated_model <- randomForest(
    x = data_untreated |> select(-!!Y_name, -!!A_name),
    y = pull(data_untreated, !!Y_name)
  )
  
  # Predictions on transported individuals
  pred_treated_t <- predict(mu_untreated_model, newdata = data_cf)
  # Observed outcome for treated
  Y_treated_obs <- data_treated |> pull(!!Y_name)
  
  # ATT with the counterfactuals
  mean(Y_treated_obs - pred_treated_t)
}
```

We apply this function to our simulated dataset.

```{r}
tb_untreated <- tb |> filter(!!sym(A_name) == !!A_untreated)
tb_treated <- tb |> filter(!!sym(A_name) != !!A_untreated)

ATT_ot <- att_counterfactuals(
  data_untreated = tb_untreated, 
  data_treated = tb_treated,
  data_cf = as_tibble(X1_t), Y_name = Y_name, A_name = A_name, A_untreated = A_untreated
)
ATT_ot
```


### With Sequential Optimal Transport

We apply the same function as that used with the counterfactuals obtained with optimal transport (`att_counterfactuals()`{.R}). However, here, we feed it with the counterfactuals obtained with sequential transport. For those where we first transport $X_1$ and then $X_2 \mid X_1$:
```{r define-ATT_sot_12}
ATT_sot_12 <- att_counterfactuals(
  data_untreated = tb_untreated, 
  data_treated = tb_treated,
  data_cf = as_tibble(X1_st_12) |> magrittr::set_colnames(c("X1", "X2")),
  Y_name = Y_name, A_name = A_name, A_untreated = A_untreated
)
```

And for the counterfactuales obtained by sequential transport where we first transport $X_2$ and then $X_1 \mid X_2$:
```{r define-ATT_sot_21}
ATT_sot_21 <- att_counterfactuals(
  data_untreated = tb_untreated, 
  data_treated = tb_treated,
  data_cf = as_tibble(X1_st_21) |> magrittr::set_colnames(c("X1", "X2")),
  Y_name = Y_name, A_name = A_name, A_untreated = A_untreated
)
```

### With Causal Mediation Analysis

```{r library-mediation}
#| message: false
#| warning: false
library(mediation)
```


```{r define-med_mod}
med_mod <- multimed(
  outcome = "Y", 
  med.main = "X1", 
  med.alt = "X2", 
  treat = "A", 
  data = df
)
```


```{r}
# lower bounds on the average causal mediation effects under treatment
# med_mod$d1.lb
# lower bounds on the average causal mediation effects under treatment
# med_mod$d1.ub
# average causal mediation effects under treatment
acme_t <- mean((med_mod$d1.lb + med_mod$d1.ub) / 2)
# lower bounds on the average direct effects under treatment
ade_t <- mean((med_mod$z1.lb + med_mod$z1.ub) / 2)
(tot_effect_t <- acme_t + ade_t)
```



### Summary

```{r}
cbind(
  ATT_aipw = ATT_aipw,
  ATT_ipw = ATT_ipw,
  ATT_ot = ATT_ot,
  ATT_sot_12 = ATT_sot_12,
  ATT_sot_21 = ATT_sot_21,
  tot_effect_t = tot_effect_t
)
```


## Decreasing Overlapping

Let us now run some simulations in which we make the distance between the two means of the covariates vary. Until now, this distance was $2$, since $\mu_0$ was set to $-1$ and $\mu_1$ was set to 1. Now, we randomly draw a shift value $\alpha\sim\mathcal{U}(0,2)$ and set the means as $\mu_0 = \alpha \times (-1)$ and $\mu_1 = \alpha \times (+1)$. The distance between the means of the two covariates now becomes equal to $2$. All the other parameters of the DGP (see @sec-dgp) remain unchanged.

To run the simulations, we create a wrapper function, `simu()`{.R}, that first generates 500 observations in each group, then proceeds to compute the ATT using the AIPW estimator (@eq-aipw)?

```{r}
#| code-fold: true
#| code-summary: The function for the Monte-Carlo simulation.
simu <- function(seed) {
  
  set.seed(seed)
  n <- 500
  a <- runif(1, min = 0, max = 2)
  
  df <- gen_data(
    n = n, 
    mu0 = -1, mu1 = +1, 
    r0 = +.7, r1 = -.5, a = a, seed = seed
  )
  
  tb <- df[, c("Y", "A", "X1", "X2")]
  
  tb

  A_name <- "A"
  A_0 <- 0
  Y_name <- "Y"
  
  n_folds <- 5 # 5-fold cross-fitting
  folds <- sample(rep(1:n_folds, length.out = n))
  # Init results
  ## outcomes
  mu0_hat <- rep(NA, n)
  mu1_hat <- rep(NA, n)
  ## propensity scores
  e_hat  <- rep(NA, n)
  
  for (k in 1:n_folds) {
    idx_valid <- which(folds == k)
    idx_train <- setdiff(1:n, idx_valid)
    tb_train <- tb |> slice(idx_train)
    tb_valid <- tb |> slice(-idx_train)
    # Outcome models
    mu0_model <- randomForest(
      x = tb_train |> filter(!!sym(A_name) == !!A_0) |>
        select(-!!Y_name, -!!A_name),
      y = tb_train |> filter(!!sym(A_name) == !!A_0) |>
        pull(!!Y_name)
    )
    mu1_model <- randomForest(
      x = tb_train |>
        filter(!!sym(A_name) != !!A_0) |> select(-!!Y_name, -!!A_name),
      y = tb_train |> filter(!!sym(A_name) != !!A_0) |>
        pull(!!Y_name)
    )
    
    mu0_hat[idx_valid] <- predict(
      mu0_model, newdata = tb_valid |> select(-!!Y_name, -!!A_name)
    ) |> as.character() |> as.numeric()
    mu1_hat[idx_valid] <- predict(
      mu1_model, newdata = tb_valid |> select(-!!Y_name, -!!A_name)
    ) |> as.character() |> as.numeric()
    
    # Propensity model
    ps_model <- glm(
      formula(paste0(A_name, "~.")), data = tb_train |> select(-!!Y_name),
      family = binomial()
    )
    # Propensity scores
    e_hat[idx_valid] <- predict(
      ps_model, newdata = tb_valid, type = "response"
    )
    
  }
  
  A <- pull(tb, !!A_name)
  Y <- pull(tb, !!Y_name)
  treated_idx <- which(A != A_0)
  
  aipw_terms <- A * (Y - mu0_hat) +
    (1 - A) * (e_hat / (1 - e_hat)) * (Y - mu0_hat)
  ATT_aipw <- sum(aipw_terms[treated_idx]) / sum(A == 1)
  
  tibble(
    a = a, 
    ATT_aipw = ATT_aipw, 
    prob_1_99 = mean((e_hat > .01) & (e_hat < .99))
  )
}
```

```{r run-simul-mc, eval=FALSE}
# The estimation takes about 4 minutes.
# Previously obtained results are loaded here (this chunk is not estimated).
library(pbapply)
library(parallel)
ncl <- detectCores()-1
(cl <- makeCluster(ncl))

clusterEvalQ(cl, {
  library(tidyverse)
  library(randomForest)
  library(mnormt)
}) |>
  invisible()
  
clusterExport(cl, "gen_data")

res_sim <- pbapply::pblapply(1:2000, simu, cl = cl)
stopCluster(cl)

res_sim_tb <- list_rbind(res_sim)

save(res_sim_tb, file = "../output/res_sim_tb.rda")
```
We load the previously obtained results:
```{r load-res_sim_tb}
load("../output/res_sim_tb.rda")
```

The results of the simulations are shown in @fig-gauss-ex-prop-1-99-alpha. Each dot represents a single replication. The left panel displays the probability that the estimated propensity scores lie within the interval $[1\%, 99\%]$, as a function of $\alpha$ (recall that the distance between the two covariates mean is $2\alpha$). The orange curve is a spline showing the overall trend. The right panel shows the estimated Average Treatment Effect on the Treated using the AIPW estimator. The central orange line corresponds to a spline fit of the point estimates, while the lower and upper orange curves represent the 10th and 90th quantiles, respectively.

```{r}
#| code-fold: true
#| code-summary: Codes to create the Figure.
#| message: false
#| warning: false
#| fig-cap: Proportion of observation with a propensity score in $[1\%,99\%]$ (left) as a function of $\alpha \in[0,2]$ ; estimation of the ATT (right), based on the AIPW estimator. Simulated toy example ($n=500$), 2,000 Monte-Carlo replications.
#| label: fig-gauss-ex-prop-1-99-alpha
#| fig-height: 2.3
#| fig-width: 4.6

library(splines)
par(mar = c(3.1, 3.1, 1.1, 1.1), mfrow = c(1, 2))

plot(
  res_sim_tb$a, res_sim_tb$prob_1_99,
  cex = .3,
  xlab = "",
  ylab = "",
  pch = 19,
  col = scales::alpha("#009E73", .1),
  family = font_family
)
title(
  xlab = latex2exp::TeX("Dist. btw. means ($\\alpha \\times 2$)"),
  # ylab = "Prob. prop. score in [1%,99%]",
  ylab = latex2exp::TeX("$1\\%<P[\\hat{e}(X)]<99\\%$"),
  line = 2, family = font_family
)

# The proportions of propensity scores within [1%,99%] for each replication
# and the drawn value for a
tb_plot <- data.frame(x = res_sim_tb$a, y = res_sim_tb$prob_1_99)
rqxbar <- lm(y ~ bs(x, 8), data = tb_plot)
vu <- (0:40) / 20
yxbar <- predict(rqxbar, newdata = data.frame(x = vu))
lines(vu, yxbar, lwd = 2,col = "#D55E00")


plot(
  res_sim_tb$a, res_sim_tb$ATT_aipw,
  cex = .3,
  xlab = "",
  ylab = "",
  pch = 19,
  col = scales::alpha("#009E73", .1),
  family = font_family
)
title(
  xlab = latex2exp::TeX("Dist. btw. means ($\\alpha \\times 2$)"), 
  # ylab = "Estimated ATT, AIPW", 
  ylab = latex2exp::TeX("$\\widehat{ATT}^{AIPW}$"),
  line = 2, family = font_family
)

# The AIPW for each replication, and the drawn value of the shift
tb_aipw_a <- tibble(x = res_sim_tb$a, y = res_sim_tb$ATT_aipw)
# Quantile regressions at two levels: .9 and .1
library(quantreg)
library(splines)
rq9 <- rq(y ~ bs(x), data = tb_aipw_a, tau = .9)
rq1 <- rq(y ~ bs(x), data = tb_aipw_a, tau = .1)
rqxbar <- lm(y ~ bs(x), data = tb_aipw_a)
vu <- (0:40) / 20
y1 <- predict(rq1, newdata = data.frame(x = vu))
y9 <- predict(rq9, newdata = data.frame(x = vu))
yxbar <- predict(rqxbar, newdata = data.frame(x = vu))
lines(vu, yxbar, lwd = 2, col = "#D55E00") # splines
lines(vu, y1, lwd = 1, col = "#D55E00") # QR (tau=.1)
lines(vu, y9, lwd = 1, col = "#D55E00") # QR (tau=.0)
abline(h = 3, col = "black")

p <- recordPlot()
pdf(paste0(path, "gauss-ex-prop-1-99-alpha.pdf"), width = 4.6, height = 4.6/2)
replayPlot(p)
dev.off()
```



