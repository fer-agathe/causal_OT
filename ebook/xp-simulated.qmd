# Simulated Data


:::{.callout-note}

## Objectives

In this page, xxx

:::

```{r package-settings}
#| warning: false
#| message: false
library(tidyverse)
# remotes::install_github(
#   repo = "fer-agathe/sequential_transport", subdir = "seqtransfairness"
# )
library(seqtransfairness)
# remotes::install_github(repo = "fer-agathe/transport-simplex")
library(transportsimplex)
library(randomForest)
library(grf)
library(cluster)

# Also required:
# install.packages(mlr3fairness)
```

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| file: _myfunctions.R
```

$$
\definecolor{wongBlack}{RGB}{0,0,0}
\definecolor{wongGold}{RGB}{230, 159, 0}
\definecolor{wongLightBlue}{RGB}{86, 180, 233}
\definecolor{wongGreen}{RGB}{0, 158, 115}
\definecolor{wongYellow}{RGB}{240, 228, 66}
\definecolor{wongBlue}{RGB}{0, 114, 178}
\definecolor{wongOrange}{RGB}{213, 94, 0}
\definecolor{wongPurple}{RGB}{204, 121, 167}
\definecolor{colA}{RGB}{255, 221, 85}
\definecolor{colB}{RGB}{148, 78, 223}
\definecolor{colC}{RGB}{63, 179, 178}
\definecolor{colGpeZero}{RGB}{127, 23, 14}
\definecolor{colGpeUn}{RGB}{27, 149, 224}
$$

```{r graphs-settings}
#| code-fold: true
#| code-summary: Codes for graphical parameters.
library(extrafont, quietly = TRUE)
font_family <- "CMU Serif"

path <- "./figs/"
if (!dir.exists(path)) dir.create(path)
```

We load the functions that will allow us to build the counterfactuals (see [Chapter -@sec-functions]), and some graphical themes for the plots (see [Chapter -@sec-utils):
```{r source-functions}
source("../scripts/functions.R")
source("../scripts/utils.R")
```

## Data Generating Process {#sec-dgp}

We simulate a dataset comprising a binary treatment indicator $A \in \{0,1\}$, a binary outcome $Y \in \{0,1\}$, and three covariates: two continuous variables $X_1, X_2 \in \mathbb{R}$ and one categorical variable $X_3 \in \{\text{A}, \text{B}, \text{C}\}$. For individuals with $A = 0$, the vector $(X_1, X_2)$ is drawn from a bivariate normal distribution with mean vector $\mu_0 = (-1, -1)$ and covariance matrix $\Sigma_0 = 1.2^2 \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}$. For those with $A = 1$, the distribution shifts to mean $\mu_1 = (1.5, 1.5)$ and covariance $\Sigma_1 = 0.9^2 \begin{bmatrix} 1 & -0.4 \\ -0.4 & 1 \end{bmatrix}$. This leads to distinct location and dependence structures across treatment groups.

The categorical variable $X_3$ is generated conditionally on $X_1, X_2$, and $A$ via a multinomial logistic model. Letting $p_{\text{A}}, p_{\text{B}}, p_{\text{C}}$ denote the unnormalized logit scores for each level of $X_3$, we set:

$$
\begin{aligned}
p_{\text{A}} &= 0.5 + 0.3 X_1 - 0.4 X_2 + 0.2 A, \\
p_{\text{B}} &= -0.3 + 0.5 X_2 - 0.2 X_1 - 0.1 A, \\
p_{\text{C}} &= 0,
\end{aligned}
$$

with the associated probabilities obtained via softmax normalization:

$$
P(X_3 = k) = \frac{\exp(p_k)}{\exp(p_{\text{A}}) + \exp(p_{\text{B}}) + \exp(p_{\text{C}})}, \quad \text{for } k \in \{\text{A}, \text{B}, \text{C}\}.
$$

The binary outcome $Y$ is modeled using a logistic regression, with functional forms differing across treatment groups. For $A = 0$, the log-odds is defined as:

$$
\eta_0 = -0.2 + 0.6 X_1 - 0.6 X_2 + \gamma(X_3),
$$

and for $A = 1$:

$$
\eta_1 = 0.1 - 0.2 X_1 + 0.8 X_2 + \gamma(X_3),
$$

where the contribution of $X_3$ is encoded as:

$$
\gamma(X_3) =
\begin{cases}
0.2 & \text{if } X_3 = \text{B}, \\
-0.3 & \text{if } X_3 = \text{C}, \\
0 & \text{if } X_3 = \text{A},
\end{cases}
\quad \text{(for } A = 0\text{)},
$$

and similarly, for $A = 1$:

$$
\gamma(X_3) =
\begin{cases}
-0.2 & \text{if } X_3 = \text{B}, \\
-0.1 & \text{if } X_3 = \text{C}, \\
0 & \text{if } X_3 = \text{A}.
\end{cases}
$$

The outcome $Y$ is then drawn from a Bernoulli distribution with success probability $P[Y = 1] = \mathrm{logit}^{-1}(\eta_A)$.

For each observation, we additionally simulate a counterfactual covariate vector and outcome under the opposite treatment status. This includes drawing $(X_1^{\text{cf}}, X_2^{\text{cf}})$ from the treatment-specific bivariate normal distribution of the opposite group, computing the corresponding $X_3^{\text{cf}}$ using the same multinomial model (with $A$ flipped), and evaluating $Y^{\text{cf}}$ via the appropriate counterfactual logit model.

We draw $n_0=200$ observations in group 0 and $n_1=400$ observations in group 1. We generate a function, `gen_data()`{.R} to generate data from this data generating process.

```{r define-gen_data}
#| code-fold: true
#| code-summary: The `gen_data()`{.R} function.
gen_data <- function(seed) {
  set.seed(seed)
  n_0 <- 200
  n_1 <- 400
  
  # X1 and X2 in both groups from sensitive-specific multivariate normal 
  # distributions
  M_0 <- c(-1, -1)
  S_0 <- matrix(c(1, .5, .5, 1) * 1.2^2, 2, 2)
  M_1 <- c(1.5, 1.5)
  S_1 <- matrix(c(1, -.4, -.4, 1) * 0.9^2, 2, 2)
  X_0 <- MASS::mvrnorm(n = n_0, mu = M_0, Sigma = S_0)
  X_1 <- MASS::mvrnorm(n = n_1, mu = M_1, Sigma = S_1)
  
  # Counterfactuals
  X_0_cf <- MASS::mvrnorm(n = n_0, mu = M_1, Sigma = S_1)
  X_1_cf <- MASS::mvrnorm(n = n_1, mu = M_0, Sigma = S_0)
  
  # X3: categorical, depends on S, X1, X3
  scores <- function(x1, x2, a) {
    p_A <- 0.5 + 0.3 * x1 - 0.4 * x2 + 0.2 * a
    p_B <- -0.3 + 0.5 * x2 - 0.2*x1 - 0.1 * a
    p_C <- 0
    exps <- exp(cbind(p_A, p_B, p_C))
    prob <- exps / rowSums(exps)
    prob
  }
  
  prob_X3_0 <- scores(x1 = X_0[, 1], x2 = X_0[, 2], a = 0)
  prob_X3_1 <- scores(x1 = X_1[, 1], x2 = X_1[, 2], a = 1)
  X3_0 <- apply(prob_X3_0, 1, function(p) sample(c("A", "B", "C"), 1, prob = p))
  X3_1 <- apply(prob_X3_1, 1, function(p) sample(c("A", "B", "C"), 1, prob = p))
  
  # Counterfactuals
  prob_X3_0_cf <- scores(x1 = X_0_cf[, 1], x2 = X_0_cf[, 2], a = 1)
  prob_X3_1_cf <- scores(x1 = X_1_cf[, 1], x2 = X_1_cf[, 2], a = 0)
  X3_0_cf <- apply(prob_X3_0_cf, 1, function(p) sample(c("A", "B", "C"), 1, prob = p))
  X3_1_cf <- apply(prob_X3_1_cf, 1, function(p) sample(c("A", "B", "C"), 1, prob = p))
  
  
  # Predictor for Y:
  eta_0 <- -0.2 + 0.6 * X_0[, 1] - 0.6 * X_0[, 2] + 
    ifelse(X3_0 == "B", 0.2, ifelse(X3_0 == "C", -0.3, 0))
  eta_1 <- 0.1 - 0.2 * X_1[, 1] + 0.8 * X_1[, 2] + 
    ifelse(X3_1 == "B", -0.2, ifelse(X3_1 == "C", -0.1, 0))
  
  p_0 <- exp(eta_0) / (1 + exp(eta_0))
  p_1 <- exp(eta_1) / (1 + exp(eta_1))
  
  # Predictor for Y, counterfactuals
  eta_0_cf <- 0.1 - 0.2 * X_0_cf[, 1] + 0.8 * X_0_cf[, 2] + 
    ifelse(X3_0_cf == "B", -0.2, ifelse(X3_0_cf == "C", -0.1, 0))
  
  eta_1_cf <- -0.2 + 0.6 * X_1_cf[, 1] - 0.6 * X_1_cf[, 2] + 
    ifelse(X3_1_cf == "B", 0.2, ifelse(X3_1_cf == "C", -0.3, 0))
  
  p_0_cf <- exp(eta_0_cf) / (1 + exp(eta_0_cf))
  p_1_cf <- exp(eta_1_cf) / (1 + exp(eta_1_cf))
  
  
  Y_0 <- rbinom(n_0, size = 1, prob = p_0)
  Y_1 <- rbinom(n_1, size = 1, prob = p_1)
  
  Y_0_cf <- rbinom(n_0, size = 1, prob = p_0_cf)
  Y_1_cf <- rbinom(n_1, size = 1, prob = p_1_cf)
  
  # Dataset with individuals in group 0 only
  data_0 <- tibble(
    A = 0, 
    X1 = X_0[, 1], X2 = X_0[, 2], X3 = X3_0, Y = Y_0,
    X1_cf = X_0_cf[, 1], X2_cf = X_0_cf[, 2], X3_cf = X3_0_cf, Y_cf = Y_0_cf,
    eta = eta_0, p = p_0,
    eta_cf = eta_0_cf, p_cf = p_0_cf
  ) |> 
    bind_cols(as_tibble(prob_X3_0) |> rename_with(~ str_c("X3_", .))) |> 
    bind_cols(as_tibble(prob_X3_0_cf) |> rename_with(~ str_c("X3_cf_", .)))
  # Dataset with individuals in group 1 only
  data_1 <- tibble(
    A = 1, 
    X1 = X_1[, 1], X2 = X_1[, 2], X3 = X3_1, Y = Y_1,
    X1_cf = X_1_cf[, 1], X2_cf = X_1_cf[, 2], X3_cf = X3_1_cf, Y_cf = Y_1_cf,
    eta = eta_1,  p = p_1,
    eta_cf = eta_1_cf, p_cf = p_1_cf
  ) |> 
    bind_cols(as_tibble(prob_X3_1) |> rename_with(~ str_c("X3_", .))) |> 
    bind_cols(as_tibble(prob_X3_1_cf) |> rename_with(~ str_c("X3_cf_", .)))
  # # Combine final dataset
  data_all <- rbind(data_0, data_1)
  
  data_all
}
```

Let us generate a dataset:
```{r define-tb <- gen_data(2)}
tb <- gen_data(2) |> 
  mutate(across(is.character, ~as.factor(.x)))
```


```{r}
#| code-fold: true
#| code-summary: Codes to create the Figure
#| fig-cap: !expr glue::glue("Distribution of the true probability of the outcome across groups for the <span style='color:{c0};'>untreated</span> and the <span style='color:{c1};'>treated</span>, for observed values (left) and unobserved values (right).", c0 = colours[["0"]], c1 = colours[["1"]])

#| label: fig-dist-true-prob
#| message: false
#| warning: false
ggplot(
  data = tb |> mutate(A = factor(A)) |> select(A, p, p_cf) |> 
    pivot_longer(cols = c(p, p_cf), names_to = "type", values_to = "p") |> 
    mutate(
      type = factor(type, levels = c("p", "p_cf"), labels = c("Obs.", "Counterfactual")
      )
    ),
  mapping = aes(x = p)
) +
  geom_histogram(
    mapping = aes(fill = A), alpha = .5, colour = "black",
    position = "identity", bins = 30
  ) +
  facet_wrap(~type) +
  scale_fill_manual(values = c("0" = colours[["0"]], "1" = colours[["1"]])) +
  theme_paper()
```

## Counterfactuals

We assume a structural model as shown in @fig-dag.

```{r}
#| fig-cap: Asumed Causal Structure
#| label: fig-dag
variables <- c("A", "X1", "X2", "X3", "Y")

adj <- matrix(
  # A  X1 X2 X3 Y
  c(0, 1, 1, 1, 1,# A
    0, 0, 1, 1, 1,# X1
    0, 0, 0, 1, 1,# X2
    0, 0, 0, 0, 1,# X3
    0, 0, 0, 0, 0  # Y
  ),
  ncol = length(variables),
  dimnames = rep(list(variables), 2),
  byrow = TRUE
)

causal_graph <- fairadapt::graphModel(adj)
plot(causal_graph)
```



Let us follow this DAGand build the counterfactuals of `colorize("treated", colours[1])`: we thus transport individuals from $A=1$ to $A=0$. Let us set a seed for reproducibility.

```{r}
seed <- 1234
set.seed(seed)
```

We call the  `seq_trans()`{.R} function (see [Chapter -@sec-functions]) function to build the counterfactuals of untreated individuals. The estimations are done using parallel computation.

```{r}
A_name <- "A" # treatment name
Y_name <- "Y" # outcome name
A_untreated <- 0
```



```{r define-sequential_transport, eval=FALSE}
# The estimation takes about 16 secondes to run.
# We do not run it here, it was previously estimated.
library(pbapply)
library(parallel)
ncl <- detectCores()-1
(cl <- makeCluster(ncl))

clusterEvalQ(cl, {
  library(transportsimplex)
}) |>
  invisible()

sequential_transport <- seq_trans(
  data = tb, 
  adj = adj, 
  s = A_name, 
  S_0 = 1, # source: treated
  y = Y_name, 
  num_neighbors = 50, 
  num_neighbors_q = NULL,
  silent = FALSE,
  cl = cl
)

save(sequential_transport, file = "../output/res_simul-seq-t.rda")

stopCluster(cl)
```

Let us load the results of the estimation:
```{r load-sequential_transport}
load("../output/res_simul-seq-t.rda")
```

## Measuring the Causal Effect

We are interested in measuring the **average treatment effect on the treated** (ATT):
$$
\text{ATT} = \mathbb{E}\bigl[Y(1) - Y(0) \mid A=1\bigr]
$$ {#eq-att}



We will compute the ATT with several methods:

- using conditional optimal transport (@sec-att-cot),
- using the AIPW estimator (@sec-att-aipw),
- using a causal forest (@sec-att-causal-forest).

### True ATT


Since we use simulated data, we can compute the true ATT:
```{r define-ATT_true}
Y_1 <- tb |> filter(!!sym(A_name) != !!A_untreated) |> pull(!!A_name)
Y_1_cf <- tb |> filter(!!sym(A_name) != !!A_untreated) |> pull(Y_cf)

(ATT_true <- mean(Y_1 - Y_1_cf))
```


### ATT with the Conditional Optimal Transport Approach {#sec-att-cot}

For a `colorize("treated", colours[1])` unit $i$, $Y_i(1)$ corresponds to the observed value and $Y_i(0)$ to its counterfactual, i.e. the transported value: $Y_i(0)\mid A=1 = x_{1,i}^\star$.

$$
\widehat{\text{ATT}}^{\text{COT}} = \frac{1}{n_1} \sum_{i:A_i=1}\bigl[ Y_i -  \hat{\mu}_0(x_{1,i}^\star)\bigr],
$$ {#eq-att-cot}
where $\hat{\mu}_0()$ is the predictive outcome model trained on the `colorize("untreated", colours[0])`, i.e., an estimation of $\mu_0(\boldsymbol{X}_i) = \mathbb{E}[Y_i \mid \boldsymbol{X}_i, A_i = 0]$


Let us split the data between `colorize("treated", colours[1])` and `colorize("untreated", colours[0])`
```{r define-tb_untreated}
tb_untreated <- tb |> filter(!!sym(A_name) == !!A_untreated) |> 
  select(all_of(!!colnames(adj))) |> 
mutate(X3 = factor(X3))
tb_treated <- tb |> filter(!!sym(A_name) != !!A_untreated) |> 
  select(all_of(!!colnames(adj)))

n_untreated <- nrow(tb_untreated)
n_treated <- nrow(tb_treated)
```

We train a random forest to predict the outcome $Y$, among the `r colorize("untreated", colours[0])` only: $\hat{\mu}_0()$.

```{r define-mu_untreated_model}
mu_untreated_model <- randomForest(
  x = tb_untreated |> select(-!!Y_name, -!!A_name),
  y = factor(pull(tb_untreated, !!Y_name), levels = c(0,1))
)
```

The transported values for $X_1$, $X_2$, and $X_3$ of all `r colorize("treated", colours[1])` ($A=1$): $x_{1,i}^\star$
```{r define-D_treated_t}
tb_treated_t <- sequential_transport$transported |> 
  as_tibble() |>
  unnest_wider(where(is.list))
```

The prediction of the algorithm on those transported individuals, i.e., $\hat{\mu}_0(x_{1,i}^\star)$
```{r define-pred_treated_t}
pred_treated_t <- predict(mu_untreated_model, newdata = tb_treated_t)
```

We can then compute the ATT (@eq-att-cot).

```{r define-att-cot}
# ATT with the counterfactuals
Y_treated_obs <- tb |> filter(!!sym(A_name) != !!A_untreated) |> pull(!!Y_name)
ATT_cot <- mean(Y_treated_obs - ifelse(pred_treated_t == 0, 0, 1))
ATT_cot
```

### ATT with the AIPW Estimator {#sec-att-aipw}

We use cross-fitting to estimate the average treatment on the `colorize("treated", colours[1])` using the AIPW estimator:
$$
\widehat{\text{ATT}}_{\text{AIPW}} = \frac{1}{n_1} \sum_{i: A_i = 1} \left[ Y_i - \hat{\mu}_0(X_i) \right] + \frac{1}{n_1} \sum_{i: A_i = 0} \frac{\hat{e}(X_i)}{1 - \hat{e}(X_i)} \left[ Y_i - \hat{\mu}_0(X_i) \right]
$$

where $\hat{e}\bigl(\boldsymbol{X}_i\bigr)$ is the estimation of the propensity score $e(X_i) = \mathbb{P}(A_i = 1 \mid \boldsymbol{X}_i)$.

```{r define-e_hat}
#| message: false
#| warning: false
set.seed(seed)
n <- n_untreated + n_treated
n_folds <- 5 # 5-fold cross-fitting
folds <- sample(rep(1:n_folds, length.out = n))
# Init results
## outcomes
mu_untreated_hat <- rep(NA, n)
mu_treated_hat <- rep(NA, n)
## propensity scores
e_hat  <- rep(NA, n)

for (k in 1:n_folds) {
  idx_valid <- which(folds == k)
  idx_train <- setdiff(1:n, idx_valid)
  tb_train <- tb |> slice(idx_train)
  tb_valid <- tb |> slice(-idx_train)
  # Outcome models
  mu_untreated_model <- randomForest(
    x = tb_train |> filter(!!sym(A_name) == !!A_untreated) |> 
      select(-!!Y_name, -!!A_name),
    y = tb_train |> filter(!!sym(A_name) == !!A_untreated) |> 
      pull(!!Y_name) |> factor(levels = c(0, 1))
  )
  mu_treated_model <- randomForest(
    x = tb_train |> 
      filter(!!sym(A_name) != !!A_untreated) |> select(-!!Y_name, -!!A_name),
    y = tb_train |> filter(!!sym(A_name) != !!A_untreated) |> 
      pull(!!Y_name) |> factor(levels = c(0, 1))
  )
  
  mu_untreated_hat[idx_valid] <- predict(
    mu_untreated_model, newdata = tb_valid |> select(-!!Y_name, -!!A_name)
  ) |> as.character() |> as.numeric()
  mu_treated_hat[idx_valid] <- predict(
    mu_treated_model, newdata = tb_valid |> select(-!!Y_name, -!!A_name)
  ) |> as.character() |> as.numeric()
  
  # Propensity model
  ps_model <- glm(
    paste(A_name, " ~ ."), data = tb_train |> select(-!!Y_name),
    family = binomial()
  )
  # Propensity scores
  e_hat[idx_valid] <- predict(
    ps_model, newdata = tb_valid, type = "response"
  )
}
```

For convenience, let us extract the treatment and the outcome:
```{r define-treated_idx}
A <- pull(tb, !!A_name)
Y <- pull(tb, !!Y_name)
# Index of treated
treated_idx <- which(A != A_untreated)
```

Lastly, we can compute the ATT with the AIPW estimator:

```{r define-ATT_aipw}
aipw_terms <- A * (Y - mu_untreated_hat) +
  (1 - A) * (e_hat / (1 - e_hat)) * (Y - mu_untreated_hat)
ATT_aipw <- sum(aipw_terms[treated_idx]) / sum(A == 1)
ATT_aipw
```

### ATT with a Causal Forest {#sec-att-causal-forest}

Let us apply a causal forest to estimate the ATT.

First, we need to perform 1-hot encoding for categorical variables to comply with the requirements of the `causal_forest()`{R} from {grf}.
```{r define-X_mat}
# 1-hot-encoding
X_mat <- tb |> select(-!!Y_name, -!!A_name)
X_mat <- model.matrix(~ . - 1, data = X_mat)
```

We train the causal forest:
```{r define)fit_cf}
fit_cf <- causal_forest(
  X = X_mat, 
  Y = Y, 
  W = A
)
```


```{r define-ATT_dml}
# the individual treatment effects
tau_hat <- predict(fit_cf)$predictions
# the ATT
ATT_dml <- mean(tau_hat[treated_idx])
ATT_dlm_se <- sqrt(var(tau_hat[treated_idx]) / n_treated)

# This can also be obtained as follows:
# average_treatment_effect(fit_cf, target.sample = "treated")

# The ATT:
ATT_dml
```

### Summary

```{r show-values}
tibble(
  ATT = ATT_true, ATT_cot = ATT_cot, ATT_aipw = ATT_aipw, ATT_dml = ATT_dml
)
```

# Monte Carlo Experiment

We run Monte-Carlo simulations to reproduce the previous steps. In each of the 200 iteration, we draw some data according to the DGP presented in @sec-dgp. Then, we use the `seq_trans()`{.R} function (see [Chapter -@sec-functions]) to perform sequential conditional transport to transport individuals from the `r colorize("treated group", colours[1])` ($A=1$) to the `r colorize("untreated group", colours[0])` ($A=0$).

```{r, eval=FALSE}
# This chunk is not evaluated.
# Each of the 200 replications takes about 16 seconds to run
library(pbapply)
library(parallel)
ncl <- detectCores()-1
(cl <- makeCluster(ncl))

clusterEvalQ(cl, {
  library(transportsimplex)
}) |>
  invisible()

seeds <- 1:200
res_simul <- vector(mode = "list", length = length(seeds))
res_ATT <- vector(mode = "list", length = length(seeds))


for (i in 1:length(seeds)) {
  cat(paste0("Simulation ", i, "/", length(seeds), "\n"))
  seed <- seeds[i]
  tb_all <- gen_data(seed)
  tb <- tb_all |> select(A, X1, X2, X3, Y) |> 
    mutate(across(is.character, ~as.factor(.x)))
  
  A_name <- "A"
  A_untreated <- 0
  Y_name <- "Y"
  
  sequential_transport <- seq_trans(
    data = tb, 
    adj = adj, 
    s = A_name, 
    S_0 = 1, # source: treated
    y = Y_name, 
    num_neighbors = 50, 
    num_neighbors_q = NULL,
    silent = FALSE,
    cl = cl
  )
  res_simul[[i]] <- sequential_transport
  
  tb_untreated <- tb |> filter(!!sym(A_name) == !!A_untreated)
  tb_treated <- tb |> filter(!!sym(A_name) != !!A_untreated)
  
  n_untreated <- nrow(tb_untreated)
  n_treated <- nrow(tb_treated)
  
  ## Measuring Treatement Effect----
  mu_untreated_model <- randomForest(
    x = tb_untreated |> select(-!!Y_name, -!!A_name),
    y = factor(pull(tb_untreated, !!Y_name), levels = c(0,1))
  )  

  tb_treated_t <- sequential_transport$transported |> 
    as_tibble() |>
    unnest_wider(where(is.list))
  pred_treated_t <- predict(mu_untreated_model, newdata = tb_treated_t)
  
  
  set.seed(seed)
  n <- n_untreated + n_treated
  n_folds <- 5 # 5-fold cross-fitting
  folds <- sample(rep(1:n_folds, length.out = n))
  # Init results
  ## outcomes
  mu_untreated_hat <- rep(NA, n)
  mu_treated_hat <- rep(NA, n)
  ## propensity scores
  e_hat  <- rep(NA, n)
  
  for (k in 1:n_folds) {
    idx_valid <- which(folds == k)
    idx_train <- setdiff(1:n, idx_valid)
    tb_train <- tb |> slice(idx_train)
    tb_valid <- tb |> slice(-idx_train)
    # Outcome models
    mu_untreated_model <- randomForest(
      x = tb_train |> filter(!!sym(A_name) == !!A_untreated) |> 
        select(-!!Y_name, -!!A_name),
      y = tb_train |> filter(!!sym(A_name) == !!A_untreated) |> 
        pull(!!Y_name) |> factor(levels = c(0, 1))
    )
    mu_treated_model <- randomForest(
      x = tb_train |> 
        filter(!!sym(A_name) != !!A_untreated) |> select(-!!Y_name, -!!A_name),
      y = tb_train |> filter(!!sym(A_name) != !!A_untreated) |> 
        pull(!!Y_name) |> factor(levels = c(0, 1))
    )
    mu_untreated_hat[idx_valid] <- predict(
      mu_untreated_model, newdata = tb_valid |> select(-!!Y_name, -!!A_name)
    ) |> as.character() |> as.numeric()
    mu_treated_hat[idx_valid] <- predict(
      mu_treated_model, newdata = tb_valid |> select(-!!Y_name, -!!A_name)
    ) |> as.character() |> as.numeric()
    
    # Propensity model
    ps_model <- glm(
      paste(A_name, " ~ ."), 
      data = tb_train |> select(-!!Y_name),
      family = binomial()
    )
    # Propensity scores
    e_hat[idx_valid] <- predict(
      ps_model, newdata = tb_valid, type = "response"
    )
    
  }
  
  # ATT with AIPW
  A <- pull(tb, !!A_name)
  Y <- pull(tb, !!Y_name)
  treated_idx <- which(A != A_untreated)
  
  aipw_terms <- A * (Y - mu_untreated_hat) +
    (1 - A) * (e_hat / (1 - e_hat)) * (Y - mu_untreated_hat)
  ATT_aipw <- sum(aipw_terms[treated_idx]) / sum(A == 1)
  
  # ATT with DML
  
  # 1-hot-encoding
  X_mat <- tb |> select(-!!Y_name, -!!A_name)
  X_mat <- model.matrix(~ . - 1, data = X_mat)
  
  fit_cf <- causal_forest(
    X = X_mat, 
    Y = Y, 
    W = A
  )
  # CATE: individual treatment effects
  tau_hat <- predict(fit_cf)$predictions
  ATT_dml <- mean(tau_hat[treated_idx])
  ATT_dlm_se <- sqrt(var(tau_hat[treated_idx]) / sum(A == 1))
  # average_treatment_effect(fit_cf, target.sample = "treated")
  Y_1 <- tb |> filter(!!sym(A_name) != !!A_untreated) |> pull(!!Y_name)
  Y_1_cf <- tb_all |> filter(!!sym(A_name) != !!A_untreated) |> pull(Y_cf)
  
  # True ATT
  ATT_true <- mean(Y_1 - Y_1_cf)
  # ATT with the counterfactuals
  ATT_cot <- mean(Y_1 - ifelse(pred_treated_t == 0, 0, 1))
  
  res_ATT[[i]] <- tibble(
      seed = seed, ATT_true = ATT_true, ATT_cot = ATT_cot, 
      ATT_aipw = ATT_aipw, ATT_dml = ATT_dml
  )
}


save(res_ATT, res_simul, file = "../output/res_simul.rda")

stopCluster(cl)
```



We load previously run simulations:
```{r load-res_simul}
load("../output/res_simul.rda")
```


```{r}
#| code-fold: true
#| code-summary: Codes to create the Figure.
#| fig-cap: test
#| label: fig-test1
#| warning: false
#| message: false
library(ggtern)
i <- 2
ggtern(
  data = gen_data(i) |> select(A, X3_p_A,X3_p_B, X3_p_C) |> 
    mutate(A = as.character(A)) |> 
    bind_rows(
      as_tibble(res_simul[[i]]$transported_prob$X3) |> 
        rename_with(.fn = ~str_c("X3_p_", .)) |> 
        mutate(A = "1 to 0")
    ) |> 
    mutate(A = factor(A, levels = c("0", "1", "1 to 0"))),
  mapping = aes(x = X3_p_A, y = X3_p_B, z = X3_p_C)
) +
  geom_point(
    mapping = aes(colour = A), size = .5, alpha = .2
  ) +
  labs(x = "A", y = "B", z = "C") +
  scale_colour_manual(
    values = c("0" = colours[["0"]], "1" = colours[["1"]], "1 to 0" = colours[["B"]])
  ) +
  theme_light(base_size = font_size, base_family = font_family) +
  theme_ggtern_paper() +
  theme(
    legend.title = element_text(size = .8 * font_size),
    legend.text = element_text(size = .8 * font_size),
    tern.axis.vshift = .08,
    tern.axis.arrow.sep = .16,
  ) +
  theme_hidetitles() +
  guides(
    colour = guide_legend(
      override.aes = list(
        size = 1.5,
        alpha = 1
      )
    )
  )
```

```{r define-ATT}
ATT <- list_rbind(res_ATT)
```


```{r, eval=FALSE}
#| code-fold: true
#| code-summary: Codes to create the Figure.
#| fig-cap: test2
#| label: fig-test2
ggplot(
  data = ATT |> pivot_longer(cols = -seed) |> 
    mutate(
      name = factor(
        name,
        levels = c("ATT_true", "ATT_aipw", "ATT_dml", "ATT_cot"),
        labels = c("True", "AIPW", "DML", "COT")
      )
    ),
  mapping = aes(x = value, y = name)
) +
  geom_violin(
    mapping = aes(fill = name), 
    draw_quantiles = c(0.25, 0.5, 0.75)) +
  scale_fill_manual(
    "ATT", 
    values = c(
      "True" = "#E69F00", "AIPW" = "#56B4E9", 
      "DML" = "#D55E00", "COT" = "#009E73"
    )
  ) +
  labs(y = NULL, title = "ATT (simulated data, 50 replications)") +
  theme_paper()
```

