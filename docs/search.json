[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Causal Inference with Counterfactuals and Optimal Transport",
    "section": "",
    "text": "1 Preface\n\n\nThis ebook contains the codes and explanations of codes used to produce the results of our paper titled CaMeLOT, Causal Mediation Leveraging (sequential) Optimal Transport.\nAbstract\n\nEstimating how a treatment works through mediators, while also capturing what it does directly, is central to causal reasoning, yet most mediation estimators average effects over the population and lean on restrictive structural-equation assumptions. We introduce CaMeLOT, a non-parametric framework that marries Causal Mediation analysis with Optimal Transport (OT) to recover natural direct and indirect effects for each individual rather than only on average. Our key idea is to generate counterfactual mediators by transporting every observation along the edges of a known causal Directed acyclic graph (DAG). A sequential transport algorithm handles continuous features, while a Dirichlet-based extension maps categorical mediators on the probability simplex, yielding a deterministic, interpretable coupling between treatment groups. We prove that the resulting effect estimators are consistent. Through experiments on both synthetic Gaussian data and a benchmark dataset, we show that our method accurately estimates individual-level total, direct, and indirect effects. It also recovers average causal effects that are comparable to those obtained using a Linear Structural Equation Model (LSEM) and entropy-regularized OT baselines, without sacrificing scalability.\n\nThe document is made of 5 parts:\n\nIntroduction\nThis part provides some refresher about causal mediation analysis (Chapter 2), gives a few colours and plot theme functions (Chapter 3), and contains the main estimation functions that are used in the subsequent chapter (Chapter 4).\nA Gaussian Example\nSimulations are conducted using Gaussian variables to evaluate the estimation of causal effects in the presence of a mediator. In particular, we compare estimates obtained using the Linear Structural Equation Model (LSEM) approach, implemented in the R package {mediation}, with those derived from counterfactuals constructed via optimal transport techniques (see Chapter 5). Monte Carlo experiments are then performed to assess how these estimates behave under varying data conditions (see Chapter 6).\nCounterfactuals for Categorical Data After a short presentation of the context (Chapter 7), we present different methods to build counterfactuals for a categorical variable: using matching (Chapter 11), using optimal transport on label-encoded variables (Chapter 9), and using optimal transport on the simplex (Chapter 10).\nTransport with Weight In (Chapter Gaussian? Conditional Univariate Transport with Local Weights), we show another method to performe univariate transport in the Gaussian case, using local weights. We illustrate the method with simulated data and compare the results with transported values obtained with sequential transport.\nExperiments We run some experiments on a synthetic dataset in Chapter 13 and on a real-world dataset in Chapter 14 to illustrate the entire method.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "reminders.html",
    "href": "reminders.html",
    "title": "2  Reminders and Definitions",
    "section": "",
    "text": "2.1 Causal Effects\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colA}{RGB}{255, 221, 85}\n\\definecolor{colB}{RGB}{148, 78, 223}\n\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colGpe1}{RGB}{127, 23, 14}\n\\definecolor{colGpe0}{RGB}{27, 149, 224}\n\\]\nWe load some useful functions to export graphs (see Chatper 3).\nLet \\(a\\in\\{0,1\\}\\) be a binary treatment, and \\(y\\in\\mathcal{Y}\\) be an outcome of interest. Assume that the treatment influences the outcome both directly and through an indirect effect, via a set of mediators \\(\\boldsymbol{x}\\in\\mathcal{X}\\).\nLet \\(y(a)\\) denote the potential outcome under treatment \\(a\\) and, following Imai, Keele, and Yamamoto (2010), let \\(\\boldsymbol{x}(a)\\) be the potential values for the mediator under treatment \\(a\\).\nAssume that no variable influences the treatment, making it the root node in the causal structure, as shown in the DAG in Figure 2.1.\nThese counterfactual mediator values allow for the definition of natural direct and indirect effects.\nAs noted by Imai, Keele, and Yamamoto (2010), under treatment status \\(a\\), we only observe \\(\\boldsymbol{x}{(a)}\\) and we never observe \\(\\boldsymbol{x}{(1-a)}\\). Using optimal transport, we will build the unobserved value, the counterfactual.\nAs explained in Robins and Greenland (1992) and further formalized in Pearl (2001), in a randomized experiment where mediators are measured after treatment assignment, the total, direct, and indirect effects are identifiable. More specifically, under well-defined counterfactuals, the unit-level total effect \\(\\tau\\) can be additively decomposed, as illustrated in Figure 2.2, into: \\[\n\\begin{cases}\n    \\delta(a):=\\widehat{\\mu}_a(\\boldsymbol{x}(1))-\\widehat{\\mu}_a(\\boldsymbol{x}(0))\\\\\n    \\zeta(a):=\\widehat{\\mu}_1(\\boldsymbol{x}(a))-\\widehat{\\mu}_0(\\boldsymbol{x}(a))\\\\\n    \\tau:=\\delta(a)+\\zeta(1-a).\n\\end{cases}\n\\]\nCodes to create the Figure.\nlibrary(tikzDevice)\n\nCOLRJ &lt;- c(\"#00A08A\",\"#F2AD00\")\ncolrj &lt;- scales::alpha(COLRJ,.3)\ncolrs &lt;- c(\"red\",\"blue\")\ncolrm &lt;- \"#9986A5\"\n\nexport_tikz &lt;- FALSE\n\n\n\n# Generate data\nn &lt;- 500\nmx0 &lt;- -1\nmx1 &lt;- +1\ns &lt;-  1\nx &lt;- seq(-3, 3, length = 601)\ndx0 &lt;- dnorm(x, mx0, s)\ndx1 &lt;- dnorm(x, mx1, s)\nset.seed(1234)\nx0 &lt;- rnorm(n, mx0, s)\nx1 &lt;- rnorm(n, mx1, s)\nfm0 &lt;- function(x) 3 + x * .7\nfm1 &lt;- function(x) 6 + x * 1.2\ny0 &lt;-  fm0(x0) + rnorm(n) / 2\ny1 &lt;- fm1(x1) + rnorm(n) / 2\n\n# First plot----\n\ncex_pts &lt;- .4\nheight_fig_tkz &lt;- width_fig_tkz &lt;- 2.67\n\nif (export_tikz == TRUE) {\n  par(mar = c(2.1, 0, 0, 0))\n  tikz('figs/gaussian-1-mean.tex', width = width_fig_tkz, height = height_fig_tkz)\n} else {\n  par(mar = c(2.1, 0, 0, 0), mfrow = c(1, 2))\n}\n\n\n# Empty plot\nplot(\n  NA, NA, ylim = c(0, 10),\n  xlab = \"\", ylab = \"\",\n  axes = FALSE, xlim = c(-4, 3)\n)\naxis(1, at = -3:3, labels = FALSE)\n\nif (export_tikz == TRUE) {\n  lab_x = c(\n    \"$\\\\bar{x}_0$\",\n    \"$\\\\bar{x}_1$\"\n  )\n  lab_line_0 &lt;- \"$y = \\\\alpha_0 + \\\\beta_0 x$\"\n  lab_line_1 &lt;- \"$y = \\\\alpha_1 + \\\\beta_1 x$\"\n} else {\n  lab_x &lt;- expression(\n    bar(x)[0], # \\bar{x}_0\n    bar(x)[1]  # \\bar{x}_1\n  )\n  lab_line_0 &lt;- expression(y == alpha[0] + beta[0] * x)\n  lab_line_1 &lt;- expression(y == alpha[1] + beta[1] * x)\n}\naxis(\n  1,\n  at = c(-1, 1),\n  labels = lab_x,\n  tick = TRUE, # still draw the little tick marks\n  line = 0 # on the axis line\n)\n\nif (1 == 0) {\n  # Outcome group 0\n  text(\n    x = 3, y = 4.15,\n    labels = lab_line_0,\n    pos = 2,  \n    cex = 1,\n    col = COLRJ[1]\n  )\n  # Outcome group 1\n  text(\n    x = -3, y = 4.15,\n    labels = lab_line_1,\n    pos = 4,  \n    cex = 1,\n    col = COLRJ[2]\n  )\n}\n# True mean in each group\nabline(v = c(mx0, mx1), lty = 2, lwd = .7)\n\n# Observed points in group 0\npoints(x0, y0, pch = 19, cex = cex_pts, col = colrj[1])\n# True conditional mean in grouo 0\nsegments(-3, fm0(-3), 3, fm0(3), col = COLRJ[1], lwd = 2)\n\n# Observed points in group 1\npoints(x1, y1, pch = 19, cex = cex_pts, col = colrj[2])\n# True conditional mean in grouo 0\nsegments(-3, fm1(-3), 3, fm1(3), col = COLRJ[2], lwd = 2)\n\nsegments(mx0, fm0(mx0), mx1, fm0(mx0))\nsegments(mx0, fm1(mx1), mx1, fm1(mx1))\n# delta(0)\nsegments(mx1, fm0(mx1), mx1, fm0(mx0), col = \"red\", lwd = 2)\n# zeta(1)\nsegments(mx1, fm1(mx1), mx1, fm0(mx1), col = \"blue\", lwd = 2)\n# delta(1)\nsegments(mx0, fm0(mx0), mx0, fm1(mx0), col = \"blue\", lwd = 2)\n# zeta(0)\nsegments(mx0, fm1(mx0), mx0, fm1(mx1), col = \"red\", lwd = 2)\n\npoints(mx0, fm0(mx0), pch = 19) # \\hat{\\mu}_0(\\bar{x}_0)\npoints(mx1, fm1(mx1), pch = 19) # \\hat{\\mu}_1(\\bar{x}_1)\npoints(mx1, fm0(mx1), pch = 19) # \\hat{\\mu}_0(\\bar{x}_1)\npoints(mx0, fm1(mx0), pch = 19) # \\hat{\\mu}_1(\\bar{x}_0)\n\n\n# ---\n# Texts for direct/indirect effects\n# ---\nh &lt;- .3\narrow_length &lt;- .05\n\nif (export_tikz == TRUE) {\n  # lab_delta_0 &lt;- \"$\\\\delta(0) = \\\\beta_0(\\\\bar{x}_1-\\\\bar{x}_0)$\"\n  # lab_delta_0 &lt;- \"$\\\\delta(1) = \\\\beta_1 (\\\\bar{x}_1 - \\\\bar{x}_0)$\"\n  # lab_zeta_0 &lt;- \"$\\\\zeta(0) = (\\\\alpha_1 - \\\\alpha_0) + \\\\bar{x}_0(\\\\beta_1-\\\\beta_0)$\"\n  # lab_zeta_1 &lt;- \"$\\\\zeta(1) = (\\\\alpha_1 - \\\\alpha_0) + \\\\bar{x}_1(\\\\beta_1-\\\\beta_0)$\"\n  lab_delta_0 &lt;- \"$\\\\delta(0)$\"\n  lab_delta_1 &lt;- \"$\\\\delta(1)$\"\n  lab_zeta_0 &lt;- \"$\\\\zeta(0)$\"\n  lab_zeta_1 &lt;- \"$\\\\zeta(1)$\"\n} else {\n  lab_delta_0 &lt;- expression(delta(0) == beta[0] * (bar(x)[1] - bar(x)[0]))\n  lab_delta_1 &lt;- expression(delta(1) == beta[1] * (bar(x)[1] - bar(x)[0]))\n  lab_zeta_0 &lt;- expression(\n    zeta(0) == (alpha[1] - alpha[0]) + bar(x)[0] * (beta[1] - beta[0])\n  )\n  lab_zeta_1 &lt;- expression(\n    zeta(1) == (alpha[1] - alpha[0]) + bar(x)[1] * (beta[1] - beta[0])\n  )\n}\n\n# delta(0)\narrows(mx1 + h, fm0(mx1), mx1 + h, fm0(mx0), code = 3, length = arrow_length, col = \"red\")\ntext(\n  x = mx1 + h, y = (fm0(mx0) + fm0(mx1)) / 2,\n  labels = lab_delta_0,\n  pos = 4,  \n  cex = 1, col = \"red\"\n)\n# zeta(0) \narrows(mx0 - h, fm0(mx0), mx0 - h, fm1(mx0), code = 3, length = arrow_length, col = \"blue\")\ntext(\n  x = mx0 - h, y = (fm0(mx0) + fm1(mx0)) / 2,\n  labels = lab_zeta_0,\n  pos = 2,  \n  cex = 1, col = \"blue\"\n)\n# delta(1)\narrows(mx0 - h, fm1(mx0), mx0 - h, fm1(mx1), code = 3, length = arrow_length, col = \"red\")\ntext(\n  x = mx0 - h, y = (fm1(mx0) + fm1(mx1)) / 2,\n  labels = lab_delta_1,\n  pos = 2,  \n  cex = 1, col = \"red\"\n)\n# zeta(1)\narrows(mx1 + h, fm0(mx1), mx1 + h, fm1(mx1), code = 3, length = arrow_length, col = \"blue\")\ntext(\n  x = mx1+h, y = (fm0(mx1) + fm1(mx1)) / 2,\n  labels = lab_zeta_1,\n  pos = 4,  \n  cex = 1, col = \"blue\"\n)\n\nif (export_tikz == TRUE) dev.off()\n\n\n# Second plot----\n\nif (export_tikz == TRUE) {\n  tikz('figs/gaussian-1-transp.tex', width = width_fig_tkz, height = height_fig_tkz)\n}\n\n# With the counterfactual\n\nt0 &lt;- -1.5\nt1 &lt;- .5\nplot(\n  NA, NA, ylim = c(0, 10),\n  xlab = \"\", ylab = \"\",\n  axes = FALSE, xlim = c(-4, 3)\n)\n# P(X &lt;= t0 | A = 0)\npolygon(\n  c(-3, x[x &lt;= t0], t0), c(0, dx0[x &lt;= t0], 0) * 4,\n  col = colrj[1], border = NA\n)\n# P(X &lt;= t0 | A = 1)\npolygon(\n  c(-3, x[x &lt;= t1], t1), c(0, dx1[x &lt;= t1], 0) * 4,\n  col = colrj[2], border = NA\n)\n# densities in both groups\nlines(x, dx0 * 4, col = COLRJ[1], lwd = 2)\nlines(x, dx1 * 4, col = COLRJ[2], lwd = 2)\n\naxis(1, at = -3:3, labels = FALSE)\nif (export_tikz == FALSE) {\n  lab_x &lt;- expression(\n    x[i], # \\bar{x}_0\n    x[i](1) # \\bar{x}_1\n  )\n  lab_line_0 &lt;- expression(y == alpha[0] + beta[0] * x)\n  lab_line_1 &lt;- expression(y == alpha[1] + beta[1] * x)\n} else {\n  lab_x = c(\n    \"$x_i$\",\n    \"$x_i(1)$\"\n  )\n  lab_line_0 &lt;- \"$y = \\\\alpha_0 + \\\\beta_0 x$\"\n  lab_line_1 &lt;- \"$y = \\\\alpha_1 + \\\\beta_1 x$\"\n}\naxis(\n  1,\n  at = c(t0, t1),\n  labels = lab_x,\n  tick = TRUE, # still draw the little tick marks\n  line = 0 # on the axis line\n)\nif (1== 0) {\n  # Outcome in group 0\n  text(\n    x = 3, y = 4.15,\n    labels = lab_line_0,\n    pos = 2,  \n    cex = 1,\n    col = COLRJ[1]\n  )\n  # Outcome in group 1\n  text(\n    x = -3, y = 4.15,\n    labels = lab_line_1,\n    pos = 4,  \n    cex = 1,\n    col = COLRJ[2]\n  )\n}\n# True mean in each groups\nabline(v = c(t0, t1), lty = 2, lwd = .7)\n\n# Observed points in group 0\npoints(x0, y0, pch = 19, cex = cex_pts, col = colrj[1])\n# True conditional mean in grouo 0\nsegments(-3, fm0(-3), 3, fm0(3), col = COLRJ[1], lwd = 2)\n\n# Observed points in group 1\npoints(x1, y1, pch = 19, cex = cex_pts, col = colrj[2])\n# True conditional mean in grouo 0\nsegments(-3, fm1(-3), 3, fm1(3), col = COLRJ[2], lwd = 2)\n# This time, instead of means: transported values\nsegments(t0, fm0(t0), t1, fm0(t0))\nsegments(t0, fm1(t1), t1, fm1(t1))\nsegments(t1, fm0(t1), t1, fm0(t0), col = \"red\", lwd = 2)\nsegments(t1, fm1(t1), t1, fm0(t1), col = \"blue\", lwd = 2)\nsegments(t0, fm0(t0), t0, fm1(t0), col = \"blue\", lwd = 2)\nsegments(t0, fm1(t0), t0, fm1(t1), col = \"red\", lwd = 2)\n\npoints(t0, fm0(t0), pch = 19) # \\hat{\\mu}_0(x_0)\npoints(t1, fm1(t1), pch = 19) # \\hat{\\mu}_1(T(x_0)\npoints(t1, fm0(t1), pch = 19) # \\hat{\\mu}_0(T(x_0))\npoints(t0, fm1(t0), pch = 19) # \\hat{\\mu}_1(x_0)\n\n# ---\n# Texts for direct/indirect effects\n# ---\nh &lt;- .3\narrow_length &lt;- .05\n\nif (export_tikz == TRUE) {\n  # lab_delta_0 &lt;- \"$\\\\delta_i(0) = \\\\beta_0 (x_i(1) - x_i)$\"\n  # lab_delta_1 &lt;- \"$\\\\delta_i(1) = \\\\beta_1(x_i(1) - x_i)$\"\n  # lab_zeta_0 &lt;- \"$\\\\zeta_i(0) = (\\\\alpha_1 - \\\\alpha_0) + x_i(\\\\beta_1 - \\\\beta_0)$\"\n  # lab_zeta_1 &lt;- \"$\\\\zeta_i(1) = (\\\\alpha_1 - \\\\alpha_0) + x_i(1)(\\\\beta_1-\\\\beta_0)$\"\n  \n  lab_delta_0 &lt;- \"$\\\\delta_i(0)$\"\n  lab_delta_1 &lt;- \"$\\\\delta_i(1)$\"\n  lab_zeta_0 &lt;- \"$\\\\zeta_i(0)$\"\n  lab_zeta_1 &lt;- \"$\\\\zeta_i(1)$\"\n} else {\n  lab_delta_0 &lt;- expression(delta[i](0) == beta[0] * (x[i](1) - x[i]))\n  lab_delta_1 &lt;- expression(delta[i](1) == beta[1] * (x[i](1) - x[i]))\n  lab_zeta_0 &lt;- expression(\n    zeta[i](0) == (alpha[1] - alpha[0]) + x[i] * (beta[1] - beta[0])\n  )\n  lab_zeta_1 &lt;- expression(\n    zeta[i](1) == (alpha[1] - alpha[0]) + x[i](1) * (beta[1] - beta[0])\n  )\n}\n\n# delta(0)\narrows(t1 + h, fm0(t1), t1 + h, fm0(t0), code = 3, length = arrow_length, col = \"red\")\ntext(\n  x = t1 + h, y = (fm0(t0) + fm0(t1)) / 2,\n  labels = lab_delta_0,\n  pos = 4,  \n  cex = 1, col = \"red\"\n)\n# zeta(0)\narrows(t0 - h, fm0(t0), t0 - h, fm1(t0), code = 3, length = arrow_length, col = \"blue\")\ntext(\n  x = t0-h, y = (fm0(t0) + fm1(t0)) / 2,\n  labels = lab_zeta_0,\n  pos = 2,  \n  cex = 1, col = \"blue\"\n)\n# delta(1)\narrows(t0 - h, fm1(t0), t0 - h, fm1(t1), code = 3, length = arrow_length, col = \"red\")\ntext(\n  x = t0 - h, y = (fm1(t0) + fm1(t1)) / 2,\n  labels = lab_delta_1,\n  pos = 2,  \n  cex = 1, col = \"red\"\n)\n# zeta(1)\narrows(t1 + h, fm0(t1), t1 + h, fm1(t1), code = 3,length = arrow_length, col = \"blue\")\ntext(\n  x = t1 + h, y = (fm0(t1) + fm1(t1)) / 2,\n  labels = lab_zeta_1,\n  pos = 4,  \n  cex = 1, col = \"blue\"\n)\n\nif (export_tikz == TRUE) {\n  dev.off()\n  plot_to_pdf(filename = \"gaussian-1-mean\", path = \"./figs/\", keep_tex = FALSE, crop = TRUE)\n  plot_to_pdf(filename = \"gaussian-1-transp\", path = \"./figs/\", keep_tex = FALSE, crop = TRUE)\n}\n\n\n\n\n\nFigure 2.2: Decomposition of the average total causal effect (left) and the total causal effect for an untreated unit (right), with notations from Imai, Keele, and Tingley (2010). Untreated in green, treated in yellow.",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Reminders and Definitions</span>"
    ]
  },
  {
    "objectID": "reminders.html#causal-effects",
    "href": "reminders.html#causal-effects",
    "title": "2  Reminders and Definitions",
    "section": "",
    "text": "Figure 2.1: Causal DAG. Mediation scenario in which the treatment \\(a\\) affects the outcome \\(y\\) both directly and indirectly through an intermediate mediator \\(x\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nNatural Indirect Effect (Pearl (2001))\n\n\n\nThe causal mediation effect for the \\(i\\)th individual writes:\n\\[\n\\delta(a):=\\widehat{\\mu}_a(\\boldsymbol{x}(1))-\\widehat{\\mu}_a(\\boldsymbol{x}(0))\n\\] where \\(\\widehat{\\mu}_a(\\boldsymbol{x})\\) denote the predicted outcome under treatment \\(a\\) and mediator value \\(\\boldsymbol{x}\\).\nImai, Keele, and Yamamoto (2010) refers to \\(\\delta_i{(a)}\\) as the causal mediation effect.\n\n\n\n\n\n\n\n\n\nAverage Natural Indirect Effect\n\n\n\nThe average causal mediation effects writes:\n\\[\n\\begin{align*}\n\\bar{\\delta}{(a)} & \\equiv \\mathbb{E}\\bigl[\\delta_i{(a)}\\bigr]\n\\end{align*}\n\\tag{2.1}\\]\n\n\n\n\n\n\n\n\nNatural Direct Effect (Pearl (2001), Imai, Keele, and Yamamoto (2010))\n\n\n\nThe natural direct effect writes: \\[\n\\zeta(a):=\\widehat{\\mu}_1(\\boldsymbol{x}(a))-\\widehat{\\mu}_0(\\boldsymbol{x}(a))\\\\\n\\tag{2.2}\\]\nHence, it represents the direct effect of the treatment for a given level of the mediator.\n\n\n\n\n\n\n\n\nTotal Causal Effect (Imai, Keele, and Yamamoto (2010))\n\n\n\nThe total causal effect is given by \\[\n\\tau:=\\delta(a)+\\zeta(1-a).\n\\tag{2.3}\\]\n\n\n\n\n\n\n\n\nImai, Kosuke, Luke Keele, and Dustin Tingley. 2010. “A General Approach to Causal Mediation Analysis.” Psychological Methods 15 (4): 309.\n\n\nImai, Kosuke, Luke Keele, and Teppei Yamamoto. 2010. “Identification, Inference and Sensitivity Analysis for Causal Mediation Effects.” Statistical Science 25 (1): 51–71.\n\n\nPearl, Judea. 2001. “Direct and Indirect Effects.” In Proceedings of the Seventeenth Conference on Uncertainty and Artificial Intelligence, 2001, 411–20. Morgan Kaufmann, San Francisco.\n\n\nRobins, James M, and Sander Greenland. 1992. “Identifiability and Exchangeability for Direct and Indirect Effects.” Epidemiology 3 (2): 143–55.",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Reminders and Definitions</span>"
    ]
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "3  Miscellaneous functions",
    "section": "",
    "text": "Objectives\n\n\n\nThis page shows some functions used later on with the exercises. They are written in the following script file: ../scripts/utils.R.\n\n\n\ncolours &lt;- c(\n  # `0` = \"#5BBCD6\", \n  # `1` = \"#FF0000\", \n  # `0` = \"#1b95e0\",\n  # `1` = \"#7F170E\",\n  `0` = \"#00A08A\", \n  `1` = \"#F2AD00\", \n  `transp` = \"#1b95e0\",\n  with = \"#046C9A\", \n  without = \"#C93312\"\n  # `2` = \"#0B775E\"\n)\n# Colour scale from colour of class 0 to class 1\ncolfunc &lt;- colorRampPalette(c(colours[\"0\"], colours[\"1\"]))\nscl &lt;- scales::alpha(colfunc(9),.9)\n\n\nfont_size &lt;- 20\nfont_family &lt;- \"CMU Serif\"\n\n#' Theme for ggplot2\n#'\n#' @param ... Arguments passed to the theme function.\n#' @export\n#' @importFrom ggplot2 element_rect element_text element_blank element_line unit\n#'   rel theme\n#'\ntheme_paper &lt;- function (...) {\n  theme(\n    text = element_text(family = font_family),\n    plot.background = element_rect(fill = \"transparent\", color = NA),\n    panel.background = element_rect(fill = \"transparent\", color = NA),\n    # panel.border = element_rect(fill = NA, colour = \"black\", linewidth = 1),\n    panel.border = element_blank(),\n    axis.line = element_line(color = \"black\"),\n    axis.text = element_text(color = \"black\"),\n    legend.text = element_text(size = rel(1)),\n    legend.title = element_text(size = rel(1)),\n    legend.background = element_rect(fill = \"transparent\", color = NULL),\n    # legend.position = \"bottom\",\n    # legend.direction = \"horizontal\",\n    # legend.box = \"vertical\",\n    legend.key = element_blank(),\n    panel.spacing = unit(1, \"lines\"),\n    panel.grid.major = element_line(colour = \"grey90\"),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0, size = rel(1), face = \"bold\"),\n    plot.title.position = \"plot\",\n    plot.margin = unit(c(1, 1, 1, 1), \"lines\"),\n    strip.background = element_rect(fill = NA, colour = NA),\n    strip.text = element_text(size = rel(1))\n  )\n}\n\ntheme_ggtern_paper &lt;- function(...) {\n  font_family &lt;- \"CMU Serif\"\n  font_size &lt;- 20\n  theme(\n    strip.background = element_rect(colour = \"black\", fill = NA),\n    strip.text.x = element_text(colour = \"black\"),\n    strip.text = ggtext::element_markdown(),\n    text = element_text(family = font_family, size = unit(font_size, \"pt\")),\n    axis.title = element_text(size = rel(.8)),\n    tern.axis.arrow.show = TRUE,\n    tern.axis.arrow.sep = .13,\n    tern.axis.vshift = .05,\n    panel.border = element_rect(colour = NA)\n  )\n}\n\n\n#' From plot created with {tikzDevice}, create a standalone latex document\n#' and compile it with pdflatex to save the plot as pdf\n#' \n#' @param filename Name of the tex file (WITHOUT THE EXTENSION) that contains \n#'  the tikzpicture.\n#' @param path_to_latex Path to LaTeX engine (Defaults to\n#'   `/Library/TeX/texbin/`).\n#' @param interpreter By default, use pdflatex (`pdflatex`).\n#' @param path Path to the destination folder.\n#' @param keep_tex should the tex file (only the one from the standalone doc) \n#'  be kept after compilation? Defaults to `FALSE`.\n#' @param verbose A logical value indicating whether diagnostic messages are\n#'   printed when measuring dimensions of strings. Defaults to `FALSE`.\n#' @param ignore.stdout A logical (not NA) indicating whether messages written\n#'   to ‘stdout’  should be ignored. Defaults to `TRUE`.\n#' @param crop If `TRUE` (default to `FALSE`), the PDF is cropped using pdfcrop.\n#' \nplot_to_pdf &lt;- function(filename,\n                        path_to_latex = \"/Library/TeX/texbin/\",\n                        interpreter = \"pdflatex\",\n                        path = \"./\",\n                        keep_tex = FALSE,\n                        verbose = FALSE,\n                        ignore.stdout = TRUE,\n                        crop = FALSE) {\n  content &lt;- paste0(\n    \"\\\\documentclass{standalone}\n      \\\\usepackage{amsmath,amssymb,amsthm,mathtools,graphicx}\n      \\\\usepackage{array,dcolumn}\n      %\\\\usepackage{dsfont}\n      %\\\\usepackage{fontspec}\n      \\\\renewcommand{\\\\rmdefault}{ptm}\n      \\\\renewcommand{\\\\sfdefault}{phv}\n      %\\\\setmainfont{Noto Sans}\n      %\n      \\\\usepackage{nicefrac}\n      \\\\usepackage{times}\n      %\\\\usepackage{natbib}\n      \\\\usepackage{microtype}\n      %\\\\usepackage{newtxtext,newtxmath}\n      %\\\\usepackage{times,mathpazo}\n      \\\\usepackage{pgfplots}\n      \\\\usetikzlibrary{pgfplots.groupplots}\n      \\\\usepackage{xcolor}\n      \\\\usepackage{mathptmx}\n      \\\\begin{document}\n\n      \\\\input{\",\n    path, filename,\n    \".tex}\n\n      \\\\end{document}\"\n  )\n  \n  # The file which will import the graph in tex format\n  fileConn &lt;- file(paste0(path, filename, \"_tmp.tex\"))\n  writeLines(content, fileConn)\n  close(fileConn)\n  \n  # Process tex file to get the PDF\n  system(\n    paste0(\n      path_to_latex,\n      interpreter, \" -shell-escape -synctex=1 -interaction=nonstopmode  \",\n      path,\n      filename, \"_tmp.tex\"),\n    ignore.stdout = TRUE\n  )\n  if (crop == TRUE) {\n    system(\n      paste0(\n        \"pdfcrop \", filename, \"_tmp.pdf \", filename, \"_tmp.pdf\"\n      )\n    )\n  }\n  if(!path %in%  c(\".\", \"./\", \"/\")) \n    system(paste0(\"mv \", filename, \"_tmp.pdf \", path))\n  system(paste0(\"rm \", filename, \"_tmp.aux\"))\n  system(paste0(\"rm \", filename, \"_tmp.log\"))\n  system(paste0(\"rm \", filename, \"_tmp.synctex.gz\"))\n  if (!keep_tex) {\n    system(paste0(\"rm \", path, filename, \"_tmp.tex\"))\n  }\n  system(paste0(\"mv \", path, filename, \"_tmp.pdf \", path, filename, \".pdf\"))\n}\n\n\n#' Save a ggplot2 plot as PDF, using LaTeX tikz\n#'\n#' @param plot A ggplot2 object.\n#' @param path_to_latex Path to LaTeX engine (Defaults to\n#'   `/Library/TeX/texbin/`).\n#' @param interpreter By default, use pdflatex (`pdflatex`).\n#' @param path Path to the destination folder.\n#' @param filename File name (without the extension).\n#' @param keep_tex should the tex file be kept after compilation? Defaults to\n#'   `FALSE`.\n#' @param width Width in inches (default to 15).\n#' @param height Height in inches (default to 15).\n#' @param verbose A logical value indicating whether diagnostic messages are\n#'   printed when measuring dimensions of strings. Defaults to `FALSE`.\n#' @param ignore.stdout A logical (not NA) indicating whether messages written\n#'   to ‘stdout’  should be ignored. Defaults to `TRUE`.\n#' @param crop If `TRUE` (default to `FALSE`), the PDF is cropped using pdfcrop.\n#'\n#' @importFrom tikzDevice tikz\n#' @importFrom grDevices dev.off\n#' @export\n#' @md\n#'\nggplot2_to_pdf &lt;- function(plot,\n                           path_to_latex = \"/Library/TeX/texbin/\",\n                           interpreter = \"pdflatex\",\n                           path = \"./\",\n                           filename,\n                           keep_tex = FALSE,\n                           width = 15,\n                           height = 15,\n                           verbose = FALSE,\n                           ignore.stdout = TRUE,\n                           crop = FALSE) {\n  content &lt;- paste0(\n    \"\\\\documentclass{standalone}\n      \\\\usepackage{amsmath,amssymb,amsthm,mathtools,graphicx}\n      \\\\usepackage{array,dcolumn}\n      %\\\\usepackage{dsfont}\n      %\\\\usepackage{fontspec}\n      \\\\renewcommand{\\\\rmdefault}{ptm}\n      \\\\renewcommand{\\\\sfdefault}{phv}\n      %\\\\setmainfont{Noto Sans}\n      %\n      \\\\usepackage{nicefrac}\n      \\\\usepackage{times}\n      %\\\\usepackage{natbib}\n      \\\\usepackage{microtype}\n      %\\\\usepackage{newtxtext,newtxmath}\n      %\\\\usepackage{times,mathpazo}\n      \\\\usepackage{pgfplots}\n      \\\\usetikzlibrary{pgfplots.groupplots}\n      \\\\usepackage{xcolor}\n      \\\\usepackage{mathptmx}\n      \\\\begin{document}\n\n      \\\\input{\",\n    path, filename,\n    \"_content.tex}\n\n      \\\\end{document}\"\n  )\n\n  # The file which will import the graph in tex format\n  fileConn &lt;- file(paste0(path, filename, \".tex\"))\n  writeLines(content, fileConn)\n  close(fileConn)\n\n  # Export graph to tex\n  tikz(file = paste0(\n    path,\n    filename, \"_content.tex\"),\n    width = width,\n    height = height,\n    verbose = verbose\n  )\n  print(plot)\n  dev.off()\n\n  # Move the scale from ggplot, if any\n  name_scale &lt;- paste0(filename, \"_content_ras1.png\")\n  scale_exists &lt;- file.exists(name_scale)\n  if (scale_exists & ! path %in% c(\".\", \"./\", \"/\")) {\n    system(paste0(\"mv \", name_scale, \" \", path))\n  }\n\n  # Process tex file to get the PDF\n  system(\n    paste0(\n      path_to_latex,\n      interpreter, \" -shell-escape -synctex=1 -interaction=nonstopmode  \",\n      path,\n      filename, \".tex\"),\n    ignore.stdout = TRUE\n  )\n  if (crop == TRUE) {\n    system(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\n  }\n  if(!path %in%  c(\".\", \"./\", \"/\")) system(paste0(\"mv \", filename, \".pdf \", path))\n  system(paste0(\"rm \", filename, \".aux\"))\n  system(paste0(\"rm \", filename, \".log\"))\n  system(paste0(\"rm \", filename, \".synctex.gz\"))\n  if (!keep_tex) {\n    system(paste0(\"rm \", path, filename, \".tex\"))\n    system(paste0(\"rm \", path, filename, \"_content.tex\"))\n  }\n  if (scale_exists) system(paste0(\"rm \", path, \"/\", name_scale))\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Miscellaneous functions</span>"
    ]
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "4  Functions for Sequential Transport",
    "section": "",
    "text": "4.1 compute_counterfactual_probs()\n#' Compute counterfactual predicted probabilities for a single observation\n#'\n#' @param i Index of the observation from group 0.\n#' @param pred_probs_0 Matrix of predicted probabilities (group 0).\n#' @param pred_probs_1 Matrix of predicted probabilities (group 1).\n#' @param weights_0 Matrix of intra-group distances for group 0.\n#' @param weights_1 Matrix of inter-group distances from group 0 to group 1.\n#' @param num_neighbors_q Number of neighbors to use.\n#' @param method Either `\"shortsimplex\"`, `\"sinkhorn\"`, or `\"OSQP\"`.\n#' @param lambda A regularization parameter (default to 0.1). Only if \n#'   `method = sinkhorn\"`\n#'\n#' @return A vector of counterfactual predicted probabilities.\ncompute_counterfactual_probs &lt;- function(i,\n                                         pred_probs_0,\n                                         pred_probs_1,\n                                         weights_0,\n                                         weights_1,\n                                         num_neighbors_q,\n                                         method = c(\"shortsimplex\", \"sinkhorn\", \"OSQP\"),\n                                         lambda = 0.1) {\n  \n  # Identify closest neighbours within the same group\n  dist_neigh_0 &lt;- weights_0[i, , drop = FALSE]\n  # and among the other group\n  dist_neigh_1 &lt;- weights_1[i, , drop = FALSE]\n  \n  ranks_weights_0 &lt;- order(dist_neigh_0, decreasing = TRUE)[1:num_neighbors_q]\n  ranks_weights_1 &lt;- order(dist_neigh_1, decreasing = TRUE)[1:num_neighbors_q]\n  i_rank &lt;- which(ranks_weights_0 == i)\n  \n  W_i &lt;- wasserstein_simplex(\n    X = pred_probs_0[ranks_weights_0, ],\n    Y = pred_probs_1[ranks_weights_1, ],\n    wx = dist_neigh_0[ranks_weights_0],\n    wy = dist_neigh_1[ranks_weights_1],\n    method = method,\n    lambda = lambda\n  )\n  \n  # Most likely match under the transport plan\n  pred_probs_1[ranks_weights_1, ][which.max(W_i$plan[i_rank, ]), ]\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#ot_simplex_probs",
    "href": "functions.html#ot_simplex_probs",
    "title": "4  Functions for Sequential Transport",
    "section": "4.2 ot_simplex_probs()",
    "text": "4.2 ot_simplex_probs()\n\n#' @param pred_probs_0 Matrix with predicted probabilities to belong the each \n#'  class of the categorical variable, in group 0 (source).\n#' @param pred_probs_1 Matrix with predicted probabilities to belong the each \n#'  class of the categorical variable, in group 1 (target).\n#' @param weights_0 Weights corresponding to the distance between observations \n#'  within source group.\n#' @param weights_1 Weights corresponding to the distance between observations \n#'  within target group.\n#' @param num_neighbors_q Number of neigbors to use for categorical variables.\n#'  Default to the min between 50 and the number of observations in the data.\n#' @param method Either `\"shortsimplex\"`, `\"sinkhorn\"`, or `\"OSQP\"`.\n#' @param lambda A regularization parameter (default to 0.1). Only if \n#'   `method = \"sinkhorn\"`.\n#' @param cl A cluster object, created by package parallel. If `NULL` (default), \n#'   no parallel computing is used to transport categorical data.\n#'  \not_simplex_probs &lt;- function(pred_probs_0,\n                             pred_probs_1,\n                             weights_0,\n                             weights_1,\n                             num_neighbors_q = NULL,\n                             method = c(\"shortsimplex\", \"sinkhorn\", \"OSQP\"),\n                             lambda = 0.1,\n                             cl = NULL) {\n  \n  method &lt;- match.arg(method)\n  \n  if (is.null(num_neighbors_q)) {\n    num_neighbors_q &lt;- min(nrow(pred_probs_0), nrow(pred_probs_1), 50)\n  } else {\n    num_neighbors_q &lt;- min(nrow(pred_probs_0), nrow(pred_probs_1), num_neighbors_q)\n  }\n  \n  mat_counter_categ &lt;- matrix(\n    NA, ncol = ncol(pred_probs_0), nrow = nrow(pred_probs_0)\n  )\n  \n  indices &lt;- seq_len(nrow(pred_probs_0))\n  \n  if (!is.null(cl)) {\n    parallel::clusterExport(\n      cl, varlist = c(\n        \"pred_probs_0\", \"pred_probs_1\", \n        \"weights_0\", \"weights_1\", \n        \"num_neighbors_q\", \"method\", \"compute_counterfactual_probs\"\n      ),\n      envir = environment()\n    )\n    res &lt;- pbapply::pblapply(\n      indices, \n      compute_counterfactual_probs,\n      pred_probs_0 = pred_probs_0,\n      pred_probs_1 = pred_probs_1,\n      weights_0 = weights_0,\n      weights_1 = weights_1,\n      num_neighbors_q = num_neighbors_q,\n      lambda = lambda,\n      method = method,\n      cl = cl\n    )\n  } else {\n    res &lt;- pbapply::pblapply(\n      indices, \n      compute_counterfactual_probs,\n      pred_probs_0 = pred_probs_0,\n      pred_probs_1 = pred_probs_1,\n      weights_0 = weights_0,\n      weights_1 = weights_1,\n      num_neighbors_q = num_neighbors_q,\n      lambda = lambda,\n      method = method\n    )\n    \n  }\n  \n  do.call(rbind, res)\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#get_assignment",
    "href": "functions.html#get_assignment",
    "title": "4  Functions for Sequential Transport",
    "section": "4.3 get_assignment()",
    "text": "4.3 get_assignment()\n\n#' OT for categorical variable, from source distribution to target \n#' probabilities.\n#' \n#' @param probs Propensities from the source distribution (individuals in rows,\n#'  classes in columns).\n#' @param labels Levels (labels) of the classes.\n#' @param p Vector of target probabilities. If omitted, uniform weights are \n#'  used.\n#' \nget_assignment &lt;- function(probs,\n                           labels,\n                           p = NULL) {\n  \n  n_labels &lt;- ncol(probs)\n  n &lt;- nrow(probs)\n  if (is.null(p)) p &lt;- rep(1, n_labels) / n_labels # Uniform weights\n  \n  # Unit vectors\n  vertices &lt;- diag(n_labels)\n  # colnames(vertices) &lt;- colnames()\n  # source weights\n  mass_source &lt;- rep(1 / n, n)\n  # target weights\n  mass_target &lt;- as.numeric(p)\n  \n  # Cost matrix (squared Euclidean distance)\n  cost_matrix &lt;- as.matrix(dist(rbind(probs, vertices))^2)\n  cost_matrix &lt;- cost_matrix[1:n, (n + 1):(n + n_labels)]\n  \n  # Assign each observation to one vertex\n  # by minimizing the global transport cost, while matching marginals\n  \n  # Solve the optimal transport plan\n  ot_plan &lt;- transport::transport(\n    a = mass_source, b = mass_target, costm = cost_matrix, \n    method = \"shortsimplex\"\n  )\n  \n  # Assign each sample to a category based on OT plan\n  assignment &lt;- rep(NA, n)\n  # mass each source sends to each target\n  mass_matrix &lt;- matrix(0, nrow = n, ncol = n_labels)\n  \n  for (j in 1:nrow(ot_plan)) {\n    from &lt;- ot_plan$from[j]\n    to &lt;- ot_plan$to[j]\n    mass &lt;- ot_plan$mass[j]\n    mass_matrix[from, to] &lt;- mass_matrix[from, to] + mass\n  }\n  \n  # Assign each source point to the target it contributes the most mass to\n  assignments &lt;- max.col(mass_matrix, ties.method = \"random\")\n  #factor(c(1, 2, 4), levels = 1:4, labels = c(\"A\", \"B\", \"C\", \"D\"))\n  \n  factor(assignments, levels = 1:length(labels), labels = labels)\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#seq_trans",
    "href": "functions.html#seq_trans",
    "title": "4  Functions for Sequential Transport",
    "section": "4.4 seq_trans()",
    "text": "4.4 seq_trans()\n\n#' Sequential Transport Using a Pre-Defined Causal Graph\n#'\n#' The sensitive attribute, S, is assumed to be a binary variable with value\n#' $S_0$ in the source distribution and $S_1$ in the target distribution.\n#'\n#' @param data Data frame with the observations.\n#' @param adj Adjacency matrix for the causal graph.\n#' @param s Name of the sensitive attribute column in the data.\n#' @param S_0 Label of the sensitive attribute in the source distribution.\n#' @param y Name of the outcome variable in the data.\n#' @param num_neighbors Number of neighbors to use in the weighted quantile\n#'        estimation. Default to 5.\n#' @param num_neighbors_q Number of neigbors to use for categorical variables.\n#'  Default to the min between 50 and the number of observations in the data.\n#' @param method Either `\"shortsimplex\"`, `\"sinkhorn\"`, or `\"OSQP\"`.\n#' @param lambda A regularization parameter (default to 0.1). Only is \n#'   `method = sinkhorn`.\n#' @param silent If `TRUE`, the messages showing progress in the estimation are\n#'        not shown. Default to `silent=FALSE`.\n#' @param cl A cluster object, created by package parallel. If `NULL` (default), \n#'   no parallel computing is used to transport categorical data. Otherwise, \n#'   only used to transport categorical data.\n#'\n#' @returns An element of class `\"sequential_transport\"` (a list):\n#' * `transported`: A named list with the transported values. The names are those of the variables.\n#' * `weights`: A list with the weights of each observation in the two groups.\n#' * `ecdf`: A list with empirical distribution functions for numerical variables.\n#' * `ecdf_values`: A list with the values of the ecdf evaluated for each observation in the source distribution.\n#' * `fit_for_categ`: A list with the estimated multinomial models to predict categories using parents characteristics\n#' * `params`: A list with some parameters used to transport observations:\n#'     * `adj`: Adjacency matrix.\n#'     * `top_order`: Topological ordering.\n#'     * `s`: Name of the sensitive attribute.\n#'     * `S_0`: Label of the sensitive attribute in the source distribution.\n#'     * `S_1`: Label of the sensitive attribute in the target distribution.\n#'     * `y`: Name of the outcome variable in the data.\n#'     * `num_neighbors`: Number of neighbors used when computing quantiles.\n#' @md\n#' @export\n#'\n#' @examples\n#' # Data with two groups: S=0, S=1, an outcome Y and two covariates X1 and X2\n#' sim_dat &lt;- simul_dataset()\n#' # Causal graph:\n#' variables &lt;- c(\"S\", \"X1\", \"X2\", \"Y\")\n#' adj &lt;- matrix(\n#'   # S  X1 X2 Y\n#'   c(0, 1, 1, 1,# S\n#'     0, 0, 1, 1,# X1\n#'     0, 0, 0, 1,# X2\n#'     0, 0, 0, 0  # Y\n#'   ),\n#'   ncol = length(variables),\n#'   dimnames = rep(list(variables), 2),\n#'   byrow = TRUE\n#' )\n#' # To visualize the causal graph:\n#' # causal_graph &lt;- fairadapt::graphModel(adj)\n#' # plot(causal_graph)\n#'\n#' # Sequential transport according to the causal graph\n#' transported &lt;- seq_trans(data = sim_dat, adj = adj, s = \"S\", S_0 = 0, y = \"Y\")\n#' transported\n#' # Transported values from S=0 to S=1, using the causal graph.\n#' transported_val &lt;- as.data.frame(transported$transported)\n#' head(transported_val)\n#' @importFrom stats predict ecdf quantile\n#' @importFrom dplyr across filter mutate pull select\n#' @importFrom tidyselect where\n#' @importFrom rlang sym !! := is_character\n#' @importFrom cluster daisy\n#' @importFrom Hmisc wtd.quantile\n#' @importFrom nnet multinom\n#' @importFrom purrr map_chr\n#' @seealso [seq_trans_new()], [simul_dataset()]\nseq_trans &lt;- function(data,\n                      adj,\n                      s,\n                      S_0,\n                      y,\n                      num_neighbors = 5,\n                      num_neighbors_q = NULL,\n                      method = c(\"shortsimplex\", \"sinkhorn\", \"OSQP\"),\n                      lambda = 0.1,\n                      silent = FALSE,\n                      cl = NULL) {\n  \n  method &lt;- match.arg(method)\n  \n  # Make sure character variables are encoded as factors\n  data &lt;-\n    data |&gt;\n    mutate(across(where(is_character), ~as.factor(.x)))\n  \n  s_unique &lt;- unique(data[[s]])\n  S_1 &lt;- s_unique[s_unique != S_0]\n  \n  # Topological ordering\n  top_order &lt;- seqtransfairness::topological_ordering(adj)\n  variables &lt;- top_order[!top_order %in% c(s, y)]\n  # Observations in group S_0\n  data_0 &lt;- data |&gt; filter(!!sym(s) == !!S_0)\n  data_1 &lt;- data |&gt; filter(!!sym(s) != !!S_0)\n  \n  # Lists where results will be stored\n  list_transported &lt;- list()  # Transported values\n  list_transported_prob &lt;- list()  # Transported prob. for categ. variables\n  list_weights &lt;- list()      # Weights\n  list_ecdf &lt;- list()         # Empirical dist. function\n  list_ecdf_values &lt;- list()  # Evaluated values of the ecdf\n  fit_for_categ &lt;- list()     # Fitted multinomial models for categ. variables\n  gower_matrix_all &lt;- NULL    # Distance between observations\n  \n  for (x_name in variables) {\n    if (silent == FALSE) cat(\"Transporting \", x_name, \"\\n\")\n    # Names of the parent variables\n    parents &lt;- colnames(adj)[adj[, x_name] == 1]\n    # values of current x in each group\n    x_S0 &lt;- data_0 |&gt; pull(!!x_name)\n    x_S1 &lt;- data_1 |&gt; pull(!!x_name)\n    # Check whether X is numeric\n    is_x_num &lt;- is.numeric(x_S0)\n    # Characteristics of the parent variables (if any)\n    parents_characteristics &lt;- data_0 |&gt; select(!!parents, -!!s)\n    \n    if (length(parents_characteristics) &gt; 0) {\n      \n      data_0_parents &lt;- data_0 |&gt; select(!!parents) |&gt; select(-!!s)\n      data_1_parents &lt;- data_1 |&gt; select(!!parents) |&gt; select(-!!s)\n      # Weights in S_0\n      weights_S0 &lt;- as.matrix(daisy(data_0_parents, metric = \"gower\"))\n      tot_weights_S0 &lt;- apply(weights_S0, MARGIN = 1, sum)\n      # Weights in S_1\n      # First, we need to get the transported values for the parents, if necessary\n      data_0_parents_t &lt;- data_0_parents #init\n      for (parent in parents) {\n        # does the parent depend on the sensitive variable\n        if (parent %in% names(list_transported)) {\n          data_0_parents_t &lt;-\n            data_0_parents_t |&gt;\n            mutate(!!sym(parent) := list_transported[[parent]])\n        }\n      }\n      # Unfortunately, we will compute a lot of distances not needed\n      combined &lt;- rbind(data_0_parents_t, data_1_parents)\n      gower_dist &lt;- daisy(combined, metric = \"gower\")\n      gower_matrix &lt;- as.matrix(gower_dist)\n      n_0 &lt;- nrow(data_0_parents_t)\n      n_1 &lt;- nrow(data_1_parents)\n      weights_S1 &lt;- gower_matrix[1:n_0, (n_0 + 1):(n_0 + n_1), drop = FALSE]\n      weights_S1 &lt;- weights_S1 + 1e-8\n      weights_S1 &lt;- 1 / (weights_S1)^2\n      tot_weights_S1 &lt;- apply(weights_S1, MARGIN = 1, sum)\n      \n      if (is_x_num == TRUE) {\n        # Numerical variable to transport\n        \n        # Empirical distribution function\n        f &lt;- rep(NA, length(x_S0))\n        for (i in 1:length(x_S0)) {\n          f[i] &lt;- weights_S0[i, ] %*% (x_S0 &lt;= x_S0[i]) / tot_weights_S0[i]\n        }\n        list_ecdf_values[[x_name]] &lt;- f\n        f[f==1] &lt;- 1-(1e-8)\n        \n        # Transported values\n        transported &lt;- rep(NA, length(x_S0))\n        for (i in 1:length(x_S0)) {\n          wts &lt;- weights_S1[i, ]\n          wts[-order(wts, decreasing = TRUE)[1:num_neighbors]] &lt;- 0\n          transported[i] &lt;- Hmisc::wtd.quantile(\n            x = x_S1, weights = weights_S1[i, ], probs = f[i]\n          ) |&gt; suppressWarnings()\n        }\n      } else {\n        # X is non numeric and has parents\n        x_labels &lt;- data |&gt; pull(!!x_name) |&gt; levels()\n        # Estimation of propensity in source group\n        fit_categ_0 &lt;- nnet::multinom(\n          paste(x_name, \"~ .\"),\n          data = data_0 |&gt; select(-!!y),\n          trace = FALSE\n        )\n        # Estimation of propensity in target group\n        fit_categ_1 &lt;- nnet::multinom(\n          paste(x_name, \"~ .\"),\n          data = data_1 |&gt; select(-!!y),\n          trace = FALSE\n        )\n        \n        # Predictions with these models:\n        pred_probs_0 &lt;- predict(fit_categ_0, type = \"probs\")\n        pred_probs_1 &lt;- predict(fit_categ_1, type = \"probs\")\n        \n        if (length(x_labels) == 2) {\n          # Binary\n          # Empirical distribution function\n          f &lt;- rep(NA, length(pred_probs_0))\n          for (i in 1:length(pred_probs_0)) {\n            f[i] &lt;- weights_S0[i, ] %*% (pred_probs_0 &lt;= pred_probs_0[i]) / tot_weights_S0[i]\n          }\n          list_ecdf_values[[x_name]] &lt;- f\n          f[f==1] &lt;- 1-(1e-8)\n          \n          # Transported values\n          pred_probs_0_t &lt;- rep(NA, length(pred_probs_0))\n          for (i in 1:length(pred_probs_0)) {\n            wts &lt;- weights_S1[i, ]\n            wts[-order(wts, decreasing = TRUE)[1:num_neighbors]] &lt;- 0\n            pred_probs_0_t[i] &lt;- Hmisc::wtd.quantile(\n              x = pred_probs_1, weights = weights_S1[i, ], probs = f[i]\n            ) |&gt; suppressWarnings()\n          }\n          pred_probs_0_t &lt;- cbind(pred_probs_0_t, 1-pred_probs_0_t)\n          transported &lt;- get_assignment(\n            probs = pred_probs_0_t, \n            labels = x_labels, \n            p = table(data_1 |&gt; pull(!!x_name)) / nrow(data_1)\n          )\n        } else {\n          # Categorical with more than two classes\n          \n          # If some classes are in a group but not in the other\n          if (!all(x_labels %in% colnames(pred_probs_0))) {\n            small_prob &lt;- min(pred_probs_0/2, 1e-8)\n            # Identify missing columns\n            x_labels_missing_0 &lt;- \n              x_labels[which(! x_labels %in% colnames(pred_probs_0))]\n            # set those to a tiny value\n            pred_probs_0_missing &lt;- matrix(\n              rep(small_prob, n_0 * length(x_labels_missing_0)), \n              ncol = length(x_labels_missing_0)\n            )\n            colnames(pred_probs_0_missing) &lt;- x_labels_missing_0\n            # Add column(s) to the prediction matrix\n            pred_probs_0 &lt;- cbind(pred_probs_0, pred_probs_0_missing)\n            # Normalize the probabilities\n            pred_probs_0 &lt;- pred_probs_0 / rowSums(pred_probs_0)\n          }\n          \n          # Same for other group\n          if (!all(x_labels %in% colnames(pred_probs_1))) {\n            small_prob &lt;- min(pred_probs_1/2, 1e-8)\n            # Identify missing columns\n            x_labels_missing_1 &lt;- \n              x_labels[which(! x_labels %in% colnames(pred_probs_1))]\n            # set those to a tiny value\n            pred_probs_1_missing &lt;- matrix(\n              rep(small_prob, n_1 * length(x_labels_missing_1)), \n              ncol = length(x_labels_missing_1)\n            )\n            colnames(pred_probs_1_missing) &lt;- x_labels_missing_1\n            # Add column(s) to the prediction matrix\n            pred_probs_1 &lt;- cbind(pred_probs_1, pred_probs_1_missing)\n            # Normalize the probabilities\n            pred_probs_1 &lt;- pred_probs_1 / rowSums(pred_probs_1)\n          }\n          \n          pred_probs_0_t &lt;- ot_simplex_probs(\n            pred_probs_0 = pred_probs_0, \n            pred_probs_1 = pred_probs_1, \n            weights_0 = 1 / (weights_S0 + 1e-8)^2, \n            weights_1 = weights_S1, \n            num_neighbors_q = num_neighbors_q,\n            method = method,\n            lambda = lambda,\n            cl = cl\n          )\n          \n          # Target prob\n          target_prob &lt;- table(data_1 |&gt; pull(!!x_name)) / nrow(data_1)\n          \n          transported &lt;- get_assignment(\n            probs = pred_probs_0_t, \n            labels = x_labels, \n            p = target_prob\n          )\n        }\n        \n        fit_for_categ[[x_name]] &lt;- list(\n          \"source\" = fit_categ_0,\n          \"target\" = fit_categ_1\n        )\n        colnames(pred_probs_0_t) &lt;- x_labels\n        list_transported_prob[[x_name]] &lt;- pred_probs_0_t\n      }\n      list_transported[[x_name]] &lt;- transported\n      \n      # Store weights for possible later use\n      list_weights[[x_name]] &lt;- list(\n        w_S0 = list(weights = weights_S0, tot_weights = tot_weights_S0),\n        w_S1 = list(weights = weights_S1, tot_weights = tot_weights_S1)\n      )\n    } else {\n      # No parents\n      if (is_x_num == TRUE) {\n        # X is numerical and has no parents\n        F_X_S0 &lt;- ecdf(x_S0)\n        list_ecdf[[x_name]] &lt;- F_X_S0\n        f &lt;- F_X_S0(x_S0)\n        list_ecdf_values[[x_name]] &lt;- f\n        transported &lt;- as.numeric(quantile(x_S1, probs = f))\n      } else {\n        # X is not numerical and has no parents\n        x_labels &lt;- data |&gt; pull(!!x_name) |&gt; levels()\n        # Estimation of propensity in source group\n        fit_categ_0 &lt;- nnet::multinom(\n          paste(x_name, \"~ .\"),\n          data = data_0 |&gt; select(-!!y),\n          trace = FALSE\n        )\n        # Estimation of propensity in target group\n        fit_categ_1 &lt;- nnet::multinom(\n          paste(x_name, \"~ .\"),\n          data = data_1 |&gt; select(-!!y),\n          trace = FALSE\n        )\n        # Predictions with these models:\n        pred_probs_0 &lt;- predict(fit_categ_0, type = \"probs\")\n        pred_probs_1 &lt;- predict(fit_categ_1, type = \"probs\")\n        \n        if (length(x_labels) == 2) {\n          # Binary variable\n          F_pred_probs_S0 &lt;- ecdf(pred_probs_0)\n          list_ecdf[[x_name]] &lt;- F_pred_probs_S0\n          f &lt;- F_pred_probs_S0(pred_probs_0)\n          list_ecdf_values[[x_name]] &lt;- f\n          pred_probs_0_t &lt;- as.numeric(quantile(pred_probs_1, probs = f))\n          pred_probs_0_t &lt;- cbind(pred_probs_0_t, 1-pred_probs_0_t)\n          transported &lt;- get_assignment(\n            probs = pred_probs_0_t, \n            labels = x_labels, \n            p = table(data_1 |&gt; pull(!!x_name)) / nrow(data_1)\n          )\n          colnames(pred_probs_0_t) &lt;- x_labels\n        } else {\n          # More than two classes\n          \n          # If some classes are in a group but not in the other\n          if (!all(x_labels %in% colnames(pred_probs_0))) {\n            small_prob &lt;- min(pred_probs_0/2, 1e-8)\n            # Identify missing columns\n            x_labels_missing_0 &lt;- \n              x_labels[which(! x_labels %in% colnames(pred_probs_0))]\n            # set those to a tiny value\n            pred_probs_0_missing &lt;- matrix(\n              rep(small_prob, n_0 * length(x_labels_missing_0)), \n              ncol = length(x_labels_missing_0)\n            )\n            colnames(pred_probs_0_missing) &lt;- x_labels_missing_0\n            # Add column(s) to the prediction matrix\n            pred_probs_0 &lt;- cbind(pred_probs_0, pred_probs_0_missing)\n            # Normalize the probabilities\n            pred_probs_0 &lt;- pred_probs_0 / rowSums(pred_probs_0)\n          }\n          \n          # Same for other group\n          if (!all(x_labels %in% colnames(pred_probs_1))) {\n            small_prob &lt;- min(pred_probs_1/2, 1e-8)\n            # Identify missing columns\n            x_labels_missing_1 &lt;- \n              x_labels[which(! x_labels %in% colnames(pred_probs_1))]\n            # set those to a tiny value\n            pred_probs_1_missing &lt;- matrix(\n              rep(small_prob, n_1 * length(x_labels_missing_1)), \n              ncol = length(x_labels_missing_1)\n            )\n            colnames(pred_probs_1_missing) &lt;- x_labels_missing_1\n            # Add column(s) to the prediction matrix\n            pred_probs_1 &lt;- cbind(pred_probs_1, pred_probs_1_missing)\n            # Normalize the probabilities\n            pred_probs_1 &lt;- pred_probs_1 / rowSums(pred_probs_1)\n          }\n          \n          mapping &lt;- wasserstein_simplex(\n            X = pred_probs_0, Y = pred_probs_1,\n            method = method,\n            lambda = lambda\n          )\n          pred_probs_0_t &lt;- counterfactual_w(\n            mapping = mapping, X0 = pred_probs_0, X1 = pred_probs_1\n          )\n          transported &lt;- get_assignment(\n            probs = pred_probs_0_t, \n            labels = x_labels, \n            p = table(data_1 |&gt; pull(!!x_name)) / nrow(data_1)\n          )\n          colnames(pred_probs_0_t) &lt;- x_labels\n        }\n        list_transported_prob[[x_name]] &lt;- pred_probs_0_t\n      }\n      list_transported[[x_name]] &lt;- transported\n    }\n  }\n  \n  structure(\n    list(\n      transported = list_transported,\n      transported_prob = list_transported_prob,\n      weights = list_weights,\n      ecdf = list_ecdf,\n      ecdf_values = list_ecdf_values,\n      fit_for_categ = fit_for_categ,\n      params = list(\n        adj = adj,\n        top_order = top_order,\n        s = s,\n        S_0 = S_0,\n        S_1 = S_1,\n        y = y,\n        num_neighbors = num_neighbors\n      )\n    ),\n    class = \"sequential_transport\"\n  )\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#compute_pdist_simplex_fast",
    "href": "functions.html#compute_pdist_simplex_fast",
    "title": "4  Functions for Sequential Transport",
    "section": "4.5 compute_pdist_simplex_fast()",
    "text": "4.5 compute_pdist_simplex_fast()\n\n#' Pairwise distance matrix on the simplex\n#'\n#' @description\n#' Computes the pairwise distance matrix of observations in the simplex, using\n#' the cost function for optimal transport on the unit simplex as the distance\n#' metric.\n#'\n#' @param X Matrix of observations (one observation per row).\n#' @param Y Matrix of observations (one observation per row).\n#'\n#' @returns A matrix of size n x m, where n is the number of observation in X,\n#'  and m is the number of observations in Y, containing the distances between\n#'  observations in X and Y.\n#' @noRd\ncompute_pdist_simplex_fast &lt;- function(X, Y) {\n  \n  p &lt;- ncol(X)\n  invX &lt;- 1 / X\n  \n  # R[j,i] = sum_k Y[j,k] * invX[i,k]\n  R &lt;- Y %*% t(invX)\n  \n  logXmean &lt;- rowMeans(log(X))\n  logYmean &lt;- rowMeans(log(Y))\n  \n  # M[i,j] = log(R[j,i]) - log(p) - logYmean[j] + logXmean[i]\n  M_t &lt;- log(R) - log(p) -\n    outer(logYmean, rep(1, length(logXmean))) +\n    outer(rep(1, length(logYmean)), logXmean)\n  \n  t(M_t)\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#wass_lp",
    "href": "functions.html#wass_lp",
    "title": "4  Functions for Sequential Transport",
    "section": "4.6 wass_lp()",
    "text": "4.6 wass_lp()\n\n#' Solving the Optimal Transport Problem\n#'\n#' @description\n#' Finds the optimal transport plan using linear programming.\n#' In a first attempts, it uses `CVXR::solve` with the OSQP solver.\n#' If this fails, it uses `lpSolve::lp` instead.\n#' The function minimizes the transport cost while ensuring:\n#' * Mass conservation (row and column sums match the marginals).\n#' * Nonnegative transport flows.\n#'\n#' @param dxy Cost matrix of transport distances between points in X and Y.\n#' @param wx Weights (marginal distribution) for X.\n#' @param wy Weights (marginal distribution) for Y.\n#' @param p Order of the Wassterstein distance. (If p=2: squared Euclidean\n#'  cost).\n#'\n#' @importFrom CVXR Variable Minimize matrix_trace Problem solve\n#' @importFrom lpSolve lp\n#'\nwass_lp &lt;- function(dxy,\n                    wx,\n                    wy,\n                    p) {\n  cxy    &lt;- dxy\n  m      &lt;- length(wx)\n  ww_m   &lt;- matrix(wx, ncol = 1)\n  n      &lt;- length(wy)\n  ww_n   &lt;- matrix(wy, nrow = 1)\n  ones_m &lt;- matrix(rep(1, n), ncol = 1)\n  ones_n &lt;- matrix(rep(1, m), nrow = 1)\n  plan   &lt;- CVXR::Variable(m, n)\n  \n  wd.obj    &lt;- CVXR::Minimize(CVXR::matrix_trace(t(cxy) %*% plan))\n  wd.const1 &lt;- list(plan &gt;= 0)\n  wd.const2 &lt;- list(plan %*% ones_m == ww_m, ones_n %*% plan == ww_n)\n  wd.prob   &lt;- CVXR::Problem(wd.obj, c(wd.const1, wd.const2))\n  wd.solve  &lt;- CVXR::solve(wd.prob, solver = \"OSQP\")\n  \n  if (all(wd.solve$status==\"optimal\")) {\n    # successful\n    gamma &lt;- wd.solve$getValue(plan)\n    value &lt;- (base::sum(gamma * cxy))\n  } else {\n    # failed : use lpsolve\n    cxy &lt;- (dxy)\n    m   &lt;- nrow(cxy)\n    n   &lt;- ncol(cxy)\n    \n    c  &lt;- as.vector(cxy)\n    A1 &lt;- base::kronecker(matrix(1, nrow = 1, ncol = n), diag(m))\n    A2 &lt;- base::kronecker(diag(n), matrix(1, nrow = 1, ncol = m))\n    A  &lt;- rbind(A1, A2)\n    \n    f.obj &lt;- c\n    f.con &lt;- A\n    f.dir &lt;- rep(\"==\", nrow(A))\n    f.rhs &lt;- c(rep(1 / m, m), rep(1 / n, n))\n    f.sol &lt;- (lpSolve::lp(\"min\", f.obj, f.con, f.dir, f.rhs))\n    \n    gamma &lt;- matrix(f.sol$solution, nrow = m)\n    value &lt;- (sum(gamma*cxy)^(1 / p))\n  }\n  \n  list(distance = value, plan = gamma)\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#wass_lp_sinkhorn",
    "href": "functions.html#wass_lp_sinkhorn",
    "title": "4  Functions for Sequential Transport",
    "section": "4.7 wass_lp_sinkhorn()",
    "text": "4.7 wass_lp_sinkhorn()\n\n#' Solving the Optimal Transport Problem with Sinkhorn Penalty\n#'\n#' @description\n#' Finds the optimal transport plan using entropic regularization.\n#'\n#' @param dxy Cost matrix of transport distances between points in X and Y.\n#' @param wx Weights (marginal distribution) for X.\n#' @param wy Weights (marginal distribution) for Y.\n#' @param p Order of the Wassterstein distance. (If p=2: squared Euclidean\n#'  cost).\n#' @param A regularization parameter (default to 0.1).\n#'\n#' @importFrom T4transport sinkhornD\n#'\n#' @noRd\nwass_lp_sinkhorn &lt;- function(dxy, \n                             wx, \n                             wy, \n                             p = 2,\n                             lambda = 0.1) {\n  \n  stopifnot(all(abs(sum(wx) - 1) &lt; 1e-8), all(abs(sum(wy) - 1) &lt; 1e-8))\n  \n  # Compute transport plan via Sinkhorn algorithm\n  gamma &lt;- T4transport::sinkhornD(dxy, p = 2, wx = wx, wy = wy, lambda = lambda)\n  \n  list(distance = gamma$distance, plan = gamma$plan)\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#wass_lp_fast",
    "href": "functions.html#wass_lp_fast",
    "title": "4  Functions for Sequential Transport",
    "section": "4.8 wass_lp_fast()",
    "text": "4.8 wass_lp_fast()\n\n#' Solving the Optimal Transport Problem\n#'\n#' @description\n#' Finds the optimal transport plan using shortsimplex method.\n#'\n#' @param dxy Cost matrix of transport distances between points in X and Y.\n#' @param wx Weights (marginal distribution) for X.\n#' @param wy Weights (marginal distribution) for Y.\n#' @param p Order of the Wassterstein distance. (If p=2: squared Euclidean\n#'  cost).\n#'\n#' @importFrom transport transport\n#'\n#' @noRd\nwass_lp_fast &lt;- function(dxy, \n                         wx, \n                         wy, \n                         p = 2) {\n  \n  stopifnot(all(abs(sum(wx) - 1) &lt; 1e-8), all(abs(sum(wy) - 1) &lt; 1e-8))\n  \n  m &lt;- length(wx)\n  n &lt;- length(wy)\n  \n  # Convert dxy to a cost matrix (flattened)\n  cost &lt;- as.matrix(dxy)^p\n  \n  # Solve the OT problem (default method = \"shortsimplex\")\n  plan &lt;- transport::transport(wx, wy, costm = cost)\n  \n  # Convert transport plan (sparse format) to matrix\n  gamma &lt;- matrix(0, m, n)\n  for (i in seq_len(nrow(plan))) {\n    gamma[plan$from[i], plan$to[i]] &lt;- plan$mass[i]\n  }\n  \n  # Compute Wasserstein distance\n  value &lt;- sum(gamma * cost)^(1 / p)\n  \n  list(distance = value, plan = gamma)\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#valid_single_marginal",
    "href": "functions.html#valid_single_marginal",
    "title": "4  Functions for Sequential Transport",
    "section": "4.9 valid_single_marginal()",
    "text": "4.9 valid_single_marginal()\n\n#' Ensures that a weight vector (marginal distribution) is valid\n#'\n#' @description\n#' Returns a uniform weight if the provided vector if NULL. Otherwise, checks\n#' if the vector has length M and nonnegative entries, and if so, normalizes\n#' the vector of weights to sum to 1.\n#'\n#' @param mvec (Optional) Vector of weights.\n#' @param M Length of the weight vector.\n#' @param fname Name of the distance used (string).\n#' @noRd\nvalid_single_marginal &lt;- function(mvec, M, fname) {\n  \n  dname &lt;- paste0(\"'\", deparse(substitute(mvec)), \"'\")\n  if ((length(mvec) == 0) && is.null(mvec)) {\n    return(rep(1 / M, M))\n  } else {\n    mvec &lt;- as.vector(mvec)\n    if ((length(mvec) != M) || (any(mvec &lt; 0))) {\n      stop(\n        paste0(\n          \"* \", fname, \" : \", dname,\n          \" should be a nonnegative vector of length \", M, \".\"\n        )\n      )\n    }\n    return(mvec / base::sum(mvec))\n  }\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#wasserstein_simplex",
    "href": "functions.html#wasserstein_simplex",
    "title": "4  Functions for Sequential Transport",
    "section": "4.10 wasserstein_simplex()",
    "text": "4.10 wasserstein_simplex()\n\n#' Wasserstein distance between two sets of probability vectors X and Y\n#'\n#' @param X Matrix of probability vectors in a first group.\n#' @param Y Matrix of probability vectors in a second group.\n#' @param wx Weights (marginal distribution) for X. Default to `NULL` (uniform\n#' weights will be used).\n#' @param wy Weights (marginal distribution) for Y. Default to `NULL` (uniform\n#' weights will be used).\n#' @param method Either `\"shortsimplex\"`, `\"sinkhorn\"`, or `\"OSQP\"`.\n#' @param A regularization parameter (default to 0.1). Only if \n#'   `method = \"sinkhorn\"`.\n#'\n#' @returns A list with two elements:\n#' * `distance`: the Wassterstein distance\n#' * `plan`: the optimal transport plan describing how mass is transported\n#'   between X and Y.\n#' @export\nwasserstein_simplex &lt;- function(X,\n                                Y,\n                                wx = NULL,\n                                wy = NULL,\n                                method = c(\"shortsimplex\", \"sinkhorn\", \"OSQP\"),\n                                lambda = 0.1) {\n  \n  \n  method &lt;- match.arg(method)\n  \n  ## Check Inputs\n  if (is.vector(X)) {\n    X &lt;- matrix(X, ncol = 1)\n  }\n  if (is.vector(Y)) {\n    Y &lt;- matrix(Y, ncol = 1)\n  }\n  if (!is.matrix(X)) { stop(\"* wasserstein : input 'X' should be a matrix.\") }\n  if (!is.matrix(Y)) { stop(\"* wasserstein : input 'Y' should be a matrix.\") }\n  if (base::ncol(X) != base::ncol(Y)){\n    stop(\"* wasserstein : input 'X' and 'Y' should be of same dimension.\")\n  }\n  \n  # Number of observation in each matrix\n  m &lt;- base::nrow(X)\n  n &lt;- base::nrow(Y)\n  \n  wxname &lt;-  paste0(\"'\", deparse(substitute(wx)), \"'\")\n  wyname &lt;- paste0(\"'\", deparse(substitute(wy)), \"'\")\n  fname  &lt;- \"wasserstein\"\n  \n  # Weight normalization\n  par_wx &lt;- valid_single_marginal(wx, m, fname)\n  par_wy &lt;- valid_single_marginal(wy, n, fname)\n  \n  # Cost matrix\n  dist_mat  &lt;- compute_pdist_simplex_fast(X, Y)\n  \n  # Solve the optimal transport problem\n  if (method == \"shortsimplex\") {\n    return(wass_lp_fast(dxy = dist_mat, wx = par_wx, wy = par_wy, p = 2))\n  } else if (method == \"OSQP\") {\n    return(wass_lp(dxy = dist_mat, wx = par_wx, wy = par_wy, p = 2))\n  } else {\n    return(\n      wass_lp_sinkhorn(\n        dxy = dist_mat, wx = par_wx, wy = par_wy, \n        p = 2, lambda = lambda\n      )\n    )\n  }\n  \n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#causal_effects_cf",
    "href": "functions.html#causal_effects_cf",
    "title": "4  Functions for Sequential Transport",
    "section": "4.11 causal_effects_cf()",
    "text": "4.11 causal_effects_cf()\n\n#' Estimation of total causal effect using counterfactuals.\n#' \n#' @param data_untreated Dataset with the untreated units only.\n#' @param data_treated Dataset with the treated units only.\n#' @param data_cf_untreated Counterfactuals for untreated had they been treated.\n#' @param data_cf_treated Counterfactuals for treated had they been untreated.\n#' @param Y_name Name of the column with the outcome variable.\n#' @param A_name Name of the column with the treatment variable.\n#' @param A_untreated Value of the treatment for the untreated units.\n#' \n#' @returns A list:\n#' - `delta_0_i`: \\eqn{\\delta_(0)}, individual causal mediation effects for \n#'   \\eqn{a=0} (computed on untreated),\n#' - `delta_0`: \\eqn{\\bar{\\delta}(0)}, average causal mediation effect for \n#'   \\eqn{a=0} (computed on untreated),\n#' - `delta_1_i`: \\eqn{\\delta_(1)}, individual causal mediation effects for \n#'   \\eqn{a=1} (computed on treated),\n#' - `delta_1`: \\eqn{\\bar{\\delta}(1)}, average causal mediation effect for \n#'   \\eqn{a=1} (computed on treated),\n#' - `zeta_0_i`: \\eqn{\\zeta_(0)}, individual causal mediation effects for \n#'   \\eqn{a=0} (computed on treaded),\n#' - `zeta_0`: \\eqn{\\bar{\\zeta}(0)}, average causal mediation effect for \n#'   \\eqn{a=0} (computed on treated),\n#' - `zeta_1_i`: \\eqn{\\zeta_(1)}, individual causal mediation effects for \n#'   \\eqn{a=1} (computed on untreaded),\n#' - `zeta_1`: \\eqn{\\bar{\\zeta}(1)}, average causal mediation effect for \n#'   \\eqn{a=1} (computed on untreated),\n#' - `tot_effect`: \\eqb{\\tau}: average total effect (\\eqn{\\bar{\\delta}(0) + \n#'   \\bar{\\zeta}(1)}).\n#'\n#' @importFrom randomForest randomForest\n#' @importFrom dplyr pull select\n#' @importFrom stats predict\n#' @md\ncausal_effects_cf &lt;- function(data_untreated,\n                              data_treated,\n                              data_cf_untreated = NULL,\n                              data_cf_treated = NULL,\n                              Y_name,\n                              A_name,\n                              A_untreated) {\n  \n  if (is.null(data_cf_untreated) & is.null(data_cf_treated))\n    stop(\"Counterfactuals needed for at least one group.\")\n  \n  n_untreated &lt;- nrow(data_untreated)\n  n_treated &lt;- nrow(data_treated)\n  \n  # Outcome model for untreated\n  mu_untreated_model &lt;- randomForest(\n    x = data_untreated |&gt; dplyr::select(-!!Y_name, -!!A_name),\n    y = pull(data_untreated, !!Y_name)\n  )\n  \n  # Outcome model for treated\n  mu_treated_model &lt;- randomForest(\n    x = data_treated |&gt; dplyr::select(-!!Y_name, -!!A_name),\n    y = pull(data_treated, !!Y_name)\n  )\n  \n  # Observed outcome\n  y_untreated_obs &lt;- data_untreated |&gt; pull(!!Y_name)\n  y_treated_obs &lt;- data_treated |&gt; pull(!!Y_name)\n  \n  \n  if (!is.null(data_cf_untreated)) {\n    # Natural Indirect Effect, using predictions\n    delta_0_i &lt;- predict(mu_untreated_model, newdata = data_cf_untreated) -\n      predict(mu_untreated_model)\n    delta_0 &lt;- mean(delta_0_i)\n    \n    # Natural Indirect Effect, using observed variables\n    delta_0_i_obs &lt;- predict(mu_untreated_model, newdata = data_cf_untreated) - \n      y_untreated_obs\n    delta_0_obs &lt;- mean(delta_0_i_obs)\n    \n    # Natural Direct Effect (only predictions)\n    zeta_1_i &lt;- predict(mu_treated_model, newdata = data_cf_untreated) - \n      predict(mu_untreated_model, newdata = data_cf_untreated)\n    zeta_1 &lt;- mean(zeta_1_i)\n    \n    # Total Causal Effect\n    tot_effect &lt;- delta_0 + zeta_1  \n    tot_effect_obs &lt;- delta_0_obs + zeta_1\n  } else {\n    delta_0_i &lt;- NULL\n    delta_0 &lt;- NULL\n    delta_0_i_obs &lt;- NULL\n    delta_0_obs &lt;- NULL\n    zeta_1_i &lt;- NULL\n    zeta_1 &lt;- NULL\n  }\n  \n  if (!is.null(data_cf_treated)) {\n    # Natural Indirect Effect, using predictions\n    delta_1_i &lt;- predict(mu_treated_model) - \n      predict(mu_treated_model, newdata = data_cf_treated)\n    delta_1 &lt;- mean(delta_1_i)\n    # Natural Indirect Effect, using observed variables\n    delta_1_i_obs &lt;- y_treated_obs - \n      predict(mu_treated_model, newdata = data_cf_treated)\n    delta_1_obs &lt;- mean(delta_1_i_obs)\n    # Natural Direct Effect (only predictions)\n    zeta_0_i &lt;- predict(mu_treated_model, newdata = data_cf_treated) -\n      predict(mu_untreated_model, newdata = data_cf_treated)\n    zeta_0 &lt;- mean(zeta_0_i)\n    # Total Causal Effect\n    tot_effect &lt;- delta_1 + zeta_0\n    tot_effect_obs &lt;- delta_1_obs + zeta_0\n  } else {\n    delta_1_i &lt;- NULL\n    delta_1 &lt;- NULL\n    delta_1_i_obs &lt;- NULL\n    delta_1_obs &lt;- NULL\n    zeta_0_i &lt;- NULL\n    zeta_0 &lt;- NULL\n  }\n  \n  list(\n    delta_0_i = delta_0_i,\n    delta_1_i = delta_1_i,\n    zeta_0_i = zeta_0_i,\n    zeta_1_i = zeta_1_i,\n    delta_0_i_obs = delta_0_i_obs,\n    delta_1_i_obs = delta_1_i_obs,\n    delta_0 = delta_0,\n    delta_1 = delta_1,\n    zeta_0 = zeta_0,\n    zeta_1 = zeta_1,\n    delta_0_obs = delta_0_obs,\n    delta_1_obs = delta_1_obs,\n    tot_effect = tot_effect,\n    tot_effect_obs = tot_effect_obs\n  )\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#optimal_transport_cf",
    "href": "functions.html#optimal_transport_cf",
    "title": "4  Functions for Sequential Transport",
    "section": "4.12 optimal_transport_cf()",
    "text": "4.12 optimal_transport_cf()\n\n#' Empirical and Multivariate Optimal Transport.\n#' \n#' @param data Dataset with all units (treated and untreated).\n#' @param Y_name Name of the column with the outcome variable.\n#' @param A_name Name of the column with the treatment variable.\n#' @param A_untreated Value of the treatment for the untreated units.\n#' @param pen Value of the Sinkhorn regularization parameter. \n#' If `NULL` (default value), classical Optimal Transport algorithm is applied.\n#' \n#' @returns A tibble:\n#' `data_transported`: it contains the transported mediator variables for the \n#' untreated group.\n#'\n#' @importFrom dplyr mutate select across replace\n#' @importFrom stats predict\n#' @md\noptimal_transport_cf &lt;- function(data,\n                                 Y_name,\n                                 A_name,\n                                 A_untreated,\n                                 pen = NULL) {\n  # Settings to apply Optimal Transport\n  A &lt;- data[[A_name]]\n  ind_untreated &lt;- which(A == A_untreated)\n  data_untreated &lt;- data[ind_untreated, ]\n  data_treated &lt;- data[-ind_untreated, ]\n  data_untreated_wo_A &lt;- data_untreated[ , !(names(data_untreated) %in% A_name)]\n  data_treated_wo_A &lt;- data_treated[ , !(names(data_treated) %in% A_name)]\n  n0 &lt;- nrow(data_untreated_wo_A)\n  n1 &lt;- nrow(data_treated_wo_A)\n  X0 &lt;- data_untreated_wo_A[ , !(names(data_untreated_wo_A) %in% Y_name)]\n  X1 &lt;- data_treated_wo_A[ , !(names(data_treated_wo_A) %in% Y_name)]\n  \n  # One-hot categorical variables\n  num_cols &lt;- names(X0)[sapply(X0, is.numeric)]\n  cat_cols &lt;- names(X0)[sapply(X0, function(col) is.factor(col) || is.character(col))]\n  X0_num &lt;- X0[ , num_cols]\n  X1_num &lt;- X1[ , num_cols]\n  X0_cat &lt;- X0[ , cat_cols]\n  X1_cat &lt;- X1[ , cat_cols]\n  cat_counts &lt;- sapply(X0[ , cat_cols], function(col) length(unique(col)))\n  X0_cat_encoded &lt;- list()\n  X1_cat_encoded &lt;- list()\n  for (col in cat_cols) {\n    # One-hot encoding with dummyVars\n    formula &lt;- as.formula(paste(\"~\", col))\n    dummies &lt;- caret::dummyVars(formula, data = X0_cat)\n    \n    # Dummy variable\n    dummy_0 &lt;- predict(dummies, newdata = X0_cat) |&gt; as.data.frame()\n    dummy_1 &lt;- predict(dummies, newdata = X1_cat) |&gt; as.data.frame()\n    \n    # Scaling\n    dummy_0_scaled &lt;- scale(dummy_0)\n    dummy_1_scaled &lt;- scale(dummy_1)\n    \n    dummy_0_df &lt;- as.data.frame(dummy_0_scaled)\n    dummy_1_df &lt;- as.data.frame(dummy_1_scaled)\n    \n    # Align categories in both treated/untreated groups\n    all_cols &lt;- union(colnames(dummy_0_df), colnames(dummy_1_df))\n    dummy_0_df &lt;- dummy_0_df |&gt; \n      mutate(across(.fns = identity)) |&gt; \n      select(all_of(all_cols)) %&gt;% \n      replace(is.na(.), 0)\n    \n    dummy_1_df &lt;- dummy_1_df |&gt; \n      mutate(across(.fns = identity)) |&gt; \n      select(all_of(all_cols)) %&gt;% \n      replace(is.na(.), 0)\n    \n    # Save in lists\n    X0_cat_encoded[[col]] &lt;- dummy_0_df\n    X1_cat_encoded[[col]] &lt;- dummy_1_df\n  }\n  \n  # Calculate Euclidean and Hamming distances for both numeric and categorical variables\n  num_dist &lt;- proxy::dist(x = X0_num, y = X1_num, method = \"Euclidean\")\n  num_dist &lt;- as.matrix(num_dist)\n  \n  cat_dists &lt;- list()\n  for (col in cat_cols) {\n    mat_0 &lt;- as.matrix(X0_cat_encoded[[col]])\n    mat_1 &lt;- as.matrix(X1_cat_encoded[[col]])\n    dist_mat &lt;- proxy::dist(x = mat_0, y = mat_1, method = \"Euclidean\")\n    cat_dists[[col]] &lt;- as.matrix(dist_mat)\n  }\n  \n  # Final cost matrix for OT optim. problem\n  combined_cost &lt;- num_dist\n  for (i in seq_along(cat_dists)) {\n    combined_cost &lt;- combined_cost + cat_dists[[i]]\n  }\n  \n  # Uniform weights (equal mass)\n  w0 &lt;- rep(1 / n0, n0)\n  w1 &lt;- rep(1 / n1, n1)\n  # Compute transport plan\n  \n  if (is.null(pen)) {\n    transport_res &lt;- transport::transport(\n      a = w0,\n      b = w1,\n      costm = combined_cost,\n      method = \"shortsimplex\"\n    )\n    \n    transport_plan &lt;- matrix(0, nrow = n0, ncol = n1)\n    for(i in seq_len(nrow(transport_res))) {\n      transport_plan[transport_res$from[i], transport_res$to[i]] &lt;- transport_res$mass[i]\n    }\n  } else {\n    transport_res &lt;- T4transport::sinkhornD(\n      combined_cost, wx = w0, wy = w1, lambda = pen\n    )\n    transport_plan &lt;- transport_res$plan\n  }\n  \n  # Transport the numerical variables\n  num_transported &lt;- n0 * (transport_plan %*% as.matrix(X1_num))\n  # Transport the categorical variables\n  cat_transported &lt;- list()\n  for (col in cat_cols) {\n    cat_probs &lt;- transport_plan %*% as.matrix(X1_cat_encoded[[col]])\n    cat_encoded_columns &lt;- colnames(X1_cat_encoded[[col]])\n    # For each obs., we take the index with the maximum value (approx. proba)\n    max_indices &lt;- apply(cat_probs, 1, which.max)\n    prefix_pattern &lt;- paste0(\"^\", col, \"\\\\.\")\n    cat_transported[[col]] &lt;- sapply(max_indices, function(x) sub(prefix_pattern, \"\", cat_encoded_columns[x]))\n  }\n  data_transported &lt;- as_tibble(num_transported)\n  for (col in cat_cols) {\n    data_transported[[col]] &lt;- cat_transported[[col]]\n  }\n  \n  data_transported\n}\n\n\n\n\n\nFernandes Machado, Agathe, Arthur Charpentier, and Ewen Gallic. 2025a. “Optimal Transport on Categorical Data for Counterfactuals Using Compositional Data and Dirichlet Transport.” https://arxiv.org/abs/2501.15549.\n\n\n———. 2025b. “Sequential Conditional Transport on Probabilistic Graphs for Interpretable Counterfactual Fairness.” Proceedings of the AAAI Conference on Artificial Intelligence 39 (18): 19358–66. https://doi.org/10.1609/aaai.v39i18.34131.",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "gaussian-example.html",
    "href": "gaussian-example.html",
    "title": "5  Gaussian Example",
    "section": "",
    "text": "5.1 Data Generating Process\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colGpe1}{RGB}{0, 160, 138}\n\\definecolor{colGpe0}{RGB}{242, 173, 0}\n\\]\nWe want to simulate potential outcomes in a binary treatment setting, with covariate shift between treatment groups.\nLet \\(n=500\\) denote the number of individuals (or unit), and let \\(\\boldsymbol{X}=(X_1,X_2)\\) be drawn from bivariate normal distrubtions whose mean vectors and covariance matrices depend on the treatment assignment \\(A\\in\\{0,1\\}\\).\nFor untreated individuals (\\(A=\\color{colGpe0}0\\)) the covariates \\(\\boldsymbol{X}^{(0)} = (X_1{(0)}, X_2{(0)})\\) are sampled from a \\(\\mathcal{N}(\\mu_0, \\Sigma_0)\\), where \\(\\mu_0 = -1\\), \\(\\Sigma_0 = \\begin{pmatrix} 1 & r_0 \\\\ r_0 & 1 \\end{pmatrix}\\) with \\(r_0 = 0.7\\).\nFor treated individuals (\\(A=\\color{colGpe1}1\\)), covariates \\(\\boldsymbol{X}{(1)} = (X_1{(1)}, X_2{(1)})\\) follow a \\(\\mathcal{N}(\\mu_1, \\Sigma_1)\\), where \\(\\mu_1 = +1\\), \\(\\Sigma_1 = \\begin{pmatrix} 1 & r_1 \\\\ r_1 & 1 \\end{pmatrix}\\) with \\(r_1 = -0.5\\).\nThe treatment assignment \\(A\\) is randomized with probability \\(p_1 = 0.5\\).\nThe potential outcomes are linear functions of the covariates: \\[\n\\begin{aligned}\nY(0) &= a_1 X_1 + a_2 X_2 + \\varepsilon,\\\\\nY(1) &= a_1 X_1 + a_2 X_2 + a_0 + \\varepsilon .\n\\end{aligned}\n\\]\nwhere \\(\\varepsilon \\sim \\mathcal{N}(0, 1)\\) and \\(a_0 = 3\\), \\(a_1 = 2\\), \\(a_2 = -1.5\\).\nThe observed outcome is \\[Y = A \\cdot Y(1) + (1 - A) \\cdot Y(0).\\]\nset.seed(12345)\n# Parameters\nn &lt;- 500\nmu0 &lt;- -1\nmu1 &lt;- +1\nr0 &lt;- +.7\nr1 &lt;- -.5\na &lt;- 1\na0 &lt;-  3\na1 &lt;-  2\na2 &lt;-  -1.5\np1 &lt;- .5\nMu0 &lt;- rep(mu0, 2)\nMu1 &lt;- rep(mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Draw covariates\nX0 &lt;- rmnorm(n, mean = a * Mu0, varcov = Sig0)\nX1 &lt;- rmnorm(n, mean = a * Mu1, varcov = Sig1)\n# Random noise\nE &lt;- rnorm(n)\n# Binary treatment\nA &lt;- sample(0:1, size = n, replace = TRUE, prob = c(1 - p1, p1))\n\nX &lt;- X0\nX[A==1, ] = X1[A==1, ]\n\ndf &lt;- tibble(\n  X1 = X[, 1],\n  X2 = X[, 2],\n  A = A,\n  Y0 = a1 * X1 + a2 * X2 + E,\n  Y1 = a1 * X1 + a2 * X2 + a0 + E,\n  Y = A * Y1 + (1-A) * Y0\n)\nWe define a function to wrap this DGP.\nThe gen_data() function.\n#' @param n Number of units.\n#' @param mu0 Mean of the two covariates in group 0.\n#' @param mu1 Mean of the two covariates in group 1.\n#' @param r0 Covariance of the two covariates in group 0.\n#' @param r1 Covariance of the two covariates in group 1.\n#' @parma a Shift parameter for the mean in both groups\n#'  (default to 1: no shift). Larger values decreases overlapping.\ngen_data &lt;- function(n = 500,\n                     mu0 = -1,\n                     mu1 = +1,\n                     r0 = +.7,\n                     r1 = -.5,\n                     a = 1,\n                     seed = NULL) {\n  \n  if (!is.null(seed)) set.seed(seed)\n  \n  a0 &lt;-  3\n  a1 &lt;-  2\n  a2 &lt;-  -1.5\n  p1 &lt;- .5\n  Mu0 &lt;- rep(mu0, 2)\n  Mu1 &lt;- rep(mu1, 2)\n  Sig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\n  Sig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n  # Draw covariates\n  X0 &lt;- rmnorm(n, mean = a * Mu0, varcov = Sig0)\n  X1 &lt;- rmnorm(n, mean = a * Mu1, varcov = Sig1)\n  # Random noise\n  E &lt;- rnorm(n)\n  # Binary treatment\n  A &lt;- sample(0:1, size = n, replace = TRUE, prob = c(1 - p1, p1))\n  X &lt;- X0\n  X[A==1, ] = X1[A==1, ]\n  df &lt;- tibble(\n    X1 = X[, 1],\n    X2 = X[, 2],\n    A = A,\n    Y0 = a1 * X1 + a2 * X2 + E,\n    Y1 = a1 * X1 + a2 * X2 + a0 + E,\n    Y = A * Y1 + (1-A) * Y0\n  )\n  \n  df\n}",
    "crumbs": [
      "II. A Gaussian Example",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Gaussian Example</span>"
    ]
  },
  {
    "objectID": "gaussian-example.html#sec-dgp",
    "href": "gaussian-example.html#sec-dgp",
    "title": "5  Gaussian Example",
    "section": "",
    "text": "Natural Indirect Effect\n\n\n\nHere, with the current DGP, we have: \\[\n\\begin{cases}\n  \\delta_i(0) = a_1(X_{1,i}(1) - X_{1,i}(0)) + a_2(X_{2,i}(1)-X_{2,i}(0))\\\\\n  \\delta_i(1) = a_1(X_{1,i}(1) - X_{1,i}(0)) + a_2(X_{2,i}(1)-X_{2,i}(0))\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n\nAverage Natural Indirect Effect\n\n\n\nHere, we have:\n\\[\n\\begin{cases}\n  \\bar{\\delta}(0) = (a_1+a2)(\\mu_1-\\mu_0)\\\\\n  \\bar{\\delta}(1) = (a_1+a2)(\\mu_1-\\mu_0)\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n\nNatural Direct Effect\n\n\n\nHere, we have:\n\\[\n\\begin{cases}\n  \\zeta_i{(0)} = a_0\\\\\n  \\zeta_i{(1)} = a_0\\\\\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n\nTotal Causal Effect\n\n\n\nHere, we have:\n\\[\n\\tau_i = a_1(X_{1,i}(1) - X_{1,i}(0)) + a_2(X_{2,i}(1)-X_{2,i}(0)) + a_0\n\\] and\n\\[\n\\bar{\\delta}=(a_1+a_2)(\\mu_1-\\mu_0) + a0\n\\]",
    "crumbs": [
      "II. A Gaussian Example",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Gaussian Example</span>"
    ]
  },
  {
    "objectID": "gaussian-example.html#sec-cf",
    "href": "gaussian-example.html#sec-cf",
    "title": "5  Gaussian Example",
    "section": "5.2 Counterfactuals",
    "text": "5.2 Counterfactuals\nLet us build counterfactuals for individuals from group 0, and for individuals from group 1. We will consider the following methods:\n\nMultivariate Optimal Transport (since we know the parameters of the two Gaussians),\nRegularized transport using Sinkhorn algorithm,\nSequential Optimal Transport.\n\n\n5.2.1 Optimal Transport\n\nlibrary(expm)\n\nGiven two collection of points \\(\\{\\boldsymbol{x}_{0,1},\\cdots,\\boldsymbol{x}_{0,n_0}\\}\\) and \\(\\{\\boldsymbol{x}_{1,1},\\cdots,\\boldsymbol{x}_{1,n_1}\\}\\) in \\(\\mathcal{X}_0\\) and \\(\\mathcal{X}_1\\), and a cost \\(c:\\mathcal{X}_0\\times\\mathcal{X}_1\\to\\mathbb{R}_+\\), define the cost matrix, \\(n_0\\times n_1\\), \\(\\boldsymbol{C}:=[C_{i,j}]\\) where \\(C_{i,j}=c(\\boldsymbol{x}_{0,i},\\boldsymbol{x}_{1,j})\\). The optimal matching problem is [ {({n_0},{n_1})} ,,,,, ={i=1}^{n_0}{j=1}^{n_1}P{ij},C_{ij}, ] where \\(\\mathcal{U}(\\boldsymbol{1}_{n_0},\\boldsymbol{1}_{n_1})\\) is the polytope [ {,P+^{n_0n_1}: P,{n_1}=,  P^_{n_0}= }. ]\nHere, in the Gaussian case, the optimal transport map \\(T(x)\\) from \\(\\mathcal{N}(\\boldsymbol{\\mu}_0, \\boldsymbol{\\Sigma}_0)\\) to \\(\\mathcal{N}(\\boldsymbol{\\mu}_1, \\boldsymbol{\\Sigma}_1)\\) is: \\[T(x) = \\boldsymbol{\\mu}_1 + \\boldsymbol{A}(x - \\boldsymbol{\\mu}_0)\\] where: \\[\n\\boldsymbol{A} = \\boldsymbol{\\Sigma}_0^{1/2}\n       \\left( \\boldsymbol{\\Sigma}_0^{1/2} \\boldsymbol{\\Sigma}_1 \\boldsymbol{\\Sigma}_0^{1/2} \\right)^{-1/2}\n      \\boldsymbol{\\Sigma}_0^{1/2}\n\\]\nWe define the function compute_ot_map() to compute the optimal mapping.\n\n#' Optimal transport mapping between two Gaussian distributions \n#'  (from \\eqn{\\mathcal{N}(\\mu_{\\text{source}}, \\Sigma_{\\text{source}})} to \n#'   \\eqn{\\mathcal{N}(\\mu_{\\text{target}}, \\Sigma_{\\text{target}})})\n#'  \n#' @param mu_source Mean vector of the source Gaussian.\n#' @param sigma_source Covariance matrix of the source Gaussian.\n#' @param mu_target Mean vector of the target Gaussian.\n#' @param sigma_target Covariance matrix of the target Gaussian.\ncompute_ot_map &lt;- function(mu_source, sigma_source, mu_target, sigma_target) {\n  sqrt_sigma_source &lt;- sqrtm(sigma_source)\n  sqrt_sigma_source_inv &lt;- solve(sqrt_sigma_source)\n  \n  inner &lt;- sqrt_sigma_source %*% sigma_target %*% sqrt_sigma_source\n  sqrt_inner &lt;- sqrtm(inner)\n  \n  A &lt;- sqrt_sigma_source_inv %*% sqrt_inner %*% sqrt_sigma_source_inv\n  \n  list(A = A, shift = mu_target - A %*% mu_source)\n}\n\nWe also define the apply_ot_transport() function which uses a transport plan to transport individuals.\n\n#' Function to apply the transport map to simulated data\n#' \n#' @param X Observations to transport.\n#' @param mapping Optimal transport mapping (from `compute_ot_map()`)?\napply_ot_transport &lt;- function(X, mapping) {\n  A &lt;- mapping$A\n  shift &lt;- mapping$shift\n  t(apply(X, 1, function(x) as.vector(shift + A %*% x)))\n}\n\nSince we generated the data, we know the exact transport plan to transport individuals from group 0 to group 1. We also know the exact transport plan to transport individuals from group 1 to group 0.\n\nSigma0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSigma1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\n# Mapping from group 0 to group 1\not_map_0_to_1 &lt;- compute_ot_map(\n  mu_source = Mu0, sigma_source = Sigma0, \n  mu_target = Mu1, sigma_target = Sigma1\n)\n# Mapping from group 1 to group 0\not_map_1_to_0 &lt;- compute_ot_map(\n  mu_source = Mu1, sigma_source = Sigma1, \n  mu_target = Mu0, sigma_target = Sigma0\n)\n\nWe apply the transport map to the untreated units (A = 0).\n\nX0 &lt;- as.matrix(df[df$A == 0, c(\"X1\", \"X2\")])\nX0_t &lt;- apply_ot_transport(X = X0, mapping = ot_map_0_to_1)\ncolnames(X0_t) &lt;- c(c(\"X1\", \"X2\"))\n\nAnd to the transport map to the treated units (A = 1).\n\nX1 &lt;- as.matrix(df[df$A == 1, c(\"X1\", \"X2\")])\nX1_t &lt;- apply_ot_transport(X = X1, mapping = ot_map_1_to_0)\ncolnames(X1_t) &lt;- c(c(\"X1\", \"X2\"))\n\nLet us visualize the transported individuals. First, we define the function draw_ellipse() which will allow us to plot the 95% confidence ellipse in both groups.\n\n\nThe draw_ellipse() function.\ndraw_ellipse &lt;- function(mu, \n                         sigma, \n                         col = \"black\", \n                         lty = 1, \n                         lwd = 1, \n                         level = 0.95, \n                         ...) {\n  \n  angles &lt;- seq(0, 2 * pi, length.out = 100)\n  vals &lt;- sqrt(\n    qchisq(level, df = 2)) * t(chol(sigma)) %*% rbind(cos(angles), sin(angles)\n    )\n  lines(mu[1] + vals[1, ], mu[2] + vals[2, ], col = col, lty = lty, lwd = lwd, ...)\n  \n}\n\n\nWe isolate the observations from group 0 and from group 1.\n\n# Prepare data for the plot\nX0 &lt;- df[df$A == 0, c(\"X1\", \"X2\")]\nX1 &lt;- df[df$A == 1, c(\"X1\", \"X2\")]\n\nThe initial points and the transported values are shown in Figure 5.1\n\n\nCodes to create the Figure.\npar(mar = c(2.1, 2.1, 2.1, 0.1), mfrow = c(1, 2))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\n\n# From 0 to 1\nplot(X0, \n     pch = 16, \n     col = adjustcolor(colGpe0, alpha = .3), \n     xlim = x_lim, ylim = y_lim, \n     xlab = \"\", ylab = \"\",\n     main = \"OT: from A=0 to A=1\",\n     family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X0_t, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0$X1, y0 = X0$X2,\n  x1 = X0_t[, 1], y1 = X0_t[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Covariance of transported points (via OT map)\nSigma0_transport &lt;- ot_map_0_to_1$A %*% Sig0 %*% t(ot_map_0_to_1$A)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\ndraw_ellipse(Mu1, Sigma0_transport, col = colGpet, lty = 2)\n\n# From 1 to 0\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"OT: from A=1 to A=0\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X1_t, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X1$X1, y0 = X1$X2,\n  x1 = X1_t[, 1], y1 = X1_t[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Covariance of transported points (via OT map)\nSigma0_transport &lt;- ot_map_1_to_0$A %*% Sig1 %*% t(ot_map_1_to_0$A)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\ndraw_ellipse(Mu0, Sigma0_transport, col = colGpet, lty = 2)\n\n\n\n\n\nFigure 5.1: 500 points in each group drawn from bivariates Gaussian distributions and transported values from group 0 to group 1 (left), and from group 1 to group 0 (right), using optimal transport.\n\n\n\n\n\n\n\n\n\n\n5.2.2 Transport-based Many-to-1 Matching\nLe us se optimal transport to perform transport-based optimal many-to-1 matching. We use optimal transport with a uniform source and target distribution. For each unit from the source group (group~0), we select the matched unit from the target group (group~1) as the one wit the maximum transported mass. This way, each unit in the source is matched to exactly one in the target.\n\n\nThe transport_many_to_one() function.\n#' @param X_source Source characteristics\n#' @param X_target Target characteristics\n#' @param method Algorithm to use for transport\ntransport_many_to_one &lt;- function(X_source, \n                                  X_target, \n                                  method = \"shortsimplex\") {\n  n_source &lt;- nrow(X_source)\n  n_target &lt;- nrow(X_target)\n  \n  # Uniform weights\n  w_source &lt;- rep(1 / n_source, n_source)\n  w_target &lt;- rep(1 / n_target, n_target)\n  \n  # Cost matrix\n  cost &lt;- as.matrix(dist(rbind(X_source, X_target)))\n  cost &lt;- cost[1:n_source, (n_source + 1):(n_source + n_target)]\n  \n  # Solve OT plan\n  ot_plan &lt;- transport::transport(\n    w_source, w_target, costm = cost, method = method\n  )\n  \n  # For each source unit, select the target with the highest mass\n  best_match &lt;- ot_plan |&gt;\n    dplyr::group_by(from) |&gt;\n    dplyr::slice_max(mass, n = 1, with_ties = FALSE) |&gt;\n    dplyr::ungroup()\n  \n  # Matched matrix\n  X_matched &lt;- X_target[best_match$to, , drop = FALSE]\n  \n  X_matched\n}\n\n\nLet us apply the transport_many_to_one() function to get the counterfactuals in both group.\n\nX0 &lt;- as.matrix(df[df$A == 0, c(\"X1\", \"X2\")])\nX1 &lt;- as.matrix(df[df$A == 1, c(\"X1\", \"X2\")])\nX0_tmatch &lt;- transport_many_to_one(X_source = X0, X_target = X1)\nX1_tmatch &lt;- transport_many_to_one(X_source = X1, X_target = X0)\n\n\n\nCodes to create the Figure.\npar(mar = c(2.1, 2.1, 2.1, 0.1), mfrow = c(1, 2))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\n\n# From 0 to 1\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"Matching: from A=0 to A=1\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X0_tmatch, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0[, \"X1\"], y0 = X0[, \"X2\"],\n  x1 = X0_tmatch[, 1], y1 = X0_tmatch[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n# From 1 to 0\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"Matching: from A=1 to A=0\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X1_tmatch, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X1[, \"X1\"], y0 = X1[, \"X2\"],\n  x1 = X1_tmatch[, 1], y1 = X1_tmatch[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n\n\n\nFigure 5.2: 500 points in each group drawn from bivariates Gaussian distributions and transported values from group 0 to group 1 (left), and from group 1 to group 0 (right), using transport-based many-to-one matching.\n\n\n\n\n\n\n\n\n\n\n5.2.3 Soft Matching\nLet us now turn to optimal transport–based matching where each unit is matched to a weighted combination of units in the other group. This allows us to produce synthetic treated units by assigning weights that sum to 1.\n\nX0 &lt;- as.matrix(df[df$A == 0, c(\"X1\", \"X2\")])\nX1 &lt;- as.matrix(df[df$A == 1, c(\"X1\", \"X2\")])\nn_0 &lt;- nrow(X0)\nn_1 &lt;- nrow(X1)\n\nLet us use uniform weights:\n\nw_0 &lt;- rep(1 / n_0, n_0)\nw_1 &lt;- rep(1 / n_1, n_1)\n\nWe use the Euclidean distance between units as costs.\n\ncost &lt;- as.matrix(dist(rbind(X0, X1)))\ncost &lt;- cost[1:n_0, (n_0 + 1):(n_0 + n_1)]\n\nLet us solve the optimal transport problem to transport units from group~0 to group~1.\n\not_plan &lt;- transport::transport(\n  w_0, w_1, costm = cost, method = \"shortsimplex\"\n)\n\nWe can then use the mapping to create synthetic individuals in group~1. We use the weights given in the mapping to create the synthetic units as fractions of the other points.\n\not_plan &lt;- ot_plan |&gt; group_by(from) |&gt; mutate(weight = mass / sum(mass))\nassignment &lt;- rep(NA, n_0)\n\nX0_sm &lt;- ot_plan |&gt; \n  left_join(\n    as_tibble(X1) |&gt; mutate(to = row_number()),\n    by = \"to\"\n  ) |&gt; \n  mutate(\n    across(colnames(X1), ~.x * weight)\n  ) |&gt; \n  group_by(from) |&gt; \n  summarise(across(colnames(X1), ~ sum(.x))) |&gt; \n  arrange(from) |&gt; \n  select(-from) |&gt; \n  as.matrix()\n\nLet us create a function, soft_match() to wrap-up the previous codes.\n\n\nThe soft_match() function.\n#' @param X_source Source characteristics\n#' @param X_target Target characteristics\n#' @param method Algorithm to use for transport\nsoft_match &lt;- function(X_source, \n                       X_target, \n                       method = \"shortsimplex\") {\n  \n  n_source &lt;- nrow(X_source)\n  n_target &lt;- nrow(X_target)\n  \n  # Uniform weights\n  w_source &lt;- rep(1 / n_source, n_source)\n  w_target &lt;- rep(1 / n_target, n_target)\n  \n  # Compute cost matrix (Euclidean distances)\n  cost &lt;- as.matrix(dist(rbind(X_source, X_target)))\n  cost &lt;- cost[1:n_source, (n_source + 1):(n_source + n_target)]\n  \n  # Solve OT problem\n  ot_plan &lt;- transport::transport(\n    w_source, w_target, costm = cost, method = method\n  )\n  \n  # Normalize weights per source unit\n  ot_plan &lt;- dplyr::group_by(ot_plan, from)\n  ot_plan &lt;- dplyr::mutate(ot_plan, weight = mass / sum(mass))\n  \n  # Build transported covariates\n  X_target_tbl &lt;- tibble::as_tibble(X_target) |&gt;\n    dplyr::mutate(to = dplyr::row_number())\n  \n  X_sm &lt;- ot_plan |&gt;\n    dplyr::left_join(X_target_tbl, by = \"to\") |&gt;\n    dplyr::mutate(\n      dplyr::across(colnames(X_target), ~ .x * weight)\n    ) |&gt;\n    dplyr::group_by(from) |&gt;\n    dplyr::summarise(\n      dplyr::across(colnames(X_target), sum),\n      .groups = \"drop\"\n    ) |&gt;\n    dplyr::arrange(from) |&gt;\n    dplyr::select(-from) |&gt;\n    as.matrix()\n  \n  X_sm\n}\n\n\nLet us do soft-matching to get counterfactuals for units from both group 0 and group 1.\n\nX0_sm &lt;- soft_match(X_source = X0 , X_target = X1)\nX1_sm &lt;- soft_match(X_source = X1 , X_target = X0)\n\n\n\nCodes to create the Figure.\npar(mar = c(2.1, 2.1, 2.1, 0.1), mfrow = c(1, 2))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\n\n# From 0 to 1\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"SM: from A=0 to A=1\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X0_sm, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0[, \"X1\"], y0 = X0[, \"X2\"],\n  x1 = X0_sm[, 1], y1 = X0_sm[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n# From 1 to 0\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"SM: from A=1 to A=0\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X1_sm, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X1[, \"X1\"], y0 = X1[, \"X2\"],\n  x1 = X1_sm[, 1], y1 = X1_sm[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n\n\n\nFigure 5.3: 500 points in each group drawn from bivariates Gaussian distributions and transported values from group 0 to group 1 (left), and from group 1 to group 0 (right), using soft matching.\n\n\n\n\n\n\n\n\n\n\n5.2.4 Entropic Regularization via Sinkhorn Algorithm\nThe optimal transport problem can be computationally intensive (not here with the small amount of observations, though). In such cases, one can consider Entropic regularization via Sinkhorn algorithm, associated to the “Matrix Scaling Problem” in Sinkhorn (1962). Entropic regularization modifies the previous problem by adding a Kullback-Leibler divergence (\\(\\mathrm{d}_{\\mathrm{KL}}\\)) term to the optimization goal \\[\n\\min_{\\boldsymbol{P}\\in\\mathcal{U}(\\boldsymbol{1}_{n_0},\\boldsymbol{1}_{n_1})}\n\\Big\\lbrace \\langle \\boldsymbol{P},\\boldsymbol{C}\\rangle +\\gamma\\cdot \\mathrm{d}_{\\mathrm{KL}}(\\boldsymbol{P}||{\\boldsymbol{1}_{n_0}}\\otimes{\\boldsymbol{1}_{n_1}}) \\Big\\rbrace\n\\tag{5.1}\\] where the Kullback-Leibler divergence term corresponds to the opposite of the discrete entropy of the coupling matrix \\(\\boldsymbol{P}\\), \\[\nH(\\boldsymbol{P}) := -\\sum_{i,j}P_{i,j}(\\log(P_{i,j}) - 1).\n\\] see Proposition 4.3 in Peyré and Cuturi (2019).\nLet us make sure that the observations are stored in matrices for each group.\n\nX0 &lt;- as.matrix(df[df$A == 0, c(\"X1\", \"X2\")])\nX1 &lt;- as.matrix(df[df$A == 1, c(\"X1\", \"X2\")])\n\nThe number of observations in each group:\n\nn_0 &lt;- nrow(X0)\nn_1 &lt;- nrow(X1)\n\nWe will use uniform weights:\n\nw_0 &lt;- rep(1 / n_0, n_0)\nw_1 &lt;- rep(1 / n_1, n_1)\n\nWe compute the pairwise cost matrix, which is simply the squared Euclidean distance in this example.\n\ncost_mat &lt;- as.matrix(dist(rbind(X0, X1)))^2\nC &lt;- cost_mat[1:n_0, (n_0 + 1):(n_0 + n_1)]\n\nThen, we can apply the Sinkhorn algorithm to solve the problem.\n\nskh_res &lt;- T4transport::sinkhornD(\n  D = C, p = 2, wx = w_0, wy = w_1, lambda = 0.1\n)\n\nWe extract the transport plan:\n\not_plan_skh &lt;- skh_res$plan\n\nWe normalize the plan:\n\nrow_sums &lt;- rowSums(ot_plan_skh)\not_plan_skh &lt;- sweep(ot_plan_skh, 1, row_sums, FUN = \"/\")\n\nThe transported version of X_1 is the barycentric projection:\n\nX0_skh &lt;- ot_plan_skh %*% X1\n\nWe wrap these steps in a function, transport_regul().\n\n\nThe transport_regul() function.\n#' @param X_source Matrix of observations to transport from the source group.\n#' @param X_target Matrix of observations from the target group.\n#' @param gamma A regularization parameter (default to 0.1).\ntransport_regul &lt;- function(X_source, \n                            X_target, \n                            gamma) {\n\n  X_source &lt;- as.matrix(X_source)\n  X_target &lt;- as.matrix(X_target)\n  n_source &lt;- nrow(X_source)\n  n_target &lt;- nrow(X_target)\n  # Uniform weights\n  w_source &lt;- rep(1 / n_source, n_source)\n  w_target &lt;- rep(1 / n_target, n_target)\n  \n  # Pairwise squared Euclidean distance\n  cost_mat &lt;- as.matrix(dist(rbind(X_source, X_target)))^2\n  C &lt;- cost_mat[1:n_source, (n_source + 1):(n_source + n_target)]\n  \n  # Run Sinkhorn with entropic regularization gamma\n  skh_res &lt;- T4transport::sinkhornD(\n    D = C, p = 2, wx = w_source, wy = w_target, lambda = gamma\n  )\n\n  # Extract and normalize plan\n  ot_plan_skh &lt;- skh_res$plan\n  ot_plan_skh &lt;- sweep(ot_plan_skh, 1, rowSums(ot_plan_skh), FUN = \"/\")\n  \n  ot_plan_skh %*% X_target\n}\n\n\nWe consider the following values for \\(\\gamma\\):\n\ngammas &lt;- c(0.1, 1, 5, 10, 100, 1000, 10000)\n\nWe transport the observations from group~0 to group~1:\n\nX0_skh_l &lt;- map(\n  gammas, \n  ~transport_regul(\n    X_source = X0, \n    X_target = X1, \n    gamma = .x\n  )\n)\nnames(X0_skh_l) &lt;- as.character(gammas)\n\nAnd from group~1 to group~0:\n\nX1_skh_l &lt;- map(\n  gammas, \n  ~transport_regul(\n    X_source = X1, \n    X_target = X0, \n    gamma = .x\n  )\n)\nnames(X1_skh_l) &lt;- as.character(gammas)\n\nWe visualize the results in Figure 5.4.\n\n\nCodes to create the Figure.\nlayout(matrix(seq_len(length(gammas) + 1), ncol = 4, byrow = TRUE))\npar(mar = c(2.1, 2.1, 2.1, 0.1))\n# par(mar = c(2.1, 2.1, 2.1, 0.1), mfrow = c(1, 2))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\n\n## OT----\n# From 0 to 1\nplot(X0, \n     pch = 16, \n     col = adjustcolor(colGpe0, alpha = .3), \n     xlim = x_lim, ylim = y_lim, \n     xlab = \"\", ylab = \"\",\n     main = \"OT: from A=0 to A=1\"\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0[, \"X1\"], y0 = X0[, \"X2\"],\n  x1 = X0_t[, 1], y1 = X0_t[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\npoints(X0_t, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n## OT with Entropic Regularization----\n\nfor (gamma in gammas) {\n  X0_skh &lt;- X0_skh_l[[as.character(gamma)]]\n  \n  # From 0 to 1\n  plot(\n    X0, \n    pch = 16, \n    col = adjustcolor(colGpe0, alpha = .3), \n    xlim = x_lim, ylim = y_lim, \n    xlab = \"\", ylab = \"\",\n    main = latex2exp::TeX(paste0(\"$\\\\gamma=\", gamma, \"$\"))\n  )\n  title(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2)\n  points(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\n  # Add arrows from original to transported\n  arrows(\n    x0 = X0[, \"X1\"], y0 = X0[, \"X2\"],\n    x1 = X0_skh[, 1], y1 = X0_skh[, 2],\n    length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n  )\n  points(X0_skh[, \"X1\"], X0_skh[, \"X2\"], col = adjustcolor(colGpet, alpha = .3), pch = 17)\n  \n  # True mean and covariance (scaled by 'a')\n  Mu0 &lt;- rep(a * mu0, 2)\n  Mu1 &lt;- rep(a * mu1, 2)\n  Sig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\n  Sig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n  \n  \n  # Add ellipses\n  draw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\n  draw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n}\n\n\n\n\n\nFigure 5.4: 500 points in each group drawn from bivariates Gaussian distributions and transported values from group 0 to group 1, using optimal transport (first panel) and using entropic regularization and Sinkhorn Algorithm with different values of the regularization parameter \\(\\gamma\\).\n\n\n\n\n\n\n\n\n\n\n5.2.5 Sequential Transport\nWe will now transport individuals using sequential transport. The results are sensitive to the ordering within the sequence. We will consider both ordering to illustrate this.\n\na first marginal univariate optimal transport along the first dimension (\\(X_1\\)), then a conditional transport for the second dimension (\\(X_2 \\mid X_1)\\): sequential_transport_12(),\na first marginal univariate optimal transport along the second dimension (\\(X_2\\)), then a conditional transport for the first dimension (\\(X_1 \\mid X_2)\\): sequential_transport_21(),\n\n\n\nThe sequential_transport_12() function.\n#' Sequential transport from N(M_source, S_source) to N(M_target, S_target),\n#' along X1, then X2 | X1\n#'\n#' @param X n x 2 matrix of source observations.\n#' @param M_source Mean vector of the source distribution (length 2).\n#' @param S_source Covariance matrix of the source distribution (2x2).\n#' @param M_target Mean vector of the target distribution.\n#' @param S_target Covariance matrix of the target distribution.\nsequential_transport_12 &lt;- function(X, \n                                    M_source, \n                                    S_source, \n                                    M_target, \n                                    S_target) {\n  \n  # marginal univariate transport along the first coordinate (X_1)\n  T1x &lt;- qnorm(\n    pnorm(X[, 1], mean = M_source[1], sd = sqrt(S_source[1, 1])),\n    mean = M_target[1], sd = sqrt(S_target[1, 1])\n  )\n  \n  # conditional parameters for X_2 | X_1\n  m_source &lt;- M_source[2] + S_source[1, 2] / S_source[1, 1] * (X[, 1] - M_source[1])\n  s_source &lt;- S_source[2, 2] - S_source[1, 2]^2 / S_source[1, 1]\n  \n  m_target &lt;- M_target[2] + S_target[1, 2] / S_target[1, 1] * (T1x - M_target[1])\n  s_target &lt;- S_target[2, 2] - S_target[1, 2]^2 / S_target[1, 1]\n  \n  # conditional transport for the second coordinate\n  T2x &lt;- qnorm(\n    pnorm(X[, 2], mean = m_source, sd = sqrt(s_source)),\n    mean = m_target, sd = sqrt(s_target)\n  )\n  \n  cbind(T1x, T2x)\n}\n\n\n\n\nThe sequential_transport_21() function.\n#' Sequential transport from N(M_source, S_source) to N(M_target, S_target),\n#' along X2, then X1 | X2\n#'\n#' @param X n x 2 matrix of source observations.\n#' @param M_source Mean vector of the source distribution (length 2).\n#' @param S_source Covariance matrix of the source distribution (2x2).\n#' @param M_target Mean vector of the target distribution.\n#' @param S_target Covariance matrix of the target distribution.\nsequential_transport_21 &lt;- function(X, M_source, S_source, M_target, S_target) {\n  \n  # marginal univariate transport along X_2\n  T2x &lt;- qnorm(\n    pnorm(X[, 2], mean = M_source[2], sd = sqrt(S_source[2, 2])),\n    mean = M_target[2], sd = sqrt(S_target[2, 2])\n  )\n  \n  # conditional parameters for X_1 | X_2\n  m_source &lt;- M_source[1] + S_source[1, 2] / S_source[2, 2] * (X[, 2] - M_source[2])\n  s_source &lt;- S_source[1, 1] - S_source[1, 2]^2 / S_source[2, 2]\n  \n  m_target &lt;- M_target[1] + S_target[1, 2] / S_target[2, 2] * (T2x - M_target[2])\n  s_target &lt;- S_target[1, 1] - S_target[1, 2]^2 / S_target[2, 2]\n  \n  # conditional transport for X1 | X_2\n  T1x &lt;- qnorm(\n    pnorm(X[, 1], mean = m_source, sd = sqrt(s_source)),\n    mean = m_target, sd = sqrt(s_target)\n  )\n  \n  cbind(T1x, T2x)\n}\n\n\nWe isolate the observations from group 0 and from group 1, and store them as matrices.\n\nX0 &lt;- as.matrix(df[df$A == 0, c(\"X1\", \"X2\")])\nX1 &lt;- as.matrix(df[df$A == 1, c(\"X1\", \"X2\")])\n\nWe then transport from group 0 to group group 1 with sequential transport, first transporting \\(X_1\\) then \\(X_2 | X_1\\).\n\nX0_st_12 &lt;- sequential_transport_12(\n  X = X0, M_source = Mu0, S_source = Sig0, M_target = Mu1, S_target = Sig1\n)\n\nWe do the same but for units in group 1 to group 0.\n\nX1_st_12 &lt;- sequential_transport_12(\n  X = X1, M_source = Mu1, S_source = Sig1, M_target = Mu0, S_target = Sig0\n)\n\nWe also transport from group 0 to group group 1 with sequential transport, first transporting \\(X_1\\) then \\(X_1 | X_2\\).\n\nX0_st_21 &lt;- sequential_transport_21(\n  X = X0, M_source = Mu0, S_source = Sig0, M_target = Mu1, S_target = Sig1\n)\n\nWe do the same but for units in group 1 to group 0.\n\nX1_st_21 &lt;- sequential_transport_21(\n  X = X1, M_source = Mu1, S_source = Sig1, M_target = Mu0, S_target = Sig0\n)\n\nAgain, we can visualize the results on a scatter plot (Figure 5.5).\n\n\nCodes to create the Figure.\n# Prepare data for the plot\nX0 &lt;- df[df$A == 0, c(\"X1\", \"X2\")]\nX1 &lt;- df[df$A == 1, c(\"X1\", \"X2\")]\n\npar(mar = c(2.1, 2.1, 2.1, 0.1), mfrow = c(2,2))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\n\n# From 0 to 1, X1 then X2----\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\ntitle(main = \"A=0 to A=1, X1 then X2\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X0_st_12, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0$X1, y0 = X0$X2,\n  x1 = X0_st_12[, 1], y1 = X0_st_12[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n# From 1 to 0, X1 then X2----\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\ntitle(main = \"A=1 to A=0, X1 then X2\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X1_st_12, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X1$X1, y0 = X1$X2,\n  x1 = X1_st_12[, 1], y1 = X1_st_12[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n# From A=0 to A=1, X2 then X1\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\ntitle(main = \"A=0 to A=1, X2 then X1\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X0_st_21, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0$X1, y0 = X0$X2,\n  x1 = X0_st_21[, 1], y1 = X0_st_21[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n# From A=1 to A=0, X2 then X1\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\ntitle(main = \"A=1 to A=0, X2 then X1\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X1_st_21, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X1$X1, y0 = X1$X2,\n  x1 = X1_st_21[, 1], y1 = X1_st_21[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n\n\n\nFigure 5.5: 500 points in each group drawn from bivariates Gaussian distributions and transported values from group 0 to group 1 (left), and from group 1 to group 0 (right), using sequential optimal transport, first transporting \\(X_1\\), then \\(X_2 \\mid X_1\\) (top), and first transporting \\(X_2\\), then \\(X_1 \\mid X_2\\) (bottom).\n\n\n\n\n\n\n\n\n\n\nCodes for the Figure in the paper\nfilename &lt;- \"gaussian-transport-0to1\"\ntikz(paste0(\"figs/\", filename, \".tex\"), width = 2.2, height = 1)\n\nlayout(matrix(1:3, ncol = 3), width = c(1, rep(.9, 2)))\npar(mar = c(2.1, 2.1, 2.1, 0.1))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\ncex_pts &lt;- .5\nalpha_arrows &lt;- .2\nlength_arrow &lt;- 0\n\n# From 0 to 1, with OT\nplot(X0, \n     pch = 16, cex = cex_pts,\n     col = adjustcolor(colGpe0, alpha = .3), \n     xlim = x_lim, ylim = y_lim, \n     xlab = \"\", ylab = \"\",\n     main = \"\",\n     family = font_family,\n     axes = FALSE\n)\naxis(1, at = -3:3)\naxis(2, at = -3:3)\n\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1, family = font_family)\ntitle(main = \"OT\", line=.5, cex.main = 1, family = font_family, font.main=1)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16, cex = cex_pts)\npoints(X0_t, col = adjustcolor(colour_methods[[\"OT\"]], alpha = .3), pch = 17, cex = cex_pts)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0$X1, y0 = X0$X2,\n  x1 = X0_t[, 1], y1 = X0_t[, 2],\n  length = length_arrow, col = adjustcolor(\"gray\", alpha = alpha_arrows)\n)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Covariance of transported points (via OT map)\nSigma0_transport &lt;- ot_map_0_to_1$A %*% Sig0 %*% t(ot_map_0_to_1$A)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\npar(mar = c(2.1, 1.1, 2.1, 0.1))\n\n# From 0 to 1, X1 then X2----\nplot(\n  X0, \n  pch = 16, cex = cex_pts,\n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family,\n  axes = FALSE\n)\naxis(1, at = -3:3)\n\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1, family = font_family)\ntitle(main = \"ST(1)\", line=.5, cex.main = 1, family = font_family, font.main=1)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16, cex = cex_pts)\npoints(X0_st_12, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .3), pch = 17, cex = cex_pts)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0$X1, y0 = X0$X2,\n  x1 = X0_st_12[, 1], y1 = X0_st_12[, 2],\n  length = length_arrow, col = adjustcolor(\"gray\", alpha = .4)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n# From A=0 to A=1, X2 then X1----\nplot(\n  X0, \n  pch = 16, cex = cex_pts,\n  col = adjustcolor(colGpe0, alpha = alpha_arrows), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family,\n  axes = FALSE\n)\naxis(1, at = -3:3)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1, family = font_family)\ntitle(main = \"ST(2)\", line=.5, cex.main = 1, family = font_family, font.main=1)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16, cex = cex_pts)\npoints(X0_st_21, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .3), pch = 17, cex = cex_pts)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0$X1, y0 = X0$X2,\n  x1 = X0_st_21[, 1], y1 = X0_st_21[, 2],\n  length = length_arrow, col = adjustcolor(\"gray\", alpha = alpha_arrows)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n# legend(\n#   \"bottomright\",\n#   pch = c(16, 16, 17),\n#   col = c(colGpe0, colGpe1, colGpet),\n#   legend = c(\"$A=0$\", \"$A=1$\", \"Transp.\"),\n#   bty = \"n\"\n# )\n\ndev.off()\nplot_to_pdf(filename = filename, path = \"./figs/\", keep_tex = FALSE, crop = FALSE)\n\n\n\n\n5.2.6 Illustration for a Single Unit\n\nexport_tikz &lt;- FALSE\n# Focus on a unit\ni &lt;- 11\n\nX0 &lt;- df[df$A == 0, c(\"X1\", \"X2\")]\nX1 &lt;- df[df$A == 1, c(\"X1\", \"X2\")]\n\nif (export_tikz == TRUE) \n  tikz('figs/gaussian-1-transport.tex', width = 2, height = 2.2)\n\npar(mar = c(2.1, 2.1, 1.8, 0.1))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\n\n# X1 then X2\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\n# title(main = \"X1 then X2\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\n\n# Individual of interest\npoints(X0[i, ], col = adjustcolor(colGpe0, alpha = 1), pch = 15, cex = 1.5)\npoints(X0_t[i, 1], X0_t[i, 2], col = adjustcolor(colour_methods[[\"OT\"]], alpha = 1), pch = 15, cex = 1.5)\npoints(X0_skh_l[[\"0.1\"]][i, 1], X0_skh_l[[\"0.1\"]][i, 2], col = adjustcolor(colour_methods[[\"skh\"]], alpha = 1), pch = 15, cex = 1.5)\npoints(X0_st_12[i, 1], X0_st_12[i, 2], col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = 1), pch = 15, cex = 1.5)\npoints(X0_st_21[i, 1], X0_st_21[i, 2], col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = 1), pch = 15, cex = 1.5)\n\nlength_arrow &lt;- 0.1\nlwd_arrow &lt;- 2\n# OT\narrows(\n  x0 = X0$X1[i], y0 = X0$X2[i],\n  x1 = X0_t[i, 1], y1 = X0_t[i, 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"OT\"]], alpha = 1),\n  lwd = lwd_arrow, lty = 2\n)\n# Regularization\narrows(\n  x0 = X0$X1[i], y0 = X0$X2[i],\n  x1 = X0_skh_l[[\"0.1\"]][i, 1], y1 = X0_skh_l[[\"0.1\"]][i, 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"skh\"]], alpha = 1),\n  lwd = lwd_arrow, lty = 2\n)\n# Seq OT (1): X_1 first\npoints(X0_st_12[i, 1], X0$X2[i], col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5), pch = 16, cex = 1.5)\narrows(\n  x0 = X0$X1[i], y0 = X0$X2[i],\n  x1 = X0_st_12[i, 1], y1 = X0$X2[i],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = 1),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0_st_12[i, 1], y0 = X0$X2[i],\n  x1 = X0_st_12[i, 1], y1 = X0_st_12[i, 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = 1),\n  lwd = lwd_arrow\n)\n\n# Seq OT (2): X_2 first\npoints(X0$X1[i], X0_st_21[i,2], col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5), pch = 16, cex = 1.5)\narrows(\n  x0 = X0$X1[i], y0 = X0$X2[i],\n  x1 = X0$X1[i], y1 = X0_st_21[i,2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = 1),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0$X1[i], y0 = X0_st_21[i,2],\n  x1 = X0_st_21[i, 1], y1 = X0_st_21[i, 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = 1),\n  lwd = lwd_arrow\n)\n\nlegend(\n  \"topleft\", \n  legend = c(\"$x_i$ (Obs.)\", \"OT\", \"Sinkhorn\", \"Seq. OT (1)\", \"Seq. OT (2)\"), \n  col = c(colGpe0, colour_methods[c(\"OT\", \"skh\", \"seq_1\", \"seq_2\")]), \n  pch = 15, pt.cex = 1.5, cex = 1,\n  bty = \"n\"\n)\n\n\n\n\n\n\n\nif (export_tikz == TRUE) {\n  dev.off()\n  \n  plot_to_pdf(filename = \"gaussian-1-transport\", path = \"./figs/\", keep_tex = FALSE, crop = TRUE)\n}",
    "crumbs": [
      "II. A Gaussian Example",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Gaussian Example</span>"
    ]
  },
  {
    "objectID": "gaussian-example.html#sec-causal-effects",
    "href": "gaussian-example.html#sec-causal-effects",
    "title": "5  Gaussian Example",
    "section": "5.3 Causal Effect",
    "text": "5.3 Causal Effect\nWe first generate (again) some data, using the DGP presented in Section 13.1.\n\ndf &lt;- gen_data(\n  n = 500, \n  mu0 = -1, mu1 = +1, \n  r0 = +.7, r1 = -.5, a = 1, \n  seed = 12345\n)\n\n\n5.3.1 With Causal Mediation Analysis\nLet us create a dataset, tb, with only the binary response (Y), the binary treatment (A), and the two covariates.\n\ntb &lt;- df[, c(\"Y\", \"A\", \"X1\", \"X2\")]\nA_name &lt;- \"A\"\nA_untreated &lt;- 0\nY_name &lt;- \"Y\"\n\n\nmed_mod_12 &lt;- mediation::multimed(\n  outcome = \"Y\", \n  med.main = \"X1\", \n  med.alt = \"X2\", \n  treat = \"A\", \n  data = df\n)\nmed_mod_21 &lt;- mediation::multimed(\n  outcome = \"Y\", \n  med.main = \"X2\", \n  med.alt = \"X1\", \n  treat = \"A\", \n  data = df\n)\n\n\n\n\n\n\n\nWarning\n\n\n\nWe do not load the {mediation} package since it creates multiple conflicts with useful functions from tidyverse (including select()).\n\n\nLet us retrieve \\(\\bar{\\delta}(0)\\) (average causal mediation effect for \\(a=0\\)):\n\ndelta_0_med &lt;- mean((med_mod_12$d0.lb + med_mod_12$d0.ub) / 2) +\n  mean((med_mod_21$d0.lb + med_mod_21$d0.ub) / 2)\ndelta_0_med\n\n[1] 0.9085616\n\n\nThe total average effect, \\(\\bar{\\tau}\\):\n\n(tot_effect_med &lt;- med_mod_12$tau)\n\n       A \n3.943122 \n\n\nWe can then deduct the average direct effect for \\(a=1\\), i.e., \\(\\bar{\\zeta}(1)\\):\n\n(zeta_1_med &lt;- tot_effect_med-delta_0_med)\n\n      A \n3.03456 \n\n\nLet us also retrieve \\(\\bar{\\delta}(1)\\) (average causal mediation effect for \\(a=1\\)) and \\(\\bar{\\zeta}(0)\\) (average direct effect for \\(a=0\\)):\n\ndelta_1_med &lt;- mean((med_mod_12$d1.lb + med_mod_12$d1.ub) / 2) + \n  mean((med_mod_21$d1.lb + med_mod_21$d1.ub) / 2)\nzeta_0_med &lt;- tot_effect_med - delta_1_med\nc(delta_1_med, zeta_0_med)\n\n                  A \n0.6905634 3.2525583 \n\n\n\n\n5.3.2 With Optimal Transport\nWe define a function, causal_effects_cf() to compute the causal effect of \\(A\\) on the outcome \\(Y\\), for the treated individuals.\n\n#' Estimation of total causal effect using counterfactuals.\n#' \n#' @param data_untreated Dataset with the untreated units only.\n#' @param data_treated Dataset with the treated units only.\n#' @param data_cf_untreated Counterfactuals for untreated had they been treated.\n#' @param data_cf_treated Counterfactuals for treated had they been untreated.\n#' @param Y_name Name of the column with the outcome variable.\n#' @param A_name Name of the column with the treatment variable.\n#' @param A_untreated Value of the treatment for the untreated units.\n#' \n#' @returns A list:\n#' - `delta_0_i`: \\eqn{\\delta_(0)}, individual causal mediation effects for \n#'   \\eqn{a=0} (computed on untreated),\n#' - `delta_0`: \\eqn{\\bar{\\delta}(0)}, average causal mediation effect for \n#'   \\eqn{a=0} (computed on untreated),\n#' - `delta_1_i`: \\eqn{\\delta_(1)}, individual causal mediation effects for \n#'   \\eqn{a=1} (computed on treated),\n#' - `delta_1`: \\eqn{\\bar{\\delta}(1)}, average causal mediation effect for \n#'   \\eqn{a=1} (computed on treated),\n#' - `zeta_0_i`: \\eqn{\\zeta_(0)}, individual causal mediation effects for \n#'   \\eqn{a=0} (computed on treaded),\n#' - `zeta_0`: \\eqn{\\bar{\\zeta}(0)}, average causal mediation effect for \n#'   \\eqn{a=0} (computed on treated),\n#' - `zeta_1_i`: \\eqn{\\zeta_(1)}, individual causal mediation effects for \n#'   \\eqn{a=1} (computed on untreaded),\n#' - `zeta_1`: \\eqn{\\bar{\\zeta}(1)}, average causal mediation effect for \n#'   \\eqn{a=1} (computed on untreated),\n#' - `tot_effect`: \\eqb{\\tau}: average total effect (\\eqn{\\bar{\\delta}(0) + \n#'   \\bar{\\zeta}(1)}).\n#'\n#' @importFrom randomForest randomForest\n#' @importFrom dplyr pull select\n#' @importFrom stats predict\n#' @md\ncausal_effects_cf &lt;- function(data_untreated,\n                              data_treated,\n                              data_cf_untreated,\n                              data_cf_treated,\n                              Y_name,\n                              A_name,\n                              A_untreated) {\n  \n  n_untreated &lt;- nrow(data_untreated)\n  n_treated &lt;- nrow(data_treated)\n  \n  # Outcome model for untreated\n  mu_untreated_model &lt;- randomForest(\n    x = data_untreated |&gt; dplyr::select(-!!Y_name, -!!A_name),\n    y = pull(data_untreated, !!Y_name)\n  )\n  \n  # Outcome model for treated\n  mu_treated_model &lt;- randomForest(\n    x = data_treated |&gt; dplyr::select(-!!Y_name, -!!A_name),\n    y = pull(data_treated, !!Y_name)\n  )\n  \n  # Observed outcome\n  y_untreated_obs &lt;- data_untreated |&gt; pull(!!Y_name)\n  y_treated_obs &lt;- data_treated |&gt; pull(!!Y_name)\n  \n  # Natural Indirect Effect, using predictions\n  delta_0_i &lt;- predict(mu_untreated_model, newdata = data_cf_untreated) -\n    predict(mu_untreated_model)\n  delta_0 &lt;- mean(delta_0_i)\n  delta_1_i &lt;- predict(mu_treated_model) - \n    predict(mu_treated_model, newdata = data_cf_treated)\n  delta_1 &lt;- mean(delta_1_i)\n\n  # Natural Indirect Effect, using observed variables\n  delta_0_i_obs &lt;- predict(mu_untreated_model, newdata = data_cf_untreated) - \n    y_untreated_obs\n  delta_0_obs &lt;- mean(delta_0_i_obs)\n  delta_1_i_obs &lt;- y_treated_obs - \n    predict(mu_treated_model, newdata = data_cf_treated)\n  delta_1_obs &lt;- mean(delta_1_i_obs)\n  \n  # Natural Direct Effect (only predictions)\n  zeta_0_i &lt;- predict(mu_treated_model, newdata = data_cf_treated) -\n    predict(mu_untreated_model, newdata = data_cf_treated)\n  zeta_0 &lt;- mean(zeta_0_i)\n  \n  zeta_1_i &lt;- predict(mu_treated_model, newdata = data_cf_untreated) - \n    predict(mu_untreated_model, newdata = data_cf_untreated)\n  zeta_1 &lt;- mean(zeta_1_i)\n  \n  # Total Causal Effect for treated\n  tot_effect &lt;- delta_0 + zeta_1  \n  tot_effect_obs &lt;- delta_0_obs + zeta_1\n  \n  \n  list(\n    delta_0_i = delta_0_i,\n    delta_1_i = delta_1_i,\n    zeta_0_i = zeta_0_i,\n    zeta_1_i = zeta_1_i,\n    delta_0_i_obs = delta_0_i_obs,\n    delta_1_i_obs = delta_1_i_obs,\n    delta_0 = delta_0,\n    delta_1 = delta_1,\n    zeta_0 = zeta_0,\n    zeta_1 = zeta_1,\n    delta_0_obs = delta_0_obs,\n    delta_1_obs = delta_1_obs,\n    tot_effect = tot_effect,\n    tot_effect_obs = tot_effect_obs\n  )\n}\n\nWe use a random forest to estimate the outcome model.\n\nlibrary(randomForest)\n\nWe apply this function to our simulated dataset.\n\ntb_untreated &lt;- tb |&gt; filter(!!sym(A_name) == !!A_untreated)\ntb_treated &lt;- tb |&gt; filter(!!sym(A_name) != !!A_untreated)\n\ncausal_effects_ot &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(X0_t),\n  data_cf_treated = as_tibble(X1_t),\n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated\n)\n\ncbind(\n  delta_0 = causal_effects_ot$delta_0,\n  zeta_1 = causal_effects_ot$zeta_1,\n  delta_1 = causal_effects_ot$delta_1,\n  zeta_0 = causal_effects_ot$zeta_0,\n  tot_effect = causal_effects_ot$tot_effect,\n  tot_effect_obs = causal_effects_ot$tot_effect_obs\n)\n\n       delta_0   zeta_1   delta_1   zeta_0 tot_effect tot_effect_obs\n[1,] 0.9422158 3.153563 0.2031006 3.781928   4.095779       4.083447\n\n\n\n\n5.3.3 With Transport-based Matching\nWe apply the same function as that used with the counterfactuals obtained with optimal transport (causal_effects_cf()). However, here, we feed it with the counterfactuals obtained with the transport-based many-to-one matching (Section 5.2.2).\n\ncausal_effects_tmatch &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(X0_tmatch) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  data_cf_treated = as_tibble(X1_tmatch) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated\n)\n\n\n\n5.3.4 With Entropic Regularization\nWe apply the same function as that used with the counterfactuals obtained with optimal transport (causal_effects_cf()). However, here, we feed it with the counterfactuals obtained with the regularization method (Section 5.2.4).\n\ncausal_effect_skh &lt;- map2(\n  X0_skh_l, X1_skh_l, \n  ~causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(.x) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    data_cf_treated = as_tibble(.y) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n)\nmap(\n  causal_effect_skh,\n  ~tibble(\n    delta_0 = .x$delta_0,\n    zeta_1 = .x$zeta_1,\n    delta_1 = .x$delta_1,\n    zeta_0 = .x$zeta_0,\n    tot_effect = .x$tot_effect,\n    tot_effect_obs = .x$tot_effect_obs\n  )\n) |&gt; \n  list_rbind(names_to = \"gamma\")\n\n# A tibble: 7 × 7\n  gamma delta_0 zeta_1 delta_1 zeta_0 tot_effect tot_effect_obs\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;\n1 0.1     0.793   3.12  0.0992   3.61       3.92           3.91\n2 1       0.854   3.10  0.0181   3.88       3.95           3.96\n3 5       0.834   3.14  0.214    3.68       3.98           3.97\n4 10      0.830   3.16 -0.0158   3.92       3.99           3.98\n5 100     0.825   3.24  0.380    3.46       4.07           4.06\n6 1000    1.18    2.78  0.383    3.97       3.96           3.96\n7 10000   1.18    2.74  0.495    3.84       3.93           3.92\n\n\n\n\n5.3.5 With Sequential Optimal Transport\nAgain, we causal_effects_cf()), feeding it with the counterfactuals obtained with sequential transport (sec-cf-sot). For those where we first transport \\(X_1\\) and then \\(X_2 \\mid X_1\\):\n\ncausal_effect_sot_12 &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(X0_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  data_cf_treated = as_tibble(X1_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated\n)\n\nAnd for the counterfactuales obtained by sequential transport where we first transport \\(X_2\\) and then \\(X_1 \\mid X_2\\):\n\ncausal_effect_sot_21 &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(X0_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  data_cf_treated = as_tibble(X1_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated\n)\n\n\n\n5.3.6 Summary\n\n\nCode\ntribble(\n  ~Method, ~Name, ~Value,\n  \"Theoretical\", \"delta(0)\", (a1+a2) * (mu1-mu0),\n  \"Theoretical\", \"delta(1)\", (a1+a2) * (mu1-mu0),\n  \"Theoretical\", \"zeta(0)\", a0,\n  \"Theoretical\", \"zeta(1)\", a0,\n  \"Theoretical\", \"tau\", (a1+a2) * (mu1-mu0) + a0,\n  #\n  \"Mediation\", \"delta(0)\", delta_0_med,\n  \"Mediation\", \"delta(1)\", delta_1_med,\n  \"Mediation\", \"zeta(0)\", zeta_0_med,\n  \"Mediation\", \"zeta(1)\", zeta_1_med,\n  \"Mediation\", \"tau\", tot_effect_med,\n  #\n  \"OT\", \"delta(0)\", causal_effects_ot$delta_0,\n  \"OT\", \"delta(1)\", causal_effects_ot$delta_1,\n  \"OT\", \"zeta(0)\", causal_effects_ot$zeta_0,  \n  \"OT\", \"zeta(1)\", causal_effects_ot$zeta_1,\n  \"OT\", \"tau\", causal_effects_ot$tot_effect,\n  #\n  \"OT (Obs)\", \"delta(0)\", causal_effects_ot$delta_0_obs,\n  \"OT (Obs)\", \"delta(1)\", causal_effects_ot$delta_1_obs,\n  \"OT (Obs)\", \"tau\", causal_effects_ot$tot_effect_obs,\n  #\n  \"Matching\", \"delta(0)\", causal_effects_tmatch$delta_0,\n  \"Matching\", \"delta(1)\", causal_effects_tmatch$delta_1,\n  \"Matching\", \"zeta(0)\", causal_effects_tmatch$zeta_0,  \n  \"Matching\", \"zeta(1)\", causal_effects_tmatch$zeta_1,\n  \"Matching\", \"tau\", causal_effects_tmatch$tot_effect,\n  #\n  \"Matching (Obs)\", \"delta(0)\", causal_effects_tmatch$delta_0_obs,\n  \"Matching (Obs)\", \"delta(1)\", causal_effects_tmatch$delta_1_obs,\n  \"Matching (Obs)\", \"tau\", causal_effects_tmatch$tot_effect_obs,\n  #\n  \"Sinkhorn (gamma=.1)\", \"delta(0)\", causal_effect_skh[[\"0.1\"]]$delta_0,\n  \"Sinkhorn (gamma=.1)\", \"delta(1)\", causal_effect_skh[[\"0.1\"]]$delta_1,\n  \"Sinkhorn (gamma=.1)\", \"zeta(0)\", causal_effect_skh[[\"0.1\"]]$zeta_0,  \n  \"Sinkhorn (gamma=.1)\", \"zeta(1)\", causal_effect_skh[[\"0.1\"]]$zeta_1,\n  \"Sinkhorn (gamma=.1)\", \"tau\", causal_effect_skh[[\"0.1\"]]$tot_effect,\n  #\n  \"Sinkhorn (gamma=.1) (Obs)\", \"delta(0)\", causal_effect_skh[[\"0.1\"]]$delta_0_obs,\n  \"Sinkhorn (gamma=.1) (Obs)\", \"delta(1)\", causal_effect_skh[[\"0.1\"]]$delta_1_obs,\n  \"Sinkhorn (gamma=.1) (Obs)\", \"tau\", causal_effect_skh[[\"0.1\"]]$tot_effect_obs,\n  #\n  \"SOT (1)\", \"delta(0)\", causal_effect_sot_12$delta_0,\n  \"SOT (1)\", \"delta(1)\", causal_effect_sot_12$delta_1,\n  \"SOT (1)\", \"zeta(0)\", causal_effect_sot_12$zeta_0,  \n  \"SOT (1)\", \"zeta(1)\", causal_effect_sot_12$zeta_1,\n  \"SOT (1)\", \"tau\", causal_effect_sot_12$tot_effect,\n  #\n  \"SOT (1) (Obs)\", \"delta(0)\", causal_effect_sot_12$delta_0_obs,\n  \"SOT (1) (Obs)\", \"delta(1)\", causal_effect_sot_12$delta_1_obs,\n  \"SOT (1) (Obs)\", \"tau\", causal_effect_sot_12$tot_effect_obs,\n  #\n  \"SOT (2)\", \"delta(0)\", causal_effect_sot_21$delta_0,\n  \"SOT (2)\", \"delta(1)\", causal_effect_sot_21$delta_1,\n  \"SOT (2)\", \"zeta(0)\", causal_effect_sot_21$zeta_0,\n  \"SOT (2)\", \"zeta(1)\", causal_effect_sot_21$zeta_1,\n  \"SOT (2)\", \"tau\", causal_effect_sot_21$tot_effect,\n  #\n  \"SOT (2) (Obs)\", \"delta(0)\", causal_effect_sot_21$delta_0_obs,\n  \"SOT (2) (Obs)\", \"delta(1)\", causal_effect_sot_21$delta_1_obs,\n  \"SOT (2) (Obs)\", \"tau\", causal_effect_sot_21$tot_effect_obs\n) |&gt; \n  pivot_wider(names_from = \"Name\", values_from = \"Value\")\n\n\n# A tibble: 12 × 6\n   Method                    `delta(0)` `delta(1)` `zeta(0)` `zeta(1)`   tau\n   &lt;chr&gt;                          &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 Theoretical                    1         1           3         3     4   \n 2 Mediation                      0.909     0.691       3.25      3.03  3.94\n 3 OT                             0.942     0.203       3.78      3.15  4.10\n 4 OT (Obs)                       0.930     0.208      NA        NA     4.08\n 5 Matching                       0.862     0.0860      3.85      3.08  3.94\n 6 Matching (Obs)                 0.858     0.0880     NA        NA     3.93\n 7 Sinkhorn (gamma=.1)            0.793     0.0992      3.61      3.12  3.92\n 8 Sinkhorn (gamma=.1) (Obs)      0.791     0.117      NA        NA     3.91\n 9 SOT (1)                        1.01      0.116       3.90      3.14  4.15\n10 SOT (1) (Obs)                  1.00      0.118      NA        NA     4.14\n11 SOT (2)                        0.904     0.114       3.95      3.04  3.94\n12 SOT (2) (Obs)                  0.889     0.122      NA        NA     3.93\n\n\nLet us have a look at the distribution of the individual causal effects (Figure 5.6).\n\n\nCodes to create the Figure.\nplot_hist_effects &lt;- function(x, \n                              var_name, \n                              tikz = FALSE,\n                              fill = \"red\",\n                              printed_method = \"\",\n                              x_lim = NULL,\n                              print_main = TRUE,\n                              print_x_axis = TRUE) {\n  if (print_main == TRUE) {\n    name_effect &lt;- case_when(\n      str_detect(var_name, \"^delta_0\") ~ \"$\\\\delta_i(0)$\",\n      str_detect(var_name, \"^zeta_1\") ~ \"$\\\\zeta_i(1)$\",\n      str_detect(var_name, \"^tot_effect\") ~ \"$\\\\tau_i(1)$\",\n      TRUE ~ \"other\"\n    )\n    if (tikz == FALSE) name_effect &lt;- latex2exp::TeX(name_effect)\n  } else {\n    name_effect &lt;- \"\"\n  }\n  \n  \n  if (var_name == \"tot_effect\") {\n    data_plot &lt;- x[[\"delta_0_i\"]] + x[[\"zeta_1_i\"]]\n  } else {\n    data_plot &lt;- x[[var_name]]\n  }\n  \n  if (is.null(x_lim)) {\n    hist(\n      data_plot, \n      main = \"\", xlab = \"\", ylab = \"\", family = font_family,\n      col = fill, axes = FALSE\n    )\n  } else {\n    hist(\n      data_plot, \n      main = \"\", xlab = \"\", ylab = \"\", family = font_family,\n      col = fill, xlim = x_lim, axes = FALSE\n    )\n  }\n  \n  if (print_x_axis) axis(1, family = font_family)\n  axis(2, family = font_family)\n  \n  title(\n    main = name_effect, cex.main = 1, family = font_family\n  )\n  \n  if (printed_method != \"\") {\n    title(\n      ylab = printed_method, line = 2, \n      cex.lab = 1, family = font_family\n    )\n  }\n  abline(v = mean(data_plot), col = \"darkred\", lty = 2, lwd = 2)\n}\n\nexport_tikz &lt;- FALSE\n\n\nfile_name &lt;- \"gaussian-indiv-effects\"\nwidth_tikz &lt;- 2.3\nheight_tikz &lt;- 2.7\nif (export_tikz == TRUE)\n  tikz(paste0(\"figs/\", file_name, \".tex\"), width = width_tikz, height = height_tikz)\n\nlayout(\n  matrix(1:(3*5), byrow = TRUE, ncol = 3),\n  widths = c(1, rep(.9, 2)), heights = c(1, rep(.72, 4))\n)\n\nfor (i in 1:5) {\n  x &lt;- case_when(\n    i == 1 ~ causal_effects_ot,\n    i == 2 ~ causal_effects_tmatch,\n    i == 3 ~ causal_effect_skh[[\"0.1\"]],\n    i == 4 ~ causal_effect_sot_12,\n    i == 5 ~ causal_effect_sot_21\n  )\n  method &lt;- case_when(\n    i == 1 ~ \"OT\",\n    i == 2 ~ \"OT-M\",\n    i == 3 ~ \"SKH\",\n    i == 4 ~ \"ST(1)\",\n    i == 5 ~ \"ST(2)\"\n  )\n  colour &lt;- case_when(\n    i == 1 ~ colour_methods[[\"OT\"]],\n    i == 2 ~ colour_methods[[\"OT-M\"]],\n    i == 3 ~ colour_methods[[\"skh\"]],\n    i == 4 ~ colour_methods[[\"seq_1\"]],\n    i == 5 ~ colour_methods[[\"seq_2\"]]\n  )\n  \n  for (var_name in c(\"delta_0_i\", \"zeta_1_i\", \"tot_effect\")) {\n    mar_bottom &lt;- ifelse(i == 5, 2.1, .6)\n    mar_left &lt;- ifelse(var_name == \"delta_0_i\", 3.1, 2.1)\n    mar_top &lt;- ifelse(i == 1, 2.1, .1)\n    mar_right &lt;- .4\n    printed_method &lt;- ifelse(var_name == \"delta_0_i\", method, \"\")\n    \n    par(mar = c(mar_bottom, mar_left, mar_top, mar_right))\n    x_lim_list &lt;- list(\n      \"delta_0_i\" = c(-3, 6),\n      \"zeta_1_i\" = c(-3, 8),\n      \"tot_effect\" = c(-4, 14)\n    )\n    \n    plot_hist_effects(\n      x = x, var_name = var_name, tikz = export_tikz, \n      fill = colour_methods[i],\n      printed_method = printed_method, \n      x_lim = x_lim_list[[var_name]],\n      print_main = i == 1,\n      print_x_axis = i == 5\n    )\n  }\n}\n\nif (export_tikz == TRUE) {\n  dev.off()\n  plot_to_pdf(\n    filename = file_name, \n    path = \"./figs/\", keep_tex = FALSE, crop = T\n  )\n}\n\n\n\n\n\nFigure 5.6: Distribution of individual direct effect (\\(\\delta_i(0)\\)), indirect effect (\\(\\zeta_i(0)\\)), and total causal effect (\\(\\tau_i\\)) estimated with transport-based counterfactuals with optimal transport (OT-M), penalized transport (SKH), and sequential transport (ST).\n\n\n\n\n\n\n\n\n\n\n5.3.7 Some Individuals\nLet us have a look at some individuals. We focus on the one with the predicted \\(\\tau_i\\) estimated using Optimal Transport which is the closest to the theoretical value, and the one that is the farthest. Let us get the theoretical values:\n\n(tau_theo &lt;- (a1 + a2) * (mu1 - mu0) + a0)\n\n[1] 4\n\n(tau_med &lt;- tot_effect_med[[1]])\n\n[1] 3.943122\n\n(tau_ot &lt;- causal_effects_ot$tot_effect)\n\n[1] 4.095779\n\n(tau_tmatch &lt;- causal_effects_tmatch$tot_effect)\n\n[1] 3.937629\n\n(tau_skh &lt;- causal_effect_skh[[\"0.1\"]]$tot_effect)\n\n[1] 3.915611\n\n(tau_sot_12 &lt;- causal_effect_sot_12$tot_effect)\n\n[1] 4.15099\n\n(tau_sot_21 &lt;- causal_effect_sot_21$tot_effect)\n\n[1] 3.94203\n\n\nWe create a table that contains the coordinates of individuals from group 0), their transported coordinates (using OT, and sequential transport), and their estimated values for \\(\\delta_i(0)\\), \\(\\zeta_i(1)\\), and \\(\\tau_i\\), obtained with the differenc counterfactuals.\n\ntb_indiv_0 &lt;- \n  tibble(\n    X1 = X0$X1,\n    X2 = X0$X2,\n    X1_t = X0_t[, 1], # with OT\n    X2_t = X0_t[, 2], # idem\n    X1_tmatch = X0_tmatch[, 1], # with transport-based matching\n    X2_tmatch = X0_tmatch[, 2], # idem\n    X1_skh = X0_skh_l[[\"0.1\"]][, 1], # with Regularization\n    X2_skh = X0_skh_l[[\"0.1\"]][, 2], # idem\n    X1_sot_12 = X0_st_12[, 1], # with Seq T (1)\n    X2_sot_12 = X0_st_12[, 2], # idem\n    X1_sot_21 = X0_st_21[, 1], # with Seq T (2)\n    X2_sot_21 = X0_st_21[, 2], # idem\n    # OT\n    delta_0_i_ot = causal_effects_ot$delta_0_i,\n    zeta_1_i_ot = causal_effects_ot$zeta_1_i,\n    # Matching\n    delta_0_i_tmatch = causal_effects_tmatch$delta_0_i,\n    zeta_1_i_tmatch = causal_effects_tmatch$zeta_1_i,\n    # Skh\n    delta_0_i_skh = causal_effect_skh[[\"0.1\"]]$delta_0_i,\n    zeta_1_i_skh = causal_effect_skh[[\"0.1\"]]$zeta_1_i,\n    # ST (1)\n    delta_0_i_sot_12 = causal_effect_sot_12$delta_0_i,\n    zeta_1_i_sot_12 = causal_effect_sot_12$zeta_1_i,\n    # ST (2)\n    delta_0_i_sot_21 = causal_effect_sot_21$delta_0_i,\n    zeta_1_i_sot_21 = causal_effect_sot_21$zeta_1_i\n  ) |&gt; \n  # Total causal effect\n  mutate(\n    tau_i_ot = delta_0_i_ot + zeta_1_i_ot,\n    tau_i_tmatch = delta_0_i_tmatch + zeta_1_i_tmatch,\n    tau_i_skh = delta_0_i_skh + zeta_1_i_skh,\n    tau_i_sot_12 = delta_0_i_sot_12 + zeta_1_i_sot_12,\n    tau_i_sot_21 = delta_0_i_ot + zeta_1_i_sot_21\n  ) |&gt; \n  # Distance to the theoretical value\n  mutate(\n    tau_i_ot_dist = abs(tau_i_ot - tau_theo),\n    tau_i_tmatch_dist = abs(tau_i_tmatch - tau_theo),\n    tau_i_skh_dist = abs(tau_i_skh - tau_theo),\n    tau_i_sot_12_dist = abs(tau_i_sot_12 - tau_theo),\n    tau_i_sot_21_dist = abs(tau_i_sot_21 - tau_theo)\n  )\n\nIn that table, we identify the two untreated units of interest.\n\nind_closest &lt;- order(tb_indiv_0$tau_i_ot_dist)[1]\nind_farthest &lt;- rev(order(tb_indiv_0$tau_i_ot_dist))[1]\n\nTheir coordinates are shown in Table 5.1, as well as the coordinates of their counterfactuals.\n\n\nCodes to create the Table.\nformat_num &lt;- function(x) scales::number(x, accuracy = 0.1)\n\ntb_indiv_0_short &lt;- \n  tb_indiv_0 |&gt; \n  select(-ends_with(\"dist\")) |&gt; \n  mutate(\n    across(where(is.numeric),\n           ~format_num(.x)\n    )\n  ) |&gt; \n  mutate(\n    obs_type = case_when(\n      row_number() == ind_closest ~ \"Closest\",\n      row_number() == ind_farthest ~ \"Farthest\",\n      TRUE ~ \"Other\"\n    )\n  ) |&gt; \n  filter(obs_type != \"Other\") |&gt; \n  mutate(\n    coord = str_c(\"(\", X1, \", \", X2, \")\"),\n    coord_OT = str_c(\"(\", X1_t, \", \", X2_t, \")\"),\n    coord_TM = str_c(\"(\", X1_tmatch, \", \", X2_tmatch, \")\"),\n    coord_SKH = str_c(\"(\", X1_skh, \", \", X2_skh, \")\"),\n    coord_ST1 = str_c(\"(\", X1_sot_12, \", \", X2_sot_12, \")\"),\n    coord_ST2 = str_c(\"(\", X1_sot_21, \", \", X2_sot_21, \")\")\n  ) |&gt; \n  select(\n    -X1, -X2, -X1_t, -X2_t, -X1_tmatch, -X2_tmatch,\n    -X1_skh, -X2_skh,\n    -X1_sot_12, -X2_sot_12, -X1_sot_21, -X2_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      -obs_type, -coord, -coord_OT, -coord_TM, -coord_SKH, -coord_ST1, -coord_ST2\n    )\n  ) |&gt; \n  mutate(\n    type = case_when(\n      str_detect(name, \"^delta\") ~ \"delta\",\n      str_detect(name, \"^zeta\") ~ \"zeta\",\n      str_detect(name, \"^tau\") ~ \"tau\",\n      TRUE ~ NA_character_\n    ),\n    type = factor(\n      type, \n      levels = c(\"delta\", \"zeta\", \"tau\")\n    ),\n    method = case_when(\n      str_detect(name, \"_med$\") ~ \"CM\",\n      str_detect(name, \"_ot$\") ~ \"OT\",\n      str_detect(name, \"_tmatch$\") ~ \"OT-M\",\n      str_detect(name, \"_skh$\") ~ \"SKH\",\n      str_detect(name, \"_sot_12$\") ~ \"ST(1)\",\n      str_detect(name, \"sot_21$\") ~ \"ST(2)\",\n      TRUE ~ \"\"\n    )\n  ) |&gt; \n  select(-name) |&gt; \n  pivot_wider(\n    names_from = type, values_from = value\n  )\n\n# tb_indiv_0_short |&gt;\n#   select(obs_type, method, delta, zeta, tau) |&gt;\n#   pivot_longer(cols = c(delta, zeta, tau)) |&gt;\n#   pivot_wider(names_from = method, values_from = value) |&gt;\n#   arrange(name, obs_type) |&gt;\n#   select(-obs_type) |&gt;\n#   kableExtra::kbl(booktabs = TRUE, format = \"latex\")\n\ntb_indiv_0_short |&gt; \n  group_by(obs_type) |&gt; \n  slice_head(n=1) |&gt; \n  select(coord, coord_OT, coord_TM, coord_SKH, coord_ST1, coord_ST2) |&gt; \n  kableExtra::kbl(booktabs = TRUE)\n\n\n\n\nTable 5.1: Coordinates of two untreated units before and after transport.\n\n\n\n\n\n\nobs_type\ncoord\ncoord_OT\ncoord_TM\ncoord_SKH\ncoord_ST1\ncoord_ST2\n\n\n\n\nClosest\n(-1.5, -1.4)\n(0.6, 0.9)\n(0.2, 0.6)\n(0.3, 0.6)\n(0.5, 1.2)\n(0.9, 0.6)\n\n\nFarthest\n(-2.4, -3.8)\n(1.4, -1.6)\n(3.5, -1.5)\n(-0.6, -0.9)\n(-0.4, -0.4)\n(3.0, -1.8)\n\n\n\n\n\n\n\n\n\n\nThe estimation of the direct, indirect and total effects are reported in Table 5.2, depending on the method used to create the counterfactual.\n\n\nCodes to create the Table.\ntb_indiv_0_short |&gt; \n  select(method, delta, zeta, tau) |&gt; \n  kableExtra::kbl(booktabs = TRUE)\n\n\n\n\nTable 5.2: Estimated values of \\(\\delta_i(0)\\), \\(\\zeta_i(1)\\), and \\(\\tau_i\\) for the two individuals, depending on the transport method.\n\n\n\n\n\n\nmethod\ndelta\nzeta\ntau\n\n\n\n\nOT\n4.2\n4.5\n8.8\n\n\nOT-M\n4.1\n7.7\n11.8\n\n\nSKH\n1.0\n3.4\n4.4\n\n\nST(1)\n1.1\n3.3\n4.4\n\n\nST(2)\n3.9\n7.6\n11.9\n\n\nOT\n1.3\n2.7\n4.0\n\n\nOT-M\n0.4\n3.2\n3.5\n\n\nSKH\n0.5\n3.2\n3.7\n\n\nST(1)\n-0.4\n3.7\n3.3\n\n\nST(2)\n1.4\n3.5\n4.9\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure\nexport_tikz &lt;- FALSE\nfile_name &lt;- \"gaussian-tau-two-indiv\"\nwidth_tikz &lt;- 3.3\nheight_tikz &lt;- 1.55\nif (export_tikz == TRUE)\n  tikz(paste0(\"figs/\", file_name, \".tex\"), width = width_tikz, height = height_tikz)\n\n# par(mar = c(2.1, 2.1, .1, .1), mfrow = c(1, 2))\nlayout(matrix(c(1, 2), nrow = 1, byrow = TRUE), widths = c(10,8.1))\npar(mar = c(2.1, 2.1, .1, .1))\n## Closest----\ncex_pts &lt;- .3\nlwd_arrow &lt;- 1.5\nlength_arrow &lt;- .05\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family,\n  axes = FALSE,\n  cex = cex_pts\n)\naxis(1, at = -3:3, labels = TRUE)\naxis(2, at = -3:3, labels = TRUE)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16, cex = cex_pts)\n\n# Individuals of interest\n# Arrows to OT\narrows(\n  x0 = X0$X1[c(ind_closest)],\n  y0 = X0$X2[c(ind_closest)],\n  x1 = X0_t[c(ind_closest), \"X1\"], \n  y1 = X0_t[c(ind_closest), \"X2\"],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"OT\"]], alpha = 1),\n  lwd = lwd_arrow, lty = 2\n)\n# Arrows to OT-Matching\narrows(\n  x0 = X0$X1[c(ind_closest)],\n  y0 = X0$X2[c(ind_closest)],\n  x1 = X0_tmatch[c(ind_closest), \"X1\"], \n  y1 = X0_tmatch[c(ind_closest), \"X2\"],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"OT-M\"]], alpha = 1),\n  lwd = lwd_arrow, lty = 2\n)\n# Arrows to SKH\narrows(\n  x0 = X0$X1[c(ind_closest)],\n  y0 = X0$X2[c(ind_closest)],\n  x1 = X0_skh_l[[\"0.1\"]][c(ind_closest), \"X1\"], \n  y1 = X0_skh_l[[\"0.1\"]][c(ind_closest), \"X2\"],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"skh\"]], alpha = 1),\n  lwd = lwd_arrow, lty = 2\n)\n# Seq OT (1): X_1 first\n# points(\n#   X0_st_12[c(ind_closest), 1], \n#   X0$X2[c(ind_closest)], \n#   col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5), pch = 16, cex = 1\n# )\narrows(\n  x0 = X0$X1[c(ind_closest)], \n  y0 = X0$X2[c(ind_closest)],\n  x1 = X0_st_12[c(ind_closest), 1], \n  y1 = X0$X2[c(ind_closest)],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0_st_12[c(ind_closest), 1], \n  y0 = X0$X2[c(ind_closest)],\n  x1 = X0_st_12[c(ind_closest), 1], \n  y1 = X0_st_12[c(ind_closest), 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0$X1[c(ind_closest)], \n  y0 = X0$X2[c(ind_closest)],\n  x1 = X0$X1[c(ind_closest)], \n  y1 = X0_st_21[c(ind_closest),2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0$X1[c(ind_closest)], \n  y0 = X0_st_21[c(ind_closest),2],\n  x1 = X0_st_21[c(ind_closest), 1], \n  y1 = X0_st_21[c(ind_closest), 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5),\n  lwd = lwd_arrow\n)\n\n# Individuals\npoints(\n  tb_indiv_0$X1[c(ind_closest)], \n  tb_indiv_0$X2[c(ind_closest)], \n  col = \"black\", pch = c(15), cex = 1\n)\n# Transported values for those individuals (OT)\npoints(\n  X0_t[c(ind_closest), \"X1\"], \n  X0_t[c(ind_closest), \"X2\"], \n  col = colour_methods[[\"OT\"]], pch = c(15), cex = 1\n)\n# With OT_based matching\npoints(\n  X0_tmatch[c(ind_closest), \"X1\"], \n  X0_tmatch[c(ind_closest), \"X2\"], \n  col = colour_methods[[\"OT-M\"]], pch = c(15), cex = 1\n)\n# With Sinkhorn\npoints(\n  X0_skh_l[[\"0.1\"]][c(ind_closest), \"X1\"], \n  X0_skh_l[[\"0.1\"]][c(ind_closest), \"X2\"], \n  col = colour_methods[[\"skh\"]], pch = c(15), cex = 1\n)\n# With Sequential transport (1)\npoints(\n  X0_st_12[c(ind_closest), 1], \n  X0_st_12[c(ind_closest), 2], \n  col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = 1), pch = 15, cex = 1\n)\n# With Sequential transport (2)\npoints(\n  X0_st_21[c(ind_closest), 1], \n  X0_st_21[c(ind_closest), 2], \n  col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = 1), pch = 15, cex = 1\n)\n\n\nif (export_tikz == FALSE) {\n  lab_points_ot &lt;- latex2exp::TeX(\"$\\\\tau_i^{OT}$\")\n  # round(tb_indiv_0$tau_i_ot[c(ind_closest)], 1)\n  lab_points_tmatch &lt;- latex2exp::TeX(\"$\\\\tau_i^{OT-M}$\")\n  # round(tb_indiv_0$tau_i_tmatch[c(ind_closest)], 1)\n  lab_points_skh &lt;- latex2exp::TeX(\"$\\\\tau_i^{SKH}$\")\n  # round(tb_indiv_0$tau_i_skh[c(ind_closest)], 1)\n  lab_points_sot_12 &lt;- latex2exp::TeX(\"$\\\\tau_i^{ST(1)}$\")\n  round(tb_indiv_0$tau_i_sot_12[c(ind_closest)], 1)\n  lab_points_sot_21 &lt;- latex2exp::TeX(\"$\\\\tau_i^{ST(2)}$\")\n  round(tb_indiv_0$tau_i_sot_21[c(ind_closest)], 1)\n} else {\n  lab_points_ot &lt;- \"OT\"\n  lab_points_tmatch &lt;- \"OT-M\"\n  lab_points_skh &lt;- \"SKH\"\n  lab_points_sot_12 &lt;- \"ST(1)\"\n  lab_points_sot_21 &lt;- \"ST(2)\"\n}\n\n\n180 \n4.9 \n\n\nCodes to create the Figure\n# \\tau_i with OT\ntext(\n  x = X0_t[c(ind_closest), \"X1\"] + 1, \n  y = X0_t[c(ind_closest), \"X2\"] + .5, \n  labels = lab_points_ot,\n  col = colour_methods[[\"OT\"]]\n)\n# \\tau_i with OT-M\ntext(\n  x = X0_tmatch[c(ind_closest), \"X1\"] -1.5, \n  y = X0_tmatch[c(ind_closest), \"X2\"] + .5, \n  labels = lab_points_tmatch,\n  col = colour_methods[[\"OT-M\"]]\n)\n# \\tau_i with SKH\ntext(\n  x = X0_skh_l[[\"0.1\"]][c(ind_closest), 1] - .25, \n  y = X0_skh_l[[\"0.1\"]][c(ind_closest), 2] - 1, \n  labels = lab_points_skh,\n  col = colour_methods[[\"skh\"]]\n)\ntext(\n  x = X0_st_12[c(ind_closest), 1], \n  y = X0_st_12[c(ind_closest), 2] + 1, \n  labels = lab_points_sot_12,\n  col = colour_methods[[\"seq_1\"]]\n)\ntext(\n  x = X0_st_21[c(ind_closest), 1] + 1, \n  y = X0_st_21[c(ind_closest), 2] - 1, \n  labels = lab_points_sot_21,\n  col = colour_methods[[\"seq_2\"]]\n)\n\n## Farthest----\npar(mar = c(2.1, .1, .1, .1))\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family,\n  axes = FALSE,\n  cex = cex_pts\n)\naxis(1, at = -3:3, labels = TRUE)\n# axis(2, at = -3:3, labels = TRUE)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16, cex = cex_pts)\n\n# Individuals of interest\n# Arrows to OT\narrows(\n  x0 = X0$X1[c(ind_farthest)],\n  y0 = X0$X2[c(ind_farthest)],\n  x1 = X0_t[c(ind_farthest), \"X1\"], \n  y1 = X0_t[c(ind_farthest), \"X2\"],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"OT\"]], alpha = 1),\n  lwd = lwd_arrow, lty = 2\n)\n# Arrows to OT-Matching\narrows(\n  x0 = X0$X1[c(ind_farthest)],\n  y0 = X0$X2[c(ind_farthest)],\n  x1 = X0_tmatch[c(ind_farthest), \"X1\"], \n  y1 = X0_tmatch[c(ind_farthest), \"X2\"],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"OT-M\"]], alpha = 1),\n  lwd = lwd_arrow, lty = 2\n)\n# Arrows to SKH\narrows(\n  x0 = X0$X1[c(ind_farthest)],\n  y0 = X0$X2[c(ind_farthest)],\n  x1 = X0_skh_l[[\"0.1\"]][c(ind_farthest), \"X1\"], \n  y1 = X0_skh_l[[\"0.1\"]][c(ind_farthest), \"X2\"],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"skh\"]], alpha = 1),\n  lwd = lwd_arrow, lty = 2\n)\n# Seq OT (1): X_1 first\n# points(\n#   X0_st_12[c(ind_farthest), 1], \n#   X0$X2[c(ind_farthest)], \n#   col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5), pch = 16, cex = 1\n# )\narrows(\n  x0 = X0$X1[c(ind_farthest)], \n  y0 = X0$X2[c(ind_farthest)],\n  x1 = X0_st_12[c(ind_farthest), 1], \n  y1 = X0$X2[c(ind_farthest)],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0_st_12[c(ind_farthest), 1], \n  y0 = X0$X2[c(ind_farthest)],\n  x1 = X0_st_12[c(ind_farthest), 1], \n  y1 = X0_st_12[c(ind_farthest), 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5),\n  lwd = lwd_arrow\n)\n# Seq OT (2): X_2 first\n# points(\n#   X0$X1[c(ind_farthest)], \n#   X0_st_21[c(ind_farthest),2], \n#   col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5), pch = 16, cex = 1\n# )\narrows(\n  x0 = X0$X1[c(ind_farthest)], \n  y0 = X0$X2[c(ind_farthest)],\n  x1 = X0$X1[c(ind_farthest)], \n  y1 = X0_st_21[c(ind_farthest),2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0$X1[c(ind_farthest)], \n  y0 = X0_st_21[c(ind_farthest),2],\n  x1 = X0_st_21[c(ind_farthest), 1], \n  y1 = X0_st_21[c(ind_farthest), 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5),\n  lwd = lwd_arrow\n)\n\n# Individuals\npoints(\n  tb_indiv_0$X1[c(ind_farthest)], \n  tb_indiv_0$X2[c(ind_farthest)], \n  col = \"black\", pch = c(15), cex = 1\n)\n# Transported values for those individuals (OT)\npoints(\n  X0_t[c(ind_farthest), \"X1\"], \n  X0_t[c(ind_farthest), \"X2\"], \n  col = colour_methods[[\"OT\"]], pch = c(15), cex = 1\n)\n# With OT-Matching\npoints(\n  X0_tmatch[c(ind_farthest), \"X1\"], \n  X0_tmatch[c(ind_farthest), \"X2\"], \n  col = colour_methods[[\"OT-M\"]], pch = c(15), cex = 1\n)\n# With Sinkhorn\npoints(\n  X0_skh_l[[\"0.1\"]][c(ind_farthest), \"X1\"], \n  X0_skh_l[[\"0.1\"]][c(ind_farthest), \"X2\"], \n  col = colour_methods[[\"skh\"]], pch = c(15), cex = 1\n)\n# With Sequential transport (1)\npoints(\n  X0_st_12[c(ind_farthest), 1], \n  X0_st_12[c(ind_farthest), 2], \n  col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = 1), pch = 15, cex = 1\n)\n# With Sequential transport (2)\npoints(\n  X0_st_21[c(ind_farthest), 1], \n  X0_st_21[c(ind_farthest), 2], \n  col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = 1), pch = 15, cex = 1\n)\n\n\nif (export_tikz == FALSE) {\n  lab_points_ot &lt;- latex2exp::TeX(\"$\\\\tau_i^{OT}\")\n  lab_points_tmatch &lt;- latex2exp::TeX(\"$\\\\tau_i^{OT-M}$\")\n  lab_points_skh &lt;- latex2exp::TeX(\"$\\\\tau_i^{SKH}$\")\n  lab_points_sot_12 &lt;- latex2exp::TeX(\"$\\\\tau_i^{ST(1)}$\")\n  lab_points_sot_21 &lt;- latex2exp::TeX(\"$\\\\tau_i^{ST(2)}$\")\n} else {\n  lab_points_ot &lt;- \"OT\"\n  lab_points_tmatch &lt;- \"OT-M\"\n  lab_points_skh &lt;- \"SKH\"\n  lab_points_sot_12 &lt;- \"ST(1)\"\n  lab_points_sot_21 &lt;- \"ST(2)\"\n}\n# \\tau with OT\ntext(\n  x = X0_t[c(ind_farthest), \"X1\"], \n  y = X0_t[c(ind_farthest), \"X2\"] + .75, \n  labels = lab_points_ot,\n  col = colour_methods[[\"OT\"]]\n)\n# \\tau with OT-Matching\ntext(\n  x = X0_tmatch[c(ind_farthest), \"X1\"] - .25, \n  y = X0_tmatch[c(ind_farthest), \"X2\"] + 1, \n  labels = lab_points_tmatch,\n  col = colour_methods[[\"OT-M\"]]\n)\ntext(\n  x = X0_skh_l[[\"0.1\"]][c(ind_farthest), \"X1\"] - 1.5, \n  y = X0_skh_l[[\"0.1\"]][c(ind_farthest), \"X2\"], \n  labels = lab_points_skh,\n  col = colour_methods[[\"skh\"]]\n)\ntext(\n  x = X0_st_12[c(ind_farthest), 1], \n  y = X0_st_12[c(ind_farthest), 2] + 1, \n  labels = lab_points_sot_12,\n  col = colour_methods[[\"seq_1\"]]\n)\ntext(\n  x = X0_st_21[c(ind_farthest), 1], \n  y = X0_st_21[c(ind_farthest), 2] - 1, \n  labels = lab_points_sot_21,\n  col = colour_methods[[\"seq_2\"]]\n)\n\n\n\n\n\n\n\n\n\nCodes to create the Figure\nif (export_tikz == TRUE) {\n  dev.off()\n  plot_to_pdf(filename = file_name, path = \"./figs/\", keep_tex = FALSE, crop = FALSE)\n}",
    "crumbs": [
      "II. A Gaussian Example",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Gaussian Example</span>"
    ]
  },
  {
    "objectID": "gaussian-example.html#monte-carlo-simulations",
    "href": "gaussian-example.html#monte-carlo-simulations",
    "title": "5  Gaussian Example",
    "section": "5.4 Monte-Carlo Simulations",
    "text": "5.4 Monte-Carlo Simulations\nLet us perform Monte-Carlo simulations to observe the stability of the previous estimations. We define a function, sim_f(), to perform three steps:\n\nGenerate a sample from the DGP shown in Section 13.1,\nBuild the counterfactuals using OT, entropy regularized transport, and Sequential transport as in Section 5.2,\nCompute the causal effects as in Section 5.3.\n\n\n\nThe sim_f() function.\nsim_f &lt;- function(n = 500,\n                  mu0, \n                  mu1, \n                  r0, \n                  r1, \n                  a, \n                  seed = NULL) {\n  \n  if (!is.null(seed)) set.seed(seed)\n  \n  # 1. Generate data\n  df &lt;- gen_data(\n    n = 500, \n    mu0 = mu0, mu1 = mu1, \n    r0 = r0, r1 = r1, a = a, \n    seed = seed\n  )\n  \n  # 2. Building Counterfactuals\n  \n  ## With Optimal Transport\n  # Transporting map for source: group 1, target: group 0 (careful here)\n  Sigma0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\n  Sigma1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n  Mu0 &lt;- rep(a * mu0, 2)\n  Mu1 &lt;- rep(a * mu1, 2)\n  \n  # Mapping from group 0 to group 1\n  ot_map_0_to_1 &lt;- compute_ot_map(\n    mu_source = Mu0, sigma_source = Sigma0, \n    mu_target = Mu1, sigma_target = Sigma1\n  )\n  # Mapping from group 1 to group 0\n  ot_map_1_to_0 &lt;- compute_ot_map(\n    mu_source = Mu1, sigma_source = Sigma0, \n    mu_target = Mu0, sigma_target = Sigma0\n  )  \n  \n  # Apply transport map to treated units (A = 1)\n  X0 &lt;- as.matrix(df[df$A == 0, c(\"X1\", \"X2\")])\n  X1 &lt;- as.matrix(df[df$A == 1, c(\"X1\", \"X2\")])\n  X0_t &lt;- apply_ot_transport(X = X0, mapping = ot_map_0_to_1)\n  colnames(X0_t) &lt;- c(c(\"X1\", \"X2\"))\n  X1_t &lt;- apply_ot_transport(X = X1, mapping = ot_map_1_to_0)\n  colnames(X1_t) &lt;- c(c(\"X1\", \"X2\"))\n  \n  # With OT-Matching\n  X0_tmatch &lt;- transport_many_to_one(X_source = X0, X_target = X1)\n  X1_tmatch &lt;- transport_many_to_one(X_source = X1, X_target = X0)\n  \n  ## With Entropy regularized transport\n  # Transport from group 0 to group 1:\n  X0_skh &lt;- transport_regul(\n    X_source = X0, \n    X_target = X1, \n    gamma = 0.1\n  )\n  # Transport from group 1 to group 0:\n  X1_skh &lt;- transport_regul(\n    X_source = X1, \n    X_target = X0, \n    gamma = 0.1\n  )\n  \n  ## With Sequential Transport\n  # Transport from group 0 to group 1: X1 then X2 | X1\n  X0_st_12 &lt;- sequential_transport_12(\n    X = X0, M_source = Mu0, S_source = Sigma0, M_target = Mu1, S_target = Sigma1\n  )\n  # Transport from group 1 to group 0: X1 then X2 | X1\n  X1_st_12 &lt;- sequential_transport_12(\n    X = X1, M_source = Mu1, S_source = Sigma1, M_target = Mu0, S_target = Sigma0\n  )\n  # Transport from group 0 to group 1: X2 then X1 | X2\n  X0_st_21 &lt;- sequential_transport_21(\n    X = X0, M_source = Mu0, S_source = Sigma0, M_target = Mu1, S_target = Sigma1\n  )\n  # Transport from group 1 to group 0: X2 then X1 | X2\n  X1_st_21 &lt;- sequential_transport_21(\n    X = X1, M_source = Mu1, S_source = Sigma1, M_target = Mu0, S_target = Sigma0\n  )\n  \n  # 3. Measuring Total Causal Effect\n  tb &lt;- df[, c(\"Y\", \"A\", \"X1\", \"X2\")]\n  A_name &lt;- \"A\"\n  A_untreated &lt;- 0\n  Y_name &lt;- \"Y\"\n  \n  # Causal Mediation Analysis\n  med_mod_12 &lt;- mediation::multimed(\n    outcome = \"Y\", \n    med.main = \"X1\", \n    med.alt = \"X2\", \n    treat = \"A\", \n    data = df\n  )\n  med_mod_21 &lt;- mediation::multimed(\n    outcome = \"Y\", \n    med.main = \"X2\", \n    med.alt = \"X1\", \n    treat = \"A\", \n    data = df\n  )\n  \n  delta_0_med &lt;- mean((med_mod_12$d0.lb + med_mod_12$d0.ub) / 2) +\n    mean((med_mod_21$d0.lb + med_mod_21$d0.ub) / 2)\n  delta_1_med &lt;- mean((med_mod_12$d1.lb + med_mod_12$d1.ub) / 2) + \n    mean((med_mod_21$d1.lb + med_mod_21$d1.ub) / 2)\n  tot_effect_med &lt;- med_mod_12$tau\n  zeta_0_med &lt;- tot_effect_med - delta_1_med\n  zeta_1_med &lt;- tot_effect_med-delta_0_med\n  \n  # With OT counterfactuals\n  tb_untreated &lt;- tb |&gt; filter(!!sym(A_name) == !!A_untreated)\n  tb_treated &lt;- tb |&gt; filter(!!sym(A_name) != !!A_untreated)\n  \n  causal_effects_ot &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_t),\n    data_cf_treated = as_tibble(X1_t),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  \n  # With OT-Matching counterfactuals\n  causal_effects_tmatch &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_tmatch),\n    data_cf_treated = as_tibble(X1_tmatch),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  \n  # With entropy regularized transport\n  causal_effects_skh &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_skh),\n    data_cf_treated = as_tibble(X1_skh),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  \n  # With Sequential Transport counterfactuals\n  causal_effect_sot_12 &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    data_cf_treated = as_tibble(X1_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  causal_effect_sot_21 &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    data_cf_treated = as_tibble(X1_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  \n  tibble(\n    # Mediation\n    delta_0_med = delta_0_med,\n    delta_1_med = delta_1_med,\n    zeta_0_med = zeta_0_med,\n    zeta_1_med = zeta_1_med,\n    tot_effect_med = tot_effect_med,\n    # OT\n    delta_0_ot = causal_effects_ot$delta_0,\n    delta_1_ot = causal_effects_ot$delta_1,\n    delta_0_ot_obs = causal_effects_ot$delta_0_obs,\n    delta_1_ot_obs = causal_effects_ot$delta_1_obs,\n    zeta_0_ot = causal_effects_ot$zeta_0,\n    zeta_1_ot = causal_effects_ot$zeta_1,\n    tot_effect_ot = causal_effects_ot$tot_effect,\n    tot_effect_ot_obs = causal_effects_ot$tot_effect_obs,\n    # OT-M\n    delta_0_tmatch = causal_effects_tmatch$delta_0,\n    delta_1_tmatch = causal_effects_tmatch$delta_1,\n    delta_0_tmatch_obs = causal_effects_tmatch$delta_0_obs,\n    delta_1_tmatch_obs = causal_effects_tmatch$delta_1_obs,\n    zeta_0_tmatch = causal_effects_tmatch$zeta_0,\n    zeta_1_tmatch = causal_effects_tmatch$zeta_1,\n    tot_effect_tmatch = causal_effects_tmatch$tot_effect,\n    tot_effect_tmatch_obs = causal_effects_tmatch$tot_effect_obs,\n    # SKH\n    delta_0_skh = causal_effects_skh$delta_0,\n    delta_1_skh = causal_effects_skh$delta_1,\n    delta_0_skh_obs = causal_effects_skh$delta_0_obs,\n    delta_1_skh_obs = causal_effects_skh$delta_1_obs,\n    zeta_0_skh = causal_effects_skh$zeta_0,\n    zeta_1_skh = causal_effects_skh$zeta_1,\n    tot_effect_skh = causal_effects_skh$tot_effect,\n    tot_effect_skh_obs = causal_effects_skh$tot_effect_obs,\n    # SOT 12\n    delta_0_sot_12 = causal_effect_sot_12$delta_0,\n    delta_1_sot_12 = causal_effect_sot_12$delta_1,\n    delta_0_sot_12_obs = causal_effect_sot_12$delta_0_obs,\n    delta_1_sot_12_obs = causal_effect_sot_12$delta_1_obs,\n    zeta_0_sot_12 = causal_effect_sot_12$zeta_0,\n    zeta_1_sot_12 = causal_effect_sot_12$zeta_1,\n    tot_effect_sot_12 = causal_effect_sot_12$tot_effect,\n    tot_effect_sot_12_obs = causal_effect_sot_12$tot_effect_obs,\n    # SOT 21\n    delta_0_sot_21 = causal_effect_sot_21$delta_0,\n    delta_1_sot_21 = causal_effect_sot_21$delta_1,\n    delta_0_sot_21_obs = causal_effect_sot_21$delta_0_obs,\n    delta_1_sot_21_obs = causal_effect_sot_21$delta_1_obs,\n    zeta_0_sot_21 = causal_effect_sot_21$zeta_0,\n    zeta_1_sot_21 = causal_effect_sot_21$zeta_1,\n    tot_effect_sot_21 = causal_effect_sot_21$tot_effect,\n    tot_effect_sot_21_obs = causal_effect_sot_21$tot_effect_obs,\n    n = n,\n    seed = seed,\n    mu0 = mu0,\n    mu1 = mu1,\n    r0 = r0,\n    r1 = r1,\n    a = a\n  )\n}\n\n\nThe simulations can be run in parallel, as follows.\n\n# This chunk takes 3 minutes and 40 seconds to run\n# (MB Pro 2023, Apple M2 Pro ship, 32 GB RAM).\n# We do not evaluate when compiling the document.\n# Instead, we load previously obtained results.\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(tidyverse)\n  library(mnormt)\n  library(expm)\n  library(randomForest)\n}) |&gt;\n  invisible()\n\nclusterExport(\n  cl = cl, c(\n    \"gen_data\", \"compute_ot_map\", \"apply_ot_transport\",\n    \"transport_regul\", \"transport_many_to_one\",\n    \"sequential_transport_12\", \"sequential_transport_21\",\n    \"causal_effects_cf\", \"sim_f\"\n  )\n)\n\nres_sim &lt;- pbapply::pblapply(1:200, function(seed) {\n  sim_f(n = 500, mu0 = -1, mu1 = +1, r0 = +.7, r1 = -.5, a = 1, seed = seed)\n}, cl = cl)\n\nstopCluster(cl)\nres_sim &lt;- list_rbind(res_sim)\n\nsave(res_sim, file = \"../output/res_sim-gaussian-mc-a1.rda\")\n\nWe load previously obtained results:\n\nload(\"../output/res_sim-gaussian-mc-a1.rda\")\n\n\n\nCodes to create the Figure.\n#' @parma metric_name Name of the metric (e.g., \"tot_effect_ot\")\n#' @param method_label Label of the method (for title, e.g., \"OT\")\nplot_hist_sim &lt;- function(metric_name, \n                          method_label,\n                          x_lim = NULL,\n                          y_axis = TRUE,\n                          export_tikz = FALSE) {\n  # type &lt;- match.arg(type)\n  type &lt;- case_when(\n    str_detect(metric_name, \"^delta\") ~ \"delta\",\n    str_detect(metric_name, \"^zeta\") ~ \"zeta\",\n    str_detect(metric_name, \"^tot_effect\") & !str_detect(metric_name, \"obs$\") ~ \"tau\",\n    str_detect(metric_name, \"^tot_effect\") & str_detect(metric_name, \"obs$\") ~ \"theta\",\n    TRUE ~ NA_character_\n  )\n  group &lt;- case_when(\n    str_detect(metric_name, \"_0_\") ~ \"0\",\n    str_detect(metric_name, \"_1_\") ~ \"1\",\n    TRUE ~ \"\"\n  )\n  \n  if (type == \"delta\") {\n    title_lab &lt;- paste0(\"$\\\\bar{\\\\delta}_\", group, \"$, \", method_label)\n  } else if (type == \"zeta\") {\n    title_lab &lt;- paste0(\"$\\\\bar{\\\\zeta}_\", group, \"$, \", method_label)\n  } else if (type == \"tau\") {\n    title_lab &lt;- paste0(\"$\\\\bar{\\\\tau}$, \", method_label)\n  } else {\n    title_lab &lt;- paste0(\"$\\\\bar{\\\\theta}$, \", method_label)\n  }\n  \n  if (export_tikz == FALSE) {\n    title_lab &lt;- latex2exp::TeX(title_lab)\n  }\n  \n  if (group == \"0\") {\n    fill_col &lt;- colGpe0\n  } else if (group == \"1\") {\n    fill_col &lt;- colGpe1\n  } else {\n    fill_col &lt;- \"gray\"\n  }\n  \n  if (is.null(x_lim)) x_lim &lt;- range(res_sim |&gt; pull(!!metric_name))\n  \n  hist(\n    res_sim |&gt; pull(!!metric_name), \n    main = title_lab,\n    xlab = \"\",\n    col = adjustcolor(fill_col, alpha = .5),\n    xlim = x_lim,\n    axes = FALSE\n  )\n  axis(1)\n  if (y_axis == TRUE) axis(2)\n  if (type == \"delta\") {\n    abline(v = (a1+a2)*(mu1-mu0), col = \"darkred\", lty = 2, lwd = 2)\n  } else if (type == \"zeta\") {\n    abline(v = a0, col = \"darkred\", lty = 2, lwd = 2)\n  } else if (type %in% c(\"tau\", \"theta\")) {\n    abline(v = (a1+a2)*(mu1-mu0) + a0, col = \"darkred\", lty = 2, lwd = 2)\n  }\n}\n\n\nexport_tikz &lt;- FALSE\nfile_name &lt;- \"gaussian-hist-mc\"\n\nif (export_tikz == TRUE)\n  tikz(paste0(\"figs/\", file_name, \".tex\"), width = 2.8, height = 2.8)\n\npar(mar = c(2.1, 2.1, 2.1, .5), mfrow = c(6, 3))\n# CM\nx_lim &lt;- c(0,5); plot_hist_sim(metric_name = \"delta_0_med\", method_label = \"CM\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5); plot_hist_sim(metric_name = \"zeta_1_med\", method_label = \"CM\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5); plot_hist_sim(metric_name = \"tot_effect_med\", method_label = \"CM\", x_lim = x_lim, export_tikz = export_tikz)\n# OT\nx_lim &lt;- c(0,5); plot_hist_sim(metric_name = \"delta_0_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5); plot_hist_sim(metric_name = \"zeta_1_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5); plot_hist_sim(metric_name = \"tot_effect_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\n# OT-M\nx_lim &lt;- c(0,5); plot_hist_sim(metric_name = \"delta_0_tmatch\", method_label = \"OT-M\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5); plot_hist_sim(metric_name = \"zeta_1_tmatch\", method_label = \"OT-M\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5); plot_hist_sim(metric_name = \"tot_effect_tmatch\", method_label = \"OT-M\", x_lim = x_lim, export_tikz = export_tikz)\n# SKH\nx_lim &lt;- c(0,5); plot_hist_sim(metric_name = \"delta_0_skh\", method_label = \"SKH\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5); plot_hist_sim(metric_name = \"zeta_1_skh\", method_label = \"SKH\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5); plot_hist_sim(metric_name = \"tot_effect_skh\", method_label = \"SKH\", x_lim = x_lim, export_tikz = export_tikz)\n# ST(1)\nx_lim &lt;- c(0,5); plot_hist_sim(metric_name = \"delta_0_sot_12\", method_label = \"ST (1)\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5); plot_hist_sim(metric_name = \"zeta_1_sot_12\", method_label = \"ST (1)\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5); plot_hist_sim(metric_name = \"tot_effect_sot_12\", method_label = \"ST (1)\", x_lim= x_lim, export_tikz = export_tikz)\n# ST(2)\nx_lim &lt;- c(0,5); plot_hist_sim(metric_name = \"delta_0_sot_21\", method_label = \"ST (2)\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5); plot_hist_sim(metric_name = \"zeta_1_sot_21\", method_label = \"ST (2)\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5); plot_hist_sim(metric_name = \"tot_effect_sot_21\", method_label = \"ST (2)\", x_lim= x_lim, export_tikz = export_tikz)\n\nif (export_tikz == TRUE) {\n  dev.off()\n  plot_to_pdf(filename = file_name, path = \"./figs/\", keep_tex = FALSE, crop = TRUE)\n}\n\n\n\n\n\nFigure 5.7: Estimated values of \\(\\bar{\\delta}(0)\\), \\(\\bar{\\zeta}(1)\\), and \\(\\bar{\\tau}\\) across 200 Monte Carlo simulations using Causal Mediation (CM), Optimal Transport (OT), Entropy Regularized Transports using Sinkhorn (SKH), and Sequential Transport ST (1) (moving \\(X_1\\) first) and ST (2) (moving \\(X_2\\) first). The red vertical bar denotes the theoretical value.\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\npar(mar = c(2.1, 2.1, 2.1, .5), mfrow = c(6, 3))\n# CM\nx_lim &lt;- c(0,5); plot_hist_sim(metric_name = \"delta_1_med\", method_label = \"CM\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5); plot_hist_sim(metric_name = \"zeta_0_med\", method_label = \"CM\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5); plot_hist_sim(metric_name = \"tot_effect_med\", method_label = \"CM\", x_lim = x_lim, export_tikz = export_tikz)\n# OT\nx_lim &lt;- c(0,5); plot_hist_sim(metric_name = \"delta_1_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5); plot_hist_sim(metric_name = \"zeta_0_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5); plot_hist_sim(metric_name = \"tot_effect_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\n# OT-M\nx_lim &lt;- c(0,5); plot_hist_sim(metric_name = \"delta_1_tmatch\", method_label = \"OT-M\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5); plot_hist_sim(metric_name = \"zeta_0_tmatch\", method_label = \"OT-M\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5); plot_hist_sim(metric_name = \"tot_effect_tmatch\", method_label = \"OT-M\", x_lim = x_lim, export_tikz = export_tikz)\n# SKH\nx_lim &lt;- c(0,5); plot_hist_sim(metric_name = \"delta_1_skh\", method_label = \"SKH\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5); plot_hist_sim(metric_name = \"zeta_0_skh\", method_label = \"SKH\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5); plot_hist_sim(metric_name = \"tot_effect_skh\", method_label = \"SKH\", x_lim = x_lim, export_tikz = export_tikz)\n# ST(1)\nx_lim &lt;- c(0,5); plot_hist_sim(metric_name = \"delta_1_sot_12\", method_label = \"ST (1)\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5); plot_hist_sim(metric_name = \"zeta_0_sot_12\", method_label = \"ST (1)\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5); plot_hist_sim(metric_name = \"tot_effect_sot_12\", method_label = \"ST (1)\", x_lim= x_lim, export_tikz = export_tikz)\n# ST(2)\nx_lim &lt;- c(0,5); plot_hist_sim(metric_name = \"delta_1_sot_21\", method_label = \"ST (2)\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5); plot_hist_sim(metric_name = \"zeta_0_sot_21\", method_label = \"ST (2)\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5); plot_hist_sim(metric_name = \"tot_effect_sot_21\", method_label = \"ST (2)\", x_lim= x_lim, export_tikz = export_tikz)\n\n\n\n\n\nFigure 5.8: Estimated values of \\(\\bar{\\delta}(1)\\), \\(\\bar{\\zeta}(0)\\), and \\(\\bar{\\tau}\\) across 200 Monte Carlo simulations using Causal Mediation (CM), Optimal Transport (OT), Entropy Regularized Transports using Sinkhorn (SKH), and Sequential Transport ST (1) (moving \\(X_1\\) first) and ST (2) (moving \\(X_2\\) first). The red vertical bar denotes the theoretical value.\n\n\n\n\n\n\n\n\nThe comparison of the estimates made using observed values for \\(y\\) (whenever observed) is shown in Figure 5.9.\n\n\nCodes to create the Figure.\npar(mar = c(2.1, 2.1, 2.1, .5), mfrow = c(6,2))\nx_lim &lt;- c(3,5)\nplot_hist_sim(metric_name = \"tot_effect_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_tmatch\", method_label = \"OT-M\", x_lim = x_lim, export_tikz = export_tikz)\n\nplot_hist_sim(metric_name = \"tot_effect_ot_obs\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_tmatch_obs\", method_label = \"OT-M\", x_lim = x_lim, export_tikz = export_tikz)\n\n\nplot_hist_sim(metric_name = \"tot_effect_skh\", method_label = \"SKH\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_sot_12\", method_label = \"ST (1)\", x_lim = x_lim, export_tikz = export_tikz)\n\n\nplot_hist_sim(metric_name = \"tot_effect_skh_obs\", method_label = \"SKH\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_sot_12_obs\", method_label = \"ST (1)\", x_lim = x_lim, export_tikz = export_tikz)\n\n\n\nplot_hist_sim(metric_name = \"tot_effect_sot_21\", method_label = \"ST (2)\", x_lim = x_lim, export_tikz = export_tikz)\nplot.new()\n\nplot_hist_sim(metric_name = \"tot_effect_sot_21_obs\", method_label = \"ST (2)\", x_lim = x_lim, export_tikz = export_tikz)\nplot.new()\n\n\n\n\n\nFigure 5.9: Estimated values of \\(\\bar{\\tau}\\) and \\(\\bar{\\theta}\\) across 200 Monte Carlo simulations using ptimal Transport (OT), and Sequential Transport ST (1) (moving \\(X_1\\) first) and ST (2) (moving \\(X_2\\) first). The red vertical bar denotes the theoretical value.\n\n\n\n\n\n\n\n\nWe also use violin plots, since exporting these histograms in a two-column format paper is not a good idea.\n\n\nCodes to create the Figure.\nexport_pdf &lt;- FALSE\n\np &lt;- ggplot(\n  data = res_sim |&gt; \n    select(\n      delta_0_med, delta_0_ot, delta_0_tmatch, \n      delta_0_skh, delta_0_sot_12, delta_0_sot_21,\n      #\n      zeta_1_med, zeta_1_ot, zeta_1_tmatch, \n      zeta_1_skh, zeta_1_sot_12, zeta_1_sot_21,\n      #\n      tot_effect_med, tot_effect_ot, tot_effect_tmatch, \n      tot_effect_skh, tot_effect_sot_12, tot_effect_sot_21\n    ) |&gt; \n    mutate(row = row_number()) |&gt; \n    pivot_longer(cols = -row) |&gt; \n    mutate(\n      type = case_when(\n        str_detect(name, \"^delta\") ~ \"delta\",\n        str_detect(name, \"^zeta\") ~ \"zeta\",\n        str_detect(name, \"^tot_effect\") & !str_detect(name, \"obs$\") ~ \"tau\",\n        TRUE ~ NA_character_\n      ),\n      type = factor(\n        type, \n        levels = c(\"delta\", \"zeta\", \"tau\"),\n        labels = c(\"$\\\\bar{\\\\delta}(0)$\", \"$\\\\bar{\\\\zeta}(1)$\", \n                   \"$\\\\bar{\\\\tau}$\")\n      ),\n      method = case_when(\n        str_detect(name, \"_med$\") ~ \"CM\",\n        str_detect(name, \"_ot$\") ~ \"OT\",\n        str_detect(name, \"_tmatch$\") ~ \"OT-M\",\n        str_detect(name, \"_skh$\") ~ \"SKH\",\n        str_detect(name, \"_sot_12$\") ~ \"ST(1)\",\n        str_detect(name, \"sot_21$\") ~ \"ST(2)\",\n        TRUE ~ \"\"\n      ),\n      method = factor(\n        method, levels = rev(c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\"))\n      )\n    )\n) +\n  geom_violin(\n    mapping = aes(x = value, y = method, fill = method),\n    draw_quantiles = c(.25, .5, .75)) +\n  labs(x = NULL, y = NULL)\n\nif (export_pdf == TRUE) {\n  p &lt;- p + \n    facet_wrap(\n      ~ type, scales = \"free_x\"\n    )\n} else {\n  p &lt;- p +\n    facet_wrap(\n      ~ type, scales = \"free_x\",\n      labeller = as_labeller(latex2exp::TeX, default = label_parsed)\n    )\n}\n\np &lt;- p +\n  geom_vline(\n    data = tibble(\n      type = c(\"$\\\\bar{\\\\delta}(0)$\", \"$\\\\bar{\\\\zeta}(1)$\", \n               \"$\\\\bar{\\\\tau}$\"), \n      val_theo = c(\n        (a1+a2)*(mu1-mu0),\n        a0,\n        (a1+a2)*(mu1-mu0) + a0\n      )\n    ) |&gt; \n      mutate(\n        type = factor(\n          type, \n          levels = c(\"$\\\\bar{\\\\delta}(0)$\", \"$\\\\bar{\\\\zeta}(1)$\", \n                     \"$\\\\bar{\\\\tau}$\")\n        )\n      ),\n    mapping = aes(xintercept = val_theo),\n    colour = \"darkred\", linetype = \"dashed\", linewidth = 1\n  ) +\n  scale_fill_manual(\n    NULL, \n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\"\n  ) +\n  theme_paper()\n\np\n\nif (export_pdf == TRUE) {\n  ggplot2_to_pdf(\n    plot = p + theme(panel.spacing = unit(0.4, \"lines\")) +\n      scale_x_continuous(\n        labels = function(x) paste0(\"$\", x, \"$\")\n      ),\n    filename = \"gaussian-violin-mc\", path = \"figs/\", \n    width = 3.4, height = 2,\n    crop = TRUE\n  )\n  \n  system(paste0(\"pdfcrop figs/gaussian-violin-mc.pdf figs/gaussian-violin-mc.pdf\"))\n}\n\n\n\n\n\nFigure 5.10: Estimated values of \\(\\bar{\\delta}(0)\\), \\(\\bar{\\zeta}(1)\\), and \\(\\bar{\\tau}\\) across 200 Monte Carlo simulations using Causal Mediation (CM), Optimal Transport (OT), Entropy Regularized Transports using Sinkhorn (SKH), and Sequential Transport ST (1) (moving \\(X_1\\) first) and ST (2) (moving \\(X_2\\) first). The red vertical bar denotes the theoretical value.\n\n\n\n\n\n\n\n\n\n\n\n\nPeyré, Gabriel, and Marco Cuturi. 2019. “Computational Optimal Transport: With Applications to Data Science.” Foundations and Trends in Machine Learning 11 (5-6): 355–607.\n\n\nSinkhorn, Richard. 1962. “On the Factor Spaces of the Complex Doubly Stochastic Matrices.” Notices of the American Mathematical Society 9: 334–35.",
    "crumbs": [
      "II. A Gaussian Example",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Gaussian Example</span>"
    ]
  },
  {
    "objectID": "gaussian-example-mc.html",
    "href": "gaussian-example-mc.html",
    "title": "6  Monte Carlo Simulations",
    "section": "",
    "text": "6.1 Functions\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colGpe1}{RGB}{0, 160, 138}\n\\definecolor{colGpe0}{RGB}{242, 173, 0}\n\\]\nLet us redefine the function shown in Chapter 5 that will be used to perform the simulations here.\nFunctions used to generate the data (gen_data()), create counterfactuals with optimal transport (compute_ot_map(), apply_ot_transport()) and sequential transport (sequential_transport_12(), sequential_transport_21()), compute the total causal effect based on (causal_effects_cf())\n## Data----\n\n#' @param n0 Number of units in group 0.\n#' @param n1 Number of units in group 1.\n#' @param mu0 Mean of the two covariates in group 0.\n#' @param mu1 Mean of the two covariates in group 1.\n#' @param r0 Covariance of the two covariates in group 0.\n#' @param r1 Covariance of the two covariates in group 1.\n#' @param a Shift parameter for the mean in both groups (default to 1: no shift). Larger values decrease overlap.\n#' @param seed Random seed for reproducibility.\ngen_data &lt;- function(n0 = 250,\n                     n1 = 250,\n                     mu0 = -1,\n                     mu1 = +1,\n                     r0 = +.7,\n                     r1 = -.5,\n                     a = 1,\n                     seed = NULL) {\n  \n  if (!is.null(seed)) set.seed(seed)\n  \n  a0 &lt;- 3\n  a1 &lt;- 2\n  a2 &lt;- -1.5\n  Mu0 &lt;- rep(mu0, 2)\n  Mu1 &lt;- rep(mu1, 2)\n  Sig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\n  Sig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n  \n  # Generate covariates for each group\n  X0 &lt;- rmnorm(n0, mean = a * Mu0, varcov = Sig0)\n  X1 &lt;- rmnorm(n1, mean = a * Mu1, varcov = Sig1)\n  # Combine into a single covariate matrix\n  X &lt;- rbind(X0, X1)\n  # Treatment indicator: 0 for first n0, 1 for next n1\n  A &lt;- c(rep(0, n0), rep(1, n1))\n  # Random noise for each unit\n  E &lt;- rnorm(n0 + n1)\n  \n  # Outcomes\n  Y0 &lt;- a1 * X[, 1] + a2 * X[, 2] + E\n  Y1 &lt;- a1 * X[, 1] + a2 * X[, 2] + a0 + E\n  Y &lt;- A * Y1 + (1 - A) * Y0\n  \n  df &lt;- tibble(\n    X1 = X[, 1],\n    X2 = X[, 2],\n    A = A,\n    Y0 = Y0,\n    Y1 = Y1,\n    Y  = Y\n  )\n  \n  df\n}\n\n## Optimal Transport----\n\n#' Optimal transport mapping between two Gaussian distributions \n#'  (from \\eqn{\\mathcal{N}(\\mu_{\\text{source}}, \\Sigma_{\\text{source}})} to \n#'   \\eqn{\\mathcal{N}(\\mu_{\\text{target}}, \\Sigma_{\\text{target}})})\n#'  \n#' @param mu_source Mean vector of the source Gaussian.\n#' @param sigma_source Covariance matrix of the source Gaussian.\n#' @param mu_target Mean vector of the target Gaussian.\n#' @param sigma_target Covariance matrix of the target Gaussian.\ncompute_ot_map &lt;- function(mu_source, sigma_source, mu_target, sigma_target) {\n  sqrt_sigma_source &lt;- sqrtm(sigma_source)\n  sqrt_sigma_source_inv &lt;- solve(sqrt_sigma_source)\n  \n  inner &lt;- sqrt_sigma_source %*% sigma_target %*% sqrt_sigma_source\n  sqrt_inner &lt;- sqrtm(inner)\n  \n  A &lt;- sqrt_sigma_source_inv %*% sqrt_inner %*% sqrt_sigma_source_inv\n  \n  list(A = A, shift = mu_target - A %*% mu_source)\n}\n\n#' Function to apply the transport map to simulated data\n#' \n#' @param X Observations to transport.\n#' @param mapping Optimal transport mapping (from `compute_ot_map()`)?\napply_ot_transport &lt;- function(X, mapping) {\n  A &lt;- mapping$A\n  shift &lt;- mapping$shift\n  t(apply(X, 1, function(x) as.vector(shift + A %*% x)))\n}\n\n## Penalized Transport----\n#' @param X_source Matrix of observations to transport from the source group.\n#' @param X_target Matrix of observations from the target group.\n#' @param gamma A regularization parameter (default to 0.1).\ntransport_regul &lt;- function(X_source, \n                            X_target, \n                            gamma) {\n\n  X_source &lt;- as.matrix(X_source)\n  X_target &lt;- as.matrix(X_target)\n  n_source &lt;- nrow(X_source)\n  n_target &lt;- nrow(X_target)\n  # Uniform weights\n  w_source &lt;- rep(1 / n_source, n_source)\n  w_target &lt;- rep(1 / n_target, n_target)\n  \n  # Pairwise squared Euclidean distance\n  cost_mat &lt;- as.matrix(dist(rbind(X_source, X_target)))^2\n  C &lt;- cost_mat[1:n_source, (n_source + 1):(n_source + n_target)]\n  \n  # Run Sinkhorn with entropic regularization gamma\n  skh_res &lt;- T4transport::sinkhornD(\n    D = C, p = 2, wx = w_source, wy = w_target, lambda = gamma\n  )\n\n  # Extract and normalize plan\n  ot_plan_skh &lt;- skh_res$plan\n  ot_plan_skh &lt;- sweep(ot_plan_skh, 1, rowSums(ot_plan_skh), FUN = \"/\")\n  \n  ot_plan_skh %*% X_target\n}\n\n## Transport Many-to-one----\n\n#' @param X_source Source characteristics\n#' @param X_target Target characteristics\n#' @param method Algorithm to use for transport\ntransport_many_to_one &lt;- function(X_source, \n                                  X_target, \n                                  method = \"shortsimplex\") {\n  n_source &lt;- nrow(X_source)\n  n_target &lt;- nrow(X_target)\n  \n  # Uniform weights\n  w_source &lt;- rep(1 / n_source, n_source)\n  w_target &lt;- rep(1 / n_target, n_target)\n  \n  # Cost matrix\n  cost &lt;- as.matrix(dist(rbind(X_source, X_target)))\n  cost &lt;- cost[1:n_source, (n_source + 1):(n_source + n_target)]\n  \n  # Solve OT plan\n  ot_plan &lt;- transport::transport(\n    w_source, w_target, costm = cost, method = method\n  )\n  \n  # For each source unit, select the target with the highest mass\n  best_match &lt;- ot_plan |&gt;\n    dplyr::group_by(from) |&gt;\n    dplyr::slice_max(mass, n = 1, with_ties = FALSE) |&gt;\n    dplyr::ungroup()\n  \n  # Matched matrix\n  X_matched &lt;- X_target[best_match$to, , drop = FALSE]\n  \n  X_matched\n}\n\n## Sequential Optimal Transport----\n\n#' Sequential transport from N(M_source, S_source) to N(M_target, S_target),\n#' along X1, then X2 | X1\n#'\n#' @param X n x 2 matrix of source observations.\n#' @param M_source Mean vector of the source distribution (length 2).\n#' @param S_source Covariance matrix of the source distribution (2x2).\n#' @param M_target Mean vector of the target distribution.\n#' @param S_target Covariance matrix of the target distribution.\nsequential_transport_12 &lt;- function(X, \n                                    M_source, \n                                    S_source, \n                                    M_target, \n                                    S_target) {\n  \n  # marginal univariate transport along the first coordinate (X_1)\n  T1x &lt;- qnorm(\n    pnorm(X[, 1], mean = M_source[1], sd = sqrt(S_source[1, 1])),\n    mean = M_target[1], sd = sqrt(S_target[1, 1])\n  )\n  \n  # conditional parameters for X_2 | X_1\n  m_source &lt;- M_source[2] + S_source[1, 2] / S_source[1, 1] * (X[, 1] - M_source[1])\n  s_source &lt;- S_source[2, 2] - S_source[1, 2]^2 / S_source[1, 1]\n  \n  m_target &lt;- M_target[2] + S_target[1, 2] / S_target[1, 1] * (T1x - M_target[1])\n  s_target &lt;- S_target[2, 2] - S_target[1, 2]^2 / S_target[1, 1]\n  \n  # conditional transport for the second coordinate\n  T2x &lt;- qnorm(\n    pnorm(X[, 2], mean = m_source, sd = sqrt(s_source)),\n    mean = m_target, sd = sqrt(s_target)\n  )\n  \n  cbind(T1x, T2x)\n}\n\n#' Sequential transport from N(M_source, S_source) to N(M_target, S_target),\n#' along X2, then X1 | X2\n#'\n#' @param X n x 2 matrix of source observations.\n#' @param M_source Mean vector of the source distribution (length 2).\n#' @param S_source Covariance matrix of the source distribution (2x2).\n#' @param M_target Mean vector of the target distribution.\n#' @param S_target Covariance matrix of the target distribution.\nsequential_transport_21 &lt;- function(X, M_source, S_source, M_target, S_target) {\n  \n  # marginal univariate transport along X_2\n  T2x &lt;- qnorm(\n    pnorm(X[, 2], mean = M_source[2], sd = sqrt(S_source[2, 2])),\n    mean = M_target[2], sd = sqrt(S_target[2, 2])\n  )\n  \n  # conditional parameters for X_1 | X_2\n  m_source &lt;- M_source[1] + S_source[1, 2] / S_source[2, 2] * (X[, 2] - M_source[2])\n  s_source &lt;- S_source[1, 1] - S_source[1, 2]^2 / S_source[2, 2]\n  \n  m_target &lt;- M_target[1] + S_target[1, 2] / S_target[2, 2] * (T2x - M_target[2])\n  s_target &lt;- S_target[1, 1] - S_target[1, 2]^2 / S_target[2, 2]\n  \n  # conditional transport for X1 | X_2\n  T1x &lt;- qnorm(\n    pnorm(X[, 1], mean = m_source, sd = sqrt(s_source)),\n    mean = m_target, sd = sqrt(s_target)\n  )\n  \n  cbind(T1x, T2x)\n}\n\n## Causal Effect----\n#' Estimation of total causal effect using counterfactuals.\n#' \n#' @param data_untreated Dataset with the untreated units only.\n#' @param data_treated Dataset with the treated units only.\n#' @param data_cf_untreated Counterfactuals for untreated had they been treated.\n#' @param data_cf_treated Counterfactuals for treated had they been untreated.\n#' @param Y_name Name of the column with the outcome variable.\n#' @param A_name Name of the column with the treatment variable.\n#' @param A_untreated Value of the treatment for the untreated units.\n#' \n#' @returns A list:\n#' - `delta_0_i`: \\eqn{\\delta_(0)}, individual causal mediation effects for \n#'   \\eqn{a=0} (computed on untreated),\n#' - `delta_0`: \\eqn{\\bar{\\delta}(0)}, average causal mediation effect for \n#'   \\eqn{a=0} (computed on untreated),\n#' - `delta_1_i`: \\eqn{\\delta_(1)}, individual causal mediation effects for \n#'   \\eqn{a=1} (computed on treated),\n#' - `delta_1`: \\eqn{\\bar{\\delta}(1)}, average causal mediation effect for \n#'   \\eqn{a=1} (computed on treated),\n#' - `zeta_0_i`: \\eqn{\\zeta_(0)}, individual causal mediation effects for \n#'   \\eqn{a=0} (computed on treaded),\n#' - `zeta_0`: \\eqn{\\bar{\\zeta}(0)}, average causal mediation effect for \n#'   \\eqn{a=0} (computed on treated),\n#' - `zeta_1_i`: \\eqn{\\zeta_(1)}, individual causal mediation effects for \n#'   \\eqn{a=1} (computed on untreaded),\n#' - `zeta_1`: \\eqn{\\bar{\\zeta}(1)}, average causal mediation effect for \n#'   \\eqn{a=1} (computed on untreated),\n#' - `tot_effect`: \\eqb{\\tau}: average total effect (\\eqn{\\bar{\\delta}(0) + \n#'   \\bar{\\zeta}(1)}).\n#'\n#' @importFrom randomForest randomForest\n#' @importFrom dplyr pull select\n#' @importFrom stats predict\n#' @md\ncausal_effects_cf &lt;- function(data_untreated,\n                              data_treated,\n                              data_cf_untreated,\n                              data_cf_treated,\n                              Y_name,\n                              A_name,\n                              A_untreated) {\n  \n  n_untreated &lt;- nrow(data_untreated)\n  n_treated &lt;- nrow(data_treated)\n  \n  # Outcome model for untreated\n  mu_untreated_model &lt;- randomForest(\n    x = data_untreated |&gt; dplyr::select(-!!Y_name, -!!A_name),\n    y = pull(data_untreated, !!Y_name)\n  )\n  \n  # Outcome model for treated\n  mu_treated_model &lt;- randomForest(\n    x = data_treated |&gt; dplyr::select(-!!Y_name, -!!A_name),\n    y = pull(data_treated, !!Y_name)\n  )\n  \n  # Observed outcome\n  y_untreated_obs &lt;- data_untreated |&gt; pull(!!Y_name)\n  y_treated_obs &lt;- data_treated |&gt; pull(!!Y_name)\n  \n  # Natural Indirect Effect, using predictions\n  delta_0_i &lt;- predict(mu_untreated_model, newdata = data_cf_untreated) -\n    predict(mu_untreated_model)\n  delta_0 &lt;- mean(delta_0_i)\n  delta_1_i &lt;- predict(mu_treated_model) - \n    predict(mu_treated_model, newdata = data_cf_treated)\n  delta_1 &lt;- mean(delta_1_i)\n\n  # Natural Indirect Effect, using observed variables\n  delta_0_i_obs &lt;- predict(mu_untreated_model, newdata = data_cf_untreated) - \n    y_untreated_obs\n  delta_0_obs &lt;- mean(delta_0_i_obs)\n  delta_1_i_obs &lt;- y_treated_obs - \n    predict(mu_treated_model, newdata = data_cf_treated)\n  delta_1_obs &lt;- mean(delta_1_i_obs)\n  \n  # Natural Direct Effect (only predictions)\n  zeta_0_i &lt;- predict(mu_treated_model, newdata = data_cf_treated) -\n    predict(mu_untreated_model, newdata = data_cf_treated)\n  zeta_0 &lt;- mean(zeta_0_i)\n  \n  zeta_1_i &lt;- predict(mu_treated_model, newdata = data_cf_untreated) - \n    predict(mu_untreated_model, newdata = data_cf_untreated)\n  zeta_1 &lt;- mean(zeta_1_i)\n  \n  # Total Causal Effect for treated\n  tot_effect &lt;- delta_0 + zeta_1  \n  tot_effect_obs &lt;- delta_0_obs + zeta_1\n  \n  \n  list(\n    delta_0_i = delta_0_i,\n    delta_1_i = delta_1_i,\n    zeta_0_i = zeta_0_i,\n    zeta_1_i = zeta_1_i,\n    delta_0_i_obs = delta_0_i_obs,\n    delta_1_i_obs = delta_1_i_obs,\n    delta_0 = delta_0,\n    delta_1 = delta_1,\n    zeta_0 = zeta_0,\n    zeta_1 = zeta_1,\n    delta_0_obs = delta_0_obs,\n    delta_1_obs = delta_1_obs,\n    tot_effect = tot_effect,\n    tot_effect_obs = tot_effect_obs\n  )\n}\nWe define the function sim_f() to run a single replication of the Monte-Carlo simulations. This functions proceeds in the following steps:\nsim_f &lt;- function(n0 = 250,\n                  n1 = 250,\n                  mu0, \n                  mu1, \n                  r0, \n                  r1, \n                  a, \n                  seed = NULL) {\n  \n  if (!is.null(seed)) set.seed(seed)\n  \n  # 1. Generate data\n  df &lt;- gen_data(\n    n0 = n0,\n    n1 = n1,\n    mu0 = mu0, \n    mu1 = mu1, \n    r0 = r0, \n    r1 = r1,\n    a = a, \n    seed = seed\n  )\n  \n  # 2. Building Counterfactuals\n  \n  ## With Optimal Transport\n  # Transporting map for source: group 1, target: group 0 (careful here)\n  Sigma0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\n  Sigma1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n  Mu0 &lt;- rep(a * mu0, 2)\n  Mu1 &lt;- rep(a * mu1, 2)\n  \n  # Mapping from group 0 to group 1\n  ot_map_0_to_1 &lt;- compute_ot_map(\n    mu_source = Mu0, sigma_source = Sigma0, \n    mu_target = Mu1, sigma_target = Sigma1\n  )\n  # Mapping from group 1 to group 0\n  ot_map_1_to_0 &lt;- compute_ot_map(\n    mu_source = Mu1, sigma_source = Sigma0, \n    mu_target = Mu0, sigma_target = Sigma0\n  )  \n  \n  # Apply transport map to treated units (A = 1)\n  X0 &lt;- as.matrix(df[df$A == 0, c(\"X1\", \"X2\")])\n  X1 &lt;- as.matrix(df[df$A == 1, c(\"X1\", \"X2\")])\n  X0_t &lt;- apply_ot_transport(X = X0, mapping = ot_map_0_to_1)\n  colnames(X0_t) &lt;- c(c(\"X1\", \"X2\"))\n  X1_t &lt;- apply_ot_transport(X = X1, mapping = ot_map_1_to_0)\n  colnames(X1_t) &lt;- c(c(\"X1\", \"X2\"))\n  \n  # With OT-Matching\n  X0_tmatch &lt;- transport_many_to_one(X_source = X0, X_target = X1)\n  X1_tmatch &lt;- transport_many_to_one(X_source = X1, X_target = X0)\n  \n  ## With Entropy regularized transport\n  # Transport from group 0 to group 1:\n  X0_skh &lt;- transport_regul(\n    X_source = X0, \n    X_target = X1, \n    gamma = 0.1\n  )\n  # Transport from group 1 to group 0:\n  X1_skh &lt;- transport_regul(\n    X_source = X1, \n    X_target = X0, \n    gamma = 0.1\n  )\n  \n  ## With Sequential Transport\n  # Transport from group 0 to group 1: X1 then X2 | X1\n  X0_st_12 &lt;- sequential_transport_12(\n    X = X0, M_source = Mu0, S_source = Sigma0, M_target = Mu1, S_target = Sigma1\n  )\n  # Transport from group 1 to group 0: X1 then X2 | X1\n  X1_st_12 &lt;- sequential_transport_12(\n    X = X1, M_source = Mu1, S_source = Sigma1, M_target = Mu0, S_target = Sigma0\n  )\n  # Transport from group 0 to group 1: X2 then X1 | X2\n  X0_st_21 &lt;- sequential_transport_21(\n    X = X0, M_source = Mu0, S_source = Sigma0, M_target = Mu1, S_target = Sigma1\n  )\n  # Transport from group 1 to group 0: X2 then X1 | X2\n  X1_st_21 &lt;- sequential_transport_21(\n    X = X1, M_source = Mu1, S_source = Sigma1, M_target = Mu0, S_target = Sigma0\n  )\n  \n  # 3. Measuring Total Causal Effect\n  tb &lt;- df[, c(\"Y\", \"A\", \"X1\", \"X2\")]\n  A_name &lt;- \"A\"\n  A_untreated &lt;- 0\n  Y_name &lt;- \"Y\"\n  \n  # Causal Mediation Analysis\n  med_mod_12 &lt;- mediation::multimed(\n    outcome = \"Y\", \n    med.main = \"X1\", \n    med.alt = \"X2\", \n    treat = \"A\", \n    data = df\n  )\n  med_mod_21 &lt;- mediation::multimed(\n    outcome = \"Y\", \n    med.main = \"X2\", \n    med.alt = \"X1\", \n    treat = \"A\", \n    data = df\n  )\n  \n  delta_0_med &lt;- mean((med_mod_12$d0.lb + med_mod_12$d0.ub) / 2) +\n    mean((med_mod_21$d0.lb + med_mod_21$d0.ub) / 2)\n  delta_1_med &lt;- mean((med_mod_12$d1.lb + med_mod_12$d1.ub) / 2) + \n    mean((med_mod_21$d1.lb + med_mod_21$d1.ub) / 2)\n  tot_effect_med &lt;- med_mod_12$tau\n  zeta_0_med &lt;- tot_effect_med - delta_1_med\n  zeta_1_med &lt;- tot_effect_med-delta_0_med\n  \n  # With OT counterfactuals\n  tb_untreated &lt;- tb |&gt; filter(!!sym(A_name) == !!A_untreated)\n  tb_treated &lt;- tb |&gt; filter(!!sym(A_name) != !!A_untreated)\n  \n  causal_effects_ot &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_t),\n    data_cf_treated = as_tibble(X1_t),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  \n  # With OT-Matching counterfactuals\n  causal_effects_tmatch &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_tmatch),\n    data_cf_treated = as_tibble(X1_tmatch),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  \n  # With entropy regularized transport\n  causal_effects_skh &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_skh),\n    data_cf_treated = as_tibble(X1_skh),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  \n  # With Sequential Transport counterfactuals\n  causal_effect_sot_12 &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    data_cf_treated = as_tibble(X1_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  causal_effect_sot_21 &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    data_cf_treated = as_tibble(X1_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  \n  tibble(\n    # Mediation\n    delta_0_med = delta_0_med,\n    delta_1_med = delta_1_med,\n    zeta_0_med = zeta_0_med,\n    zeta_1_med = zeta_1_med,\n    tot_effect_med = tot_effect_med,\n    # OT\n    delta_0_ot = causal_effects_ot$delta_0,\n    delta_1_ot = causal_effects_ot$delta_1,\n    delta_0_ot_obs = causal_effects_ot$delta_0_obs,\n    delta_1_ot_obs = causal_effects_ot$delta_1_obs,\n    zeta_0_ot = causal_effects_ot$zeta_0,\n    zeta_1_ot = causal_effects_ot$zeta_1,\n    tot_effect_ot = causal_effects_ot$tot_effect,\n    tot_effect_ot_obs = causal_effects_ot$tot_effect_obs,\n    # OT-M\n    delta_0_tmatch = causal_effects_tmatch$delta_0,\n    delta_1_tmatch = causal_effects_tmatch$delta_1,\n    delta_0_tmatch_obs = causal_effects_tmatch$delta_0_obs,\n    delta_1_tmatch_obs = causal_effects_tmatch$delta_1_obs,\n    zeta_0_tmatch = causal_effects_tmatch$zeta_0,\n    zeta_1_tmatch = causal_effects_tmatch$zeta_1,\n    tot_effect_tmatch = causal_effects_tmatch$tot_effect,\n    tot_effect_tmatch_obs = causal_effects_tmatch$tot_effect_obs,\n    # SKH\n    delta_0_skh = causal_effects_skh$delta_0,\n    delta_1_skh = causal_effects_skh$delta_1,\n    delta_0_skh_obs = causal_effects_skh$delta_0_obs,\n    delta_1_skh_obs = causal_effects_skh$delta_1_obs,\n    zeta_0_skh = causal_effects_skh$zeta_0,\n    zeta_1_skh = causal_effects_skh$zeta_1,\n    tot_effect_skh = causal_effects_skh$tot_effect,\n    tot_effect_skh_obs = causal_effects_skh$tot_effect_obs,\n    # SOT 12\n    delta_0_sot_12 = causal_effect_sot_12$delta_0,\n    delta_1_sot_12 = causal_effect_sot_12$delta_1,\n    delta_0_sot_12_obs = causal_effect_sot_12$delta_0_obs,\n    delta_1_sot_12_obs = causal_effect_sot_12$delta_1_obs,\n    zeta_0_sot_12 = causal_effect_sot_12$zeta_0,\n    zeta_1_sot_12 = causal_effect_sot_12$zeta_1,\n    tot_effect_sot_12 = causal_effect_sot_12$tot_effect,\n    tot_effect_sot_12_obs = causal_effect_sot_12$tot_effect_obs,\n    # SOT 21\n    delta_0_sot_21 = causal_effect_sot_21$delta_0,\n    delta_1_sot_21 = causal_effect_sot_21$delta_1,\n    delta_0_sot_21_obs = causal_effect_sot_21$delta_0_obs,\n    delta_1_sot_21_obs = causal_effect_sot_21$delta_1_obs,\n    zeta_0_sot_21 = causal_effect_sot_21$zeta_0,\n    zeta_1_sot_21 = causal_effect_sot_21$zeta_1,\n    tot_effect_sot_21 = causal_effect_sot_21$tot_effect,\n    tot_effect_sot_21_obs = causal_effect_sot_21$tot_effect_obs,\n    n0 = n0,\n    n1 = n1,\n    seed = seed,\n    mu0 = mu0,\n    mu1 = mu1,\n    r0 = r0,\n    r1 = r1,\n    a = a\n  )\n}",
    "crumbs": [
      "II. A Gaussian Example",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Monte Carlo Simulations</span>"
    ]
  },
  {
    "objectID": "gaussian-example-mc.html#functions",
    "href": "gaussian-example-mc.html#functions",
    "title": "6  Monte Carlo Simulations",
    "section": "",
    "text": "Generate data depending on the provided parameters for the DGP,\nBuild Counterfactuals (with optimal transport and with sequential optimal transport) of units from the untreated group (\\(A=0\\)), as well as units from the treated group (\\(A=1\\)),\nCompute the total causal effect.",
    "crumbs": [
      "II. A Gaussian Example",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Monte Carlo Simulations</span>"
    ]
  },
  {
    "objectID": "gaussian-example-mc.html#varying-the-distance-between-the-means",
    "href": "gaussian-example-mc.html#varying-the-distance-between-the-means",
    "title": "6  Monte Carlo Simulations",
    "section": "6.2 Varying the Distance Between the Means",
    "text": "6.2 Varying the Distance Between the Means\nWe make the distance between the means of the Gaussian distributions of the two groups increase. With \\(\\boldsymbol{\\mu}_0 = \\begin{pmatrix}-1\\\\-1\\end{pmatrix}\\) and \\(\\boldsymbol{\\mu}_1 = \\begin{pmatrix}1\\\\1\\end{pmatrix}\\), the distance is equal to \\(1\\). We apply a scalar coefficient \\(\\alpha\\geq 0\\) to the means to increase that distance: \\(a\\boldsymbol{\\mu}_0\\) and \\(a\\boldsymbol{\\mu}_1\\). We make \\(\\alpha\\) vary from 0 to 2 by steps of .1. When \\(\\alpha=0\\), the distance is equal to \\(0\\), when \\(\\alpha=2\\), the distance is equal to \\(4\\).\nA visual representation of the samples that can be drawn from the DGP with three values of \\(\\alpha\\) is provided in Figure 6.1.\n\n\nCodes to create the Figure.\nlibrary(tikzDevice)\nexport_tikz &lt;- FALSE\n\nif (export_tikz == TRUE) {\n  filename &lt;- \"gaussian-example-alpha\"\n  tikz(paste0(\"figs/\", filename, \".tex\"), width = 2.2, height = 1)\n}\n\n\ndraw_ellipse &lt;- function(mu, \n                         sigma, \n                         col = \"black\", \n                         lty = 1, \n                         lwd = 1, \n                         level = 0.95, \n                         ...) {\n  \n  angles &lt;- seq(0, 2 * pi, length.out = 100)\n  vals &lt;- sqrt(\n    qchisq(level, df = 2)) * t(chol(sigma)) %*% rbind(cos(angles), sin(angles)\n    )\n  lines(mu[1] + vals[1, ], mu[2] + vals[2, ], col = col, lty = lty, lwd = lwd, ...)\n  \n}\n\nset.seed(123)\n\nmu0 &lt;- -1\nmu1 &lt;- +1\nr0 &lt;- +.7\nr1 &lt;- -.5\n\n# Generate data with alpha=0, alpha=1, alpha=2\ndata_alpha_0 &lt;- gen_data(a = 0, mu0 = mu0, mu1 = mu1, r0 = r0, r1 = r1)\ndata_alpha_1 &lt;- gen_data(a = 1, mu0 = mu0, mu1 = mu1, r0 = r0, r1 = r1)\ndata_alpha_2 &lt;- gen_data(a = 2, mu0 = mu0, mu1 = mu1, r0 = r0, r1 = r1)\n\n\npar(mar = c(2.1, 2.1, 2.1, 0.1), mfrow = c(1, 3))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\ncex_pts &lt;- .4\n\n# With alpha=0----\na &lt;- 0\n\nx_lab &lt;- \"$\\\\alpha = 0$\"\nif (export_tikz == FALSE) x_lab &lt;- latex2exp::TeX(x_lab)\n\nplot(\n  data_alpha_0$X1[data_alpha_0$A == 0], \n  data_alpha_0$X2[data_alpha_0$A == 0], \n  pch = 16, \n  cex = cex_pts,\n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = x_lab,\n  family = font_family,\n  axes = FALSE\n)\naxis(1, at = -3:3)\naxis(2, at = -3:3)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(\n  data_alpha_0$X1[data_alpha_0$A == 1], \n  data_alpha_0$X2[data_alpha_0$A == 1], \n  col = adjustcolor(colGpe1, alpha = .3), pch = 16, cex = cex_pts\n)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n# With alpha=1----\na &lt;- 1\n\nx_lab &lt;- \"$\\\\alpha = 1$\"\nif (export_tikz == FALSE) x_lab &lt;- latex2exp::TeX(x_lab)\n\nplot(\n  data_alpha_1$X1[data_alpha_1$A == 0], \n  data_alpha_1$X2[data_alpha_1$A == 0], \n  pch = 16, cex = cex_pts,\n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = x_lab,\n  family = font_family,\n  axes = FALSE\n)\naxis(1, at = -3:3)\naxis(2, at = -3:3)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(\n  data_alpha_1$X1[data_alpha_1$A == 1], \n  data_alpha_1$X2[data_alpha_1$A == 1], \n  col = adjustcolor(colGpe1, alpha = .3), pch = 16, cex = cex_pts\n)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n# With alpha=2----\na &lt;- 2\n\nx_lab &lt;- \"$\\\\alpha = 2$\"\nif (export_tikz == FALSE) x_lab &lt;- latex2exp::TeX(x_lab)\n\nplot(\n  data_alpha_2$X1[data_alpha_2$A == 0], \n  data_alpha_2$X2[data_alpha_2$A == 0], \n  pch = 16, cex = cex_pts, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = x_lab,\n  family = font_family,\n  axes = FALSE\n)\naxis(1, at = -3:3)\naxis(2, at = -3:3)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(\n  data_alpha_2$X1[data_alpha_2$A == 1], \n  data_alpha_2$X2[data_alpha_2$A == 1], \n  col = adjustcolor(colGpe1, alpha = .3), pch = 16, cex = cex_pts\n)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\nif (export_tikz == TRUE) {\n  dev.off()\n  plot_to_pdf(\n    filename = filename, path = \"./figs/\", keep_tex = FALSE, crop = FALSE\n  )\n}\n\n\n\n\n\nFigure 6.1: Example of simulated data for three values for the distance between the means of the Gaussian distributions in groups 0 and 1 (\\(\\alpha\\)).\n\n\n\n\n\n\n\n\nWe define a grid with the different simulations.\n\nn_repl &lt;- 200\ngrid_params &lt;- expand_grid(\n  n0 = 250,\n  n1 = 250,\n  mu0 = -1,\n  mu1 = +1,\n  r0 = +.7,\n  r1 = -.5,\n  a = seq(0, 2, by = .1),\n  seed = seq_len(n_repl)\n)\n\nThe simulations can be run in parallel.\n\n\nThe codes to run the simulations\n# This chunk takes about XX minutes to run.\n# We do not evaluate when compiling the document.\n# Instead, we load previously obtained results.\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(tidyverse)\n  library(mnormt)\n  library(expm)\n  library(randomForest)\n}) |&gt;\n  invisible()\n\nclusterExport(\n  cl = cl, c(\n    \"gen_data\", \"compute_ot_map\", \"apply_ot_transport\",\n    \"transport_regul\", \"transport_many_to_one\",\n    \"sequential_transport_12\", \"sequential_transport_21\",\n    \"causal_effects_cf\", \"sim_f\", \"grid_params\"\n  )\n)\n\n# For an unknown reason, there seems to be an issue with performing this in \n# one go. Let us divide the task into two.\n\nres_sim_1 &lt;- pbapply::pblapply(1:2100, function(i) {\n  \n  grid_params_current &lt;- grid_params[i, ]\n  \n  n0 &lt;- grid_params_current$n0\n  n1 &lt;- grid_params_current$n1\n  mu0 &lt;- grid_params_current$mu0\n  mu1 &lt;- grid_params_current$mu1\n  r0 &lt;- grid_params_current$r0\n  r1 &lt;- grid_params_current$r1\n  a &lt;- grid_params_current$a\n  seed &lt;- grid_params_current$seed\n  \n  sim_f(\n    n0 = n0, n1 = n1, \n    mu0 = mu0, mu1 = mu1, \n    r0 = r0, r1 = r1, \n    a = a, seed = seed\n  )\n}, cl = cl)\n\nres_sim_2 &lt;- pbapply::pblapply(2101:nrow(grid_params), function(i) {\n  \n  grid_params_current &lt;- grid_params[i, ]\n  \n  n0 &lt;- grid_params_current$n0\n  n1 &lt;- grid_params_current$n1\n  mu0 &lt;- grid_params_current$mu0\n  mu1 &lt;- grid_params_current$mu1\n  r0 &lt;- grid_params_current$r0\n  r1 &lt;- grid_params_current$r1\n  a &lt;- grid_params_current$a\n  seed &lt;- grid_params_current$seed\n  \n  sim_f(\n    n0 = n0, n1 = n1, \n    mu0 = mu0, mu1 = mu1, \n    r0 = r0, r1 = r1, \n    a = a, seed = seed\n  )\n}, cl = cl)\n\nres_sim_1 &lt;- list_rbind(res_sim_1)\nres_sim_2 &lt;- list_rbind(res_sim_2)\n\nres_sim &lt;- res_sim_1 |&gt; bind_rows(res_sim_2)\n\nstopCluster(cl)\n\n\nsave(res_sim, file = \"../output/res_sim-gaussian-mc.rda\")\n\n\nWe load previously obtained results:\n\nload(\"../output/res_sim-gaussian-mc.rda\")\n\n\nTotal Causal Effect (\\(\\bar{\\tau}\\))Natural Indirect Effect (\\(\\delta(0)\\))Natural Indirect Effect (\\(\\delta(1)\\))Natural Direct Effect (\\(\\zeta(0)\\))Natural Direct Effect (\\(\\zeta(1)\\))\n\n\n\n\nCodes to create the Figure.\na1 &lt;- 2\na2 &lt;- -1.5\nexport_pdf &lt;- TRUE\n\nx_lab &lt;- \"$\\\\alpha$ (distance $=2\\\\alpha\\\\sqrt{2}$)\"\ny_lab &lt;- \"Distance to $\\\\bar\\\\tau$\"\n\nif (export_pdf == FALSE) {\n  x_lab &lt;- latex2exp::TeX(x_lab)\n  y_lab &lt;- latex2exp::TeX(y_lab)\n}\n\ndata_plot &lt;- res_sim |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1,\n    tot_effect_med, tot_effect_ot, tot_effect_tmatch,\n    tot_effect_skh, tot_effect_sot_12, tot_effect_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      tot_effect_med, tot_effect_ot, tot_effect_tmatch,\n      tot_effect_skh, tot_effect_sot_12, tot_effect_sot_21\n    ), \n    names_to = \"type\", values_to = \"tau\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"tot_effect_med\", \"tot_effect_ot\", \"tot_effect_tmatch\",\n        \"tot_effect_skh\", \"tot_effect_sot_12\", \"tot_effect_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_causal_effect = (a1+a2) * (a*mu1 - a*mu0) + 3 - tau\n  )\n\np &lt;- ggplot(\n  data = data_plot,\n  mapping = aes(x = factor(a), y = dist_to_causal_effect)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\",\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = x_lab,\n    y = y_lab,\n  ) +\n  scale_x_discrete(\n    labels = ifelse(unique(data_plot$a) %% .5 == 0, unique(data_plot$a), \"\")\n  )\n\nif (export_pdf == TRUE) {\n  filename &lt;- \"gaussian-mc-alpha-tau\"\n  ggplot2_to_pdf(\n    plot = p + theme(panel.spacing = unit(0.4, \"lines\")),\n    filename = filename, path = \"figs/\", \n    width = 3.3, height = 3.5,\n    crop = TRUE\n  )\n  \n  system(paste0(\"pdfcrop figs/\", filename, \".pdf figs/\", filename, \".pdf\"))\n}\n\np\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\nexport_pdf &lt;- TRUE\n\nx_lab &lt;- \"$\\\\alpha$ (distance $=2\\\\alpha\\\\sqrt{2}$)\"\ny_lab &lt;- \"Distance to $\\\\bar\\\\delta(0)$\"\n\nif (export_pdf == FALSE) {\n  x_lab &lt;- latex2exp::TeX(x_lab)\n  y_lab &lt;- latex2exp::TeX(y_lab)\n}\n\ndata_plot &lt;- res_sim |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1,\n    delta_0_med, delta_0_ot, delta_0_tmatch,\n    delta_0_skh, delta_0_sot_12, delta_0_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      delta_0_med, delta_0_ot, delta_0_tmatch,\n      delta_0_skh, delta_0_sot_12, delta_0_sot_21\n    ), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"delta_0_med\", \"delta_0_ot\", \"delta_0_tmatch\",\n        \"delta_0_skh\", \"delta_0_sot_12\", \"delta_0_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_theo_val = ((a1+a2)*(a*mu1-a*mu0)) - val\n  )\n\np &lt;- ggplot(\n  data = data_plot,\n  mapping = aes(x = factor(a), y = dist_to_theo_val)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = x_lab,\n    y = y_lab,\n  ) +\n  scale_x_discrete(\n    labels = ifelse(unique(data_plot$a) %% .5 == 0, unique(data_plot$a), \"\")\n  )\n\nif (export_pdf == TRUE) {\n  filename &lt;- \"gaussian-mc-alpha-delta0\"\n  ggplot2_to_pdf(\n    plot = p + theme(panel.spacing = unit(0.4, \"lines\")),\n    filename = filename, path = \"figs/\", \n    width = 3.3, height = 3.5,\n    crop = TRUE\n  )\n  \n  system(paste0(\"pdfcrop figs/\", filename, \".pdf figs/\", filename, \".pdf\"))\n}\np\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\ndata_plot &lt;- res_sim |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1,\n    delta_1_med, delta_1_ot, delta_1_tmatch,\n    delta_1_skh, delta_1_sot_12, delta_1_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n    delta_1_med, delta_1_ot, delta_1_tmatch,\n    delta_1_skh, delta_1_sot_12, delta_1_sot_21), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"delta_1_med\", \"delta_1_ot\", \"delta_1_tmatch\",\n        \"delta_1_skh\", \"delta_1_sot_12\", \"delta_1_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_theo_val = ((a1+a2)*(a*mu1-a*mu0)) - val\n  )\nggplot(\n  data = data_plot,\n  mapping = aes(x = factor(a), y = dist_to_theo_val)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = latex2exp::TeX(\"$\\\\alpha$ (distance $=2\\\\alpha\\\\sqrt{2}$)\"),\n    y = \"Distance to theoretical natural indirect effect\",\n  ) +\n  scale_x_discrete(\n    labels = ifelse(unique(data_plot$a) %% .5 == 0, unique(data_plot$a), \"\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\ndata_plot &lt;- res_sim |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1,\n    zeta_0_med, zeta_0_ot, zeta_0_tmatch,\n    zeta_0_skh, zeta_0_sot_12, zeta_0_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(zeta_0_med, zeta_0_ot, zeta_0_tmatch,\n    zeta_0_skh, zeta_0_sot_12, zeta_0_sot_21), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"zeta_0_med\", \"zeta_0_ot\", \"zeta_0_tmatch\",\n        \"zeta_0_skh\", \"zeta_0_sot_12\", \"zeta_0_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_theo_val = 3 - val\n  )\nggplot(\n  data = data_plot,\n  mapping = aes(x = factor(a), y = dist_to_theo_val)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = latex2exp::TeX(\"$\\\\alpha$ (distance $=2\\\\alpha\\\\sqrt{2}$)\"),\n    y = \"Distance to theoretical natural direct effect\",\n  ) +\n  scale_x_discrete(\n    labels = ifelse(unique(data_plot$a) %% .5 == 0, unique(data_plot$a), \"\")\n  )\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\np\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\nexport_pdf &lt;- TRUE\n\nx_lab &lt;- \"$\\\\alpha$ (distance $=2\\\\alpha\\\\sqrt{2}$)\"\ny_lab &lt;- \"Distance to $\\\\bar\\\\zeta(1)$\"\n\nif (export_pdf == FALSE) {\n  x_lab &lt;- latex2exp::TeX(x_lab)\n  y_lab &lt;- latex2exp::TeX(y_lab)\n}\n\ndata_plot &lt;- res_sim |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1,\n    zeta_1_med, zeta_1_ot, zeta_1_tmatch,\n    zeta_1_skh, zeta_1_sot_12, zeta_1_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      zeta_1_med, zeta_1_ot, zeta_1_tmatch,\n      zeta_1_skh, zeta_1_sot_12, zeta_1_sot_21), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"zeta_1_med\", \"zeta_1_ot\", \"zeta_1_tmatch\",\n        \"zeta_1_skh\", \"zeta_1_sot_12\", \"zeta_1_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_theo_val = 3 - val\n  )\np &lt;- ggplot(\n  data = data_plot,\n  mapping = aes(x = factor(a), y = dist_to_theo_val)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = x_lab,\n    y = y_lab,\n  ) +\n  scale_x_discrete(\n    labels = ifelse(unique(data_plot$a) %% .5 == 0, unique(data_plot$a), \"\")\n  )\n\nif (export_pdf == TRUE) {\n  filename &lt;- \"gaussian-mc-alpha-zeta1\"\n  ggplot2_to_pdf(\n    plot = p + theme(panel.spacing = unit(0.4, \"lines\")),\n    filename = filename, path = \"figs/\", \n    width = 3.3, height = 3.5,\n    crop = TRUE\n  )\n  \n  system(paste0(\"pdfcrop figs/\", filename, \".pdf figs/\", filename, \".pdf\"))\n}\n\np\n\n\n\n\n\n\n\n\n\n\n\n\nA more condensed figure, which focuses on \\(\\bar{\\delta}(0)\\), \\(\\bar{\\zeta}(1)\\), and \\(\\bar{\\tau}\\).\n\n\nCodes to create the Figure.\na1 &lt;- 2\na2 &lt;- -1.5\nexport_pdf &lt;- TRUE\n\nx_lab &lt;- \"$\\\\alpha$ (distance $=2\\\\alpha\\\\sqrt{2}$)\"\ny_lab &lt;- \"Estimation error\"\nmetrics_lab &lt;- c(\"$\\\\bar{\\\\delta}(0)$\", \"$\\\\bar{\\\\zeta}(1)$\", \"$\\\\bar{\\\\tau}$\")\n\nif (export_pdf == FALSE) {\n  x_lab &lt;- latex2exp::TeX(x_lab)\n  y_lab &lt;- latex2exp::TeX(y_lab)\n  metrics_lab &lt;- latex2exp::TeX(metrics_lab)\n}\n\ndata_plot_tau &lt;- res_sim |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1,\n    tot_effect_med, tot_effect_ot, tot_effect_tmatch,\n    tot_effect_skh, tot_effect_sot_12, tot_effect_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      tot_effect_med, tot_effect_ot, tot_effect_tmatch,\n      tot_effect_skh, tot_effect_sot_12, tot_effect_sot_21\n    ), \n    names_to = \"type\", values_to = \"tau\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"tot_effect_med\", \"tot_effect_ot\", \"tot_effect_tmatch\",\n        \"tot_effect_skh\", \"tot_effect_sot_12\", \"tot_effect_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_causal_effect = (a1+a2) * (a*mu1 - a*mu0) + 3 - tau\n  )\n\ndata_plot_delta0 &lt;- res_sim |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1,\n    delta_0_med, delta_0_ot, delta_0_tmatch,\n    delta_0_skh, delta_0_sot_12, delta_0_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      delta_0_med, delta_0_ot, delta_0_tmatch,\n      delta_0_skh, delta_0_sot_12, delta_0_sot_21\n    ), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"delta_0_med\", \"delta_0_ot\", \"delta_0_tmatch\",\n        \"delta_0_skh\", \"delta_0_sot_12\", \"delta_0_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_theo_val = ((a1+a2)*(a*mu1-a*mu0)) - val\n  )\n\ndata_plot_zeta1 &lt;- res_sim |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1,\n    zeta_1_med, zeta_1_ot, zeta_1_tmatch,\n    zeta_1_skh, zeta_1_sot_12, zeta_1_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      zeta_1_med, zeta_1_ot, zeta_1_tmatch,\n      zeta_1_skh, zeta_1_sot_12, zeta_1_sot_21), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"zeta_1_med\", \"zeta_1_ot\", \"zeta_1_tmatch\",\n        \"zeta_1_skh\", \"zeta_1_sot_12\", \"zeta_1_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_theo_val = 3 - val\n  )\n\ndata_plot &lt;- data_plot_tau |&gt; \n  rename(dist_tau = dist_to_causal_effect) |&gt; \n  left_join(\n    data_plot_delta0 |&gt; \n      rename(\n        delta0 = val,\n        dist_delta0 = dist_to_theo_val\n      ),\n    by = c(\"n0\", \"n1\", \"seed\", \"a\", \"mu0\", \"mu1\", \"type\")\n  ) |&gt; \n  left_join(\n    data_plot_zeta1 |&gt; \n      rename(\n        zeta1 = val,\n        dist_zeta1 = dist_to_theo_val\n      ),\n    by = c(\"n0\", \"n1\", \"seed\", \"a\", \"mu0\", \"mu1\", \"type\")\n  ) |&gt; \nfilter(a %in% seq(0, 2, by = .2))\n\np &lt;- ggplot(\n  data = data_plot |&gt; select(-tau, -delta0, -zeta1) |&gt; \n    pivot_longer(\n      cols = c(dist_tau, dist_delta0, dist_zeta1), \n      names_to = \"metric\", \n      values_to = \"dist\"\n    ) |&gt; \n    mutate(\n      metric = factor(\n        metric,\n        levels = c(\"dist_delta0\", \"dist_zeta1\", \"dist_tau\"),\n        labels = metrics_lab\n      )\n    ),\n  mapping = aes(x = factor(a), y = dist)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_grid(type ~ metric, scales = \"free_x\") +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\",\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = x_lab,\n    y = y_lab,\n  ) +\n  scale_x_discrete(\n    labels = ifelse(unique(data_plot$a) %% .5 == 0, unique(data_plot$a), \"\")\n  )\n\nif (export_pdf == TRUE) {\n  filename &lt;- \"gaussian-mc-alpha\"\n  ggplot2_to_pdf(\n    plot = p + theme(panel.spacing = unit(0.4, \"lines\")),\n    filename = filename, path = \"figs/\", \n    width = 3.3, height = 6,\n    crop = TRUE\n  )\n  \n  system(paste0(\"pdfcrop figs/\", filename, \".pdf figs/\", filename, \".pdf\"))\n}\n\np",
    "crumbs": [
      "II. A Gaussian Example",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Monte Carlo Simulations</span>"
    ]
  },
  {
    "objectID": "gaussian-example-mc.html#varying-the-proportion-of-0s-and-1s",
    "href": "gaussian-example-mc.html#varying-the-proportion-of-0s-and-1s",
    "title": "6  Monte Carlo Simulations",
    "section": "6.3 Varying the Proportion of 0s and 1s",
    "text": "6.3 Varying the Proportion of 0s and 1s\nIn this section, we let the proportion of untreated/treated units vary from 5% of 0s to 95% of them. Note that we go back to the distance between the mean equal to 1, as in Chapter 5.\nA visual representation of the samples that can be drawn from the DGP with different proportions 0s is shown in Figure 6.2\n\n\nCodes to create the Figure.\nset.seed(123)\n\nalpha &lt;- 1\nmu0 &lt;- -1\nmu1 &lt;- +1\nr0 &lt;- +.7\nr1 &lt;- -.5\n\n# Generate data with alpha=0, alpha=1, alpha=2\ndata_alpha_10 &lt;- gen_data(\n  a = alpha, mu0 = mu0, mu1 = mu1, r0 = r0, r1 = r1,\n  n0 = 50, n1 = 450\n)\ndata_alpha_50 &lt;- gen_data(\n  a = alpha, mu0 = mu0, mu1 = mu1, r0 = r0, r1 = r1,\n  n0 = 25, n1 = 475\n)\ndata_alpha_90 &lt;- gen_data(\n  a = alpha, mu0 = mu0, mu1 = mu1, r0 = r0, r1 = r1,\n  n0 = 450, n1 = 50\n)\n\n\npar(mar = c(2.1, 2.1, 2.1, 0.1), mfrow = c(1, 3))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\ncex_pts &lt;- .4\n\n# With 10%----\na &lt;- 0\n\nx_lab &lt;- \"Prop. 0s: $10\\\\%$\"\nif (export_tikz == FALSE) x_lab &lt;- latex2exp::TeX(x_lab)\n\nplot(\n  data_alpha_10$X1[data_alpha_10$A == 0], \n  data_alpha_10$X2[data_alpha_10$A == 0], \n  pch = 16, \n  cex = cex_pts,\n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = x_lab,\n  family = font_family,\n  axes = FALSE\n)\naxis(1, at = -3:3)\naxis(2, at = -3:3)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(\n  data_alpha_10$X1[data_alpha_10$A == 1], \n  data_alpha_10$X2[data_alpha_10$A == 1], \n  col = adjustcolor(colGpe1, alpha = .3), pch = 16, cex = cex_pts\n)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(alpha * mu0, 2)\nMu1 &lt;- rep(alpha * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n# With 50%----\na &lt;- 1\n\nx_lab &lt;- \"Prop. 0s: $50\\\\%$\"\nif (export_tikz == FALSE) x_lab &lt;- latex2exp::TeX(x_lab)\n\nplot(\n  data_alpha_50$X1[data_alpha_50$A == 0], \n  data_alpha_50$X2[data_alpha_50$A == 0], \n  pch = 16, cex = cex_pts,\n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = x_lab,\n  family = font_family,\n  axes = FALSE\n)\naxis(1, at = -3:3)\naxis(2, at = -3:3)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(\n  data_alpha_50$X1[data_alpha_50$A == 1], \n  data_alpha_50$X2[data_alpha_50$A == 1], \n  col = adjustcolor(colGpe1, alpha = .3), pch = 16, cex = cex_pts\n)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(alpha * mu0, 2)\nMu1 &lt;- rep(alpha * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n# With 90%----\na &lt;- 2\n\nx_lab &lt;- \"Prop. 0s: $90\\\\%$\"\nif (export_tikz == FALSE) x_lab &lt;- latex2exp::TeX(x_lab)\n\nplot(\n  data_alpha_90$X1[data_alpha_90$A == 0], \n  data_alpha_90$X2[data_alpha_90$A == 0], \n  pch = 16, cex = cex_pts, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = x_lab,\n  family = font_family,\n  axes = FALSE\n)\naxis(1, at = -3:3)\naxis(2, at = -3:3)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(\n  data_alpha_90$X1[data_alpha_90$A == 1], \n  data_alpha_90$X2[data_alpha_90$A == 1], \n  col = adjustcolor(colGpe1, alpha = .3), pch = 16, cex = cex_pts\n)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(alpha * mu0, 2)\nMu1 &lt;- rep(alpha * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n\n\n\nFigure 6.2: Example of simulated data for different proportions of 0s.\n\n\n\n\n\n\n\n\nWe define a grid with the different simulations.\n\ngrid_params &lt;- expand_grid(\n  prop_0 = seq(5, 95, by = 5)/100,\n  mu0 = -1,\n  mu1 = +1,\n  r0 = +.7,\n  r1 = -.5,\n  a = 1,\n  seed = seq_len(n_repl)\n)\n\nThe simulations can be run in parallel, as follows.\n\n\nThe codes to run the simulations\n# This chunk takes about XX minutes to run.\n# We do not evaluate when compiling the document.\n# Instead, we load previously obtained results.\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(tidyverse)\n  library(mnormt)\n  library(expm)\n  library(randomForest)\n}) |&gt;\n  invisible()\n\nclusterExport(\n  cl = cl, c(\n    \"gen_data\", \"compute_ot_map\", \"apply_ot_transport\",\n    \"transport_regul\", \"transport_many_to_one\",\n    \"sequential_transport_12\", \"sequential_transport_21\",\n    \"causal_effects_cf\", \"sim_f\", \"grid_params\"\n  )\n)\n\nres_sim_prop &lt;- pbapply::pblapply(\n  1:nrow(grid_params), function(i) {\n  \n    grid_params_current &lt;- grid_params[i, ]\n    \n    n &lt;- 500\n    prop_0 &lt;- grid_params_current$prop_0\n    n0 &lt;- prop_0 * n\n    n1 &lt;- n - n0\n    mu0 &lt;- grid_params_current$mu0\n    mu1 &lt;- grid_params_current$mu1\n    r0 &lt;- grid_params_current$r0\n    r1 &lt;- grid_params_current$r1\n    a &lt;- grid_params_current$a\n    seed &lt;- grid_params_current$seed\n    \n    sim_f(\n      n0 = n0, n1 = n1, \n      mu0 = mu0, mu1 = mu1, \n      r0 = r0, r1 = r1, \n      a = a, seed = seed\n    ) |&gt; \n    mutate(prop_0 = prop_0)\n}, cl = cl)\n\n\nstopCluster(cl)\nres_sim_prop &lt;- list_rbind(res_sim_prop)\n\nsave(\n    res_sim_prop, \n    file = \"../output/res_sim_prop-gaussian-mc.rda\"\n)\n\n\nWe load previously obtained results:\n\nload(\"../output/res_sim_prop-gaussian-mc.rda\")\n\n\nTotal Causal Effect (\\(\\bar{\\tau}\\))Natural Indirect Effect (\\(\\delta(0)\\))Natural Indirect Effect (\\(\\delta(1)\\))Natural Direct Effect (\\(\\zeta(0)\\))Natural Direct Effect (\\(\\zeta(1)\\))\n\n\n\n\nCodes to create the Figure.\na1 &lt;- 2\na2 &lt;- -1.5\nexport_pdf &lt;- FALSE\n\nx_lab &lt;- \"Proportion of untreated\"\ny_lab &lt;- \"Distance to $\\\\bar\\\\tau$\"\n\nif (export_pdf == FALSE) {\n  x_lab &lt;- latex2exp::TeX(x_lab)\n  y_lab &lt;- latex2exp::TeX(y_lab)\n}\n\ndata_plot &lt;- res_sim_prop |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1, prop_0,\n    tot_effect_med, tot_effect_ot, tot_effect_tmatch,\n    tot_effect_skh, tot_effect_sot_12, tot_effect_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      tot_effect_med, tot_effect_ot, tot_effect_tmatch,\n      tot_effect_skh, tot_effect_sot_12, tot_effect_sot_21\n    ), \n    names_to = \"type\", values_to = \"tau\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"tot_effect_med\", \"tot_effect_ot\", \"tot_effect_tmatch\",\n        \"tot_effect_skh\", \"tot_effect_sot_12\", \"tot_effect_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_causal_effect = (a1+a2) * (a*mu1 - a*mu0) + 3 - tau\n  )\n\np &lt;- ggplot(\n  data = data_plot,\n  mapping = aes(x = factor(prop_0), y = dist_to_causal_effect)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\",\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = x_lab,\n    y = y_lab,\n  ) + \n  scale_x_discrete(\n    labels = ifelse(\n      (unique(data_plot$prop_0)*100) %% 20 == 0, \n      yes = unique(data_plot$prop_0), no = \"\")\n  )\n\nif (export_pdf == TRUE) {\n  filename &lt;- \"gaussian-mc-prop-tau\"\n  ggplot2_to_pdf(\n    plot = p + theme(panel.spacing = unit(0.4, \"lines\")),\n    filename = filename, path = \"figs/\", \n    width = 3.3, height = 3.5,\n    crop = TRUE\n  )\n  \n  system(paste0(\"pdfcrop figs/\", filename, \".pdf figs/\", filename, \".pdf\"))\n}\n\np\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\na1 &lt;- 2\na2 &lt;- -1.5\nexport_pdf &lt;- FALSE\n\nx_lab &lt;- \"Proportion of untreated\"\ny_lab &lt;- \"Distance to $\\\\bar\\\\delta(0)$\"\n\nif (export_pdf == FALSE) {\n  x_lab &lt;- latex2exp::TeX(x_lab)\n  y_lab &lt;- latex2exp::TeX(y_lab)\n}\n\ndata_plot &lt;- res_sim_prop |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1, prop_0,\n    delta_0_med, delta_0_ot, delta_0_tmatch,\n    delta_0_skh, delta_0_sot_12, delta_0_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      delta_0_med, delta_0_ot, delta_0_tmatch,\n      delta_0_skh, delta_0_sot_12, delta_0_sot_21\n    ), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"delta_0_med\", \"delta_0_ot\", \"delta_0_tmatch\",\n        \"delta_0_skh\", \"delta_0_sot_12\", \"delta_0_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_theo_val = ((a1+a2)*(mu1-mu0)) - val\n  )\n\np &lt;- ggplot(\n  data = data_plot,\n  mapping = aes(x = factor(prop_0), y = dist_to_theo_val)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = x_lab,\n    y = y_lab\n  ) +\n  scale_x_discrete(\n    labels = ifelse(\n      (unique(data_plot$prop_0)*100) %% 20 == 0, \n      yes = unique(data_plot$prop_0), no = \"\")\n  )\n\nif (export_pdf == TRUE) {\n  filename &lt;- \"gaussian-mc-prop-delta0\"\n  ggplot2_to_pdf(\n    plot = p + theme(panel.spacing = unit(0.4, \"lines\")),\n    filename = filename, path = \"figs/\", \n    width = 3.3, height = 3.5,\n    crop = TRUE\n  )\n  \n  system(paste0(\"pdfcrop figs/\", filename, \".pdf figs/\", filename, \".pdf\"))\n}\n\np\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\ndata_plot &lt;- res_sim_prop |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1, prop_0,\n    delta_1_med, delta_1_ot, delta_1_tmatch,\n    delta_1_skh, delta_1_sot_12, delta_1_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n    delta_1_med, delta_1_ot, delta_1_tmatch,\n    delta_1_skh, delta_1_sot_12, delta_1_sot_21), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"delta_1_med\", \"delta_1_ot\", \"delta_1_tmatch\",\n        \"delta_1_skh\", \"delta_1_sot_12\", \"delta_1_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_theo_val = ((a1+a2)*(mu1-mu0)) - val\n  )\nggplot(\n  data = data_plot,\n  mapping = aes(x = factor(prop_0), y = dist_to_theo_val)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = \"Proportion of 0\",\n    y = \"Distance to theoretical natural indirect effect\",\n  ) +\n  scale_x_discrete(\n    labels = ifelse(\n      (unique(data_plot$prop_0)*100) %% 10 == 0, \n      yes = unique(data_plot$prop_0), no = \"\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\ndata_plot &lt;- res_sim_prop |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1, prop_0,\n    zeta_0_med, zeta_0_ot, zeta_0_tmatch,\n    zeta_0_skh, zeta_0_sot_12, zeta_0_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(zeta_0_med, zeta_0_ot, zeta_0_tmatch,\n    zeta_0_skh, zeta_0_sot_12, zeta_0_sot_21), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"zeta_0_med\", \"zeta_0_ot\", \"zeta_0_tmatch\",\n        \"zeta_0_skh\", \"zeta_0_sot_12\", \"zeta_0_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_theo_val = 3 - val\n  )\nggplot(\n  data = data_plot,\n  mapping = aes(x = factor(prop_0), y = dist_to_theo_val)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = \"Proportion of 0\",\n    y = \"Distance to theoretical natural direct effect\",\n  ) +\n  scale_x_discrete(\n    labels = ifelse(\n      (unique(data_plot$prop_0)*100) %% 10 == 0, \n      yes = unique(data_plot$prop_0), no = \"\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\na1 &lt;- 2\na2 &lt;- -1.5\nexport_pdf &lt;- FALSE \n\nx_lab &lt;- \"Proportion of untreated\"\ny_lab &lt;- \"Distance to $\\\\bar\\\\zeta(1)$\"\n\nif (export_pdf == FALSE) {\n  x_lab &lt;- latex2exp::TeX(x_lab)\n  y_lab &lt;- latex2exp::TeX(y_lab)\n}\n\ndata_plot &lt;- res_sim_prop |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1, prop_0,\n    zeta_1_med, zeta_1_ot, zeta_1_tmatch,\n    zeta_1_skh, zeta_1_sot_12, zeta_1_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      zeta_1_med, zeta_1_ot, zeta_1_tmatch,\n      zeta_1_skh, zeta_1_sot_12, zeta_1_sot_21), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"zeta_1_med\", \"zeta_1_ot\", \"zeta_1_tmatch\",\n        \"zeta_1_skh\", \"zeta_1_sot_12\", \"zeta_1_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_theo_val = 3 - val\n  )\np &lt;- ggplot(\n  data = data_plot,\n  mapping = aes(x = factor(prop_0), y = dist_to_theo_val)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = x_lab,\n    y = y_lab\n  ) +\n  scale_x_discrete(\n    labels = ifelse(\n      (unique(data_plot$prop_0)*100) %% 20 == 0, \n      yes = unique(data_plot$prop_0), no = \"\")\n  )\n\nif (export_pdf == TRUE) {\n  filename &lt;- \"gaussian-mc-prop-zeta1\"\n  ggplot2_to_pdf(\n    plot = p + theme(panel.spacing = unit(0.4, \"lines\")),\n    filename = filename, path = \"figs/\", \n    width = 3.3, height = 3.5,\n    crop = TRUE\n  )\n  \n  system(paste0(\"pdfcrop figs/\", filename, \".pdf figs/\", filename, \".pdf\"))\n}\n\np\n\n\n\n\n\n\n\n\n\n\n\n\nA more condensed figure, which focuses on \\(\\bar{\\delta}(0)\\), \\(\\bar{\\zeta}(1)\\), and \\(\\bar{\\tau}\\).\n\n\nCodes to create the Figure.\na1 &lt;- 2\na2 &lt;- -1.5\nexport_pdf &lt;- FALSE\n\nx_lab &lt;- \"Proportion of untreated ($\\\\%$)\"\ny_lab &lt;- \"Estimation error\"\nmetrics_lab &lt;- c(\"$\\\\bar{\\\\delta}(0)$\", \"$\\\\bar{\\\\zeta}(1)$\", \"$\\\\bar{\\\\tau}$\")\n\nif (export_pdf == FALSE) {\n  x_lab &lt;- latex2exp::TeX(x_lab)\n  y_lab &lt;- latex2exp::TeX(y_lab)\n  metrics_lab &lt;- latex2exp::TeX(metrics_lab)\n}\n\ndata_plot_tau &lt;- res_sim_prop |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1, prop_0,\n    tot_effect_med, tot_effect_ot, tot_effect_tmatch,\n    tot_effect_skh, tot_effect_sot_12, tot_effect_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      tot_effect_med, tot_effect_ot, tot_effect_tmatch,\n      tot_effect_skh, tot_effect_sot_12, tot_effect_sot_21\n    ), \n    names_to = \"type\", values_to = \"tau\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"tot_effect_med\", \"tot_effect_ot\", \"tot_effect_tmatch\",\n        \"tot_effect_skh\", \"tot_effect_sot_12\", \"tot_effect_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_causal_effect = (a1+a2) * (a*mu1 - a*mu0) + 3 - tau\n  )\n\ndata_plot_delta0 &lt;- res_sim_prop |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1, prop_0,\n    delta_0_med, delta_0_ot, delta_0_tmatch,\n    delta_0_skh, delta_0_sot_12, delta_0_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      delta_0_med, delta_0_ot, delta_0_tmatch,\n      delta_0_skh, delta_0_sot_12, delta_0_sot_21\n    ), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"delta_0_med\", \"delta_0_ot\", \"delta_0_tmatch\",\n        \"delta_0_skh\", \"delta_0_sot_12\", \"delta_0_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_theo_val = ((a1+a2)*(mu1-mu0)) - val\n  )\n\ndata_plot_zeta1 &lt;- res_sim_prop |&gt; \n  dplyr::select(\n    n0, n1, seed, a, mu0, mu1, prop_0,\n    zeta_1_med, zeta_1_ot, zeta_1_tmatch,\n    zeta_1_skh, zeta_1_sot_12, zeta_1_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      zeta_1_med, zeta_1_ot, zeta_1_tmatch,\n      zeta_1_skh, zeta_1_sot_12, zeta_1_sot_21), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"zeta_1_med\", \"zeta_1_ot\", \"zeta_1_tmatch\",\n        \"zeta_1_skh\", \"zeta_1_sot_12\", \"zeta_1_sot_21\"\n      ),\n      labels = c(\"CM\", \"OT\", \"OT-M\", \"SKH\", \"ST(1)\", \"ST(2)\")\n    ),\n    dist_to_theo_val = 3 - val\n  )\n\ndata_plot &lt;- data_plot_tau |&gt; \n  rename(dist_tau = dist_to_causal_effect) |&gt; \n  left_join(\n    data_plot_delta0 |&gt; \n      rename(\n        delta0 = val,\n        dist_delta0 = dist_to_theo_val\n      ),\n    by = c(\"n0\", \"n1\", \"seed\", \"a\", \"mu0\", \"mu1\", \"type\", \"prop_0\")\n  ) |&gt; \n  left_join(\n    data_plot_zeta1 |&gt; \n      rename(\n        zeta1 = val,\n        dist_zeta1 = dist_to_theo_val\n      ),\n    by = c(\"n0\", \"n1\", \"seed\", \"a\", \"mu0\", \"mu1\", \"type\", \"prop_0\")\n  )\n\ndata_plot &lt;- data_plot |&gt; filter(prop_0 %in% seq(.05, .95, by =.1))\n\n\n\np &lt;- ggplot(\n  data = data_plot |&gt; select(-tau, -delta0, -zeta1) |&gt; \n    pivot_longer(\n      cols = c(dist_tau, dist_delta0, dist_zeta1), \n      names_to = \"metric\", \n      values_to = \"dist\"\n    ) |&gt; \n    mutate(\n      metric = factor(\n        metric,\n        levels = c(\"dist_delta0\", \"dist_zeta1\", \"dist_tau\"),\n        labels = metrics_lab\n      )\n    ),\n  mapping = aes(x = factor(prop_0), y = dist)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_grid(type ~ metric, scales = \"free_x\") +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\",\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = x_lab,\n    y = y_lab,\n  ) +\n  scale_x_discrete(\n    labels = 100*unique(data_plot$prop_0)\n  )\n\nif (export_pdf == TRUE) {\n  filename &lt;- \"gaussian-mc-prop\"\n  ggplot2_to_pdf(\n    plot = p + theme(panel.spacing = unit(0.4, \"lines\")),\n    filename = filename, path = \"figs/\", \n    width = 3.3, height = 6,\n    crop = TRUE\n  )\n  \n  system(paste0(\"pdfcrop figs/\", filename, \".pdf figs/\", filename, \".pdf\"))\n}\np",
    "crumbs": [
      "II. A Gaussian Example",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Monte Carlo Simulations</span>"
    ]
  },
  {
    "objectID": "transp-categ-objectives.html",
    "href": "transp-categ-objectives.html",
    "title": "7  Objectives",
    "section": "",
    "text": "Objectives\n\n\n\nThe chapters of this part of the ebook present the following methods to build counterfactuals for a categorical variable:\n\nUsing matching (Chapter 11),\nUsing optimal transport on label-encoded variables (Chapter 9),\nUsing optimal transport on the simplex (Chapter 10).\n\n\n\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n%\\definecolor{colA}{RGB}{255, 221, 85}\n%\\definecolor{colB}{RGB}{148, 78, 223}\n%\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colA}{RGB}{0, 114, 178}\n\\definecolor{colB}{RGB}{213, 94, 0}\n\\definecolor{colC}{RGB}{204, 121, 167}\n\\definecolor{colGpeZero}{RGB}{0,160,138}\n\\definecolor{colGpeUn}{RGB}{242, 173, 0}\n\\]\nConsider a categorical variables \\(x \\in \\{{\\color{colA}A}, {\\color{colB}B}, {\\color{colC}C}\\}\\), with group-specific distributions. The categorical variable could be, for example, the treatment administered for a disease: A=surgery, B=medication, C=no treatment. We consider two groups (this could non-Black/Black, for example). We want to build a counterfactual category for each individual from a group to the other.\nLet Group 0 and Group 1 represent two subpopulations in which the distribution of \\(x\\) differs. For example, we can have:\n\nin Group 0 it is \\(\\boldsymbol{p}_0 = (0.1, 0.5, 0.4)\\).\nin Group 1, the category distribution is \\(\\boldsymbol{p}_1 = (0.5, 0.3, 0.2)\\).\n\nGroup 0 could be, for example, Black individuals, whereas Group 1 could be individuals who are not Black.\nThe objective is to define, for each individual in Group 0, a counterfactual category that reflects the distributional characteristics of Group 1. That is, we want to know what would be the medical treatment (surgery, medication, no treatment) of a Black individual that received a given treatment (e.g., “C=no treatment) had they been non-Black.\nTo do so, the remainder of this part of the ebook revisits two approaches:\n\nUsing matching (Chapter 11),\nUsing optimal transport on label-encoded variables (Chapter 9),\nUsing transport on the simplex (Chapter 10) (the one used in our paper).",
    "crumbs": [
      "III. Counterfactuals for Categorical Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Objectives</span>"
    ]
  },
  {
    "objectID": "transp-categ-coupling.html",
    "href": "transp-categ-coupling.html",
    "title": "8  Random Matching",
    "section": "",
    "text": "8.1 Preliminary Example: 1-to-1 Random Matching\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n%\\definecolor{colA}{RGB}{255, 221, 85}\n%\\definecolor{colB}{RGB}{148, 78, 223}\n%\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colA}{RGB}{0, 114, 178}\n\\definecolor{colB}{RGB}{213, 94, 0}\n\\definecolor{colC}{RGB}{204, 121, 167}\n\\definecolor{colGpeZero}{RGB}{0,160,138}\n\\definecolor{colGpeUn}{RGB}{242, 173, 0}\n\\]\nRecall from Chapter 7 that \\(a\\in\\{0,1\\}\\) denotes a binary treatment. Let \\(x\\in\\mathcal{X}\\) denote a mediator variable. The objective here is to obtain counterfactuals \\((a=1,\\boldsymbol{x}(1))\\) for untreated units \\((t=0,\\boldsymbol{x})\\), when the variable \\(x\\) is categorical.\nAs in Chapter 7, consider the case where \\(x\\in\\{A,B,C\\}\\) with the following group-wise proportions: \\(\\boldsymbol{p}_0 = (0.1, 0.5, 0.4)\\) (untreated units) and \\(\\boldsymbol{p}_1 = (0.5, 0.3, 0.2)\\) (treated units). The proportion in group 0 are shown in Figure 10.1.\nLet us generate a dummy data set with 100 individuals in both Group 0 and Group 1.\nset.seed(1234)\nn &lt;- 100\nn0 &lt;- n1 &lt;- n\np0 &lt;- c(0.1, 0.5, 0.4)\np1 &lt;- c(0.5, 0.3, 0.2)\n# Sample category\nx0 &lt;- sample(c(rep(\"A\", p0[1] * n0), rep(\"B\", p0[2] * n0), rep(\"C\", p0[3] * n0)), replace = FALSE)\nx1 &lt;- sample(c(rep(\"A\", p1[1] * n1), rep(\"B\", p1[2] * n1), rep(\"C\", p1[3] * n1)), replace = FALSE)\ncat_levels &lt;- c(\"A\", \"B\", \"C\")\nA way to obtain the counterfactual for the categorical variable is to implement a 1-to-1 matching procedure.\nEach category is assigned an arbitrary numeric value (e.g., \\(A = 1\\), \\(B = 2\\), \\(C = 3\\)), allowing us to define a cost matrix based on the absolute difference between encoded categories. That is, the cost of matching an individual from Group 0 with category \\(x_{j0}\\) to an individual from Group 1 with category \\(x_{i1}\\) is given by \\(C_{ij} = |x_{i1} - x_{j0}|\\).\nA linear sum assignment problem can then be used to find the matching that minimizes the total cost across pairs.\nThe matched category from Group 1 is interpreted as the counterfactual category for the initial Group 0 individual.\nWe can compute the distance between the observations from Group 0 to Group 1, by setting numeric values to each category: A=1, B=2, C=3:\nx0_index &lt;- match(x0, cat_levels)\nx1_index &lt;- match(x1, cat_levels)\ncost_matrix &lt;- outer(x0_index, x1_index, function(i, j) abs(i - j))\nThe linear sum assignment problem is tackled with solve_LSAP() from {clue}.\nlibrary(clue)\nassignment &lt;- solve_LSAP(cost_matrix)\nThe mapping can be stored in a tibble.\ntb_coupling &lt;- tibble(\n  x0 = x0,\n  x1 = x1[assignment]\n) |&gt; \n  mutate(\n    cost = abs(match(x0, cat_levels) - match(x1, cat_levels))\n  )\nWe compute the number of observations from Group 0 matched with observations from Group 1 per category.\ntb_coupling |&gt; \n  group_by(x0, x1) |&gt; \n  count() |&gt; \n  group_by(x0) |&gt; \n  mutate(prop_0 = 100 * n / sum(n)) |&gt; \n  group_by(x1) |&gt; \n  mutate(prop_1 = 100 * n / sum(n))\n\n# A tibble: 5 × 5\n# Groups:   x1 [3]\n  x0    x1        n prop_0 prop_1\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 A     A        10    100     20\n2 B     A        20     40     40\n3 B     B        30     60    100\n4 C     A        20     50     40\n5 C     C        20     50    100\nThen, we can visualize the results, using an alluvial plot (Figure 8.1). All individuals in Group 0 with label A are matched directly to individuals in Group 1 with the same label. The remaining individuals in Group 1 labeled A are then matched to Group 0 individuals who originally had label B or C. This matching is performed probabilistically: among Group 0 individuals with label B, 60% retain their original label, and 40% are reclassified as A; among those with label C, 50% remain C, and 50% are reclassified as A.\nCodes to create the Figure.\nflow &lt;- data.frame(\n  depart = rep(LETTERS[1:3], 3),\n  category = rep(LETTERS[1:3], each = 3),\n  freq = as.vector(table(tb_coupling$x0, tb_coupling$x1))\n)\np_1 &lt;- ggplot(\n  data = flow,\n  mapping = aes(axis1 = depart, axis2 = category, y = freq)\n) +\n  geom_alluvium(aes(fill = category)) +\n  geom_stratum() +\n  scale_fill_manual(values = col_categ) +\n  geom_text(\n    stat = \"stratum\",\n    mapping = aes(label = after_stat(stratum)),\n    family = font_family\n  ) +\n  # scale_x_discrete(\n  #   limits = c(\"Group 1\", \"Group 0\"),\n  #   expand = c(0.15, 0.05)\n  # ) +\n  scale_x_discrete(\n    limits = c(\"Group 0\", \"Group 1\"),\n    labels = c(\n      \"Group 0\" = str_c(\"&lt;span style='color:\", col_group[1], \";'&gt;Group 0&lt;/span&gt;\"),\n      \"Group 1\" = str_c(\"&lt;span style='color:\", col_group[2], \";'&gt;Group 1&lt;/span&gt;\")\n    ),\n    expand = c(0.15, 0.05)\n  ) +\n  ylab(\"Proportions\") + \n  scale_y_continuous(transform = ) +\n  # theme_minimal(base_size = font_size, base_family = font_family) +\n  theme_paper() +\n  theme(\n    axis.text.x = ggtext::element_markdown()\n  )\np_1\n\n\n\n\n\nFigure 8.1: Matching individuals given a categorical variable.\nThis can also be visualized on a ternary plot (Figure 8.2).\nCodes to create the Figure.\n# Create interpolated values using McCann (1997) displacement\nf_line_simplex &lt;- function(x, \n                           y, \n                           lgt = 601) {\n  \n  zx &lt;- as.numeric(clr(x))[1:2]\n  zy &lt;- as.numeric(clr(y))[1:2]\n  t &lt;- seq(0, 1, length = lgt)\n  \n  tx &lt;- cbind(\n    (1 - t) * zx[1] + t * zy[1], \n    (1 - t) * zx[2] + t * zy[2]\n  )\n  tx &lt;- cbind(tx, -(tx[, 1] + tx[, 2]))\n  df &lt;- as.data.frame(matrix(as.numeric(clrInv(tx)), lgt, 3))\n  names(df) &lt;- c(\"A\",\"B\",\"C\")\n  \n  df\n}\n\n# dummy dataset to create an empty ternary plot\nSB &lt;- tibble(\n  A = c(0.2, 0.3, 0.5, 0.6),\n  B = c(0.3, 0.4, 0.2, 0.1),\n  C = 1 - c(0.2, 0.3, 0.5, 0.6) - c(0.3, 0.4, 0.2, 0.1),\n  group = c(\"0\", \"0\", \"1\", \"1\")\n)\n\np_2 &lt;- ggtern(data = SB, aes(x = A, y = B, z = C)) +\n  scale_colour_manual(name = \"group\", values = col_group) +\n  guides(\n    colour = guide_legend(\n      override.aes = list(\n        linetype = \"solid\",\n        shape = NA,\n        size = 1.5,\n        alpha = 1\n      )\n    )\n  ) +\n  theme_light(base_size = font_size, base_family = font_family) +\n  theme_ggtern_paper() +\n  theme(\n    legend.title = element_text(size = font_size),\n    legend.text = element_text(size = font_size)\n    # tern.axis.hshift = .10\n  ) +\n  theme_latex(TRUE) +\n  theme_hidetitles()\n\n\np_2 &lt;- p_2 + \n  geom_text(mapping = aes(x = 0.9, y = 0.06, z = 0.08), label = p1[1], color = col_group[2], family = font_family, size = font_size-3, size.unit = \"pt\") +\n  geom_text(mapping = aes(x = 0.09, y = 0.9, z = 0.09), label = p1[2], color = col_group[2], family = font_family, size = font_size-3, size.unit = \"pt\") +\n  geom_text(mapping = aes(x = 0.08, y = 0.06, z = 0.9), label = p1[3], color = col_group[2], family = font_family, size = font_size-3, size.unit = \"pt\") + \n  geom_text(mapping = aes(x = 0.3, y = 0.1, z = 0.11), label = p0[1], color = col_group[1], family = font_family, size = font_size-3, size.unit = \"pt\") +\n  geom_text(mapping = aes(x = 0.15, y = 0.65, z = 0.25), label = p0[2], color = col_group[1], family = font_family, size = font_size-3, size.unit = \"pt\") +\n  geom_text(mapping = aes(x = 0.1, y = 0.2, z = 0.8), label = p0[3], color = col_group[1], family = font_family, size = font_size-3, size.unit = \"pt\") \n\n\nLi1 &lt;- f_line_simplex(x = c(.75, .125, .125), y = c(.125, .125, .75), lgt = 2)\nLi2 &lt;- f_line_simplex(x = c(.75, .125, .125), y = c(.125, .75, .125), lgt = 2)\np_2 &lt;- p_2 + \n  geom_line(\n    data = Li2, aes(x = A, y = B, z = C), \n    color = col_group[1], linwidth = .6,\n    arrow = arrow(length=unit(0.20,\"cm\"))\n  ) + \n  geom_line(\n    data = Li1, aes(x = A, y = B, z = C), \n    color = col_group[1], linwidth = .6,\n    arrow = arrow(length=unit(0.20,\"cm\"))\n  ) \np_2\n\n\n\n\n\nFigure 8.2: Matching individuals given a categorical variable, on a Ternary plot.\nCodes to export the figures in PDF.\np_matching_indiv &lt;- cowplot::plot_grid(\n  ggplotGrob(\n    p_1 +\n      # Remove top/bottom margin\n      theme(\n        plot.margin = ggplot2::margin(t = 0, r = 0, b = 0, l = 0)\n      )\n  ),\n  # table_grob,\n  ggplotGrob(\n    p_2 +\n      # Remove top/bottom margin\n      theme(\n        plot.background = element_rect(fill = \"transparent\", color = NA),\n        plot.margin = ggplot2::margin(t = 0, r = 0, b = 0, l = 0)\n      )\n  ),\n  rel_widths = c(1.4,1),\n  ncol = 2\n)\n\np_matching_indiv\n\nfilename &lt;- \"ternary-categ-matching-indiv\"\nggsave(\n  p_matching_indiv, file = str_c(path, filename, \".pdf\"),\n  height = 2*1.75, width = 3.75*1.75,\n  family = font_family,\n  device = cairo_pdf\n)\n# Crop PDF\nsystem(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\nRather than randomly matching individuals, we can use optimal transport to do the assignment. In Chapter 9, we begin by arbitrarily assigning numerical values to each category and computing pairwise distances based on these values. In contrast, Chapter 10 relies on an which consists in representing the categorical variable in the probability simplex, using probability vectors that reflect the likelihood of each category.",
    "crumbs": [
      "III. Counterfactuals for Categorical Data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Random Matching</span>"
    ]
  },
  {
    "objectID": "transp-categ-discrete.html",
    "href": "transp-categ-discrete.html",
    "title": "9  Optimal Transport on Label-Encoded Variables",
    "section": "",
    "text": "9.1 Matching\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n%\\definecolor{colA}{RGB}{255, 221, 85}\n%\\definecolor{colB}{RGB}{148, 78, 223}\n%\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colA}{RGB}{0, 114, 178}\n\\definecolor{colB}{RGB}{213, 94, 0}\n\\definecolor{colC}{RGB}{204, 121, 167}\n\\definecolor{colGpeZero}{RGB}{0,160,138}\n\\definecolor{colGpeUn}{RGB}{242, 173, 0}\n\\]\nAs in the previous chapter (Chapter 11), consider a categorical variables \\(x \\in \\{{\\color{colA}A}, {\\color{colB}B}, {\\color{colC}C}\\}\\). Let Group 0 and Group 1 represent two subpopulations, in which the distribution of \\(x\\) differs\nLet us generate a dummy data set with 100 individuals in both Group 0 and Group 1.\nNow, assume we were able to estimate the propensities of belonging to each category, using a probabilistic classifier. Here, instead of really training a classifier, we simply draw the values from a Dirichlet distribution, using rdirichlet() from {MCMCpack}. We consider two different scenarios:\nThe categorical variable in the simplex, using the simulated propensity scores, can be visualized on a ternary plot (Figure 11.2).\nWe apply 1-to-1 matching, setting numeric values to each category: A=1, B=2, C=3.\nWe define the absolute distance between the numerical values as the cost.\nx0_index &lt;- match(x0, cat_levels)\nx1_index &lt;- match(x1, cat_levels)\ncost_matrix &lt;- outer(x0_index, x1_index, function(i, j) abs(i - j))\n# 1-1 matching\nassignment &lt;- solve_LSAP(cost_matrix)\n# Store this in a tibble\ntb_coupling &lt;- tibble(\n  x0 = x0,\n  x1 = x1[assignment]\n) |&gt; \n  mutate(\n    cost = abs(match(x0, cat_levels) - match(x1, cat_levels))\n  )\nThe matching can be visualized on a ternary plot (Figure 9.2).\n# Create interpolated values using McCann (1997) displacement\nf_line_simplex &lt;- function(x, \n                           y, \n                           lgt = 601) {\n  \n  zx &lt;- as.numeric(clr(x))[1:2]\n  zy &lt;- as.numeric(clr(y))[1:2]\n  t &lt;- seq(0, 1, length = lgt)\n  \n  tx &lt;- cbind(\n    (1 - t) * zx[1] + t * zy[1], \n    (1 - t) * zx[2] + t * zy[2]\n  )\n  tx &lt;- cbind(tx, -(tx[, 1] + tx[, 2]))\n  df &lt;- as.data.frame(matrix(as.numeric(clrInv(tx)), lgt, 3))\n  names(df) &lt;- c(\"A\",\"B\",\"C\")\n  \n  df\n}\n\nidx &lt;- which(tb_coupling$cost != 0)\n\n# Ise the plot from previous figure as a baseline\np_matching &lt;- p\n\n# Draw a line joining the matched observations.\nfor (i in idx) {\n  lines_1 &lt;- f_line_simplex(\n    x = tb_sample_z_1[i, 1:3], \n    y = tb_sample_z_1[n + assignment[i], 1:3], \n    lgt = 101\n  )\n  lines_2 &lt;- f_line_simplex(\n    x = tb_sample_z_2[i, 1:3], \n    y = tb_sample_z_2[n + assignment[i], 1:3], \n    lgt = 101\n  )\n  lines_both &lt;- as_tibble(lines_1) |&gt; mutate(type = \"(1)\") |&gt; \n    bind_rows(\n      as_tibble(lines_2) |&gt; mutate(type = \"(2)\")\n    )\n  \n  p_matching &lt;- p_matching + \n    geom_line(\n      data = lines_both, \n      mapping = aes(x = A, y = B, z = C), \n      color = col_group[1], linewidth = .2,, alpha = .5,\n      arrow = arrow(length = unit(0.20, \"cm\"))\n    )\n}\n\np_matching\n\n\n\n\nFigure 9.2: Optimal matching of \\(\\boldsymbol{p}_{0,i}\\)’s and \\(\\boldsymbol{p}_{1,i}\\)’s in the simplex \\(\\mathcal{S}_2\\).\nCodes to export the figures in PDF.\nfilename &lt;- \"ternary-categ-ot\"\nggsave(\n  p_matching, file = str_c(path, filename, \".pdf\"),\n  height = 2*1.75, width = 3.75*1.75,\n  family = font_family,\n  device = cairo_pdf\n)\n# Crop PDF\nsystem(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\nIn Chapter 10, rather than defining distances between individuals based on arbitrary numerical encodings of categorical values, we use each individual’s estimated propensity to belong to each category. This yields a probability vector on the simplex, and optimal transport is then performed within the simplex space.",
    "crumbs": [
      "III. Counterfactuals for Categorical Data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Optimal Transport on Label-Encoded Variables</span>"
    ]
  },
  {
    "objectID": "transp-categ-transport.html",
    "href": "transp-categ-transport.html",
    "title": "10  Transport on Simplex",
    "section": "",
    "text": "10.2 Step 1: From Categorical to Compositional Data\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n%\\definecolor{colA}{RGB}{255, 221, 85}\n%\\definecolor{colB}{RGB}{148, 78, 223}\n%\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colA}{RGB}{0, 114, 178}\n\\definecolor{colB}{RGB}{213, 94, 0}\n\\definecolor{colC}{RGB}{204, 121, 167}\n\\definecolor{colGpeZero}{RGB}{0,160,138}\n\\definecolor{colGpeUn}{RGB}{242, 173, 0}\n\\]\nLet us generate a categorical variable \\(x\\in\\{A,B,C\\}\\), as explained in Chatper 7, with group-specific distributions. Let Group 0 and Group 1 represent two subpopulations in which the distribution of \\(x\\) differs. Here, we have:\nThe objective, as in the previous chapter, is to obtain a counterfactual for each observation from group 0 had they received the treatment \\(a=1\\), i.e., to obtain \\(x(1)\\).\nThe entire procedure is carried out in three steps, as outlined in Algorithm 10.1:\nThe proportions of each class in group 0 are shown in Figure 10.1.\nCodes to generate data and create the Figure.\nsource(\"../scripts/utils.R\")\n\np_barplot_source &lt;- ggplot(\n  data = tibble(x0 = x0) |&gt; count(x0) |&gt; \n    arrange(desc(x0)) |&gt; \n    mutate(\n      prop = n / sum(n),\n      lab_y = cumsum(prop) - prop/2\n    )\n) +\n  geom_bar(stat = \"identity\", mapping = aes(x = factor(1), y = prop, fill = x0)) +\n  geom_text(mapping = aes(x = factor(1), y = lab_y, label = x0), family = font_family) +\n  scale_fill_manual(values = col_categ, guide = \"none\") +\n  labs(x = NULL, y = NULL) +\n  theme_paper() +\n  theme(\n    axis.ticks.x = element_blank(), \n    axis.text.x = element_blank(), \n    panel.grid.major.x = element_blank()\n  )\np_barplot_source\n\n\n\n\n\nFigure 10.1: Proportions of observations in group 0.\nSuppose that, for each observation, the probability of assignment to each category of the categorical variable \\(x \\in \\{\\text{A}, \\text{B}, \\text{C}\\}\\) is known. These probabilities can be estimated, for example, using a multinomial logistic regression model.\nFor illustration purposes, we simulate these probabilities by drawing from a Dirichlet distribution, which ensures that each observation lies on the 3-dimensional simplex \\(\\mathcal{S}_3\\). Thus, for each unit, both the observed category of \\(x\\) and its associated probability vector are assumed to be known.\nThese probability vectors can then be represented as points on the simplex \\(\\mathcal{S}_3\\), as shown in Figure 10.2.\nCodes to generate the probabilities and create the Figure.\nlibrary(MCMCpack)\nset.seed(12345)\nalpha_A &lt;- c(9, 3, 2)\nZ_A &lt;- as.data.frame(rdirichlet(n0 + n1, alpha_A))\nalpha_B &lt;- c(3, 11, 4)\nZ_B &lt;- as.data.frame(rdirichlet(n0 + n1, alpha_B))\nalpha_C &lt;- c(2, 3, 9)\nZ_C &lt;- as.data.frame(rdirichlet(n0 + n1, alpha_C))\n# For each observation from group 0 and matched obs from group 1, we have\n# drawn a category (A, B, or C).\n# We add drawn propensities, depending on the category\nZ &lt;- Z_A\ncategory &lt;- c(x0, x1)\nZ[category == \"B\", ] &lt;- Z_B[category == \"B\", ]\nZ[category == \"C\", ] &lt;- Z_C[category == \"C\", ]\ntb_sample_z &lt;- as_tibble(Z)\nnames(tb_sample_z) &lt;- c(\"A\", \"B\", \"C\")\ntb_sample_z$group &lt;- factor(c(rep(0, n0), rep(1, n1)), levels = c(0, 1))\n\ntb_sample_z_1 &lt;- tb_sample_z\n\np_compositional &lt;- ggtern(\n  data = tb_sample_z_1 |&gt; filter(group == 0),\n  mapping = aes(x = A, y = B, z = C)) +\n  geom_point(alpha = .8, size = .5, mapping = aes(color = group)) +\n  scale_colour_manual(name = \"group\",values = col_group, guide = \"none\") +\n  theme_light(base_size = font_size, base_family = font_family) +\n  theme_ggtern_minimal()\n  \np_compositional\n\n\n\n\n\nFigure 10.2: Representation of the units in the simplex \\(\\mathcal{S}_3\\), in group 0.",
    "crumbs": [
      "III. Counterfactuals for Categorical Data",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transport on Simplex</span>"
    ]
  },
  {
    "objectID": "transp-categ-transport.html#objectives-1",
    "href": "transp-categ-transport.html#objectives-1",
    "title": "10  Transport on Simplex",
    "section": "10.1 Objectives",
    "text": "10.1 Objectives\nThis page shows how optimal transport can be applied to map a categorical variable from one group to another through a three-step procedure:\n\nRepresentation (from categorical to compositional): Encode each categorical value as a point in the probability simplex (see Section 10.2).\nTransport (coupling in the simplex): Use optimal transport to learn a mapping from a group to the other by solving the transport problem over the simplex (see Section 10.3).\nReassignment (from composition to category): Convert the transported probability vector back into a categorical value by assigning it to a vertex of the simplex, using optimal transport theory—specifically transporting mass from a continuous distribution to a discrete one concentrated on the simplex’s corners.",
    "crumbs": [
      "III. Counterfactuals for Categorical Data",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transport on Simplex</span>"
    ]
  },
  {
    "objectID": "transp-categ-transport.html#sec-coupling-simplex",
    "href": "transp-categ-transport.html#sec-coupling-simplex",
    "title": "10  Transport on Simplex",
    "section": "10.3 Step 2: Coupling on the Simplex",
    "text": "10.3 Step 2: Coupling on the Simplex\nIn Chapter 9 we assigned arbitrary numerical values to each category and computed pairwise distances between observations based on those values. Here, we instead use the probability vectors associated with each observation (obtained in the previous section) and perform optimal transport in the simplex \\(\\mathcal{S}_3\\).\nFirst, we define a function, compute_pdist_simplex_fast(), to compute the pairwise distance between observations from each group. The distance metric is based on the optimal transport cost between two probability vectors in the unit simplex, as described in Fernandes Machado, Charpentier, and Gallic (2025).\n\n\nThe compute_pdist_simplex_fast() function.\n#' Pairwise distance matrix on the simplex\n#'\n#' @description\n#' Computes the pairwise distance matrix of observations in the simplex, using\n#' the cost function for optimal transport on the unit simplex as the distance\n#' metric.\n#'\n#' @param X Matrix of observations (one observation per row).\n#' @param Y Matrix of observations (one observation per row).\n#'\n#' @returns A matrix of size n x m, where n is the number of observation in X,\n#'  and m is the number of observations in Y, containing the distances between\n#'  observations in X and Y.\n#' @noRd\ncompute_pdist_simplex_fast &lt;- function(X, Y) {\n  \n  p &lt;- ncol(X)\n  invX &lt;- 1 / X\n  \n  # R[j,i] = sum_k Y[j,k] * invX[i,k]\n  R &lt;- Y %*% t(invX)\n  \n  logXmean &lt;- rowMeans(log(X))\n  logYmean &lt;- rowMeans(log(Y))\n  \n  # M[i,j] = log(R[j,i]) - log(p) - logYmean[j] + logXmean[i]\n  M_t &lt;- log(R) - log(p) -\n    outer(logYmean, rep(1, length(logXmean))) +\n    outer(rep(1, length(logYmean)), logXmean)\n  \n  t(M_t)\n}\n\n\nWe then define a function, wass_lp_fast(), to solve the optimal transport problem between two empirical distributions. This function uses the shortsimplex algorithm implemented in the {transport} package and returns both the optimal transport cost (i.e., the Wasserstein distance) and the associated transport plan.\n\n\nThe wass_lp_fast() function.\n#' Solving the Optimal Transport Problem\n#'\n#' @description\n#' Finds the optimal transport plan using shortsimplex method.\n#'\n#' @param dxy Cost matrix of transport distances between points in X and Y.\n#' @param wx Weights (marginal distribution) for X.\n#' @param wy Weights (marginal distribution) for Y.\n#' @param p Order of the Wassterstein distance. (If p=2: squared Euclidean\n#'  cost).\n#'\n#' @importFrom transport transport\n#'\n#' @noRd\nwass_lp_fast &lt;- function(dxy, \n                         wx, \n                         wy, \n                         p = 2) {\n  \n  stopifnot(all(abs(sum(wx) - 1) &lt; 1e-8), all(abs(sum(wy) - 1) &lt; 1e-8))\n  \n  m &lt;- length(wx)\n  n &lt;- length(wy)\n  \n  # Convert dxy to a cost matrix (flattened)\n  cost &lt;- as.matrix(dxy)^p\n  \n  # Solve the OT problem (default method = \"shortsimplex\")\n  plan &lt;- transport::transport(wx, wy, costm = cost)\n  \n  # Convert transport plan (sparse format) to matrix\n  gamma &lt;- matrix(0, m, n)\n  for (i in seq_len(nrow(plan))) {\n    gamma[plan$from[i], plan$to[i]] &lt;- plan$mass[i]\n  }\n  \n  # Compute Wasserstein distance\n  value &lt;- sum(gamma * cost)^(1 / p)\n  \n  list(distance = value, plan = gamma)\n}\n\n\nTo illustrate the transport methodology, we use the propensity vectors from the first scenario. We begin by splitting the sample according to the group indicator.\n\ntb_sample_z_1_0 &lt;- tb_sample_z_1 |&gt; filter(group == 0)\ntb_sample_z_1_1 &lt;- tb_sample_z_1 |&gt; filter(group == 1)\n\nWe extract the propensity vectors.\n\nprop_0 &lt;- tb_sample_z_1_0 |&gt; \n  dplyr::select(-group) |&gt; \n  as.matrix()\n\nprop_1 &lt;- tb_sample_z_1_1 |&gt; \n  dplyr::select(-group) |&gt; \n  as.matrix()\n\nThen, we apply our compute_pdist_simplex_fast() function to compute the pairwise distance matrix between observations from the two groups, using their corresponding propensity vectors:\n\ndist_mat &lt;- compute_pdist_simplex_fast(X = prop_0, Y = prop_1)\n\nUsing this distance matrix, we solve the optimal transport problem with uniform weights on both marginals:\n\npar_w0 &lt;- rep(1/nrow(prop_0), nrow(prop_0))\npar_w1 &lt;- rep(1/nrow(prop_1), nrow(prop_1))\n# Solve the optimal transport problem\not_plan &lt;- wass_lp_fast(dxy = dist_mat, wx = par_w0, wy = par_w1, p = 2)\n\nTo identify the most likely match for each observation in Group 0 under the optimal transport plan, we extract, for each row, the column index with the highest transported mass. This creates a table of one-to-one matches based on the maximal transport mass for each observation in group 0.\n\not_plan_tb &lt;- tibble(\n  from = 1:n0,\n  to = max.col(ot_plan$plan, ties.method = \"first\")\n)\n\nWe can visualize the resulting matching on a ternary plot (see Figure 10.3).\n\n\nCodes to create the Figure (and codes for the f_line_simplex() function.\np_matching_1 &lt;- ggtern(\n  data = tb_sample_z_1,\n  mapping = aes(x = A, y = B, z = C)) +\n  geom_point(size = .5, alpha = 0.8, mapping = aes(color = group)) +\n  scale_colour_manual(name = \"group\",values = col_group, guide = \"none\") +\n  theme_light(base_size = font_size, base_family = font_family) +\n  theme_ggtern_minimal()\n\n\n# Create interpolated values using McCann (1997) displacement\nf_line_simplex &lt;- function(x, \n                           y, \n                           lgt = 601) {\n  \n  zx &lt;- as.numeric(clr(x))[1:2]\n  zy &lt;- as.numeric(clr(y))[1:2]\n  t &lt;- seq(0, 1, length = lgt)\n  \n  tx &lt;- cbind(\n    (1 - t) * zx[1] + t * zy[1], \n    (1 - t) * zx[2] + t * zy[2]\n  )\n  tx &lt;- cbind(tx, -(tx[, 1] + tx[, 2]))\n  df &lt;- as.data.frame(matrix(as.numeric(clrInv(tx)), lgt, 3))\n  names(df) &lt;- c(\"A\",\"B\",\"C\")\n  \n  df\n}\n\n\nfor (i in 1:nrow(ot_plan_tb)) {\n  lines_1 &lt;- f_line_simplex(\n    x = prop_0[i, 1:3], \n    y = prop_1[ot_plan_tb$to[i], 1:3], \n    lgt = 101\n  ) |&gt; \n    as_tibble()\n  \n  p_matching_1 &lt;- p_matching_1 + \n    geom_line(\n      data = lines_1, \n      mapping = aes(x = A, y = B, z = C), \n      color = col_group[1], linewidth = .2,, alpha = .5,\n      arrow = arrow(length = unit(0.10, \"cm\"))\n    )\n}\n\np_matching_1\n\n\n\n\n\nFigure 10.3: Optimal matching on the simplex.\n\n\n\n\n\n\n\n\nThe subset of matched units are shown in Figure 10.4.\n\n\nCodes to create the Figure.\np_ggtern_matched_1 &lt;- ggtern(\n  data = tb_sample_z_1 |&gt; filter(group == 1),\n  mapping = aes(x = A, y = B, z = C)\n) +\n  geom_point(alpha = .8, size = .5, colour = col_group[2]) +\n  theme_light(base_size = font_size, base_family = font_family) +\n  theme_ggtern_minimal()\n  \np_ggtern_matched_1\n\n\n\n\n\nFigure 10.4: Matched individuals.",
    "crumbs": [
      "III. Counterfactuals for Categorical Data",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transport on Simplex</span>"
    ]
  },
  {
    "objectID": "transp-categ-transport.html#step-3-composition-to-categorical",
    "href": "transp-categ-transport.html#step-3-composition-to-categorical",
    "title": "10  Transport on Simplex",
    "section": "10.4 Step 3: Composition to categorical",
    "text": "10.4 Step 3: Composition to categorical\nSo far, for each unit from group 0, we have a matched individual in group 1. We have, since the first step, a compositional representation for each unit (\\(\\widehat{\\boldsymbol{p}}\\)). The third and final step involves mapping the transported compositional representation back to a categorical variable. As detailed in Algorithm 10.2 (from Fernandes Machado, Charpentier, and Gallic (2025)), this is done via classical optimal transport on the simplex.\n\n\n\n\n\n\nObjectives\n\n\n\nHere, want to know how to divide the simplex \\(\\mathcal{S}_3\\) into three regions (\\(R_A, R_B, R_C\\)) so that each region contains a prescribed amount of probability mass (\\(p_A, p_B, p_C\\)) from a continuous distribution (here, Dirichlet).\nWe use optimal transport theory (particularly Brenier’s theory) for transporting mass from a continuous distribution to a discrete one (point masses at the triangle’s corners).\nThe method is performed in two steps:\n\nDefinition of a transport cost: we use squared distance between points.\nFind a map \\(T\\) that moves each point \\(\\boldsymbol{x}\\) in the simplex to a vertex \\(\\boldsymbol{u}_i\\) (e.g., \\((1,0,0)\\)) while minimizing total transport cost.\n\nThe map \\(T\\) is defined via Laguerre cells (power diagrams), which are convex regions where each point is closer (in a weighted sense) to one vertex than to the others.\nThe obtained regions together form a weighted Voronoi diagram on the simplex. Each region has exactly the desired share of the total probability mass: \\(\\int_{R_i} f(\\boldsymbol{x}) dx = p_i\\).\n\n\n\n\n\\begin{algorithm} \\caption{From compositional to categorical feature, with marginal constraints.} \\begin{algorithmic} \\Require $n$ observations on $\\mathcal{S}_d$, $\\widehat{\\boldsymbol{p}}_1,\\cdots,\\widehat{\\boldsymbol{p}}_n$ \\Require target proportions $\\pi_1,\\cdots,\\pi_d$ \\State Optimal mapping $T^\\star:\\mathcal{S}_d\\to\\{1,\\cdots,d\\}$\\\\ (from $\\widehat{\\boldsymbol{p}}\\in\\mathcal{S}_d$ to vertices of $\\mathcal{S}_d$, with masses $\\pi$)\\\\ \\Return $T^\\star:\\mathcal{S}_d\\to\\{1,\\cdots,d\\}$ (Voronoi tessellation) \\end{algorithmic} \\end{algorithm}\n\n\nBefore we apply this algorithm to our categorical variable, we want to explain in further details how it works. If you want to skip this part, go directly to Section 10.4.2 to continue with the current data.\n\n10.4.1 Barycentric Centroid of Balance\nLet us play with the distributions of the propensities (\\(p_0\\) and \\(p_1\\)) to illustrate how Algorithm 10.2 works. We draw random samples from a Dirichlet distribution. Let us start with a concentration parameter \\(\\alpha=(2, 5, 3)\\). Each sample lies in the 3-dimensional simplex \\(\\mathcal{S}_3\\), and the resulting distribution has density \\(f\\) with respect to Lebesgue measure on \\(\\mathcal{S}_3\\).\n\nset.seed(123)\nn &lt;- 1000\n# Concentration parameter:\nalpha &lt;-  c(2, 5, 3)\n# Draw n samples\nsamples &lt;- rdirichlet(n, alpha = alpha)\n\nWe want to find a partition \\(R_A,R_B,R_C\\) of \\(\\mathcal{S}_3\\) such that \\[\n\\int_{R_i}f(\\boldsymbol{x})\\mathrm{d}\\boldsymbol{x}=p_i,~i\\in\\{A,B,C\\}.\n\\] We can use (classical) optimal transport theory to find partitions of the simplex that map probability mass from the Dirichlet to the discrete distribution \\(\\boldsymbol{p}=(p_A,p_B,p_C)\\), in each vertex of the simplex, \\[\n\\int_{T^{-1}(\\boldsymbol{u}_i)}f(\\boldsymbol{x})\\mathrm{d}\\boldsymbol{x}=p_i,~i\\in\\{A,B,C\\},\n\\] where \\(\\{\\boldsymbol{u}_A,\\boldsymbol{u}_B,\\boldsymbol{u}_C\\}\\) are unit vectors, vertices of the \\(\\mathcal{S}_3\\) (i.e., \\((1,0,0)\\), \\((0,1,0)\\) and \\((0,0,1)\\)).\n\n\n\n\n\n\nNote\n\n\n\nSince the initial measures are absolutely continuous with respect to Lebesgue measure, and since both have finite second moment, there exists a unique optimal transport map \\(T\\) (and this map is the gradient of a convex function).\n\n\nLet us consider for now that \\(\\boldsymbol{p}=(1/2,1/3,1/6))\\).\n\n# Unit vectors of S_3\nvertices &lt;- matrix(c(\n  1, 0, 0,  # A\n  0, 1, 0,  # B\n  0, 0, 1   # C\n), byrow = TRUE, ncol = 3)\n\n# source weights\nmass_source &lt;- rep(1 / n, n)\n# target weights\nmass_target &lt;- c(3, 2, 1) / 6\n\n# Cost matrix (squared Euclidean distance)\ncost_matrix &lt;- as.matrix(dist(rbind(samples, vertices))^2)\ncost_matrix &lt;- cost_matrix[1:n, (n + 1):(n + 3)]\n\n# We assign eah observation to one vertex\n# by minimizing the global transport cost, while matching marginals\n\n# Solve the optimal transport plan\not_plan &lt;- transport::transport(\n  a = mass_source, b = mass_target, costm = cost_matrix, \n  method = \"shortsimplex\"\n)\n\n# Assign each sample to a category based on OT plan\nassignment &lt;- rep(NA, n)\n# mass each source sends to each target\nmass_matrix &lt;- matrix(0, nrow = n, ncol = 3)\n\nfor (j in 1:nrow(ot_plan)) {\n  from &lt;- ot_plan$from[j]\n  to &lt;- ot_plan$to[j]\n  mass &lt;- ot_plan$mass[j]\n  mass_matrix[from, to] &lt;- mass_matrix[from, to] + mass\n}\n\n# Assign each source point to the target it contributes the most mass to\nassignment &lt;- max.col(mass_matrix, ties.method = \"first\")\n\ncolnames(samples) &lt;- c(\"A\", \"B\", \"C\")\n\nsamples_dirichlet_p &lt;- \n  as_tibble(samples) |&gt; \n  mutate(category = colnames(samples)[assignment])\nsamples_dirichlet_p\n\n# A tibble: 1,000 × 4\n        A     B      C category\n    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n 1 0.101  0.837 0.0615 B       \n 2 0.120  0.642 0.238  B       \n 3 0.0520 0.235 0.713  C       \n 4 0.196  0.537 0.267  A       \n 5 0.0715 0.611 0.317  B       \n 6 0.200  0.497 0.303  A       \n 7 0.0943 0.804 0.101  B       \n 8 0.0851 0.498 0.417  C       \n 9 0.124  0.452 0.424  C       \n10 0.232  0.542 0.226  A       \n# ℹ 990 more rows\n\n\nEach region \\(R_i\\) corresponds to the set of points \\(\\boldsymbol{x}\\in\\mathcal{S}_3\\) such that \\(\\boldsymbol{u}_i\\) minimizes \\(\\|\\boldsymbol{x}-\\boldsymbol{u}_i\\|^2-\\phi_i\\) where \\(\\phi_i\\in\\mathbb{R}\\) is a potential offset (weight, determined via dual optimization). This structure defines a power diagram, also known as a Laguerre–Voronoi diagram (or additively weighted Voronoi diagram). These subsets form a weighted Voronoi tessellation (in barycentric space), as shown in Figure 10.5.\n\n\nCodes to create the Figure.\nggtern(\n  data = samples_dirichlet_p,\n  mapping = aes(x = A, y = B, z = C, color = category)\n) +\n  geom_point(alpha = .8, size = .5) +\n  scale_colour_manual(name = \"category\", values = col_categ) +\n  theme_light(base_size = font_size, base_family = font_family) +\n  theme(\n    strip.background = element_rect(colour = \"black\", fill = NA),\n    strip.text.x = element_text(colour = \"black\"),\n    strip.text.y = element_text(colour = \"black\"),\n    # strip.text = ggtext::element_markdown(),\n    text = element_text(family = font_family, size = unit(font_size, \"pt\")),\n    axis.title = element_text(size = rel(.8)),\n    tern.axis.arrow.show = TRUE,\n    tern.axis.arrow.sep = .16,\n    tern.axis.vshift = .09,\n    legend.position = \"bottom\",\n    legend.title = element_text(size = .8 * font_size),\n    legend.text = element_text(size = .8 * font_size),\n    panel.border = element_rect(colour = NA)\n  ) +\n  theme_hidetitles() +\n  guides(colour = guide_legend(override.aes = list(size = 2)))\n\n\n\n\n\nFigure 10.5: Barycentric centroid of balance, when \\(\\mathcal{D}(\\boldsymbol{\\alpha})\\) with \\(\\boldsymbol{\\alpha}=(2, 5, 3)\\) and when \\(\\boldsymbol{p}=(3 ,2,1)/6\\).\n\n\n\n\n\n\n\n\nWe can, in addition, identify the intersection, i.e., the point where the minimum of the class-wise kernel density estimates is maximized. We do it by considering a grid over which we estimate the density. We create a function, generate_simplex_grid(), to generate a grid on \\(\\mathcal{S}_3\\).\n\n\n\n\n\n\nWarning\n\n\n\nThis step was originally introduced to improve visualization and is not actually used in the algorithm itself. In addition, there appears to be a minor issue: the resulting points do not lie exactly at the expected intersections, although they remain close. This discrepancy suggests a potential numerical or approximation artifact, but it does not affect the main transport procedure.\n\n\n\ngenerate_simplex_grid &lt;- function(resolution = 100) {\n  grid &lt;- expand_grid(\n    A = seq(0, 1, length.out = resolution),\n    B = seq(0, 1, length.out = resolution)\n  ) |&gt; \n    mutate(C = 1 - A - B) |&gt; \n    filter(C &gt;= 0)\n  \n  as_tibble(grid)\n}\n\nWe create a function, get_category_density_2D(), to estimate the kernel density estumation for a given category.\n\nget_category_density_2D &lt;- function(samples, \n                                    grid_points,\n                                    category_label) {\n  \n  category_data &lt;- samples |&gt; \n    filter(category == !!category_label) |&gt; \n    dplyr::select(\"A\", \"B\")\n  eval_grid &lt;- grid_points[, c(\"A\", \"B\")]\n  \n  if (nrow(category_data) &lt; 10) {\n    H &lt;- diag(0.01, 2)\n  } else {\n    H &lt;- tryCatch(Hpi(category_data), error = function(e) diag(0.01, 2))\n  }\n  \n  kde_result &lt;- ks::kde(x = category_data, H = H, eval.points = eval_grid)\n  \n  kde_result$estimate\n}\n\nLet us create a triangular grid over (A,B,C) constrained to S_3:\n\ngrid_points &lt;- generate_simplex_grid(resolution = 100)\n\nWe evaluate the KDE for data from the source distribution:\n\ndens_A &lt;- get_category_density_2D(\n  samples = samples_dirichlet_p, grid_points = grid_points, category_label = \"A\"\n)\ndens_B &lt;- get_category_density_2D(\n  samples = samples_dirichlet_p, grid_points = grid_points, category_label = \"B\"\n)\ndens_C &lt;- get_category_density_2D(\n  samples = samples_dirichlet_p, grid_points = grid_points, category_label = \"C\"\n)\n\nThen, we can find the point where min(densities) is maximal.\n\nmin_dens &lt;- pmin(dens_A, dens_B, dens_C)\nmax_idx &lt;- which.max(min_dens)\nintersection_point &lt;- grid_points[max_idx, ]\ntb_intersection &lt;- as_tibble(intersection_point)\n\n\n\nCodes to create the Figure.\np &lt;- ggtern(\n    data = samples_dirichlet_p,\n  mapping = aes(x = A, y = B, z = C)\n) +\n  geom_point(alpha = .8, size = .5, mapping = aes(color = category)) +\n  geom_point(data = tb_intersection) +\n  scale_colour_manual(values = col_categ) +\n  theme_light(base_size = font_size, base_family = font_family) +\n  theme(\n    strip.background = element_rect(colour = \"black\", fill = NA),\n    strip.text.x = element_text(colour = \"black\"),\n    strip.text.y = element_text(colour = \"black\"),\n    text = element_text(family = font_family, size = unit(font_size, \"pt\")),\n    axis.title = element_text(size = rel(.8)),\n    tern.axis.arrow.show = TRUE,\n    tern.axis.arrow.sep = .16,\n    tern.axis.vshift = .09,\n    legend.position = \"bottom\",\n    legend.title = element_text(size = .8 * font_size),\n    legend.text = element_text(size = .8 * font_size),\n    panel.border = element_rect(colour = NA)\n  ) +\n  theme_hidetitles() +\n  guides(colour = guide_legend(override.aes = list(size = 2)))\n\np\n\n\n\n\n\nFigure 10.6: Barycentric centroid of balance, when \\(\\mathcal{D}(\\boldsymbol{\\alpha})\\) with \\(\\boldsymbol{\\alpha}=(2, 5, 3)\\) and when \\(\\boldsymbol{p}=(3,2,1)/6\\). Black dot: intersection (point where the minimum of the class-wise kernel density estimates is maximized).\n\n\n\n\n\n\n\n\n\n10.4.1.1 Varying \\(\\alpha\\) and \\(\\boldsymbol{p}\\).\nLet us now make \\(\\alpha\\) and \\(\\boldsymbol{p}\\) vary. We will consider \\(\\boldsymbol{\\alpha} = (1,1,1)\\) (uniform distribution), and \\(\\boldsymbol{\\alpha} = (2, 5, 3)\\); and \\(\\boldsymbol{p} = (1/3,1/3,1/3)\\), and \\(\\boldsymbol{p} = (1/2,1/3,1/6)\\).\nFor convenience, let us wrap the previous code in a function, get_data_assignment().\n\n\nCode for the get_data_assignment function\n#' @param n Number of observations to sample from the Dirichlet Distribution.\n#' @param Vector of shape parameters, or matrix of shape parameters \n#'  corresponding to the number of draw. Default to \\eqn{(1,1,1)}.\n#' @param p Vector of target probabilities. Default to \\eqn{(1/3, 1/3, 1/3)}.\n#' \nget_data_assignment &lt;- function(n,\n                                alpha = c(1, 1, 1),\n                                p = c(1, 1, 1) / 3,\n                                intersection_point = TRUE) {\n  \n  # Draw n samples\n  samples &lt;- rdirichlet(n, alpha = alpha)\n  \n  # Unit vectors of S_3\n  vertices &lt;- matrix(c(\n    1, 0, 0,  # A\n    0, 1, 0,  # B\n    0, 0, 1   # C\n  ), byrow = TRUE, ncol = 3)\n  \n  # source weights\n  mass_source &lt;- rep(1 / n, n)\n  # target weights\n  mass_target &lt;- p\n  \n  # Cost matrix (squared Euclidean distance)\n  cost_matrix &lt;- as.matrix(dist(rbind(samples, vertices))^2)\n  cost_matrix &lt;- cost_matrix[1:n, (n + 1):(n + 3)]\n  \n  # We assign eah observation to one vertex\n  # by minimizing the global transport cost, while matching marginals\n  \n  # Solve the optimal transport plan\n  ot_plan &lt;- transport::transport(\n    a = mass_source, b = mass_target, costm = cost_matrix, \n    method = \"shortsimplex\"\n  )\n  \n  # Assign each sample to a category based on OT plan\n  assignment &lt;- rep(NA, n)\n  # mass each source sends to each target\n  mass_matrix &lt;- matrix(0, nrow = n, ncol = 3)\n  \n  for (j in 1:nrow(ot_plan)) {\n    from &lt;- ot_plan$from[j]\n    to &lt;- ot_plan$to[j]\n    mass &lt;- ot_plan$mass[j]\n    mass_matrix[from, to] &lt;- mass_matrix[from, to] + mass\n  }\n  \n  # Assign each source point to the target it contributes the most mass to\n  assignment &lt;- max.col(mass_matrix, ties.method = \"first\")\n  \n  colnames(samples) &lt;- c(\"A\", \"B\", \"C\")\n  samples &lt;- \n    as_tibble(samples) |&gt; \n    mutate(category = colnames(samples)[assignment])\n  \n  #\n  # Intersection point\n  #\n  if (intersection_point == TRUE) {\n    # Create a triangular grid over (A,B,C) constrained to S_3\n    grid_points &lt;- generate_simplex_grid(resolution = 100)\n    \n    # Evaluation of KDE for data from the source distribution\n    dens_A &lt;- get_category_density_2D(\n      samples = samples, grid_points = grid_points, category_label = \"A\"\n    )\n    dens_B &lt;- get_category_density_2D(\n      samples = samples, grid_points = grid_points, category_label = \"B\"\n    )\n    dens_C &lt;- get_category_density_2D(\n      samples = samples, grid_points = grid_points, category_label = \"C\"\n    )\n    # Find point where min(densities) is maximal\n    min_dens &lt;- pmin(dens_A, dens_B, dens_C)\n    max_idx &lt;- which.max(min_dens)\n    \n    intersection_point &lt;- grid_points[max_idx, ]\n    \n    tb_intersection &lt;- as_tibble(intersection_point)\n  } else {\n    tb_intersection &lt;- NULL\n  }\n  \n  list(\n    samples = samples,\n    tb_intersection = tb_intersection\n  )\n}\n\n\nUsing get_data_assignment(), we draw samples according to \\(\\boldsymbol{\\alpha}\\) and then we find partitions of the simplex that map probability mass from the Dirichlet to the discrete distribution \\(\\boldsymbol{p}\\), in each vertex of the simplex.\n\nsamples_unif_unif &lt;- get_data_assignment(\n  n = n, \n  alpha = c(1, 1, 1), \n  p = c(1, 1, 1) / 3\n)\n\nsamples_unif_p &lt;- get_data_assignment(\n  n = n, \n  alpha = c(1, 1, 1), \n  p = c(3, 2, 1) / 6\n)\n\nsamples_dirichlet_unif &lt;- get_data_assignment(\n  n = n, \n  alpha = c(2, 5, 3), \n  p = c(1, 1, 1) / 3\n)\n\nsamples_dirichlet_p &lt;- get_data_assignment(\n  n = n, \n  alpha = c(2, 5, 3), \n  p = c(3, 2, 1) / 6\n)\n\nThe results can be visualized in simplex-baryc-centr-bal-example-full, when \\(\\mathcal{D}(\\boldsymbol{\\alpha})\\) with \\(\\boldsymbol{\\alpha}=(1, 1, 1)\\) (left) and \\(\\boldsymbol{\\alpha}=(2, 5, 3)\\) (right), when \\(\\boldsymbol{p}=(1,1,1)/3\\) (top) and \\(\\boldsymbol{p}=(3,2,1)/6\\) (bottom).\n\n\nCodes to create the Figure.\np &lt;- ggtern(\n  data = samples_unif_unif$samples |&gt; \n    mutate(distrib = \"Uniform\", p = \"(1,1,1)/3\") |&gt; \n    bind_rows(\n      samples_unif_p$samples |&gt; \n        mutate(distrib = \"Uniform\", p = \"(3,2,1)/6\")\n    ) |&gt; \n    bind_rows(\n      samples_dirichlet_unif$samples |&gt; \n        mutate(distrib = \"2_5_3\", p = \"(1,1,1)/3\")\n    ) |&gt; \n    bind_rows(\n      samples_dirichlet_p$samples |&gt; \n        mutate(distrib = \"2_5_3\", p = \"(3,2,1)/6\")\n    ) |&gt;\n    mutate(\n      distrib = factor(\n        distrib,\n        levels = c(\"Uniform\", \"2_5_3\"),\n        labels = c(\n          \"Uniform\" = parse(text = latex2exp::TeX(\"D(1,1,1)\")),\n          \"2_5_3\" = parse(text = latex2exp::TeX(\"$D(2,5,3)$\"))\n        )\n      ),\n      p = factor(\n        p,\n        levels = c(\"(1,1,1)/3\", \"(3,2,1)/6\"),\n        labels = c(\n          \"(1,1,1)/3\" = parse(text = latex2exp::TeX(\"$p=(1,1,1)/3$\")),\n          \"(3,2,1)/6\" = parse(text = latex2exp::TeX(\"$p=(3,2,1)/6$\"))\n        )\n      )\n    ),\n  mapping = aes(x = A, y = B, z = C)\n) +\n  geom_point(alpha = .8, size = .5, mapping = aes(color = category)) +\n  # geom_point(\n  #   data = samples_unif_unif$tb_intersection |&gt; \n  #     mutate(distrib = \"Uniform\", p = \"(1,1,1)/3\") |&gt; \n  #     bind_rows(\n  #       samples_unif_p$tb_intersection |&gt; \n  #         mutate(distrib = \"Uniform\", p = \"(3,2,1)/6\")\n  #     ) |&gt; \n  #     bind_rows(\n  #       samples_dirichlet_unif$tb_intersection |&gt; \n  #         mutate(distrib = \"2_5_3\", p = \"(1,1,1)/3\")\n  #     ) |&gt; \n  #     bind_rows(\n  #       samples_dirichlet_p$tb_intersection |&gt; \n  #         mutate(distrib = \"2_5_3\", p = \"(3,2,1)/6\")\n  #     ) |&gt;\n  #     mutate(\n  #       distrib = factor(\n  #         distrib,\n  #         levels = c(\"Uniform\", \"2_5_3\"),\n  #         labels = c(\n  #           \"Uniform\" = parse(text = latex2exp::TeX(\"D(1,1,1)\")),\n  #           \"2_5_3\" = parse(text = latex2exp::TeX(\"$D(2,5,3)$\"))\n  #         )\n  #       ),\n  #       p = factor(\n  #         p,\n  #         levels = c(\"(1,1,1)/3\", \"(3,2,1)/6\"),\n  #         labels = c(\n  #           \"(1,1,1)/3\" = parse(text = latex2exp::TeX(\"$p=(1,1,1)/3$\")),\n  #           \"(3,2,1)/6\" = parse(text = latex2exp::TeX(\"$p=(3,2,1)/6$\"))\n  #         )\n  #       )\n  #     )\n  # ) +\n  scale_colour_manual(values = col_categ) +\n  facet_grid(p ~ distrib, labeller = label_parsed, switch = \"y\") +\n  theme_light(base_size = font_size, base_family = font_family) +\n  theme(\n    strip.background = element_rect(colour = \"black\", fill = NA),\n    strip.text.x = element_text(colour = \"black\"),\n    strip.text.y = element_text(colour = \"black\"),\n    text = element_text(family = font_family, size = unit(font_size, \"pt\")),\n    axis.title = element_text(size = rel(.8)),\n    tern.axis.arrow.show = TRUE,\n    tern.axis.arrow.sep = .16,\n    tern.axis.vshift = .09,\n    legend.position = \"bottom\",\n    legend.title = element_text(size = .8 * font_size),\n    legend.text = element_text(size = .8 * font_size),\n    panel.border = element_rect(colour = NA)\n  ) +\n  theme_hidetitles() +\n  guides(colour = guide_legend(override.aes = list(size = 2)))\n\np\n\n\n\n\n\nFigure 10.7: Barycentric centroid of balance, when \\(\\mathcal{D}(\\boldsymbol{\\alpha})\\) with \\(\\boldsymbol{\\alpha}=(1, 1, 1)\\) (left) and \\(\\boldsymbol{\\alpha}=(2, 5, 3)\\) (right), when \\(\\boldsymbol{p}=(1,1,1)/3\\) (top) and \\(\\boldsymbol{p}=(3,2,1)/6\\) (bottom). Black dot: intersection (point where the minimum of the class-wise kernel density estimates is maximized).\n\n\n\n\n\n\n\n\n\n\nCodes to export the figure in PDF.\nfilename &lt;- \"baryc-centr-bal\"\nggsave(\n  p, file = str_c(path, filename, \".pdf\"),\n  height = 3.3*1.75, width = 3.25*1.75,\n  family = font_family,\n  device = cairo_pdf\n)\n# Crop PDF\nsystem(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\n\n\n\n\n\n10.4.2 Back to the Initial Example\nWe define a function, get_assignment(), to map probability vectors from the simplex to categorical labels by solving an optimal transport problem. The transport is computed under marginal constraints, and each individual is assigned to the category to which it contributes the most mass in the optimal transport plan.\n\n\nThe get_assignment() function.\n#' OT for categorical variable, from source distribution to target \n#' probabilities.\n#' \n#' @param probs Propensities from the source distribution (individuals in rows,\n#'  classes in columns).\n#' @param labels Levels (labels) of the classes.\n#' @param p Vector of target probabilities. If omitted, uniform weights are \n#'  used.\n#' \nget_assignment &lt;- function(probs,\n                           labels,\n                           p = NULL) {\n  \n  n_labels &lt;- ncol(probs)\n  n &lt;- nrow(probs)\n  if (is.null(p)) p &lt;- rep(1, n_labels) / n_labels # Uniform weights\n  \n  # Unit vectors\n  vertices &lt;- diag(n_labels)\n  # colnames(vertices) &lt;- colnames()\n  # source weights\n  mass_source &lt;- rep(1 / n, n)\n  # target weights\n  mass_target &lt;- as.numeric(p)\n  \n  # Cost matrix (squared Euclidean distance)\n  cost_matrix &lt;- as.matrix(dist(rbind(probs, vertices))^2)\n  cost_matrix &lt;- cost_matrix[1:n, (n + 1):(n + n_labels)]\n  \n  # Assign each observation to one vertex\n  # by minimizing the global transport cost, while matching marginals\n  \n  # Solve the optimal transport plan\n  ot_plan &lt;- transport::transport(\n    a = mass_source, b = mass_target, costm = cost_matrix, \n    method = \"shortsimplex\"\n  )\n  \n  # Assign each sample to a category based on OT plan\n  assignment &lt;- rep(NA, n)\n  # mass each source sends to each target\n  mass_matrix &lt;- matrix(0, nrow = n, ncol = n_labels)\n  \n  for (j in 1:nrow(ot_plan)) {\n    from &lt;- ot_plan$from[j]\n    to &lt;- ot_plan$to[j]\n    mass &lt;- ot_plan$mass[j]\n    mass_matrix[from, to] &lt;- mass_matrix[from, to] + mass\n  }\n  \n  # Assign each source point to the target it contributes the most mass to\n  assignments &lt;- max.col(mass_matrix, ties.method = \"random\")\n  #factor(c(1, 2, 4), levels = 1:4, labels = c(\"A\", \"B\", \"C\", \"D\"))\n  \n  factor(assignments, levels = 1:length(labels), labels = labels)\n}\n\n\nWe apply our get_assignment() function to get the transported categories for the individuals from group 0.\n\ntransported &lt;- get_assignment(\n  probs = tb_sample_z_1 |&gt; filter(group == 0) |&gt; dplyr::select(-group) |&gt; as.matrix(), \n  labels = c(\"A\", \"B\", \"C\"), \n  p = p1\n)\n\nInitial solution based on shortlist is degenerate. Adding 2 basis vector(s)... done.\n\nhead(transported)\n\n[1] B C B A A B\nLevels: A B C\n\n\nThe observed categories of units in both groups are shown in Figure 10.8.\n\n\nCodes to generate data and create the Figure.\nggtern(\n  data = tb_sample_z_1 |&gt; filter(group == 0) |&gt; \n    mutate(category = x0) |&gt; \n    bind_rows(\n      tb_sample_z_1 |&gt; filter(group == 1) |&gt; \n        mutate(category = x1)\n    ) |&gt; \n    mutate(\n      group = factor(\n        group, \n        levels = c(0, 1), \n        labels = c(\n          paste0(\"&lt;span style='color:\", colGpe0,\";'&gt;Group 0&lt;/span&gt;\"), \n          paste0(\"&lt;span style='color:\", colGpe1,\";'&gt;Group 1&lt;/span&gt;\")\n        )\n      )\n    ),\n  mapping = aes(x = A, y = B, z = C)\n) +\n  geom_point(alpha = .8, size = .5, mapping = aes(color = category)) +\n  facet_wrap(~ group) +\n  scale_colour_manual(values = col_categ, guide = \"none\") +\n  theme_light(base_size = font_size, base_family = font_family) +\n  theme_ggtern_minimal() +\n  theme(\n    strip.text.x = element_text(colour = \"black\"),\n    strip.text = ggtext::element_markdown()\n  )\n\n\n\n\n\nFigure 10.8: Observed categories in group 0 (left) and in group 1 (right).\n\n\n\n\n\n\n\n\nThe transported categories of observations from group 0 are represented in Figure 10.9.\n\n\nCodes to generate data and create the Figure.\np_ggtern_assignment_1 &lt;- ggtern(\n  data = tb_sample_z_1 |&gt; filter(group == 0) |&gt; \n    mutate(category = transported),\n  mapping = aes(x = A, y = B, z = C)\n) +\n  geom_point(alpha = .8, size = .5, mapping = aes(color = category)) +\n  scale_colour_manual(values = col_categ, guide = \"none\") +\n  theme_light(base_size = font_size, base_family = font_family) +\n  theme_ggtern_minimal()\np_ggtern_assignment_1\n\n\n\n\n\nFigure 10.9: Transported categories of observation from group 0 had they been in group 1 (right).\n\n\n\n\n\n\n\n\nWe can display on a barplot (Figure 10.10) the proportion of each category for the transported values, and compare them to the targetted distribution in that group: \\(p_1 = (0.5, 0.3, 0.2)\\).\n\n\nCodes to generate data and create the Figure.\np_barplot_target_1 &lt;- ggplot(\n  data = tibble(x_t = transported) |&gt; count(x_t) |&gt; \n    arrange(desc(x_t)) |&gt; \n    mutate(\n      prop = n / sum(n),\n      lab_y = cumsum(prop) - prop/2\n    )\n) +\n  geom_bar(stat = \"identity\", mapping = aes(x = factor(1), y = prop, fill = x_t)) +\n  geom_text(mapping = aes(x = factor(1), y = lab_y, label = x_t), family = font_family) +\n  scale_fill_manual(values = col_categ, guide = \"none\") +\n  labs(x = NULL, y = NULL) +\n  theme_paper() +\n  theme(\n    axis.ticks.x = element_blank(), \n    axis.text.x = element_blank(), \n    panel.grid.major.x = element_blank()\n  )\np_barplot_target_1\n\n\n\n\n\nFigure 10.10: Share of each category for the transported units.\n\n\n\n\n\n\n\n\n\n\nCodes to export Figures in PDF.\nexport_graph &lt;- FALSE\n\nif (export_graph) {\n\n  library(tikzDevice)\n  path &lt;- \"figs/\"\n  filename &lt;- \"transp-categ-barplot-source\"\n  ggplot2_to_pdf(\n    plot = p_barplot_source + \n      scale_y_continuous(labels = function(x) paste0(\"$\", x, \"$\")),\n    filename = filename, path = path, \n    width = .8, height = 1.6,\n    crop = TRUE\n  )\n  system(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\n  \n  filename &lt;- \"transp-categ-barplot-target\"\n  ggplot2_to_pdf(\n    plot = p_barplot_target_1 + \n      scale_y_continuous(labels = function(x) paste0(\"$\", x, \"$\")),\n    filename = filename, path = path, \n    width = .8, height = 1.6,\n    crop = TRUE\n  )\n  system(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\n  \n  filename &lt;- \"transp-categ-comp\"\n  ggplot2_to_pdf(\n    plot = p_compositional + theme(tern.axis.title.show = FALSE),\n    filename = filename, path = \"figs/\", \n    width = 3, height = 1.6,\n    crop = TRUE\n  )\n  system(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\n  \n  filename &lt;- \"transp-categ-matching\"\n  ggplot2_to_pdf(\n    plot = p_matching_1 + theme(tern.axis.title.show = FALSE),\n    filename = filename, path = path, \n    width = 3, height = 1.6,\n    crop = TRUE\n  )\n  system(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\n  \n  filename &lt;- \"transp-categ-matched\"\n  ggplot2_to_pdf(\n    plot = p_ggtern_matched_1 + theme(tern.axis.title.show = FALSE),\n    filename = filename, path = path, \n    width = 3, height = 1.6,\n    crop = TRUE\n  )\n  system(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\n  \n  filename &lt;- \"transp-categ-assignment\"\n  ggplot2_to_pdf(\n    plot = p_ggtern_assignment_1 + theme(tern.axis.title.show = FALSE),\n    filename = filename, path = path, \n    width = 3, height = 1.6,\n    crop = TRUE\n  )\n  system(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\n}\n\n\n\n\n\n\nFernandes Machado, Agathe, Arthur Charpentier, and Ewen Gallic. 2025. “Optimal Transport on Categorical Data for Counterfactuals Using Compositional Data and Dirichlet Transport.” https://arxiv.org/abs/2501.15549.",
    "crumbs": [
      "III. Counterfactuals for Categorical Data",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transport on Simplex</span>"
    ]
  },
  {
    "objectID": "transp-categ-small-example.html",
    "href": "transp-categ-small-example.html",
    "title": "11  Small Example",
    "section": "",
    "text": "11.1 Random Matching\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n%\\definecolor{colA}{RGB}{255, 221, 85}\n%\\definecolor{colB}{RGB}{148, 78, 223}\n%\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colA}{RGB}{0, 114, 178}\n\\definecolor{colB}{RGB}{213, 94, 0}\n\\definecolor{colC}{RGB}{204, 121, 167}\n\\definecolor{colGpeZero}{RGB}{0,160,138}\n\\definecolor{colGpeUn}{RGB}{242, 173, 0}\n\\]\nLet us consider a simplistic toy example.\nAs in the previous chapters, assume two groups: 0 and 1. In the first group, there are \\(n_0=6\\) individuals indexed 1, 2, 3, 4, 5, 6; and in group 1, there are \\(n_1=6\\) individuals indexed 7, 8, 9, 10, 11, 12. Let \\(Y\\) denote a response variable that takes values in \\(\\mathbb{R}\\), and let \\(X\\) be a categorical variable taking values \\(\\{A,B,C\\}\\).\nLet us assume that we obtained the estimated probabilities of being in each class using a multinomial regression model. This allows to convert categorical observations \\(\\{x_{1,1},\\cdots,x_{1,n_1}\\}\\) and \\(\\{x_{0,1},\\cdots,x_{0,n_0}\\}\\) into estimated probabilities, \\(\\{\\boldsymbol{p}_{1,1},\\cdots,\\boldsymbol{p}_{1,n_1}\\}\\) and \\(\\{\\boldsymbol{p}_{0,1},\\cdots,\\boldsymbol{p}_{0,n_0}\\}\\).\nLet us create a toy example:\nThere are \\(6!=720\\) different random matching that can be done. We will show two of them below.",
    "crumbs": [
      "III. Counterfactuals for Categorical Data",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Small Example</span>"
    ]
  },
  {
    "objectID": "transp-categ-small-example.html#random-matching",
    "href": "transp-categ-small-example.html#random-matching",
    "title": "11  Small Example",
    "section": "",
    "text": "11.1.1 First Random Matching\nLet us first consider a random matching in which the individuals matched are 1 (group 0) and 12 (group 1), 2 and 9, 3 and 7, 4 and 10, 5 and 8, 6 and 12.\n\nmatched_ex_1 &lt;- tribble(\n  ~i_0, ~i_1,\n  1, 12,\n  2, 9,\n  3, 7,\n  4, 10,\n  5, 8,\n  6, 11\n) |&gt;\n  left_join(\n    group_0 |&gt;\n      rename_with(~str_c(.x, \"_0\")),\n    by = \"i_0\"\n  ) |&gt;\n  left_join(\n    group_1 |&gt;\n      rename_with(~str_c(.x, \"_1\")),\n    by = \"i_1\"\n  )\n\n\n\n11.1.2 Second Random Matching\nWe can consider, for the sake of illustration, a second random matching, where the individuals matched are 1 and 8, 2 and 7, 3 and 11, 4 and 10, 5 and 9, 6 and 12.\n\nmatched_ex_2 &lt;- tribble(\n  ~i_0, ~i_1,\n  1, 8,\n  2, 7,\n  3, 11,\n  4, 10,\n  5, 9,\n  6, 12\n) |&gt;\n  left_join(\n    group_0 |&gt;\n      rename_with(~str_c(.x, \"_0\")),\n    by = \"i_0\"\n  ) |&gt;\n  left_join(\n    group_1 |&gt;\n      rename_with(~str_c(.x, \"_1\")),\n    by = \"i_1\"\n  )",
    "crumbs": [
      "III. Counterfactuals for Categorical Data",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Small Example</span>"
    ]
  },
  {
    "objectID": "transp-categ-small-example.html#matching-on-arbitrarily-assigned-numerical-values-to-the-categories",
    "href": "transp-categ-small-example.html#matching-on-arbitrarily-assigned-numerical-values-to-the-categories",
    "title": "11  Small Example",
    "section": "11.2 Matching on Arbitrarily Assigned Numerical Values to the Categories",
    "text": "11.2 Matching on Arbitrarily Assigned Numerical Values to the Categories\nLet us arbitrarily set the following values for the categories: \\(A=1\\), \\(B=2\\), \\(C=3\\).\n\ncat_levels &lt;- c(\"A\", \"B\", \"C\")\nx0_index &lt;- match(group_0$x, cat_levels)\nx1_index &lt;- match(group_1$x, cat_levels)\n\nFor the cost matrix, we can use the Euclidean distance between the arbitrarily assigned numerical values.\n\ncost_matrix &lt;- outer(x0_index, x1_index, function(i, j) sqrt((i - j)^2))\ncost_matrix\n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]    0    1    1    1    2    2\n[2,]    0    1    1    1    2    2\n[3,]    0    1    1    1    2    2\n[4,]    1    0    0    0    1    1\n[5,]    1    0    0    0    1    1\n[6,]    2    1    1    1    0    0\n\n\nUsing this cost matrix, the transport problem can be solved with the solve_LSAP() function from {clue}.\n\nassignment &lt;- solve_LSAP(cost_matrix)\n\nWe add the IDs of each observation:\n\nn0 &lt;- nrow(group_0)\nn1 &lt;- nrow(group_1)\not_plan_num &lt;- tibble(\n  from = 1:n0,\n  to = as.numeric(assignment)\n)\not_plan_num$i_0 &lt;- group_0$i[ot_plan_num$from]\not_plan_num$i_1 &lt;- group_1$i[ot_plan_num$to]\not_plan_num\n\n# A tibble: 6 × 4\n   from    to   i_0   i_1\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     1     1     7\n2     2     4     2    10\n3     3     6     3    12\n4     4     2     4     8\n5     5     3     5     9\n6     6     5     6    11\n\n\nThe matched individuals are shown in Figure 11.2.\n\n\nCodes to create the Figure.\nggtern(\n  data = group_0 |&gt; mutate(group = \"0\") |&gt; \n    bind_rows(group_1 |&gt; mutate(group = \"1\")) |&gt; \n    left_join(\n      ot_plan_num |&gt; \n        mutate(\n          id_match = as.character(row_number())\n        ) |&gt; \n        dplyr::select(i_0, i_1, id_match) |&gt; \n        pivot_longer(cols = c(i_0, i_1), values_to = \"i\") |&gt; \n        dplyr::select(-name),\n      by = \"i\"\n    ),\n  mapping = aes(x = p_A, y = p_B, z = p_C, group = id_match)\n) +\n  geom_point(mapping = aes(shape = group, colour = x), size = 4) +\n  geom_text(\n    mapping = aes(\n      label = i, \n      x = p_A + ifelse(group == 0, -1, 1) * 0.05\n    ),\n    size = .3*font_size\n  ) +\n  labs(x = \"$p_A$\", y = \"$p_B$\", z = \"$p_C\") +\n  geom_line(\n    colour = \"gray40\", \n    # mapping = aes(linetype = id_match)\n  ) +\n  scale_colour_manual(\n    name = \"category\", \n    values = col_categ, \n    labels = c(\"A\" = \"A=1\", \"B\" = \"B=2\", \"C\" = \"C=3\")\n  ) +\n  scale_shape_discrete(name = \"group\") +\n  theme_light(base_size = font_size, base_family = font_family) +\n  # theme_paper() +\n  theme_ggtern() +\n  theme(\n    legend.title = element_text(size = .8*font_size),\n    legend.text = element_text(size = .8*font_size)\n  ) +\n  theme_latex(TRUE) +\n  theme_hidetitles()\n\n\n\n\n\nFigure 11.1: 1-to-1 Matching with optimal transport based on the distances between the individuals with respect to the abrbitrarily assigned numerical values to the categories.",
    "crumbs": [
      "III. Counterfactuals for Categorical Data",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Small Example</span>"
    ]
  },
  {
    "objectID": "transp-categ-small-example.html#transport-on-simplex",
    "href": "transp-categ-small-example.html#transport-on-simplex",
    "title": "11  Small Example",
    "section": "11.3 Transport on Simplex",
    "text": "11.3 Transport on Simplex\nLet us now perform optimal matching between individuals from the two groups with optimal transport using a representation in the probability simplex.s\n\n11.3.1 Matching Using the Euclidean Distances Cost Matrix\nLet us use the Euclidean distance for the transport costs. These distances are computed in the space of centered log-ratio (clr) transformed probability vectors associated with each individual’s membership in one of the classes.\nLet us first extract the probability vectors (\\(p_A, p_B, p_C\\)) from both groups and apply the clr transformation to make them suitable for Euclidean geometry in the compositional space.\n\nlibrary(compositions)\nall_coords &lt;- rbind(\n  as.matrix(group_0[, c(\"p_A\", \"p_B\", \"p_C\")]),\n  as.matrix(group_1[, c(\"p_A\", \"p_B\", \"p_C\")])\n) |&gt; \n  clr()\n\nThen, we can compute the pairwise Euclidean distances between individuals in group 0 and those in group 1, based on their clr-transformed probability vectors.\n\nrow.names(all_coords) &lt;- c(group_0$i, group_1$i)\n# Euclidean distances between the clr transform of the propensities\nD &lt;- as.matrix(dist(all_coords, method = \"euclidean\"))\nn0 &lt;- nrow(group_0)\nn1 &lt;- nrow(group_1)\nbetween_distances &lt;- D[1:n0, (n0 + 1):(n0 + n1)]\nround(between_distances, 2)\n\n     7    8    9   10   11   12\n1 0.63 2.91 0.80 2.27 1.99 2.92\n2 0.00 2.42 0.64 1.85 2.09 2.67\n3 1.30 2.67 0.79 1.93 0.98 2.21\n4 1.77 0.98 1.78 1.06 2.67 2.09\n5 1.38 1.30 1.46 1.15 2.53 2.21\n6 2.75 1.77 2.16 1.36 1.30 0.41\n\n\nWe aim to find the optimal matching between the individuals in group 1 and group 0 based on these distances. Formally, we want to solve the following optimal transport problem: \\[\n\\min_{P\\in\\mathcal{U}(\\boldsymbol{1}_{n_1},\\boldsymbol{1}_{n_0})}\n\\langle P,\\,C\\rangle,\n\\] where \\(C:=[C_{i,j}]\\) is the cost matrix, with \\(C_{ij}\\) measuring the cost of matching individual \\(i\\) from group 1 to individual \\(j\\) from group 0. Here, we use the Euclidean distance that we juste computed. The total cost is given by \\(\\langle P, C\\rangle=\\sum_{i=1}^{n_1}\\sum_{j=1}^{n_0}P_{ij}\\,C_{ij}\\). The set of admissible transport plans is defined as follows: \\[\n\\left\\{\\,P\\in\\mathbb{R}_+^{n_1\\times n_0}:\nP\\,\\mathbf{1}_{n_0}=\\frac{\\mathbf{1}_{n_1}}{n_1},\\\nP^\\top\\mathbf{1}_{n_1}=\\frac{\\mathbf{1}_{n_0}}{n_0}\n\\right\\}.\n\\] We thus have a uniform mass distribution across both groups.\n\n\n\n\n\n\nNote\n\n\n\nAn alternative cost function (which is not used here) is the cross-entropy between two compositional vectors: \\[\n\\begin{equation*}\nc(\\mathbf{x},\\mathbf{y})=\\log\\left(\\frac{1}{d}\\sum_{i=1}^d\\frac{y_i}{x_i}\\right)-\\frac{1}{d}\\sum_{i=1}^d\\log\\left(\\frac{y_i}{x_i}\\right),\n\\end{equation*}.\n\\] This corresponds to the “Dirichlet transport” (Baxendale and Wong (2022)). This alternative is considered below, in Section 11.3.2.\n\n\nWe solve the optimal transport problem using the transport() function from the {transport} package. This function computes the optimal matching plan based on the cost matrix.\n\n# source weights\nmass_source &lt;- rep(1 / n0, n0)\n# target weights\nmass_target &lt;- rep(1 / n1, n1)\n\n# Solve the optimal transport plan\not_plan &lt;- transport::transport(\n  a = mass_source, b = mass_target, costm = between_distances, \n  method = \"networkflow\"\n)\not_plan$i_0 &lt;- group_0$i[ot_plan$from]\not_plan$i_1 &lt;- group_1$i[ot_plan$to]\not_plan\n\n  from to      mass i_0 i_1\n1    1  3 0.1666667   1   9\n2    2  1 0.1666667   2   7\n3    3  5 0.1666667   3  11\n4    4  2 0.1666667   4   8\n5    5  4 0.1666667   5  10\n6    6  6 0.1666667   6  12\n\n\nWe can visualize the results in a ternary plot (Figure 11.2). The lines depict the matched individuals (shown by dots and their index).\n\n\nCodes to create the Figure.\nall_data &lt;- group_0 |&gt; mutate(group = \"0\") |&gt; \n  bind_rows(group_1 |&gt; mutate(group = \"1\"))\n\nlibrary(ggtern)\n\np &lt;- ggtern(\n  data = all_data |&gt; \n    left_join(\n      ot_plan |&gt; \n        mutate(\n          i_0 = as.numeric(i_0),\n          i_1 = as.numeric(i_1),\n          id_match = as.character(row_number())\n        ) |&gt; \n        dplyr::select(i_0, i_1, id_match) |&gt; \n        pivot_longer(cols = c(i_0, i_1), values_to = \"i\") |&gt; \n        dplyr::select(-name)\n    ),\n  mapping = aes(x = p_A, y = p_B, z = p_C, group = id_match)\n) +\n  geom_point(mapping = aes(shape = group, colour = x), size = 4) +\n  geom_text(\n    mapping = aes(\n      label = i, \n      x = p_A + ifelse(group == 0, -1, 1) * 0.05\n    ),\n    size = .3*font_size\n  ) +\n  labs(x = \"$p_A$\", y = \"$p_B$\", z = \"$p_C\") +\n  geom_line(\n    colour = \"gray40\", \n    # mapping = aes(linetype = id_match)\n  ) +\n  scale_colour_manual(name = \"category\", values = col_categ) +\n  scale_shape_discrete(name = \"group\") +\n  theme_light(base_size = font_size, base_family = font_family) +\n  # theme_paper() +\n  theme_ggtern() +\n  theme(\n    legend.title = element_text(size = .8*font_size),\n    legend.text = element_text(size = .8*font_size)\n  ) +\n  theme_latex(TRUE) +\n  theme_hidetitles()\n\np\n\n\n\n\n\nFigure 11.2: 1-to-1 Matching with optimal transport based on the distances between the individuals with respect to their estimated probabilities of being in each class.\n\n\n\n\n\n\n\n\n\n\nCodes to export the figure in PDF.\nfilename &lt;- \"ternary-toy\"\nggsave(\n  p, file = str_c(path, filename, \".pdf\"),\n  height = 2.2*1.75, width = 4*1.75,\n  family = font_family,\n  device = cairo_pdf\n)\n# Crop PDF\nsystem(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\n\n\n\n\n11.3.2 Matching Using the Cross-Entropy Cost Matrix\nIn Section 11.3.1, we used the Euclidean distance of the clr-transformed vector of probabilities as the cost function to solve the optimal transport problem. Here, we consider an alternative cost function, the cross-entreopy: \\[\nc(\\mathbf{x}, \\mathbf{y}) = \\log\\left(\\frac{1}{d} \\sum_{i=1}^d \\frac{y_i}{x_i}\\right) - \\frac{1}{d} \\sum_{i=1}^d \\log\\left(\\frac{y_i}{x_i}\\right).\n\\]\nWe first extract the probability vectors for the individuals from both groups (without clr transform), and we make sure there is no probability equal to 0.\n\np0 &lt;- as.matrix(group_0[, c(\"p_A\", \"p_B\", \"p_C\")])\np1 &lt;- as.matrix(group_1[, c(\"p_A\", \"p_B\", \"p_C\")])\np0 &lt;- pmax(p0, 1e-10)\np1 &lt;- pmax(p1, 1e-10)\n\nLet us define the cross-entropy cost function:\n\ncross_entropy_cost &lt;- function(x, y) {\n  d &lt;- length(x)\n  log(mean(y / x)) - mean(log(y / x))\n}\n\nWe can then compute the pairwise cost matrix (group0 rows vs group1 columns).\n\nbetween_distances_ce &lt;- outer(\n  1:nrow(p0), 1:nrow(p1),\n  Vectorize(function(i, j) cross_entropy_cost(p0[i, ], p1[j, ]))\n)\nround(between_distances_ce, 4)\n\n       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]\n[1,] 0.0694 0.9259 0.0933 0.5710 0.6292 0.8421\n[2,] 0.0000 0.6318 0.0716 0.4027 0.7533 0.8514\n[3,] 0.2379 1.0435 0.1048 0.5769 0.1542 0.5436\n[4,] 0.4670 0.1542 0.3867 0.1979 0.8514 0.7533\n[5,] 0.2844 0.2379 0.2718 0.2352 0.8708 0.8232\n[6,] 0.9985 0.4670 0.7076 0.2424 0.2894 0.0287\n\n\nThen, we can solde the optimal transport problem.\n\not_plan_ce &lt;- transport::transport(\n  a = mass_source,\n  b = mass_target,\n  costm = between_distances_ce,\n  method = \"networkflow\"\n)\not_plan_ce$i_0 &lt;- group_0$i[ot_plan_ce$from]\not_plan_ce$i_1 &lt;- group_1$i[ot_plan_ce$to]\not_plan_ce\n\n  from to      mass i_0 i_1\n1    1  3 0.1666667   1   9\n2    2  1 0.1666667   2   7\n3    3  5 0.1666667   3  11\n4    4  2 0.1666667   4   8\n5    5  4 0.1666667   5  10\n6    6  6 0.1666667   6  12\n\n\nAgain, we can visualize the matched individuals on a ternary plot (Figure 11.3).\n\n\nCodes to create the Figure.\nggtern(\n  data = all_data |&gt; \n    left_join(\n      ot_plan_ce |&gt; \n        mutate(\n          i_0 = as.numeric(i_0),\n          i_1 = as.numeric(i_1),\n          id_match = as.character(row_number())\n        ) |&gt; \n        dplyr::select(i_0, i_1, id_match) |&gt; \n        pivot_longer(cols = c(i_0, i_1), values_to = \"i\") |&gt; \n        dplyr::select(-name)\n    ),\n  mapping = aes(x = p_A, y = p_B, z = p_C, group = id_match)\n) +\n  geom_point(mapping = aes(shape = group, colour = x), size = 4) +\n  geom_text(\n    mapping = aes(\n      label = i, \n      x = p_A + ifelse(group == 0, -1, 1) * 0.05\n    ),\n    size = .3*font_size\n  ) +\n  labs(x = \"$p_A$\", y = \"$p_B$\", z = \"$p_C\") +\n  geom_line(\n    colour = \"gray40\", \n    # mapping = aes(linetype = id_match)\n  ) +\n  scale_colour_manual(name = \"category\", values = col_categ) +\n  scale_shape_discrete(name = \"group\") +\n  theme_light(base_size = font_size, base_family = font_family) +\n  # theme_paper() +\n  theme_ggtern() +\n  theme(\n    legend.title = element_text(size = .8*font_size),\n    legend.text = element_text(size = .8*font_size)\n  ) +\n  theme_latex(TRUE) +\n  theme_hidetitles()\n\n\n\n\n\nFigure 11.3: 1-to-1 Matching with optimal transport based on cross entropy as the transport cost between the individuals with respect to their estimated probabilities of being in each class.\n\n\n\n\n\n\n\n\n\n\n\n\nBaxendale, Peter, and Ting-Kam Leonard Wong. 2022. “Random Concave Functions.” The Annals of Applied Probability 32 (2): 812–52.",
    "crumbs": [
      "III. Counterfactuals for Categorical Data",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Small Example</span>"
    ]
  },
  {
    "objectID": "transport-gaussian-local-weights.html",
    "href": "transport-gaussian-local-weights.html",
    "title": "12  Gaussian Conditional Univariate Transport with Local Weights",
    "section": "",
    "text": "12.1 Sequential Optimal Transport\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colA}{RGB}{0, 114, 178}\n\\definecolor{colB}{RGB}{213, 94, 0}\n\\definecolor{colC}{RGB}{204, 121, 167}\n\\definecolor{colGpeZero}{RGB}{127, 23, 14}\n\\definecolor{colGpeUn}{RGB}{27, 149, 224}\n\\]\nLet \\(A=\\{0,1\\}\\) be a binary treatment. Individuals for which \\(A=0\\) are in group 0, those for which \\(A=1\\) are in group 1. Let \\(\\boldsymbol{X}=(X_1, X_2) | A=a\\) follow a multivariate Normal distribution. We set the following means for group 0 and group 1, \\(\\boldsymbol{\\mu}_0\\) and \\(\\boldsymbol{\\mu}_1\\), respectively:\nM0 &lt;- c(-1, -1)\nM1 &lt;- c(1.5, 1.5)\nand the following variance-covariance matrices, \\(\\boldsymbol{\\Sigma}_0\\) and \\(\\boldsymbol{\\Sigma}_1\\):\nS0 &lt;- 4 * matrix(c(1, .5, .5, 1) * 1.2^2, 2, 2)\nS1 &lt;- 4 * matrix(c(1, -.4, -.4, 1) * .9^2, 2, 2)\nSet the seed for reproducibility:\nset.seed(1234)\nWe will first focus on the point \\((x_{1,0} = 0, x_{2,0} =1)\\) from group 0 that we want to transport in group 1.\nx0 &lt;- c(0, 0)\nWe will proceed in a sequential way, assuming the following topological order: \\(A \\rightarrow X_1 \\rightarrow X_2\\).\nFirst, transport \\(x_{1,0}\\) from group 0 to group 1. To do so, simply estimate the cumulative distribution function on the individuals in group 0 \\(\\widehat{F}_{1,a=0}\\) and the quantile function on the individuals in group 1 \\(\\widehat{Q}_{1,t=1}\\). The transport map is \\(T_1^\\star = \\widehat{Q}_{1,t=1}\\circ\\widehat{F}_{1,t=0}\\) so that the counterfactual of \\(x_{1,0}\\) in group 1 is \\(x_{1,1}^\\star=T_1^\\star(x_{1,0})\\).\nT1x0 &lt;- qnorm(\n  p = pnorm(q = x0[1], mean = M0[1], sd = sqrt(S0[1, 1])), \n  mean = M1[1], sd = sqrt(S1[1,1])\n)\nThen, transport \\(x_{2,0}\\) conditional on \\(x_{1,0}\\). To do so, estimate the cumulative distribution function on individuals from group 0 \\(\\widehat{F}_{2,a=0}\\) conditional on \\(X_1=x_{1,0}\\), for \\(X_2\\); and the quantile function on the individuals from group 1 \\(\\widehat{Q}_{2,t=1}\\), conditional on \\(X_2=x^\\star_{1,0}\\), for \\(X_2\\). The transport map is \\(T_2^\\star = \\widehat{Q}_{2,t=1}\\circ\\widehat{F}_{2,t=0}\\) so that the counterfactual of \\(x_{2,0}\\) in group 1 is \\(x_{2,1}^\\star=T_{2\\mid1}^\\star(x_{2,0})\\).\nm10 &lt;- M0[2] + S0[1, 2] / S0[1, 1] * (x0[1] - M0[1])\ns10 &lt;- S0[2, 2] - S0[1, 2]^2 / S0[1, 1]\nm11 &lt;- M1[2] + S1[1, 2] / S1[1, 1] * (T1x0[1] - M1[1])\ns11 &lt;- S1[2, 2] - S1[1, 2]^2 / S1[1, 1]\n\nT2x0 &lt;- qnorm(\n  p = pnorm(q = x0[2], mean = m10, sd = sqrt(s10)), \n  mean = m11, \n  sd = sqrt(s11)\n)\nThe coordinates of the transported point are:\nc(round(T1x0,4), round(T2x0,4))\n\n[1] 2.2500 1.5969\nWe define a wraper function, transp_ot() for the previous codes, to transport an observation from group 0 to group 1 with that framework.\nThe transp_ot() function.\ntransp_ot &lt;- function(x0) {\n  # First, transport X_1 from group 0 to group 1\n  T1x0 &lt;- qnorm(\n    p = pnorm(q = x0[1], mean = M0[1], sd = sqrt(S0[1, 1])), \n    mean = M1[1], sd = sqrt(S1[1,1])\n  )\n  \n  # Then, transport X_2 conditional on X_1\n  m10 &lt;- M0[2] + S0[1, 2] / S0[1, 1] * (x0[1] - M0[1])\n  s10 &lt;- S0[2, 2] - S0[1, 2]^2 / S0[1, 1]\n  m11 &lt;- M1[2] + S1[1, 2] / S1[1, 1] * (T1x0[1] - M1[1])\n  s11 &lt;- S1[2, 2] - S1[1, 2]^2 / S1[1, 1]\n  \n  T2x0 &lt;- qnorm(\n    p = pnorm(q = x0[2], mean = m10, sd = sqrt(s10)), \n    mean = m11, \n    sd = sqrt(s11)\n  )\n  \n  T2x0\n}\nLet us visualize the initial point and is transported version on a plot.\nCodes to create the Figure.\n# Let us display the 50% confidence ellipses for both groups\nZ0 &lt;- as.data.frame(ellipse::ellipse(S0, level = .5))\nZ0 &lt;- Z0 + rep(M0, each = nrow(Z0))\nZ1 &lt;- as.data.frame(ellipse::ellipse(S1, level = .5))\nZ1 &lt;- Z1 + rep(M1, each = nrow(Z1))\nplot(\n  Z0, type = \"l\", col = colours[1],\n  xlim = range(c(Z0[, 1], Z1[, 1])),\n  ylim = range(c(Z0[, 2], Z1[, 2])),\n  xlab = \"\", ylab = \"\"\n)\nlines(Z1, type = \"l\", col = colours[2])\n# The starting point\npoints(x0[1], x0[2], pch = 19, col = \"black\", cex = 2)\n# Transport of the first component (x_1): intermediate point\nsegments(x0[1], x0[2], T1x0, x0[2], col = colours[3])\npoints(T1x0, x0[2], pch = 19, col = \"gray\", cex = 1)\n# Transport of the second component (x_2), conditional on x_1\n# The resulting point in the transported individual from group 0 to group 1.\nsegments(T1x0, T2x0, T1x0, x0[2], col = colours[3])\npoints(T1x0, T2x0, pch = 19, col = colours[3], cex = 2)\n\n\n\n\nPoint \\((x_{1,0} = 0, x_{2,0} =1)\\) in group 0 transported in group 1. The intermediate point from the sequential transport is shown in gray.",
    "crumbs": [
      "IV. Transport with Weights",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Gaussian Conditional Univariate Transport with Local Weights</span>"
    ]
  },
  {
    "objectID": "transport-gaussian-local-weights.html#sequential-transport-using-kernel-method",
    "href": "transport-gaussian-local-weights.html#sequential-transport-using-kernel-method",
    "title": "12  Gaussian Conditional Univariate Transport with Local Weights",
    "section": "12.2 Sequential Transport using Kernel Method",
    "text": "12.2 Sequential Transport using Kernel Method\nLet us now transport the point using local weights.\nAgain, we will proceed in two steps. In a first step, we transport \\(x_{1,t=0}\\) from group 0 to group 1. The transport map is \\(T_1^\\star=\\widehat{Q}_{1,t=1}\\circ \\widehat{F}_{1,t=0}(x)\\) where \\[\n\\widehat{F}_{1,t}(x)=\\frac{1}{n_t}\\sum_{i=1}^{n_t}\\boldsymbol{1}(x_{1,i,t}\\leq x)\\text{ and }\\widehat{Q}_{1,t}=\\widehat{F}_{1,t}^{-1}.\n\\]\nThen, we proceed to the transport of \\(x_{2,0}\\) conditional on \\(x_{1,0}\\). The transport map is \\(T_2^\\star=\\widehat{Q}_{2|1,t=1}\\circ \\widehat{F}_{2|1,t=0}(x)\\) where \\[\n\\widehat{F}_{2|1,t}(x)=\\sum_{i=1}^{n_t}\\omega_{i,t}\\boldsymbol{1}(x_{1,i,t}\\leq x)\\text{ and }\\widehat{Q}_{2|1,t}=\\widehat{F}_{2|1,t}^{-1}.\n\\] with \\[\n\\omega_{i,t=0} \\propto k_h(x_{1,i,t=0}-x_{1,0})\n\\text{ and }\n\\omega_{i,t=1} \\propto k_h(x_{1,i,t=1}-x^\\star_{1,0})\n\\] for some kernel \\(k_h\\).\n\nlibrary(mvtnorm)\nlibrary(Hmisc)\n\n\nAttaching package: 'Hmisc'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    src, summarize\n\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\n\nWe set the seed for reproducibility:\n\nset.seed(12345)\n\nWe define a function, Transp2x0(), to transport an observation under this Gaussian framework, using either a Gaussian or a Uniform (retangular) kernel.\n\n#' @param x0 Point to transport\n#' @param n Number of observations to draw\n#' @param kernel Type of kernel to use: \"gaussian\" for Gaussian kernel, or \n#'  \"uniform\" for rectangular (uniform) kernel.\nTransp2x0 &lt;- function(x0,\n                      n, \n                      kernel = c(\"gaussian\", \"uniform\"),\n                      seed = NULL) {\n  \n  if (!is.null(seed)) set.seed(seed)\n  kernel &lt;- match.arg(kernel)\n  \n  # Parameters of the multivariate Gaussian distributions in the\n  # two groups\n  M0 &lt;- c(-1, -1)\n  M1 &lt;- c(1.5, 1.5)\n  S0 &lt;- 4 * matrix(c(1, .5, .5, 1) * 1.2^2, 2, 2)\n  S1 &lt;- 4 * matrix(c(1, -.4, -.4, 1) * .9^2, 2, 2)\n  \n  # Bandwidth for smoothing (to be used in the Gaussian kernel weights)\n  h &lt;- .0001 + runif(1)\n  \n  # Drawing individuals in both groups\n  X0 &lt;- mnormt::rmnorm(n, M0, S0)\n  X1 &lt;- mnormt::rmnorm(n, M1, S1)\n  \n  # Transport of the first coordinate\n  # cdf value of starting point in group 0\n  u &lt;- mean(X0[, 1] &lt;= x0[1])\n  # corresponding quantile level in group 1\n  T1x0 &lt;- as.numeric(quantile(X1[, 1], u))\n  \n  if (kernel == \"gaussian\") {\n    # Transport of the second coordinate, conditional on the first\n    # using kernel smoothing\n    # Weights based on the proximity in the first dimension\n    w0x0 &lt;- dnorm(X0[, 1], x0[1], sd = h)\n    w0x0 &lt;- w0x0 / sum(w0x0)\n    w1x0 &lt;- dnorm(X1[, 1], T1x0, sd = h)\n    w1x0 &lt;- w1x0 / sum(w1x0)\n    # conditional distribution of the second coordinate in group 0\n    # weighted by proximity in the first coordinate\n  } else {\n    # uniform (or rectangular) kernel\n    w0x0 &lt;- (abs(X0[, 1] - x0[1]) &lt; (h)) * 1\n    w0x0 &lt;- w0x0 / sum(w0x0)\n    w1x0 &lt;- (abs(X1[, 1] - T1x0) &lt; h) * 1\n    w1x0 &lt;- w1x0 / sum(w1x0)\n  }\n  u &lt;- weighted.mean(X0[, 2] &lt;= x0[2], w0x0)\n  \n  # u-th weighted quantile of the second coordinate, where the weights\n  # reflect the closeness to T1x0\n  T2x0 &lt;- Hmisc::wtd.quantile(\n    x = X1[, 2], weights = w1x0, probs = u, normwt = TRUE) |&gt; \n    as.numeric()\n  \n  c(x = h, y = T2x0)\n}\n\n\n12.2.1 Simulations\nLet us now run some simulations. We will consider two different kernels: a Gaussian, and a Uniform. We will tranpsport two points: \\((x_{1,0} = 0, x_{2,0} =1)\\) and \\((x_{1,0} = -2, x_{2,0} = -1)\\). For each case, we generate 5,000 samples from the DGP shown in Section 12.1.\n\n# This chunk is not evaluated here. Each simulation takes about 4 minutes.\n# The results of previously run simulations are loaded in this notebook.\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(mvtnorm)\n}) |&gt;\n  invisible()\n\nn &lt;- 1e5\nn_repl &lt;- 5000\n\nclusterExport(cl, c(\"Transp2x0\", \"n\", \"n_repl\"))\n\n# Starting point: (0,0) and Gaussian kernel\nres_sim_gaussian_1 &lt;- pbapply::pblapply(\n  seq_len(n_repl), \n  function(x) Transp2x0(x0 = c(0, 0), n = n, kernel = \"gaussian\", seed = x),\n  cl = cl\n)\nres_sim_gaussian_1 &lt;- do.call(\"rbind\", res_sim_gaussian_1)\n\n# Starting point: (0,0) and uniform kernel\nres_sim_uniform_1 &lt;- pbapply::pblapply(\n  seq_len(n_repl), \n  function(x) Transp2x0(x0 = c(0, 0), n = n, kernel = \"uniform\", seed = x),\n  cl = cl\n)\nres_sim_uniform_1 &lt;- do.call(\"rbind\", res_sim_uniform_1)\n\n# Starting point: (-2,1) and Gaussian kernel\nres_sim_gaussian_2 &lt;- pbapply::pblapply(\n  seq_len(n_repl), \n  function(x) Transp2x0(x0 = c(-2, -1), n = n, kernel = \"gaussian\", seed = x),\n  cl = cl\n)\n\nres_sim_gaussian_2 &lt;- do.call(\"rbind\", res_sim_gaussian_2)\n\n# Starting point: (-2,1) and uniform kernel\nres_sim_uniform_2 &lt;- pbapply::pblapply(\n  seq_len(n_repl), \n  function(x) Transp2x0(x0 = c(-2, -1), n = n, kernel = \"uniform\", seed = x),\n  cl = cl\n)\nres_sim_uniform_2 &lt;- do.call(\"rbind\", res_sim_uniform_2)\n\nstopCluster(cl)\n\nsave(\n  res_sim_gaussian_1,\n  res_sim_gaussian_2,\n  res_sim_uniform_1,\n  res_sim_uniform_2,\n  file = \"../output/simyot-loc-weights.rda\"\n)\n\nWe load the results:\n\nload(\"../output/simyot-loc-weights.rda\")\n\n\n12.2.1.1 Results\nWe can visualize the results. In Figure 12.1 we can visualize \\(x_{2|1,0}^\\star\\) (on the \\(y\\)-axis) when \\((x_{1,0},x_{2,0})=(0,0)\\) (on top) and when \\((x_{1,0},x_{2,0})=(-2,-1)\\) (below) using simulated Gaussian samples, for two choices of kernels (Gaussian on the left, uniform on the right). The horizontal dashed line indicates the transported value from standard optimal transport (as in Section 12.1).\n\n\nCodes to create the Figure\nexport_tikz &lt;- FALSE\nlibrary(tikzDevice)\nlibrary(mgcv)\nf_plot &lt;- function(res_sim, \n                   kernel, \n                   x0, \n                   ylim = NULL, \n                   tikz = FALSE, \n                   draw_y_axis = TRUE) {\n  plot(\n    res_sim[, 1], res_sim[, 2],\n    # V[1,], V[2,],\n    cex = .4, col = scales::alpha(colours[3], .2),\n    xlab = \"\",\n    ylab = \"\",\n    main = \"\",\n    ylim = ylim,\n    family = font_family,\n    axes = FALSE\n  )\n  axis(1, family = font_family)\n  if (draw_y_axis) axis(2, family = font_family)\n  title(\n    main = paste(kernel, \"kernel\"),\n    family = font_family,\n    adj = 0,\n    line = 2,\n    cex.main = 1\n  )\n  sub_title &lt;- paste0(\n    \"$(x_{1,0}, x_{2,0}) = (\",\n    paste(x0, collapse = \", \"), \")$\"\n  )\n  \n  if (tikz == FALSE) sub_title &lt;- latex2exp::TeX(sub_title)\n  title(\n    main =  sub_title,\n    family = font_family,\n    adj = 0,\n    line = 1,\n    cex.main = 1,\n  )\n  title(\n    xlab = \"Neighborhood size\", \n    ylab = \"Transported value\", \n    line = 2,\n    family = font_family\n  )\n  \n  T2x0 &lt;- transp_ot(x0)\n  # Result obtained sequential transport\n  abline(h = T2x0, lty=2, col=\"darkred\")\n  # Smooth line of the transported values obtained with the kernel approach\n  base &lt;- data.frame(x = res_sim[, 1], y = res_sim[, 2])\n  reg &lt;- mgcv::gam(y ~ s(x), data = base)\n  nbase &lt;- data.frame(x = (1:100) / 100)\n  p &lt;- predict(reg, newdata = nbase, type = \"link\", se.fit = TRUE)\n  lines(nbase$x, p$fit, col = colours[4], lwd = 3)\n}\n\npath &lt;- \"./figs/\"\nfile_name &lt;- \"gaussian-ot-local-weights\"\n\nif (export_tikz == TRUE)\n  tikz(paste0(\"figs/\", file_name, \".tex\"), width = 2.75, height = 2.75)\n\nlayout(matrix(1:4, ncol = 2, byrow = TRUE), width = c(1, .8))\npar(mar = c(3.1, 3.1, 3.1, .1))\nf_plot(\n  res_sim_gaussian_1, \n  kernel = \"Gaussian\", x0 = c(0, 0), ylim = c(1.4, 1.8), tikz = export_tikz\n)\npar(mar = c(3.1, .6, 3.1, .1))\nf_plot(\n  res_sim_uniform_1, \n  kernel = \"Uniform\", x0 = c(0, 0), ylim = c(1.4, 1.8), tikz = export_tikz,\n  draw_y_axis = FALSE\n)\npar(mar = c(3.1, 3.1, 3.1, .1))\nf_plot(\n  res_sim_gaussian_2, \n  kernel = \"Gaussian\", x0 = c(-2, -1), ylim = c(2, 2.5), tikz = export_tikz\n)\npar(mar = c(3.1, .6, 3.1, .1))\nf_plot(\n  res_sim_uniform_2, \n  kernel = \"Uniform\", x0 = c(-2, -1), ylim = c(2, 2.5), tikz = export_tikz,\n  draw_y_axis = FALSE\n)\n\nif (export_tikz == TRUE) {\n  dev.off()\n  plot_to_pdf(filename = file_name, path = path, keep_tex = FALSE, crop = FALSE)\n}\n\n\n\n\n\nFigure 12.1: Conditional Optimal Transport using local weights. Value of \\(x_{2|1,0}^\\star\\) on the \\(y\\)-axis when \\((x_{1,0}, x_{2,0}) = (0,0)\\) (top) and \\((-2, -1)\\) (bottom), based on 5,000 simulated Gaussian samples. The left panel uses Gaussian kernels; the right panel uses rectangular (uniform) kernels. The horizontal dashed line indicates the transported value from standard optimal transport.",
    "crumbs": [
      "IV. Transport with Weights",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Gaussian Conditional Univariate Transport with Local Weights</span>"
    ]
  },
  {
    "objectID": "xp-simulated.html",
    "href": "xp-simulated.html",
    "title": "13  Simulated Data",
    "section": "",
    "text": "13.1 Data Generating Process\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colA}{RGB}{255, 221, 85}\n\\definecolor{colB}{RGB}{148, 78, 223}\n\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colGpeZero}{RGB}{127, 23, 14}\n\\definecolor{colGpeUn}{RGB}{27, 149, 224}\n\\]\nWe load the functions that will allow us to build the counterfactuals (see Chapter 4), and some graphical themes for the plots (see [Chapter 3):\nWe simulate a dataset comprising a binary treatment indicator \\(A \\in \\{0,1\\}\\), a binary outcome \\(Y \\in \\{0,1\\}\\), and three covariates: two continuous variables \\(X_1, X_2 \\in \\mathbb{R}\\) and one categorical variable \\(X_3 \\in \\{\\text{A}, \\text{B}, \\text{C}\\}\\). For individuals with \\(A = 0\\), the vector \\((X_1, X_2)\\) is drawn from a bivariate normal distribution with mean vector \\(\\mu_0 = (-1, -1)\\) and covariance matrix \\(\\Sigma_0 = 1.2^2 \\begin{bmatrix} 1 & 0.5 \\\\ 0.5 & 1 \\end{bmatrix}\\). For those with \\(A = 1\\), the distribution shifts to mean \\(\\mu_1 = (1.5, 1.5)\\) and covariance \\(\\Sigma_1 = 0.9^2 \\begin{bmatrix} 1 & -0.4 \\\\ -0.4 & 1 \\end{bmatrix}\\). This leads to distinct location and dependence structures across treatment groups.\nThe categorical variable \\(X_3\\) is generated conditionally on \\(X_1, X_2\\), and \\(A\\) via a multinomial logistic model. Letting \\(p_{\\text{A}}, p_{\\text{B}}, p_{\\text{C}}\\) denote the unnormalized logit scores for each level of \\(X_3\\), we set:\n\\[\n\\begin{aligned}\np_{\\text{A}} &= 0.5 + 0.3 X_1 - 0.4 X_2 + 0.2 A, \\\\\np_{\\text{B}} &= -0.3 + 0.5 X_2 - 0.2 X_1 - 0.1 A, \\\\\np_{\\text{C}} &= 0,\n\\end{aligned}\n\\]\nwith the associated probabilities obtained via softmax normalization:\n\\[\nP(X_3 = k) = \\frac{\\exp(p_k)}{\\exp(p_{\\text{A}}) + \\exp(p_{\\text{B}}) + \\exp(p_{\\text{C}})}, \\quad \\text{for } k \\in \\{\\text{A}, \\text{B}, \\text{C}\\}.\n\\]\nThe binary outcome \\(Y\\) is modeled using a logistic regression, with functional forms differing across treatment groups. For \\(A = 0\\), the log-odds is defined as:\n\\[\n\\eta_0 = -0.2 + 0.6 X_1 - 0.6 X_2 + \\gamma(X_3),\n\\]\nand for \\(A = 1\\):\n\\[\n\\eta_1 = 0.1 - 0.2 X_1 + 0.8 X_2 + \\gamma(X_3),\n\\]\nwhere the contribution of \\(X_3\\) is encoded as:\n\\[\n\\gamma(X_3) =\n\\begin{cases}\n0.2 & \\text{if } X_3 = \\text{B}, \\\\\n-0.3 & \\text{if } X_3 = \\text{C}, \\\\\n0 & \\text{if } X_3 = \\text{A},\n\\end{cases}\n\\quad \\text{(for } A = 0\\text{)},\n\\]\nand similarly, for \\(A = 1\\):\n\\[\n\\gamma(X_3) =\n\\begin{cases}\n-0.2 & \\text{if } X_3 = \\text{B}, \\\\\n-0.1 & \\text{if } X_3 = \\text{C}, \\\\\n0 & \\text{if } X_3 = \\text{A}.\n\\end{cases}\n\\]\nThe outcome \\(Y\\) is then drawn from a Bernoulli distribution with success probability \\(P[Y = 1] = \\mathrm{logit}^{-1}(\\eta_A)\\).\nFor each observation, we additionally simulate a counterfactual covariate vector and outcome under the opposite treatment status. This includes drawing \\((X_1^{\\text{cf}}, X_2^{\\text{cf}})\\) from the treatment-specific bivariate normal distribution of the opposite group, computing the corresponding \\(X_3^{\\text{cf}}\\) using the same multinomial model (with \\(A\\) flipped), and evaluating \\(Y^{\\text{cf}}\\) via the appropriate counterfactual logit model.\nWe draw \\(n_0=400\\) observations in group 0 and \\(n_1=200\\) observations in group 1. We generate a function, gen_data() to generate data from this data generating process.\nThe gen_data() function.\ngen_data &lt;- function(seed) {\n  set.seed(seed)\n  n_0 &lt;- 400\n  n_1 &lt;- 200\n  \n  # X1 and X2 in both groups from sensitive-specific multivariate normal \n  # distributions\n  M_0 &lt;- c(-1, -1)\n  S_0 &lt;- matrix(c(1, .5, .5, 1) * 1.2^2, 2, 2)\n  M_1 &lt;- c(1.5, 1.5)\n  S_1 &lt;- matrix(c(1, -.4, -.4, 1) * 0.9^2, 2, 2)\n  X_0 &lt;- MASS::mvrnorm(n = n_0, mu = M_0, Sigma = S_0)\n  X_1 &lt;- MASS::mvrnorm(n = n_1, mu = M_1, Sigma = S_1)\n  \n  # Counterfactuals\n  X_0_cf &lt;- MASS::mvrnorm(n = n_0, mu = M_1, Sigma = S_1)\n  X_1_cf &lt;- MASS::mvrnorm(n = n_1, mu = M_0, Sigma = S_0)\n  \n  # X3: categorical, depends on S, X1, X3\n  scores &lt;- function(x1, x2, a) {\n    p_A &lt;- 0.5 + 0.3 * x1 - 0.4 * x2 + 0.2 * a\n    p_B &lt;- -0.3 + 0.5 * x2 - 0.2*x1 - 0.1 * a\n    p_C &lt;- 0\n    exps &lt;- exp(cbind(p_A, p_B, p_C))\n    prob &lt;- exps / rowSums(exps)\n    prob\n  }\n  \n  prob_X3_0 &lt;- scores(x1 = X_0[, 1], x2 = X_0[, 2], a = 0)\n  prob_X3_1 &lt;- scores(x1 = X_1[, 1], x2 = X_1[, 2], a = 1)\n  X3_0 &lt;- apply(prob_X3_0, 1, function(p) sample(c(\"A\", \"B\", \"C\"), 1, prob = p))\n  X3_1 &lt;- apply(prob_X3_1, 1, function(p) sample(c(\"A\", \"B\", \"C\"), 1, prob = p))\n  \n  # Counterfactuals\n  prob_X3_0_cf &lt;- scores(x1 = X_0_cf[, 1], x2 = X_0_cf[, 2], a = 1)\n  prob_X3_1_cf &lt;- scores(x1 = X_1_cf[, 1], x2 = X_1_cf[, 2], a = 0)\n  X3_0_cf &lt;- apply(prob_X3_0_cf, 1, function(p) sample(c(\"A\", \"B\", \"C\"), 1, prob = p))\n  X3_1_cf &lt;- apply(prob_X3_1_cf, 1, function(p) sample(c(\"A\", \"B\", \"C\"), 1, prob = p))\n  \n  \n  # Predictor for Y:\n  eta_0 &lt;- -0.2 + 0.6 * X_0[, 1] - 0.6 * X_0[, 2] + \n    ifelse(X3_0 == \"B\", 0.2, ifelse(X3_0 == \"C\", -0.3, 0))\n  eta_1 &lt;- 0.1 - 0.2 * X_1[, 1] + 0.8 * X_1[, 2] + \n    ifelse(X3_1 == \"B\", -0.2, ifelse(X3_1 == \"C\", -0.1, 0))\n  \n  p_0 &lt;- exp(eta_0) / (1 + exp(eta_0))\n  p_1 &lt;- exp(eta_1) / (1 + exp(eta_1))\n  \n  # Predictor for Y, counterfactuals\n  eta_0_cf &lt;- 0.1 - 0.2 * X_0_cf[, 1] + 0.8 * X_0_cf[, 2] + \n    ifelse(X3_0_cf == \"B\", -0.2, ifelse(X3_0_cf == \"C\", -0.1, 0))\n  \n  eta_1_cf &lt;- -0.2 + 0.6 * X_1_cf[, 1] - 0.6 * X_1_cf[, 2] + \n    ifelse(X3_1_cf == \"B\", 0.2, ifelse(X3_1_cf == \"C\", -0.3, 0))\n  \n  p_0_cf &lt;- exp(eta_0_cf) / (1 + exp(eta_0_cf))\n  p_1_cf &lt;- exp(eta_1_cf) / (1 + exp(eta_1_cf))\n  \n  \n  Y_0 &lt;- rbinom(n_0, size = 1, prob = p_0)\n  Y_1 &lt;- rbinom(n_1, size = 1, prob = p_1)\n  \n  Y_0_cf &lt;- rbinom(n_0, size = 1, prob = p_0_cf)\n  Y_1_cf &lt;- rbinom(n_1, size = 1, prob = p_1_cf)\n  \n  # Dataset with individuals in group 0 only\n  data_0 &lt;- tibble(\n    A = 0, \n    X1 = X_0[, 1], X2 = X_0[, 2], X3 = X3_0, Y = Y_0,\n    X1_cf = X_0_cf[, 1], X2_cf = X_0_cf[, 2], X3_cf = X3_0_cf, Y_cf = Y_0_cf,\n    eta = eta_0, p = p_0,\n    eta_cf = eta_0_cf, p_cf = p_0_cf\n  ) |&gt; \n    bind_cols(as_tibble(prob_X3_0) |&gt; rename_with(~ str_c(\"X3_\", .))) |&gt; \n    bind_cols(as_tibble(prob_X3_0_cf) |&gt; rename_with(~ str_c(\"X3_cf_\", .)))\n  # Dataset with individuals in group 1 only\n  data_1 &lt;- tibble(\n    A = 1, \n    X1 = X_1[, 1], X2 = X_1[, 2], X3 = X3_1, Y = Y_1,\n    X1_cf = X_1_cf[, 1], X2_cf = X_1_cf[, 2], X3_cf = X3_1_cf, Y_cf = Y_1_cf,\n    eta = eta_1,  p = p_1,\n    eta_cf = eta_1_cf, p_cf = p_1_cf\n  ) |&gt; \n    bind_cols(as_tibble(prob_X3_1) |&gt; rename_with(~ str_c(\"X3_\", .))) |&gt; \n    bind_cols(as_tibble(prob_X3_1_cf) |&gt; rename_with(~ str_c(\"X3_cf_\", .)))\n  # # Combine final dataset\n  data_all &lt;- rbind(data_0, data_1)\n  \n  data_all\n}\nLet us generate a dataset:\ntb &lt;- gen_data(2) |&gt; \n  mutate(across(where(is.character), ~as.factor(.x)))\nThe distribution of the true probabilities in group 0 and in group 1 are shown in Figure 13.1.\nCodes to create the Figure\nggplot(\n  data = tb |&gt; mutate(A = factor(A)) |&gt; dplyr::select(A, p, p_cf) |&gt; \n    pivot_longer(cols = c(p, p_cf), names_to = \"type\", values_to = \"p\") |&gt; \n    mutate(\n      type = factor(type, levels = c(\"p\", \"p_cf\"), labels = c(\"Obs.\", \"Counterfactual\")\n      )\n    ),\n  mapping = aes(x = p)\n) +\n  geom_histogram(\n    mapping = aes(fill = A), alpha = .5, colour = \"black\",\n    position = \"identity\", bins = 30\n  ) +\n  facet_wrap(~type) +\n  scale_fill_manual(values = c(\"0\" = colours[[\"0\"]], \"1\" = colours[[\"1\"]])) +\n  theme_paper()\n\n\n\n\n\nFigure 13.1: Distribution of the true probability of the outcome across groups for the untreated and the treated, for observed values (left) and unobserved values (right).",
    "crumbs": [
      "V. Experiments",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Simulated Data</span>"
    ]
  },
  {
    "objectID": "xp-simulated.html#counterfactuals",
    "href": "xp-simulated.html#counterfactuals",
    "title": "13  Simulated Data",
    "section": "13.2 Counterfactuals",
    "text": "13.2 Counterfactuals\nWe assume a structural model as shown in Figure 13.2.\n\nvariables &lt;- c(\"A\", \"X1\", \"X2\", \"X3\", \"Y\")\n\nadj &lt;- matrix(\n  # A  X1 X2 X3 Y\n  c(0, 1, 1, 1, 1,# A\n    0, 0, 1, 1, 1,# X1\n    0, 0, 0, 1, 1,# X2\n    0, 0, 0, 0, 1,# X3\n    0, 0, 0, 0, 0  # Y\n  ),\n  ncol = length(variables),\n  dimnames = rep(list(variables), 2),\n  byrow = TRUE\n)\n\ncausal_graph &lt;- fairadapt::graphModel(adj)\nplot(causal_graph)\n\n\n\n\nFigure 13.2: Asumed Causal Structure\n\n\n\n\n\n\n\n\nLet us follow this DAG and build the counterfactuals of untreated: we thus transport individuals from \\(A=0\\) to \\(A=1\\). Let us set a seed for reproducibility.\n\nseed &lt;- 1234\nset.seed(seed)\n\nWe call the seq_trans() function (see Chapter 4) function to build the counterfactuals of untreated units. The estimations are done using parallel computation.\n\nA_name &lt;- \"A\" # treatment name\nY_name &lt;- \"Y\" # outcome name\nA_untreated &lt;- 0\nA &lt;- tb[[A_name]]\nind_untreated &lt;- which(A == A_untreated)\ntb_estim &lt;- tb |&gt; dplyr::select(A, X1, X2, X3, Y)\ntb_untreated &lt;- tb_estim[ind_untreated, ]\ntb_treated &lt;- tb_estim[-ind_untreated, ]\n\nLet us follow the DAG from Figure 13.2 and build the counterfactuals of units from group 0: we thus transport individuals from \\(A=0\\) to \\(A=1\\), using the predictions on the test set.\n\n13.2.1 Multivariate Optimal Transport\nWe apply multivariate optimal transport (OT), following the methodology developed in De Lara et al. (2024).\n\ntb_untreated_wo_A &lt;- tb_untreated[ , !(names(tb_untreated) %in% A_name)]\ntb_treated_wo_A &lt;- tb_treated[ , !(names(tb_treated) %in% A_name)]\nn0 &lt;- nrow(tb_untreated_wo_A)\nn1 &lt;- nrow(tb_treated_wo_A)\ny0 &lt;- tb_untreated_wo_A[[Y_name]]\ny1 &lt;- tb_treated_wo_A[[Y_name]]\nX0 &lt;- tb_untreated_wo_A[ , !(names(tb_untreated_wo_A) %in% Y_name)]\nX1 &lt;- tb_treated_wo_A[ , !(names(tb_treated_wo_A) %in% Y_name)]\n\nTo apply Optimal Transport on the dataset, we first need to one-hot the categorical variable.\n\nnum_cols &lt;- names(X0)[sapply(X0, is.numeric)]\ncat_cols &lt;- names(X0)[sapply(X0, function(col) is.factor(col) || is.character(col))]\nX0_num &lt;- X0[ , num_cols]\nX1_num &lt;- X1[ , num_cols]\nX0_cat &lt;- X0[ , cat_cols]\nX1_cat &lt;- X1[ , cat_cols]\n\ncat_counts &lt;- sapply(X0[ , cat_cols], function(col) length(unique(col)))\n\nCategorical variables are one-hot encoded:\n\nlibrary(caret)\n\nLoading required package: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nX0_cat_encoded &lt;- list()\nX1_cat_encoded &lt;- list()\nfor (col in cat_cols) {\n  # One-hot encoding with dummyVars\n  formula &lt;- as.formula(paste(\"~\", col))\n  dummies &lt;- caret::dummyVars(formula, data = X0_cat)\n  \n  # Dummy variable\n  dummy_0 &lt;- predict(dummies, newdata = X0_cat) |&gt; as.data.frame()\n  dummy_1 &lt;- predict(dummies, newdata = X1_cat) |&gt; as.data.frame()\n  \n  # Scaling\n  dummy_0_scaled &lt;- scale(dummy_0)\n  dummy_1_scaled &lt;- scale(dummy_1)\n\n  dummy_0_df &lt;- as.data.frame(dummy_0_scaled)\n  dummy_1_df &lt;- as.data.frame(dummy_1_scaled)\n  \n  # Aling categories in both treated/untreated groups\n  all_cols &lt;- union(colnames(dummy_0_df), colnames(dummy_1_df))\n  dummy_0_df &lt;- dummy_0_df |&gt;\n    mutate(across(everything(), .fns = identity)) |&gt;\n    dplyr::select(all_of(all_cols)) |&gt;\n    mutate(across(everything(), ~replace_na(.x, 0)))\n  dummy_1_df &lt;- dummy_1_df |&gt;\n    mutate(across(everything(), .fns = identity)) |&gt;\n    dplyr::select(all_of(all_cols)) |&gt;\n    mutate(across(everything(), ~replace_na(.x, 0)))\n\n  X0_cat_encoded[[col]] &lt;- dummy_0_df\n  X1_cat_encoded[[col]] &lt;- dummy_1_df\n}\n\nWe calculate Euclidean distance for numerical variables.\n\n# library(proxy)\nnum_dist &lt;- proxy::dist(x = X0_num, y = X1_num, method = \"Euclidean\")\nnum_dist &lt;- as.matrix(num_dist)\n\nFor categorical variables, we use the Hamming distance.\n\ncat_dists &lt;- list()\nfor (col in cat_cols) {\n  mat_0 &lt;- as.matrix(X0_cat_encoded[[col]])\n  mat_1 &lt;- as.matrix(X1_cat_encoded[[col]])\n  dist_mat &lt;- proxy::dist(x = mat_0, y = mat_1, method = \"Euclidean\")\n  cat_dists[[col]] &lt;- as.matrix(dist_mat)\n}\n\nThen we need to combine the two distance matrices. We use weights equal to the proportion of numerical variables and the proportion of categorical variables, respectively for distances based on numerical and categorical variables.\n\ncombined_cost &lt;- num_dist\nfor (i in seq_along(cat_dists)) {\n  combined_cost &lt;- combined_cost + cat_dists[[i]]\n}\n\nThen, we can compute the transport map:\n\n# Uniform weights (equal mass)\nw0 &lt;- rep(1 / n0, n0)\nw1 &lt;- rep(1 / n1, n1)\n# Compute transport plan\ntransport_res &lt;- transport::transport(\n  a = w0,\n  b = w1,\n  costm = combined_cost,\n  method = \"shortsimplex\"\n)\n\nInitial solution based on shortlist is degenerate. Adding 199 basis vector(s)... done.\n\ntransport_plan &lt;- matrix(0, nrow = n0, ncol = n1)\nfor(i in seq_len(nrow(transport_res))) {\n  transport_plan[transport_res$from[i], transport_res$to[i]] &lt;- transport_res$mass[i]\n}\n\nWe first transport the numerical variables.\n\nnum_transported &lt;- n0 * (transport_plan %*% as.matrix(X1_num))\n\nThen, we transport the categorical variables with label reconstruction (not perfect here).\n\ncat_transported &lt;- list()\nfor (col in cat_cols) {\n  cat_probs &lt;- transport_plan %*% as.matrix(X1_cat_encoded[[col]])\n  cat_encoded_columns &lt;- colnames(X1_cat_encoded[[col]])\n  # For each obs., we take the index with the maximum value (approx. proba)\n  max_indices &lt;- apply(cat_probs, 1, which.max)\n  prefix_pattern &lt;- paste0(\"^\", col, \"\\\\.\")\n  cat_transported[[col]] &lt;- sapply(\n    max_indices, \n    function(x) sub(prefix_pattern, \"\", cat_encoded_columns[x])\n  )\n}\n\nWe can now store the results into a tibble.\n\ntb_ot_transported &lt;- as_tibble(num_transported)\nfor (col in cat_cols) {\n  tb_ot_transported[[col]] &lt;- cat_transported[[col]]\n}\n\nsave(tb_ot_transported, file = \"../output/ot-synthetic.rda\")\n\n\n# Load tb_ot_transported\nload(\"../output/ot-synthetic.rda\")\ntb_ot_transported &lt;- tb_ot_transported |&gt;\n  mutate(X3 = as.factor(X3))\ntb_ot_transported &lt;- as.list(tb_ot_transported)\n\nWe can also use the function optimal_transport_cf() with default parameters (i.e., without any regularization).\n\n\n13.2.2 Penalized Optimal Transport\nWe can directly compute the transport map using Sinkhorn penalty. Let us set the regularization parameter, \\(\\gamma=0.1\\).\n\n# Compute transport plan\nsinkhorn_transport_res &lt;- T4transport::sinkhornD(\n  combined_cost, wx = w0, wy = w1, lambda = 0.1\n)\n\nsinkhorn_transport_plan &lt;- sinkhorn_transport_res$plan\n\nWe first transport the numerical variables.\n\nnum_sinkhorn_transported &lt;- n0 * (sinkhorn_transport_plan %*% as.matrix(X1_num))\n\nThen, we transport the categorical variables with label reconstruction (not perfect here).\n\ncat_sinkhorn_transported &lt;- list()\nfor (col in cat_cols) {\n  cat_probs &lt;- sinkhorn_transport_plan %*% as.matrix(X1_cat_encoded[[col]])\n  cat_encoded_columns &lt;- colnames(X1_cat_encoded[[col]])\n  # For each obs., we take the index with the maximum value (approx. proba)\n  max_indices &lt;- apply(cat_probs, 1, which.max)\n  prefix_pattern &lt;- paste0(\"^\", col, \"\\\\.\")\n  cat_sinkhorn_transported[[col]] &lt;- sapply(\n    max_indices, \n    function(x) sub(prefix_pattern, \"\", cat_encoded_columns[x])\n  )\n}\n\nWe can now store the results into a tibble.\n\ntb_sinkhorn_transported &lt;- as_tibble(num_sinkhorn_transported)\nfor (col in cat_cols) {\n  tb_sinkhorn_transported[[col]] &lt;- cat_sinkhorn_transported[[col]]\n}\n\nsave(tb_sinkhorn_transported, file = \"../output/sinkhorn-synthetic.rda\")\n\n\n# Load tb_sinkhorn_transported\nload(\"../output/sinkhorn-synthetic.rda\")\ntb_sinkhorn_transported &lt;- tb_sinkhorn_transported |&gt;\n  mutate(X3 = as.factor(X3))\ntb_sinkhorn_transported &lt;- as.list(tb_sinkhorn_transported)\n\nWe can also use the function optimal_transport_cf() but this time we need to indicate a value for the parameter pen to apply Sinkhorn regularization.\n\n\n13.2.3 Sequential Transport\n\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nsocket cluster with 9 nodes on host 'localhost'\n\nclusterEvalQ(cl, {\n  library(transportsimplex)\n  source(\"../scripts/functions.R\")\n}) |&gt;\n  invisible()\n\nsequential_transport &lt;- seq_trans(\n  data = tb_estim, \n  adj = adj, \n  s = A_name, \n  S_0 = 0, # source: untreated\n  y = Y_name, \n  num_neighbors = 50, \n  num_neighbors_q = NULL,\n  silent = FALSE,\n  method = \"shortsimplex\",\n  cl = cl\n)\n\nTransporting  X1 \nTransporting  X2 \nTransporting  X3 \nInitial solution based on shortlist is degenerate. Adding 2 basis vector(s)... done.\n\nsave(sequential_transport, file = \"../output/seq-t-synthetic.rda\")\n\nstopCluster(cl)\n\nLet us load the results of the estimation:\n\nload(\"../output/seq-t-synthetic.rda\")",
    "crumbs": [
      "V. Experiments",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Simulated Data</span>"
    ]
  },
  {
    "objectID": "xp-simulated.html#measuring-the-causal-effect",
    "href": "xp-simulated.html#measuring-the-causal-effect",
    "title": "13  Simulated Data",
    "section": "13.3 Measuring the Causal Effect",
    "text": "13.3 Measuring the Causal Effect\n\n13.3.1 With Causal Mediation Analysis\nLet us use the multimed() function from {mediation} to estimate the direct effect: - A -&gt; Y, and the different indirect effects: - A -&gt; X1 -&gt; Y, - A -&gt; X2 -&gt; Y, - A -&gt; X3 -&gt; Y, - A -&gt; X1 -&gt; X2 -&gt; Y, - A -&gt; X1 -&gt; X3 -&gt; Y, - A -&gt; X2 -&gt; X3 -&gt; Y, - A -&gt; X1 -&gt; X2 -&gt; X3 -&gt; Y.\n\n# library(mediation) # we do not load it\n# otherwise it masks a lot of useful functions\n\n# We encode the categorical variable as for optimal transport\ntb_med &lt;- tb_estim |&gt; \n  mutate(\n    X3 = case_when(\n      X3 == \"A\" ~ 0,\n      X3 == \"B\" ~ 1,\n      X3 == \"C\" ~ 2\n    )\n  )\n\nmed_mod_X1 &lt;- mediation::multimed(\n  outcome = \"Y\", \n  med.main = \"X1\", \n  med.alt = c(\"X2\", \"X3\"), \n  treat = \"A\", \n  data = tb_med\n)\n# Indirect effect for X1: A -&gt; X1 -&gt; Y\ndelta_0_med_X1 &lt;- mean((med_mod_X1$d0.lb + med_mod_X1$d0.ub) / 2)\n# Direct + Other indirect effects: A -&gt; Y, A -&gt; X2 -&gt; Y, A -&gt; X3 -&gt; Y, \n# A -&gt; X1 -&gt; X2 -&gt; Y, A -&gt; X2 -&gt; X3 -&gt; Y, A -&gt; X1 -&gt; X3 -&gt; Y, A -&gt; X1 -&gt; X2 -&gt; X3 -&gt; Y\nzeta_1_med_X1 &lt;- mean((med_mod_X1$z1.lb + med_mod_X1$z1.ub) / 2)\n# Total effect\ntot_effect_med_X1 &lt;- delta_0_med_X1 + zeta_1_med_X1\n\nmed_mod_X2 &lt;- mediation::multimed(\n  outcome = \"Y\", \n  med.main = \"X2\", \n  med.alt = c(\"X1\", \"X3\"), \n  treat = \"A\", \n  data = tb_med\n)\n# Indirect effect for X2: A -&gt; X2 -&gt; Y, A -&gt; X1 -&gt; X2 -&gt; Y\ndelta_0_med_X2 &lt;- mean((med_mod_X2$d0.lb + med_mod_X2$d0.ub) / 2)\n# Direct + Other indirect effects: A -&gt; Y, A -&gt; X1 -&gt; Y, A -&gt; X3 -&gt; Y, \n# A -&gt; X1 -&gt; X3 -&gt; Y, A -&gt; X2 -&gt; X3 -&gt; Y, A -&gt; X1 -&gt; X2 -&gt; X3\nzeta_1_med_X2 &lt;- mean((med_mod_X2$z1.lb + med_mod_X2$z1.ub) / 2)\n# Total effect\ntot_effect_med_X2 &lt;- delta_0_med_X2 + zeta_1_med_X2\n\nmed_mod_X3 &lt;- mediation::multimed(\n  outcome = \"Y\", \n  med.main = \"X3\", \n  med.alt = c(\"X1\", \"X2\"), \n  treat = \"A\", \n  data = tb_med\n)\n# Indirect effect for ccd: A -&gt; X3 -&gt; Y, A -&gt; X1 -&gt; X3 -&gt; Y, A -&gt; X2 -&gt; X3 -&gt; Y,\n# A -&gt; X1 -&gt; X2 -&gt; X3 -&gt; Y\ndelta_0_med_X3 &lt;- mean((med_mod_X3$d0.lb + med_mod_X3$d0.ub) / 2)\n# Direct + Other indirect effects: A -&gt; Y, A -&gt; X1 -&gt; Y, A -&gt; X2 -&gt; Y, \n# A -&gt; X1 -&gt; X2 -&gt; Y\nzeta_1_med_X3 &lt;- mean((med_mod_X3$z1.lb + med_mod_X3$z1.ub) / 2)\n# Total effect\ntot_effect_med_X3 &lt;- delta_0_med_X3 + zeta_1_med_X3\n\nThe estimated values:\n\n# Total effect\ntot_effect_med &lt;- tot_effect_med_X1\n# Indirect effects\ndelta_0_med &lt;- delta_0_med_X1 + delta_0_med_X2 + delta_0_med_X3\n# Direct effect \nzeta_1_med &lt;- tot_effect_med - delta_0_med\ncbind(delta_0 = delta_0_med, zeta_1 = zeta_1_med, tot_effect = tot_effect_med)\n\n      delta_0   zeta_1 tot_effect\n[1,] 0.101747 0.203253      0.305\n\n\n\n\n13.3.2 With Optimal Transport\n\nlibrary(randomForest)\n\nWe use a random forest to estimate the outcome model (see causal_effects_cf() in Chapter 4).\n\ncausal_effects_ot &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(tb_ot_transported), \n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated # 0\n)\n\ncbind(\n  delta_0 = causal_effects_ot$delta_0,\n  zeta_1 = causal_effects_ot$zeta_1, \n  tot_effect = causal_effects_ot$tot_effect\n)\n\n       delta_0    zeta_1 tot_effect\n[1,] 0.1075145 0.1952067  0.3027212\n\n\n\n\n13.3.3 With Penalized Optimal Transport\n\ncausal_effects_sink_ot &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(tb_sinkhorn_transported), \n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated # 0\n)\n\ncbind(\n  delta_0 = causal_effects_sink_ot$delta_0,\n  zeta_1 = causal_effects_sink_ot$zeta_1, \n  tot_effect = causal_effects_sink_ot$tot_effect\n)\n\n       delta_0  zeta_1 tot_effect\n[1,] 0.1004735 0.20018  0.3006535\n\n\n\n\n13.3.4 With Sequential Transport\n\ncausal_effects_st &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(sequential_transport$transported), \n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated\n)\n\ncbind(\n  delta_0 = causal_effects_st$delta_0,\n  zeta_1 = causal_effects_st$zeta_1, \n  tot_effect = causal_effects_st$tot_effect\n)\n\n        delta_0    zeta_1 tot_effect\n[1,] 0.08792841 0.2101339  0.2980623\n\n\nLet us visualize the distribution on the individuals effects for each transport-based method, in Figure 14.2 (frequency on the y-axis).\n\n\nCodes to create the Figure.\nlibrary(tikzDevice)\nsource(\"../scripts/utils.R\")\n\nplot_hist_effects &lt;- function(x, \n                              var_name, \n                              tikz = FALSE,\n                              fill = \"red\",\n                              printed_method = \"\",\n                              x_lim = NULL,\n                              print_main = TRUE,\n                              print_x_axis = TRUE) {\n  if (print_main == TRUE) {\n    name_effect &lt;- case_when(\n      str_detect(var_name, \"^delta_0\") ~ \"$\\\\delta_i(0)$\",\n      str_detect(var_name, \"^zeta_1\") ~ \"$\\\\zeta_i(1)$\",\n      str_detect(var_name, \"^tot_effect\") ~ \"$\\\\tau_i(1)$\",\n      TRUE ~ \"other\"\n    )\n    if (tikz == FALSE) name_effect &lt;- latex2exp::TeX(name_effect)\n  } else {\n    name_effect &lt;- \"\"\n  }\n  \n  \n  if (var_name == \"tot_effect\") {\n    data_plot &lt;- x[[\"delta_0_i\"]] + x[[\"zeta_1_i\"]]\n  } else {\n    data_plot &lt;- x[[var_name]]\n  }\n  \n  if (is.null(x_lim)) {\n    hist(\n      data_plot, \n      main = \"\", xlab = \"\", ylab = \"\", family = font_family,\n      col = fill, axes = FALSE\n    )\n  } else {\n    hist(\n      data_plot, \n      main = \"\", xlab = \"\", ylab = \"\", family = font_family,\n      col = fill, xlim = x_lim, axes = FALSE\n    )\n  }\n  \n  if (print_x_axis) axis(1, family = font_family)\n  axis(2, family = font_family)\n  \n  title(\n    main = name_effect, cex.main = 1, family = font_family\n  )\n  \n  if (printed_method != \"\") {\n    title(\n      ylab = printed_method, line = 2, \n      cex.lab = 1, family = font_family\n    )\n  }\n  abline(v = mean(data_plot), col = \"darkred\", lty = 2, lwd = 2)\n}\n\ncolour_methods &lt;- c(\n  # \"OT\" = \"#CC79A7\",\n  \"OT-M\" = \"#009E73\",\n  \"skh\" = \"darkgray\",\n  \"seq_1\" = \"#0072B2\", \n  \"seq_2\" = \"#D55E00\"\n)\n\nexport_tikz &lt;- FALSE\n\n\nfile_name &lt;- \"xp-simulated-indiv-effects\"\nwidth_tikz &lt;- 2.3\nheight_tikz &lt;- 1.7\nif (export_tikz == TRUE)\n  tikz(paste0(\"figs/\", file_name, \".tex\"), width = width_tikz, height = height_tikz)\n\nlayout(\n  matrix(1:9, byrow = TRUE, ncol = 3),\n  widths = c(1, rep(.9, 2)), heights = c(1, rep(.72, 2))\n)\n\nfor (i in 1:3) {\n  x &lt;- case_when(\n    i == 1 ~ causal_effects_ot,\n    i == 2 ~ causal_effects_sink_ot,\n    i == 3 ~ causal_effects_st\n  )\n  method &lt;- case_when(\n    i == 1 ~ \"OT-M\",\n    i == 2 ~ \"SKH\",\n    i == 3 ~ \"ST\"\n  )\n  \n  for (var_name in c(\"delta_0_i\", \"zeta_1_i\", \"tot_effect\")) {\n    mar_bottom &lt;- ifelse(i == 3, 2.1, .6)\n    mar_left &lt;- ifelse(var_name == \"delta_0_i\", 3.1, 2.1)\n    mar_top &lt;- ifelse(i == 1, 2.1, .1)\n    mar_right &lt;- .4\n    printed_method &lt;- ifelse(var_name == \"delta_0_i\", method, \"\")\n    \n    par(mar = c(mar_bottom, mar_left, mar_top, mar_right))\n    x_lim_list &lt;- list(\n      \"delta_0_i\" = c(-.6, .6),\n      \"zeta_1_i\" = c(-.6, .6),\n      \"tot_effect\" = c(-1, 1)\n    )\n    \n    plot_hist_effects(\n      x = x, var_name = var_name, tikz = export_tikz, \n      fill = colour_methods[i],\n      printed_method = printed_method, \n      x_lim = x_lim_list[[var_name]],\n      print_main = i == 1,\n      print_x_axis = i == 3\n    )\n  }\n}\n\n\nif (export_tikz == TRUE) {\n  dev.off()\n  plot_to_pdf(\n    filename = file_name, \n    path = \"./figs/\", keep_tex = FALSE, crop = T\n  )\n}\n\n\n\n\n\nFigure 13.3: Distribution of individual direct effect (\\(\\delta_i(0)\\)), indirect effect (\\(\\zeta_i(0)\\)), and total causal effect (\\(\\tau_i\\)) estimated with transport-based counterfactuals with optimal transport (OT-M), penalized transport (SKH), and sequential transport (ST).",
    "crumbs": [
      "V. Experiments",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Simulated Data</span>"
    ]
  },
  {
    "objectID": "xp-simulated.html#monte-carlo-experiment",
    "href": "xp-simulated.html#monte-carlo-experiment",
    "title": "13  Simulated Data",
    "section": "13.4 Monte-Carlo Experiment",
    "text": "13.4 Monte-Carlo Experiment\nWe run Monte-Carlo simulations to reproduce the previous steps. In each of the 200 iteration, we draw some data according to the DGP presented in Section 13.1. Then, we use the seq_trans() function (see Chapter 4) to perform sequential conditional transport to transport individuals from the untreated group (\\(A=0\\)) to the treated group (\\(A=1\\)). We also use OT and penalized OT.\nWe set the seeds for each replication and we define placeholders.\n\nseeds &lt;- 1:200\nres_simul_opt_trans &lt;- vector(mode = \"list\", length = length(seeds))\nres_simul_sink_trans &lt;- vector(mode = \"list\", length = length(seeds))\nres_simul_seq_trans &lt;- vector(mode = \"list\", length = length(seeds))\nres_simul_effects &lt;- vector(mode = \"list\", length = length(seeds))\n\n\n# This chunk is not evaluated. \n# The results from previously run simulations are loaded after this chunk.\n# Each of the 200 replications takes about 9 seconds per run on a MB Pro with\n# a Apple M2 Pro chip and 32GB RAM.\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(transportsimplex)\n  source(\"../scripts/functions.R\")\n}) |&gt;\n  invisible()\n\nfor (i in 1:length(seeds)) {\n  cat(paste0(\"Simulation \", i, \"/\", length(seeds), \"\\n\"))\n  seed &lt;- seeds[i]\n  tb_all &lt;- gen_data(seed)\n  tb &lt;- tb_all |&gt; select(A, X1, X2, X3, Y) |&gt; \n    mutate(across(where(is.character), ~as.factor(.x)))\n  \n  A_name &lt;- \"A\"\n  A_untreated &lt;- 0\n  Y_name &lt;- \"Y\"\n  \n  # Optimal Transport\n  tb_ot_transported &lt;- optimal_transport_cf(\n    tb,\n    Y_name,\n    A_name,\n    A_untreated\n  )\n  tb_ot_transported &lt;- tb_ot_transported |&gt;\n    mutate(X3 = as.factor(X3))\n  tb_ot_transported &lt;- as.list(tb_ot_transported)\n  res_simul_opt_trans[[i]] &lt;- tb_ot_transported\n  \n  # Penalized (0.1) Optimal Transport with Sinkhorn\n  tb_sinkhorn_transported &lt;- optimal_transport_cf(\n    tb,\n    Y_name,\n    A_name,\n    A_untreated,\n    pen = 0.1\n  )\n  tb_sinkhorn_transported &lt;- tb_sinkhorn_transported |&gt;\n    mutate(X3 = as.factor(X3))\n  tb_sinkhorn_transported &lt;- as.list(tb_sinkhorn_transported)\n  res_simul_sink_trans[[i]] &lt;- tb_sinkhorn_transported\n  \n  # Sequential Transport                                        \n  sequential_transport &lt;- seq_trans(\n    data = tb, \n    adj = adj, \n    s = A_name, \n    S_0 = 0, # source: untreated\n    y = Y_name, \n    num_neighbors = 50, \n    num_neighbors_q = NULL,\n    silent = FALSE,\n    cl = cl\n  )\n  res_simul_seq_trans[[i]] &lt;- sequential_transport$transported\n  \n  tb_untreated &lt;- tb |&gt; filter(!!sym(A_name) == !!A_untreated)\n  tb_treated &lt;- tb |&gt; filter(!!sym(A_name) != !!A_untreated)\n  \n  n_untreated &lt;- nrow(tb_untreated)\n  n_treated &lt;- nrow(tb_treated)\n  \n  ## Measuring Causal Effect----\n  \n  # With Causal Mediation Analysis\n  tb_med &lt;- tb |&gt; \n    mutate(\n      X3 = case_when(\n        X3 == \"A\" ~ 0,\n        X3 == \"B\" ~ 1,\n        X3 == \"C\" ~ 2\n      )\n    )\n  \n  med_mod_X1 &lt;- mediation::multimed(\n    outcome = \"Y\", \n    med.main = \"X1\", \n    med.alt = c(\"X2\", \"X3\"), \n    treat = \"A\", \n    data = tb_med\n  )\n  delta_0_med_X1 &lt;- mean((med_mod_X1$d0.lb + med_mod_X1$d0.ub) / 2)\n  zeta_1_med_X1 &lt;- mean((med_mod_X1$z1.lb + med_mod_X1$z1.ub) / 2)\n  tot_effect_med_X1 &lt;- delta_0_med_X1 + zeta_1_med_X1\n  \n  med_mod_X2 &lt;- mediation::multimed(\n    outcome = \"Y\", \n    med.main = \"X2\", \n    med.alt = c(\"X1\", \"X3\"), \n    treat = \"A\", \n    data = tb_med\n  )\n  delta_0_med_X2 &lt;- mean((med_mod_X2$d0.lb + med_mod_X2$d0.ub) / 2)\n  zeta_1_med_X2 &lt;- mean((med_mod_X2$z1.lb + med_mod_X2$z1.ub) / 2)\n  tot_effect_med_X2 &lt;- delta_0_med_X2 + zeta_1_med_X2\n  \n  med_mod_X3 &lt;- mediation::multimed(\n    outcome = \"Y\", \n    med.main = \"X3\", \n    med.alt = c(\"X1\", \"X2\"), \n    treat = \"A\", \n    data = tb_med\n  )\n  delta_0_med_X3 &lt;- mean((med_mod_X3$d0.lb + med_mod_X3$d0.ub) / 2)\n  zeta_1_med_X3 &lt;- mean((med_mod_X3$z1.lb + med_mod_X3$z1.ub) / 2)\n  tot_effect_med_X3 &lt;- delta_0_med_X3 + zeta_1_med_X3\n  # Summary of the causal effects\n  tot_effect_med &lt;- tot_effect_med_X1\n  delta_0_med &lt;- delta_0_med_X1 + delta_0_med_X2 + delta_0_med_X3\n  zeta_1_med &lt;- tot_effect_med - delta_0_med\n  \n  # With Counterfactual Values\n  ## Optimal Transport\n  causal_effects_ot &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(tb_ot_transported), \n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  ## Sinkhorn Optimal Transport\n  causal_effects_sink_ot &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(tb_sinkhorn_transported), \n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  ## Sequential Transport\n  causal_effects_st &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(sequential_transport$transported), \n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  \n  res_simul_effects[[i]] &lt;- tibble(\n    seed = seed,\n    delta_0_med = delta_0_med, \n    zeta_1_med = zeta_1_med, \n    tot_effect_med = tot_effect_med,\n    delta_0_ot = causal_effects_ot$delta_0,\n    zeta_1_ot = causal_effects_ot$zeta_1, \n    tot_effect_ot = causal_effects_ot$tot_effect,\n    delta_0_sink_ot = causal_effects_sink_ot$delta_0,\n    zeta_1_sink_ot = causal_effects_sink_ot$zeta_1, \n    tot_effect_sink_ot = causal_effects_sink_ot$tot_effect,\n    delta_0_st = causal_effects_st$delta_0,\n    zeta_1_st = causal_effects_st$zeta_1, \n    tot_effect_st = causal_effects_st$tot_effect\n  )\n}\n\nsave(\n  res_simul_opt_trans, \n  res_simul_sink_trans, \n  res_simul_seq_trans, \n  res_simul_effects, \n  file = \"../output/res_simul.rda\"\n)\n\nstopCluster(cl)\n\nWe load previously run simulations:\n\nload(\"../output/res_simul.rda\")\n\nWe can look at the measures of causal effects.\n\ncausal_effects &lt;- list_rbind(res_simul_effects)\n\n\n\nCodes to create the Figure.\nlibrary(stringr)\nlibrary(tikzDevice)\nexport_pdf &lt;- FALSE\n\nlabels_strip &lt;- c(\n  \"$\\\\bar{\\\\delta}(0)$\",\n  \"$\\\\bar{\\\\zeta}(1)$\",\n  \"$\\\\bar{\\\\tau}$\"\n)\nif (export_pdf == FALSE) {\n  labels_strip = latex2exp::TeX(labels_strip)\n}\n\n\ndata_plot &lt;- causal_effects |&gt; \n  pivot_longer(\n    cols = -seed, \n    names_to = \"name\", values_to = \"tau\"\n  ) |&gt; \n  mutate(\n    type = case_when(\n      str_detect(name, \"^delta\") ~ \"delta\",\n      str_detect(name, \"^zeta\") ~ \"zeta\",\n      str_detect(name, \"^tot_effect\") ~ \"tot_effect\",\n      TRUE ~ NA_character_\n    ),\n    type = factor(\n      type, \n      levels = c(\"delta\", \"zeta\", \"tot_effect\"),\n      labels = labels_strip\n    ),\n    Method = case_when(\n      str_detect(name, \"_med$\") ~ \"causal_med\",\n      str_detect(name, \"_st$\") ~ \"seq_ot\",\n      str_detect(name, \"_sink_ot$\") ~ \"sink_ot\",\n      str_detect(name, \"_ot$\") ~ \"ot\",\n      TRUE ~ NA_character_\n    ),\n    Method = factor(\n      Method,\n      levels = c(\n        \"seq_ot\", \"sink_ot\", \"ot\", \"causal_med\"\n      ),\n      labels = c(\"ST\", \"SKH\", \"OT-M\", \"CM\")\n    )\n  )\np &lt;- ggplot(\n  data = data_plot,\n  mapping = aes(x = tau, y = Method)\n) +\n  geom_violin(\n    #mapping = aes(x = value, y = method, fill = method),\n    mapping = aes(fill = Method),\n    draw_quantiles = c(.25, .5, .75)) +\n  labs(x = NULL, y = NULL)\n\nif (export_pdf == TRUE) {\n  p &lt;- p + \n    facet_wrap(\n      ~ type, scales = \"free_x\"\n    )\n} else {\n  p &lt;- p +\n    facet_wrap(\n      ~ type, scales = \"free_x\",\n      labeller = as_labeller(latex2exp::TeX, default = label_parsed)\n    )\n}\n\np &lt;- p +\n  scale_fill_manual(\n    NULL, \n    values = c(\n      \"CM\" = \"#56B4E9\",\n      \"OT-M\" = colour_methods[[\"OT-M\"]], \n      \"SKH\" = colour_methods[[\"skh\"]], \n      \"ST\" =  colour_methods[[\"seq_1\"]]\n    ),\n    guide = \"none\"\n  ) +\n  theme_paper()\n\np\n\nif (export_pdf == TRUE) {\n  ggplot2_to_pdf(\n    plot = p + theme(panel.spacing = unit(0.4, \"lines\")) +\n      scale_x_continuous(\n        labels = function(x) paste0(\"$\", x, \"$\"),\n        breaks = scales::pretty_breaks(n = 3)\n      ),\n    filename = \"xp-simulated-violin-mc\", path = \"figs/\", \n    width = 3.3, height = 1.3,\n    crop = TRUE\n  )\n  \n  system(paste0(\"pdfcrop figs/xp-simulated-violin-mc.pdf figs/xp-simulated-violin-mc.pdf\"))\n}\n\n\n\n\n\nFigure 13.4: Causal effects, 200 replications.\n\n\n\n\n\n\n\n\n\n\n\n\nDe Lara, Lucas, Alberto González-Sanz, Nicholas Asher, Laurent Risser, and Jean-Michel Loubes. 2024. “Transport-Based Counterfactual Models.” Journal of Machine Learning Research 25 (136): 1–59.",
    "crumbs": [
      "V. Experiments",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Simulated Data</span>"
    ]
  },
  {
    "objectID": "xp-compas.html",
    "href": "xp-compas.html",
    "title": "14  Compas",
    "section": "",
    "text": "14.1 Data\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colA}{RGB}{255, 221, 85}\n\\definecolor{colB}{RGB}{148, 78, 223}\n\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colGpeZero}{RGB}{127, 23, 14}\n\\definecolor{colGpeUn}{RGB}{27, 149, 224}\n\\]\nWe load the functions that will allow us to build the counterfactuals (see Chapter 4):\nWe load the COMPAS dataset that is available in the {mlr3fairness} package.\ndata(compas, package = \"mlr3fairness\")\nThe outcome variable is binary here: whether the defendant is rearrested at any time. The “treatment” \\(A\\) will be the sensitive attribute, race. We will consider a binary version of the race: Caucasian (whites, \\(A=1\\)) and African-American (Blacks, \\(A=0\\)). The idea is to build counterfactuals for Black people to ask questions such as “had this Black individual been white, what whould the prediction of an algorithm modeling recidivism be?”.\nTo train the predictive model of recidivism, we will use the following covariates: the age, the prior criminal records of defendants, and the charge degree (felony or misdemeanor).\ntb &lt;- compas |&gt; \n  as_tibble() |&gt; \n  filter(race %in% c(\"Caucasian\", \"African-American\")) |&gt;\n  select(\n    race, # sensitive\n    age, \n    priors_count, # The prior criminal records of defendants. \n    c_charge_degree, # F: Felony M: Misdemeanor\n    is_recid # outcome\n  ) |&gt; \n  mutate(\n   race = ifelse(race == \"African-American\", 0, 1), # African-American as \"untreated\"\n   is_recid = ifelse(is_recid == 0, 0, 1)\n  )\ndim(tb)\n\n[1] 5278    5\n\nsummary(tb)\n\n      race             age         priors_count    c_charge_degree\n Min.   :0.0000   Min.   :18.00   Min.   : 0.000   F:3440         \n 1st Qu.:0.0000   1st Qu.:25.00   1st Qu.: 0.000   M:1838         \n Median :0.0000   Median :31.00   Median : 2.000                  \n Mean   :0.3984   Mean   :34.45   Mean   : 3.462                  \n 3rd Qu.:1.0000   3rd Qu.:42.00   3rd Qu.: 5.000                  \n Max.   :1.0000   Max.   :80.00   Max.   :38.000                  \n    is_recid     \n Min.   :0.0000  \n 1st Qu.:0.0000  \n Median :1.0000  \n Mean   :0.5015  \n 3rd Qu.:1.0000  \n Max.   :1.0000\nWe assume the DAG shown in Figure 14.1.\nvariables &lt;- c(\"race\", \n               \"age\", \"priors_count\", \"c_charge_degree\", \n               \"is_recid\")\n# Row: outgoing arrow\nadj &lt;- matrix(\n  # S  1  2  3  Y\n  c(0, 1, 1, 1, 1,# S\n    0, 0, 1, 2, 1,# 1 (age)\n    0, 0, 0, 0, 1,# 2 (priors_count)\n    0, 0, 0, 0, 1,# 3 (c_charge_degree)\n    0, 0, 0, 0, 0 # Y\n  ),\n  ncol = length(variables),\n  dimnames = rep(list(variables), 2),\n  byrow = TRUE\n)\n\ncausal_graph &lt;- fairadapt::graphModel(adj)\nplot(causal_graph)\n\n\n\n\nFigure 14.1: Assumed structural model for the probability of recidivism.",
    "crumbs": [
      "V. Experiments",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Compas</span>"
    ]
  },
  {
    "objectID": "xp-compas.html#counterfactuals",
    "href": "xp-compas.html#counterfactuals",
    "title": "14  Compas",
    "section": "14.2 Counterfactuals",
    "text": "14.2 Counterfactuals\nLet us set a seed for reproducibility.\n\nseed &lt;- 1234\nset.seed(seed)\n\n\nA_name &lt;- \"race\" # treatment name\nY_name &lt;- \"is_recid\" # outcome name\nA_untreated &lt;- 0\nA &lt;- tb[[A_name]]\nind_untreated &lt;- which(A == A_untreated)\ntb_untreated &lt;- tb[ind_untreated, ]\ntb_treated &lt;- tb[-ind_untreated, ]\n\nLet us follow the DAG from Figure 14.1 and build the counterfactuals of Black individuals: we thus transport individuals from \\(A=0\\) to \\(A=1\\), using the predictions on the test set.\n\n14.2.1 Multivariate Optimal Transport\nWe apply multivariate optimal transport (OT), following the methodology developed in De Lara et al. (2024).\n\ntb_untreated_wo_A &lt;- tb_untreated[ , !(names(tb_untreated) %in% A_name)]\ntb_treated_wo_A &lt;- tb_treated[ , !(names(tb_treated) %in% A_name)]\nn0 &lt;- nrow(tb_untreated_wo_A)\nn1 &lt;- nrow(tb_treated_wo_A)\ny0 &lt;- tb_untreated_wo_A[[Y_name]]\ny1 &lt;- tb_treated_wo_A[[Y_name]]\nX0 &lt;- tb_untreated_wo_A[ , !(names(tb_untreated_wo_A) %in% Y_name)]\nX1 &lt;- tb_treated_wo_A[ , !(names(tb_treated_wo_A) %in% Y_name)]\n\nTo apply Optimal Transport on the COMPAS dataset, we first need to one-hot the categorical variables.\n\nnum_cols &lt;- names(X0)[sapply(X0, is.numeric)]\ncat_cols &lt;- names(X0)[sapply(X0, function(col) is.factor(col) || is.character(col))]\nX0_num &lt;- X0[ , num_cols]\nX1_num &lt;- X1[ , num_cols]\nX0_cat &lt;- X0[ , cat_cols]\nX1_cat &lt;- X1[ , cat_cols]\n\ncat_counts &lt;- sapply(X0[ , cat_cols], function(col) length(unique(col)))\n\nCategorical variables are one-hot encoded:\n\nlibrary(caret)\nX0_cat_encoded &lt;- list()\nX1_cat_encoded &lt;- list()\nfor (col in cat_cols) {\n  # One-hot encoding with dummyVars\n  formula &lt;- as.formula(paste(\"~\", col))\n  dummies &lt;- dummyVars(formula, data = X0_cat)\n  \n  # Dummy variable\n  dummy_0 &lt;- predict(dummies, newdata = X0_cat) %&gt;% as.data.frame()\n  dummy_1 &lt;- predict(dummies, newdata = X1_cat) %&gt;% as.data.frame()\n  \n  # Scaling\n  dummy_0_scaled &lt;- scale(dummy_0)\n  dummy_1_scaled &lt;- scale(dummy_1)\n\n  dummy_0_df &lt;- as.data.frame(dummy_0_scaled)\n  dummy_1_df &lt;- as.data.frame(dummy_1_scaled)\n  \n  # Aling categories in both treated/untreated groups\n  all_cols &lt;- union(colnames(dummy_0_df), colnames(dummy_1_df))\n  dummy_0_df &lt;- dummy_0_df %&gt;% mutate(across(.fns = identity)) %&gt;% select(all_of(all_cols)) %&gt;% replace(is.na(.), 0)\n  dummy_1_df &lt;- dummy_1_df %&gt;% mutate(across(.fns = identity)) %&gt;% select(all_of(all_cols)) %&gt;% replace(is.na(.), 0)\n  \n  # Sauvegarde dans les listes\n  X0_cat_encoded[[col]] &lt;- dummy_0_df\n  X1_cat_encoded[[col]] &lt;- dummy_1_df\n}\n\nWe calculate Euclidean distance for numerical variables.\n\n# library(proxy)\nnum_dist &lt;- proxy::dist(x = X0_num, y = X1_num, method = \"Euclidean\")\nnum_dist &lt;- as.matrix(num_dist)\n\nFor categorical variables, we use the Hamming distance.\n\ncat_dists &lt;- list()\nfor (col in cat_cols) {\n  mat_0 &lt;- as.matrix(X0_cat_encoded[[col]])\n  mat_1 &lt;- as.matrix(X1_cat_encoded[[col]])\n  dist_mat &lt;- proxy::dist(x = mat_0, y = mat_1, method = \"Euclidean\")\n  cat_dists[[col]] &lt;- as.matrix(dist_mat)\n}\n\nThen we need to combine the two distance matrices. We use weights equal to the proportion of numerical variables and the proportion of categorical variables, respectively for distances based on numerical and categorical variables.\n\ncombined_cost &lt;- num_dist\nfor (i in seq_along(cat_dists)) {\n  combined_cost &lt;- combined_cost + cat_dists[[i]]\n}\n\nThen, we can compute the transport map:\n\n# Uniform weights (equal mass)\nw0 &lt;- rep(1 / n0, n0)\nw1 &lt;- rep(1 / n1, n1)\n# Compute transport plan\ntransport_res &lt;- transport::transport(\n  a = w0,\n  b = w1,\n  costm = combined_cost,\n  method = \"shortsimplex\"\n)\n\ntransport_plan &lt;- matrix(0, nrow = n0, ncol = n1)\nfor(i in seq_len(nrow(transport_res))) {\n  transport_plan[transport_res$from[i], transport_res$to[i]] &lt;- transport_res$mass[i]\n}\n\nWe first transport the numerical variables.\n\nnum_transported &lt;- n0 * (transport_plan %*% as.matrix(X1_num))\n\nThen, we transport the categorical variables with label reconstruction (not perfect here).\n\ncat_transported &lt;- list()\nfor (col in cat_cols) {\n  cat_probs &lt;- transport_plan %*% as.matrix(X1_cat_encoded[[col]])\n  cat_encoded_columns &lt;- colnames(X1_cat_encoded[[col]])\n  # For each obs., we take the index with the maximum value (approx. proba)\n  max_indices &lt;- apply(cat_probs, 1, which.max)\n  prefix_pattern &lt;- paste0(\"^\", col, \"\\\\.\")\n  cat_transported[[col]] &lt;- sapply(max_indices, function(x) sub(prefix_pattern, \"\", cat_encoded_columns[x]))\n}\n\nWe can now store the results into a tibble.\n\ntb_ot_transported &lt;- as_tibble(num_transported)\nfor (col in cat_cols) {\n  tb_ot_transported[[col]] &lt;- cat_transported[[col]]\n}\n\nsave(tb_ot_transported, file = \"../output/ot-compas.rda\")\n\n\n# Load tb_ot_transported\nload(\"../output/ot-compas.rda\")\ntb_ot_transported &lt;- tb_ot_transported |&gt;\n  mutate(c_charge_degree = as.factor(c_charge_degree))\ntb_ot_transported &lt;- as.list(tb_ot_transported)\n\n\n\n14.2.2 Penalized Optimal Transport\nWe can directly compute the transport map using Sinkhorn penalty.\n\n# Compute transport plan\nsinkhorn_transport_res &lt;- T4transport::sinkhornD(\n  combined_cost, wx = w0, wy = w1, lambda = 0.1\n)\n\nsinkhorn_transport_plan &lt;- sinkhorn_transport_res$plan\n\nWe first transport the numerical variables.\n\nnum_sinkhorn_transported &lt;- n0 * (sinkhorn_transport_plan %*% as.matrix(X1_num))\n\nThen, we transport the categorical variables with label reconstruction (not perfect here).\n\ncat_sinkhorn_transported &lt;- list()\nfor (col in cat_cols) {\n  cat_probs &lt;- sinkhorn_transport_plan %*% as.matrix(X1_cat_encoded[[col]])\n  cat_encoded_columns &lt;- colnames(X1_cat_encoded[[col]])\n  # For each obs., we take the index with the maximum value (approx. proba)\n  max_indices &lt;- apply(cat_probs, 1, which.max)\n  prefix_pattern &lt;- paste0(\"^\", col, \"\\\\.\")\n  cat_sinkhorn_transported[[col]] &lt;- sapply(max_indices, function(x) sub(prefix_pattern, \"\", cat_encoded_columns[x]))\n}\n\nWe can now store the results into a tibble.\n\ntb_sinkhorn_transported &lt;- as_tibble(num_sinkhorn_transported)\nfor (col in cat_cols) {\n  tb_sinkhorn_transported[[col]] &lt;- cat_sinkhorn_transported[[col]]\n}\n\nsave(tb_sinkhorn_transported, file = \"../output/sinkhorn-compas.rda\")\n\n\n# Load tb_sinkhorn_transported\nload(\"../output/sinkhorn-compas.rda\")\ntb_sinkhorn_transported &lt;- tb_sinkhorn_transported |&gt;\n  mutate(c_charge_degree = as.factor(c_charge_degree))\ntb_sinkhorn_transported &lt;- as.list(tb_sinkhorn_transported)\n\n\n\n14.2.3 Sequential Transport\nWe call the seq_trans() function (see Chapter 4) function to build the counterfactuals of Black individuals. The estimations are done using parallel computation.\n\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nsocket cluster with 9 nodes on host 'localhost'\n\nclusterEvalQ(cl, {\n  library(transportsimplex)\n}) |&gt;\n  invisible()\n\n\nA_name &lt;- \"race\" # treatment name\nY_name &lt;- \"is_recid\" # outcome name\n\nsequential_transport &lt;- seq_trans(\n  data = tb, \n  adj = adj, \n  s = A_name, \n  S_0 = 0, # source: untreated\n  y = Y_name, \n  num_neighbors = 50, \n  num_neighbors_q = NULL,\n  silent = FALSE,\n  cl = cl\n)\n\nTransporting  age \nTransporting  priors_count \nTransporting  c_charge_degree \n\nsave(sequential_transport, file = \"../output/seq-t-compas.rda\")\n\nstopCluster(cl)\n\n\n# Load sequential_transport\nload(\"../output/seq-t-compas.rda\")",
    "crumbs": [
      "V. Experiments",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Compas</span>"
    ]
  },
  {
    "objectID": "xp-compas.html#measuring-the-causal-effect",
    "href": "xp-compas.html#measuring-the-causal-effect",
    "title": "14  Compas",
    "section": "14.3 Measuring the Causal Effect",
    "text": "14.3 Measuring the Causal Effect\n\n14.3.1 With Causal Mediation Analysis\nLet us use the multimed() function from {mediation} to estimate the direct effect: - race -&gt; is_recid (ir), and the different indirect effects: - race -&gt; age -&gt; is_recid, - race -&gt; priors_count (pc) -&gt; is_recid, - race -&gt; c_charge_degree (ccd) -&gt; is_recid, - race -&gt; age -&gt; priors_count -&gt; is_recid, - race -&gt; age -&gt; c_charge_degree -&gt; is_recid.\n\n# library(mediation) # we do not load it\n#  otherwise it masks a lot of useful functions\n\n# We encode the categorical variable as for optimal transport\ntb_med &lt;- tb |&gt; \n  mutate(\n    c_charge_degree = ifelse(c_charge_degree == \"F\", 0, 1)\n  )\n\nmed_mod_age &lt;- mediation::multimed(\n  outcome = \"is_recid\", \n  med.main = \"age\", \n  med.alt = c(\"priors_count\", \"c_charge_degree\"), \n  treat = \"race\", \n  data = tb_med\n)\n# Indirect effect for age: race -&gt; age -&gt; ir\ndelta_0_med_age &lt;- mean((med_mod_age$d0.lb + med_mod_age$d0.ub) / 2)\n# Direct + Other indirect effects: race -&gt; ir, race -&gt; pc -&gt; ir, race -&gt; ccd -&gt; ir, \n# race -&gt; age -&gt; pc -&gt; ir, race -&gt; age -&gt; ccd -&gt; ir\nzeta_1_med_age &lt;- mean((med_mod_age$z1.lb + med_mod_age$z1.ub) / 2)\n# Total effect\ntot_effect_med_age &lt;- delta_0_med_age + zeta_1_med_age\n\nmed_mod_pc &lt;- mediation::multimed(\n  outcome = \"is_recid\", \n  med.main = \"priors_count\", \n  med.alt = c(\"age\", \"c_charge_degree\"), \n  treat = \"race\", \n  data = tb_med\n)\n# Indirect effect for pc: race -&gt; pc -&gt; ir, race -&gt; age -&gt; pc -&gt; ir\ndelta_0_med_pc &lt;- mean((med_mod_pc$d0.lb + med_mod_pc$d0.ub) / 2)\n# Direct + Other indirect effects: race -&gt; ir, race -&gt; age -&gt; ir, race -&gt; ccd -&gt; ir, \n# race -&gt; age -&gt; ccd -&gt; ir\nzeta_1_med_pc &lt;- mean((med_mod_pc$z1.lb + med_mod_pc$z1.ub) / 2)\n# Total effect\ntot_effect_med_pc &lt;- delta_0_med_pc + zeta_1_med_pc\n\nmed_mod_ccd &lt;- mediation::multimed(\n  outcome = \"is_recid\", \n  med.main = \"c_charge_degree\", \n  med.alt = c(\"age\", \"priors_count\"), \n  treat = \"race\", \n  data = tb_med\n)\n# Indirect effect for ccd: race -&gt; ccd -&gt; ir, race -&gt; age -&gt; ccd -&gt; ir\ndelta_0_med_ccd &lt;- mean((med_mod_ccd$d0.lb + med_mod_ccd$d0.ub) / 2)\n# Direct + Other indirect effects: race -&gt; ir, race -&gt; age -&gt; ir, race -&gt; pc -&gt; ir, \n# race -&gt; age -&gt; pc -&gt; ir\nzeta_1_med_ccd &lt;- mean((med_mod_ccd$z1.lb + med_mod_ccd$z1.ub) / 2)\n# Total effect\ntot_effect_med_ccd &lt;- delta_0_med_ccd + zeta_1_med_ccd\n\nThe estimated values:\n\n# Total effect\ntot_effect_med &lt;- tot_effect_med_age\n# Indirect effects\ndelta_0_med &lt;- delta_0_med_age + delta_0_med_pc + delta_0_med_ccd\n# Direct effect \nzeta_1_med &lt;- tot_effect_med - delta_0_med\ncbind(delta_0 = delta_0_med, zeta_1 = zeta_1_med, tot_effect = tot_effect_med)\n\n        delta_0      zeta_1 tot_effect\n[1,] -0.1205852 -0.02224323 -0.1428284\n\n\n\n\n14.3.2 With Optimal Transport\n\nlibrary(randomForest)\n\nWe use a random forest to estimate the outcome model (see causal_effects_cf() in Chapter 4).\n\ncausal_effects_ot &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(tb_ot_transported), \n  data_cf_treated = NULL, \n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated # 0\n)\n\ncbind(\n  delta_0 = causal_effects_ot$delta_0,\n  zeta_1 = causal_effects_ot$zeta_1, \n  tot_effect = causal_effects_ot$tot_effect\n)\n\n         delta_0      zeta_1 tot_effect\n[1,] -0.08485616 -0.05826527 -0.1431214\n\n\n\n\n14.3.3 With Penalized Optimal Transport\n\ncausal_effects_sink_ot &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(tb_sinkhorn_transported), \n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated # 0\n)\n\ncbind(\n  delta_0 = causal_effects_sink_ot$delta_0,\n  zeta_1 = causal_effects_sink_ot$zeta_1, \n  tot_effect = causal_effects_sink_ot$tot_effect\n)\n\n        delta_0      zeta_1  tot_effect\n[1,] 0.02267429 -0.07670223 -0.05402794\n\n\n\n\n14.3.4 With Sequential Transport\n\ncausal_effects_st &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(sequential_transport$transported), \n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated\n)\n\ncbind(\n  delta_0 = causal_effects_st$delta_0,\n  zeta_1 = causal_effects_st$zeta_1, \n  tot_effect = causal_effects_st$tot_effect\n)\n\n         delta_0      zeta_1 tot_effect\n[1,] -0.09665954 -0.04450242  -0.141162\n\n\nLet us visualize the distribution on the individuals effects for each transport-based method, in Figure 14.2 (frequency on the y-axis).\n\n\nCodes to create the Figure.\nlibrary(tikzDevice)\nsource(\"../scripts/utils.R\")\n\nplot_hist_effects &lt;- function(x, \n                              var_name, \n                              tikz = FALSE,\n                              fill = \"red\",\n                              printed_method = \"\",\n                              x_lim = NULL,\n                              print_main = TRUE,\n                              print_x_axis = TRUE) {\n  if (print_main == TRUE) {\n    name_effect &lt;- case_when(\n      str_detect(var_name, \"^delta_0\") ~ \"$\\\\delta_i(0)$\",\n      str_detect(var_name, \"^zeta_1\") ~ \"$\\\\zeta_i(1)$\",\n      str_detect(var_name, \"^tot_effect\") ~ \"$\\\\tau_i(1)$\",\n      TRUE ~ \"other\"\n    )\n    if (tikz == FALSE) name_effect &lt;- latex2exp::TeX(name_effect)\n  } else {\n    name_effect &lt;- \"\"\n  }\n  \n  \n  if (var_name == \"tot_effect\") {\n    data_plot &lt;- x[[\"delta_0_i\"]] + x[[\"zeta_1_i\"]]\n  } else {\n    data_plot &lt;- x[[var_name]]\n  }\n  \n  if (is.null(x_lim)) {\n    hist(\n      data_plot, \n      main = \"\", xlab = \"\", ylab = \"\", family = font_family,\n      col = fill, axes = FALSE\n    )\n  } else {\n    hist(\n      data_plot, \n      main = \"\", xlab = \"\", ylab = \"\", family = font_family,\n      col = fill, xlim = x_lim, axes = FALSE\n    )\n  }\n  \n  if (print_x_axis) axis(1, family = font_family)\n  axis(2, family = font_family)\n  \n  title(\n    main = name_effect, cex.main = 1, family = font_family\n  )\n  \n  if (printed_method != \"\") {\n    title(\n      ylab = printed_method, line = 2, \n      cex.lab = 1, family = font_family\n    )\n  }\n  abline(v = mean(data_plot), col = \"darkred\", lty = 2, lwd = 2)\n}\n\n\ncolour_methods &lt;- c(\n  # \"OT\" = \"#CC79A7\",\n  \"OT-M\" = \"#009E73\",\n  \"skh\" = \"darkgray\",\n  \"seq_1\" = \"#0072B2\", \n  \"seq_2\" = \"#D55E00\"\n)\n\n\nexport_tikz &lt;- FALSE\n\n\nfile_name &lt;- \"compas-dist-indiv-effects\"\nwidth_tikz &lt;- 2.25\nheight_tikz &lt;- 1.4\nif (export_tikz == TRUE)\n  tikz(paste0(\"figs/\", file_name, \".tex\"), width = width_tikz, height = height_tikz)\n\nlayout(\n  matrix(1:9, byrow = TRUE, ncol = 3),\n  widths = c(1, rep(.9, 2)), heights = c(1, rep(.72, 2))\n)\n\nfor (i in 1:3) {\n  x &lt;- case_when(\n    i == 1 ~ causal_effects_ot,\n    i == 2 ~ causal_effects_sink_ot,\n    i == 3 ~ causal_effects_st\n  )\n  method &lt;- case_when(\n    i == 1 ~ \"OT-M\",\n    i == 2 ~ \"SKH\",\n    i == 3 ~ \"ST\"\n  )\n  \n  for (var_name in c(\"delta_0_i\", \"zeta_1_i\", \"tot_effect\")) {\n    mar_bottom &lt;- ifelse(i == 3, 2.1, .6)\n    mar_left &lt;- ifelse(var_name == \"delta_0_i\", 3.1, 2.1)\n    mar_top &lt;- ifelse(i == 1, 2.1, .1)\n    mar_right &lt;- .4\n    printed_method &lt;- ifelse(var_name == \"delta_0_i\", method, \"\")\n    \n    par(mar = c(mar_bottom, mar_left, mar_top, mar_right))\n    x_lim_list &lt;- list(\n      \"delta_0_i\" = c(-.5, .5),\n      \"zeta_1_i\" = c(-.4, .4),\n      \"tot_effect\" = c(-.6, .6)\n    )\n    \n    plot_hist_effects(\n      x = x, var_name = var_name, tikz = export_tikz, \n      fill = colour_methods[i],\n      printed_method = printed_method, \n      x_lim = x_lim_list[[var_name]],\n      print_main = i == 1,\n      print_x_axis = i == 3\n    )\n  }\n}\n\n\nif (export_tikz == TRUE) {\n  dev.off()\n  plot_to_pdf(\n    filename = file_name, \n    path = \"./figs/\", keep_tex = FALSE, crop = T\n  )\n}\n\n\n\n\n\nFigure 14.2: Distribution of individual direct effect (\\(\\delta_i(0)\\)), indirect effect (\\(\\zeta_i(0)\\)), and total causal effect (\\(\\tau_i\\)) estimated with transport-based counterfactuals with optimal transport (OT-M), penalized transport (SKH), and sequential transport (ST).\n\n\n\n\n\n\n\n\n\n\n14.3.5 Summary\n\ntibble::tribble(\n  ~method, ~delta_0, ~zeta_1, ~tot_effect,\n  \"CM\", delta_0_med, zeta_1_med, tot_effect_med,\n  \"OT\", causal_effects_ot$delta_0, causal_effects_ot$zeta_1, causal_effects_ot$tot_effect,\n  \"SKH\", causal_effects_sink_ot$delta_0, causal_effects_sink_ot$zeta_1, causal_effects_sink_ot$tot_effect,\n  \"ST\", causal_effects_st$delta_0, causal_effects_st$zeta_1, causal_effects_st$tot_effect\n) |&gt; \n  knitr::kable(digits = 2)\n\n\n\n\nmethod\ndelta_0\nzeta_1\ntot_effect\n\n\n\n\nCM\n-0.12\n-0.02\n-0.14\n\n\nOT\n-0.08\n-0.06\n-0.14\n\n\nSKH\n0.02\n-0.08\n-0.05\n\n\nST\n-0.10\n-0.04\n-0.14\n\n\n\n\n\n\n\n14.3.6 Decomposition of the Indirect Effect\nDue to the iterative nature of the sequential transport approach, which follows the topological order of the mediators in the causal graph, it is possible to further decompose the causal influence of each mediator on the indirect effect at the individual level.\n\n# Load sequential_transport\nload(\"../output/seq-t-compas.rda\")\n\nTotal indirect effect with the Sequential Transport approach:\n\ncausal_effects_st$delta_0\n\n[1] -0.09665954\n\n\nBefore decomposing the indirect effect, we need to retrieve the fitted RF model of the total indirect effect.\n\n# Observations\ndata_untreated &lt;- tb_untreated\n# All variables transported\ndata_cf_untreated &lt;- as_tibble(sequential_transport$transported)\n\nY_name &lt;- Y_name\nA_name &lt;- A_name\n\n# Outcome model for untreated\nmu_untreated_model &lt;- randomForest(\n  x = data_untreated |&gt; dplyr::select(-!!Y_name, -!!A_name),\n  y = pull(data_untreated, !!Y_name)\n)\n\nNow we can modify the causal_effects_cf() to take the fitted RF model as an argument to be able to decompose the indirect effect and we return only the indirect effect at the individual level, delta_0_i and the average delta_0.\n\nmodified_causal_effects_cf &lt;- function(data_untreated,\n                                       data_cf_untreated = NULL,\n                                       mu_untreated_model) {\n  \n  if (is.null(data_cf_untreated))\n    stop(\"Counterfactuals needed for the untreated group.\")\n  \n  n_untreated &lt;- nrow(data_untreated)\n  \n  # Natural Indirect Effect, using predictions\n  delta_0_i &lt;- predict(mu_untreated_model, newdata = data_cf_untreated) -\n      predict(mu_untreated_model, newdata = data_untreated)\n  delta_0 &lt;- mean(delta_0_i)\n  \n  list(\n    delta_0_i = delta_0_i,\n    delta_0 = delta_0\n  )\n}\n\nThe total indirect effect is:\n\nmodified_causal_effects_cf(data_untreated, data_cf_untreated, mu_untreated_model)$delta_0\n\n[1] -0.09093245\n\n\n\n14.3.6.1 Causal Influence of Age\n\ncf_treated_first &lt;- data_untreated |&gt; \n  mutate(age = as_tibble(sequential_transport$transported)$age)\n\nindirect_age &lt;- modified_causal_effects_cf(\n  data_untreated = data_untreated, \n  data_cf_untreated = cf_treated_first, \n  mu_untreated_model = mu_untreated_model\n)\n\ncbind(\n  delta_0_age = indirect_age$delta_0\n)\n\n     delta_0_age\n[1,] -0.04003191\n\n\n\n\n14.3.6.2 Causal Influence of Prior Counts\n\ncf_treated_second &lt;- cf_treated_first |&gt; \n  mutate(priors_count = as_tibble(sequential_transport$transported)$priors_count)\n\nindirect_priors_count &lt;- modified_causal_effects_cf(\n  data_untreated = cf_treated_first, \n  data_cf_untreated = cf_treated_second, \n  mu_untreated_model = mu_untreated_model\n)\n\ncbind(\n  delta_0_priors_count = indirect_priors_count$delta_0\n)\n\n     delta_0_priors_count\n[1,]          -0.04443848\n\n\n\n\n14.3.6.3 Causal Influence of Charge Degree\n\ncf_treated_third &lt;- cf_treated_second |&gt; \n  mutate(c_charge_degree = as_tibble(sequential_transport$transported)$c_charge_degree)\n\nindirect_c_charge_degree &lt;- modified_causal_effects_cf(\n  data_untreated = cf_treated_second, \n  data_cf_untreated = cf_treated_third, \n  mu_untreated_model = mu_untreated_model\n)\n\ncbind(\n  delta_0_c_charge_degree = indirect_c_charge_degree$delta_0\n)\n\n     delta_0_c_charge_degree\n[1,]            -0.006462064\n\n\n\n\n\n\nDe Lara, Lucas, Alberto González-Sanz, Nicholas Asher, Laurent Risser, and Jean-Michel Loubes. 2024. “Transport-Based Counterfactual Models.” Journal of Machine Learning Research 25 (136): 1–59.",
    "crumbs": [
      "V. Experiments",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Compas</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Baxendale, Peter, and Ting-Kam Leonard Wong. 2022. “Random Concave\nFunctions.” The Annals of Applied Probability 32 (2):\n812–52.\n\n\nDe Lara, Lucas, Alberto González-Sanz, Nicholas Asher, Laurent Risser,\nand Jean-Michel Loubes. 2024. “Transport-Based Counterfactual\nModels.” Journal of Machine Learning Research 25 (136):\n1–59.\n\n\nFernandes Machado, Agathe, Arthur Charpentier, and Ewen Gallic. 2025a.\n“Optimal Transport on Categorical Data for Counterfactuals Using\nCompositional Data and Dirichlet Transport.” https://arxiv.org/abs/2501.15549.\n\n\n———. 2025b. “Sequential Conditional Transport on Probabilistic\nGraphs for Interpretable Counterfactual Fairness.”\nProceedings of the AAAI Conference on Artificial Intelligence\n39 (18): 19358–66. https://doi.org/10.1609/aaai.v39i18.34131.\n\n\nImai, Kosuke, Luke Keele, and Dustin Tingley. 2010. “A General\nApproach to Causal Mediation Analysis.” Psychological\nMethods 15 (4): 309.\n\n\nImai, Kosuke, Luke Keele, and Teppei Yamamoto. 2010.\n“Identification, Inference and Sensitivity Analysis for Causal\nMediation Effects.” Statistical Science 25 (1): 51–71.\n\n\nPearl, Judea. 2001. “Direct and Indirect Effects.” In\nProceedings of the Seventeenth Conference on Uncertainty and\nArtificial Intelligence, 2001, 411–20. Morgan Kaufmann, San\nFrancisco.\n\n\nPeyré, Gabriel, and Marco Cuturi. 2019. “Computational Optimal\nTransport: With Applications to Data Science.” Foundations\nand Trends in Machine Learning 11 (5-6): 355–607.\n\n\nRobins, James M, and Sander Greenland. 1992. “Identifiability and\nExchangeability for Direct and Indirect Effects.”\nEpidemiology 3 (2): 143–55.\n\n\nSinkhorn, Richard. 1962. “On the Factor Spaces of the Complex\nDoubly Stochastic Matrices.” Notices of the American\nMathematical Society 9: 334–35.",
    "crumbs": [
      "References"
    ]
  }
]