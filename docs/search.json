[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Causal Inference with Counterfactuals and Optimal Transport",
    "section": "",
    "text": "1 Preface\n\nThis ebook contains the codes and explanations of codes used to produce the results of our paper titled Causal Inference with Counterfactuals and Optimal Transport.\n[TBD]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "reminders.html",
    "href": "reminders.html",
    "title": "2  Reminders and Definitions",
    "section": "",
    "text": "Objectives\n\n\n\nIn this page, XXX\n\n\n\nlibrary(tidyverse)\nlibrary(mnormt)\n\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colA}{RGB}{255, 221, 85}\n\\definecolor{colB}{RGB}{148, 78, 223}\n\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colGpe1}{RGB}{127, 23, 14}\n\\definecolor{colGpe0}{RGB}{27, 149, 224}\n\\]\n\n\nCodes to create the Figure.\nlibrary(tikzDevice)\n\nCOLRJ &lt;- c(\"#00A08A\",\"#F2AD00\")\ncolrj &lt;- scales::alpha(COLRJ,.3)\ncolrs &lt;- c(\"red\",\"blue\")\ncolrm &lt;- \"#9986A5\"\n\nexport_tikz &lt;- FALSE\n\nplot_to_pdf &lt;- function(filename,\n                        path_to_latex = \"/Library/TeX/texbin/\",\n                        interpreter = \"pdflatex\",\n                        path = \"./\",\n                        keep_tex = FALSE,\n                        verbose = FALSE,\n                        ignore.stdout = TRUE,\n                        crop = FALSE) {\n  content &lt;- paste0(\n    \"\\\\documentclass{standalone}\n      \\\\usepackage{amsmath,amssymb,amsthm,mathtools,graphicx}\n      \\\\usepackage{array,dcolumn}\n      %\\\\usepackage{dsfont}\n      %\\\\usepackage{fontspec}\n      \\\\renewcommand{\\\\rmdefault}{ptm}\n      \\\\renewcommand{\\\\sfdefault}{phv}\n      %\\\\setmainfont{Noto Sans}\n      %\n      \\\\usepackage{nicefrac}\n      \\\\usepackage{times}\n      %\\\\usepackage{natbib}\n      \\\\usepackage{microtype}\n      %\\\\usepackage{newtxtext,newtxmath}\n      %\\\\usepackage{times,mathpazo}\n      \\\\usepackage{pgfplots}\n      \\\\usetikzlibrary{pgfplots.groupplots}\n      \\\\usepackage{xcolor}\n      \\\\begin{document}\n\n      \\\\input{\",\n    path, filename,\n    \".tex}\n\n      \\\\end{document}\"\n  )\n  \n  # The file which will import the graph in tex format\n  fileConn &lt;- file(paste0(path, filename, \"_tmp.tex\"))\n  writeLines(content, fileConn)\n  close(fileConn)\n  \n  # Process tex file to get the PDF\n  system(\n    paste0(\n      path_to_latex,\n      interpreter, \" -shell-escape -synctex=1 -interaction=nonstopmode  \",\n      path,\n      filename, \"_tmp.tex\"),\n    ignore.stdout = TRUE\n  )\n  if (crop == TRUE) {\n    system(\n      paste0(\n        \"pdfcrop \", filename, \"_tmp.pdf \", filename, \"_tmp.pdf\"\n      )\n    )\n  }\n  if(!path %in%  c(\".\", \"./\", \"/\")) \n    system(paste0(\"mv \", filename, \"_tmp.pdf \", path))\n  system(paste0(\"rm \", filename, \"_tmp.aux\"))\n  system(paste0(\"rm \", filename, \"_tmp.log\"))\n  system(paste0(\"rm \", filename, \"_tmp.synctex.gz\"))\n  if (!keep_tex) {\n    system(paste0(\"rm \", path, filename, \"_tmp.tex\"))\n  }\n  system(paste0(\"mv \", path, filename, \"_tmp.pdf \", path, filename, \".pdf\"))\n}\n\n\n# Generate data\nn &lt;- 500\nmx0 &lt;- -1\nmx1 &lt;- +1\ns &lt;-  1\nx &lt;- seq(-3, 3, length = 601)\ndx0 &lt;- dnorm(x, mx0, s)\ndx1 &lt;- dnorm(x, mx1, s)\nset.seed(1234)\nx0 &lt;- rnorm(n, mx0, s)\nx1 &lt;- rnorm(n, mx1, s)\nfm0 &lt;- function(x) 3 + x * .7\nfm1 &lt;- function(x) 6 + x * 1.2\ny0 &lt;-  fm0(x0) + rnorm(n) / 2\ny1 &lt;- fm1(x1) + rnorm(n) / 2\n\n# First plot----\n\n\nif (export_tikz == TRUE) {\n  par(mar = c(2.1, 0, 0, 0))\n  tikz('figs/gaussian-1-mean.tex', width = 3, height = 3)\n} else {\n  par(mar = c(2.1, 0, 0, 0), mfrow = c(1, 2))\n}\n\n\n# Empty plot\nplot(\n  NA, NA, ylim = c(0, 10),\n  xlab = \"\", ylab = \"\",\n  axes = FALSE, xlim = c(-4, 3)\n)\naxis(1, at = -3:3, labels = FALSE)\n\nif (export_tikz == TRUE) {\n  lab_x = c(\n    \"$\\\\bar{x}_0$\",\n    \"$\\\\bar{x}_1$\"\n  )\n  lab_line_0 &lt;- \"$y = \\\\alpha_0 + \\\\beta_0 x$\"\n  lab_line_1 &lt;- \"$y = \\\\alpha_1 + \\\\beta_1 x$\"\n} else {\n  lab_x &lt;- expression(\n    bar(x)[0], # \\bar{x}_0\n    bar(x)[1]  # \\bar{x}_1\n  )\n  lab_line_0 &lt;- expression(y == alpha[0] + beta[0] * x)\n  lab_line_1 &lt;- expression(y == alpha[1] + beta[1] * x)\n}\naxis(\n  1,\n  at = c(-1, 1),\n  labels = lab_x,\n  tick = TRUE, # still draw the little tick marks\n  line = 0 # on the axis line\n)\n\nif (1 == 0) {\n  # Outcome group 0\n  text(\n    x = 3, y = 4.15,\n    labels = lab_line_0,\n    pos = 2,  \n    cex = 1,\n    col = COLRJ[1]\n  )\n  # Outcome group 1\n  text(\n    x = -3, y = 4.15,\n    labels = lab_line_1,\n    pos = 4,  \n    cex = 1,\n    col = COLRJ[2]\n  )\n}\n# True mean in each group\nabline(v = c(mx0, mx1), lty = 2, lwd = .7)\n\n# Observed points in group 0\npoints(x0, y0, pch = 19, cex = .6, col = colrj[1])\n# True conditional mean in grouo 0\nsegments(-3, fm0(-3), 3, fm0(3), col = COLRJ[1], lwd = 2)\n\n# Observed points in group 1\npoints(x1, y1, pch = 19, cex = .6, col = colrj[2])\n# True conditional mean in grouo 0\nsegments(-3, fm1(-3), 3, fm1(3), col = COLRJ[2], lwd = 2)\n\nsegments(mx0, fm0(mx0), mx1, fm0(mx0))\nsegments(mx0, fm1(mx1), mx1, fm1(mx1))\n# delta(0)\nsegments(mx1, fm0(mx1), mx1, fm0(mx0), col = \"red\", lwd = 2)\n# zeta(1)\nsegments(mx1, fm1(mx1), mx1, fm0(mx1), col = \"blue\", lwd = 2)\n# delta(1)\nsegments(mx0, fm0(mx0), mx0, fm1(mx0), col = \"blue\", lwd = 2)\n# zeta(0)\nsegments(mx0, fm1(mx0), mx0, fm1(mx1), col = \"red\", lwd = 2)\n\npoints(mx0, fm0(mx0), pch = 19) # \\hat{\\mu}_0(\\bar{x}_0)\npoints(mx1, fm1(mx1), pch = 19) # \\hat{\\mu}_1(\\bar{x}_1)\npoints(mx1, fm0(mx1), pch = 19) # \\hat{\\mu}_0(\\bar{x}_1)\npoints(mx0, fm1(mx0), pch = 19) # \\hat{\\mu}_1(\\bar{x}_0)\n\n\n# ---\n# Texts for direct/indirect effects\n# ---\nh &lt;- .3\narrow_length &lt;- .05\n\nif (export_tikz == TRUE) {\n  # lab_delta_0 &lt;- \"$\\\\delta(0) = \\\\beta_0(\\\\bar{x}_1-\\\\bar{x}_0)$\"\n  # lab_delta_0 &lt;- \"$\\\\delta(1) = \\\\beta_1 (\\\\bar{x}_1 - \\\\bar{x}_0)$\"\n  # lab_zeta_0 &lt;- \"$\\\\zeta(0) = (\\\\alpha_1 - \\\\alpha_0) + \\\\bar{x}_0(\\\\beta_1-\\\\beta_0)$\"\n  # lab_zeta_1 &lt;- \"$\\\\zeta(1) = (\\\\alpha_1 - \\\\alpha_0) + \\\\bar{x}_1(\\\\beta_1-\\\\beta_0)$\"\n  lab_delta_0 &lt;- \"$\\\\delta(0)$\"\n  lab_delta_1 &lt;- \"$\\\\delta(1)$\"\n  lab_zeta_0 &lt;- \"$\\\\zeta(0)$\"\n  lab_zeta_1 &lt;- \"$\\\\zeta(1)$\"\n} else {\n  lab_delta_0 &lt;- expression(delta(0) == beta[0] * (bar(x)[1] - bar(x)[0]))\n  lab_delta_1 &lt;- expression(delta(1) == beta[1] * (bar(x)[1] - bar(x)[0]))\n  lab_zeta_0 &lt;- expression(\n    zeta(0) == (alpha[1] - alpha[0]) + bar(x)[0] * (beta[1] - beta[0])\n  )\n  lab_zeta_1 &lt;- expression(\n    zeta(1) == (alpha[1] - alpha[0]) + bar(x)[1] * (beta[1] - beta[0])\n  )\n}\n\n# delta(0)\narrows(mx1 + h, fm0(mx1), mx1 + h, fm0(mx0), code = 3, length = arrow_length, col = \"red\")\ntext(\n  x = mx1 + h, y = (fm0(mx0) + fm0(mx1)) / 2,\n  labels = lab_delta_0,\n  pos = 4,  \n  cex = 1, col = \"red\"\n)\n# zeta(0) \narrows(mx0 - h, fm0(mx0), mx0 - h, fm1(mx0), code = 3, length = arrow_length, col = \"blue\")\ntext(\n  x = mx0 - h, y = (fm0(mx0) + fm1(mx0)) / 2,\n  labels = lab_zeta_0,\n  pos = 2,  \n  cex = 1, col = \"blue\"\n)\n# delta(1)\narrows(mx0 - h, fm1(mx0), mx0 - h, fm1(mx1), code = 3, length = arrow_length, col = \"red\")\ntext(\n  x = mx0 - h, y = (fm1(mx0) + fm1(mx1)) / 2,\n  labels = lab_delta_1,\n  pos = 2,  \n  cex = 1, col = \"red\"\n)\n# zeta(1)\narrows(mx1 + h, fm0(mx1), mx1 + h, fm1(mx1), code = 3, length = arrow_length, col = \"blue\")\ntext(\n  x = mx1+h, y = (fm0(mx1) + fm1(mx1)) / 2,\n  labels = lab_zeta_1,\n  pos = 4,  \n  cex = 1, col = \"blue\"\n)\n\nif (export_tikz == TRUE) dev.off()\n\n\n# Second plot----\n\nif (export_tikz == TRUE) {\n  tikz('figs/gaussian-1-transp.tex', width = 3, height = 3)\n}\n\n# With the counterfactual\n\nt0 &lt;- -1.5\nt1 &lt;- .5\nplot(\n  NA, NA, ylim = c(0, 10),\n  xlab = \"\", ylab = \"\",\n  axes = FALSE, xlim = c(-4, 3)\n)\n# P(X &lt;= t0 | A = 0)\npolygon(\n  c(-3, x[x &lt;= t0], t0), c(0, dx0[x &lt;= t0], 0) * 4,\n  col = colrj[1], border = NA\n)\n# P(X &lt;= t0 | A = 1)\npolygon(\n  c(-3, x[x &lt;= t1], t1), c(0, dx1[x &lt;= t1], 0) * 4,\n  col = colrj[2], border = NA\n)\n# densities in both groups\nlines(x, dx0 * 4, col = COLRJ[1], lwd = 2)\nlines(x, dx1 * 4, col = COLRJ[2], lwd = 2)\n\naxis(1, at = -3:3, labels = FALSE)\nif (export_tikz == FALSE) {\n  lab_x &lt;- expression(\n      x[i], # \\bar{x}_0\n      x[i](1) # \\bar{x}_1\n    )\n  lab_line_0 &lt;- expression(y == alpha[0] + beta[0] * x)\n  lab_line_1 &lt;- expression(y == alpha[1] + beta[1] * x)\n} else {\n  lab_x = c(\n    \"$x_i$\",\n    \"$x_i(1)$\"\n  )\n  lab_line_0 &lt;- \"$y = \\\\alpha_0 + \\\\beta_0 x$\"\n  lab_line_1 &lt;- \"$y = \\\\alpha_1 + \\\\beta_1 x$\"\n}\naxis(\n  1,\n  at = c(t0, t1),\n  labels = lab_x,\n  tick = TRUE, # still draw the little tick marks\n  line = 0 # on the axis line\n)\nif (1== 0) {\n  # Outcome in group 0\n  text(\n    x = 3, y = 4.15,\n    labels = lab_line_0,\n    pos = 2,  \n    cex = 1,\n    col = COLRJ[1]\n  )\n  # Outcome in group 1\n  text(\n    x = -3, y = 4.15,\n    labels = lab_line_1,\n    pos = 4,  \n    cex = 1,\n    col = COLRJ[2]\n  )\n}\n# True mean in each groups\nabline(v = c(t0, t1), lty = 2, lwd = .7)\n\n# Observed points in group 0\npoints(x0, y0, pch = 19, cex = .6, col = colrj[1])\n# True conditional mean in grouo 0\nsegments(-3, fm0(-3), 3, fm0(3), col = COLRJ[1], lwd = 2)\n\n# Observed points in group 1\npoints(x1, y1, pch = 19, cex = .6, col = colrj[2])\n# True conditional mean in grouo 0\nsegments(-3, fm1(-3), 3, fm1(3), col = COLRJ[2], lwd = 2)\n# This time, instead of means: transported values\nsegments(t0, fm0(t0), t1, fm0(t0))\nsegments(t0, fm1(t1), t1, fm1(t1))\nsegments(t1, fm0(t1), t1, fm0(t0), col = \"red\", lwd = 2)\nsegments(t1, fm1(t1), t1, fm0(t1), col = \"blue\", lwd = 2)\nsegments(t0, fm0(t0), t0, fm1(t0), col = \"blue\", lwd = 2)\nsegments(t0, fm1(t0), t0, fm1(t1), col = \"red\", lwd = 2)\n\npoints(t0, fm0(t0), pch = 19) # \\hat{\\mu}_0(x_0)\npoints(t1, fm1(t1), pch = 19) # \\hat{\\mu}_1(T(x_0)\npoints(t1, fm0(t1), pch = 19) # \\hat{\\mu}_0(T(x_0))\npoints(t0, fm1(t0), pch = 19) # \\hat{\\mu}_1(x_0)\n\n# ---\n# Texts for direct/indirect effects\n# ---\nh &lt;- .3\narrow_length &lt;- .05\n\nif (export_tikz == TRUE) {\n  # lab_delta_0 &lt;- \"$\\\\delta_i(0) = \\\\beta_0 (x_i(1) - x_i)$\"\n  # lab_delta_1 &lt;- \"$\\\\delta_i(1) = \\\\beta_1(x_i(1) - x_i)$\"\n  # lab_zeta_0 &lt;- \"$\\\\zeta_i(0) = (\\\\alpha_1 - \\\\alpha_0) + x_i(\\\\beta_1 - \\\\beta_0)$\"\n  # lab_zeta_1 &lt;- \"$\\\\zeta_i(1) = (\\\\alpha_1 - \\\\alpha_0) + x_i(1)(\\\\beta_1-\\\\beta_0)$\"\n  \n  lab_delta_0 &lt;- \"$\\\\delta_i(0)$\"\n  lab_delta_1 &lt;- \"$\\\\delta_i(1)$\"\n  lab_zeta_0 &lt;- \"$\\\\zeta_i(0)$\"\n  lab_zeta_1 &lt;- \"$\\\\zeta_i(1)$\"\n} else {\n  lab_delta_0 &lt;- expression(delta[i](0) == beta[0] * (x[i](1) - x[i]))\n  lab_delta_1 &lt;- expression(delta[i](1) == beta[1] * (x[i](1) - x[i]))\n  lab_zeta_0 &lt;- expression(\n    zeta[i](0) == (alpha[1] - alpha[0]) + x[i] * (beta[1] - beta[0])\n  )\n  lab_zeta_1 &lt;- expression(\n    zeta[i](1) == (alpha[1] - alpha[0]) + x[i](1) * (beta[1] - beta[0])\n  )\n}\n\n# delta(0)\narrows(t1 + h, fm0(t1), t1 + h, fm0(t0), code = 3, length = arrow_length, col = \"red\")\ntext(\n  x = t1 + h, y = (fm0(t0) + fm0(t1)) / 2,\n  labels = lab_delta_0,\n  pos = 4,  \n  cex = 1, col = \"red\"\n)\n# zeta(0)\narrows(t0 - h, fm0(t0), t0 - h, fm1(t0), code = 3, length = arrow_length, col = \"blue\")\ntext(\n  x = t0-h, y = (fm0(t0) + fm1(t0)) / 2,\n  labels = lab_zeta_0,\n  pos = 2,  \n  cex = 1, col = \"blue\"\n)\n# delta(1)\narrows(t0 - h, fm1(t0), t0 - h, fm1(t1), code = 3, length = arrow_length, col = \"red\")\ntext(\n  x = t0 - h, y = (fm1(t0) + fm1(t1)) / 2,\n  labels = lab_delta_1,\n  pos = 2,  \n  cex = 1, col = \"red\"\n)\n# zeta(1)\narrows(t1 + h, fm0(t1), t1 + h, fm1(t1), code = 3,length = arrow_length, col = \"blue\")\ntext(\n  x = t1 + h, y = (fm0(t1) + fm1(t1)) / 2,\n  labels = lab_zeta_1,\n  pos = 4,  \n  cex = 1, col = \"blue\"\n)\n\nif (export_tikz == TRUE) {\n  dev.off()\n  plot_to_pdf(filename = \"gaussian-1-mean\", path = \"./figs/\", keep_tex = FALSE, crop = TRUE)\n  plot_to_pdf(filename = \"gaussian-1-transp\", path = \"./figs/\", keep_tex = FALSE, crop = TRUE)\n}\n\n\n\n\n\nFigure 2.1: Decomposition of the average total causal effect (left) and the total causal effect for an untreated unit (right), with notations from Imai, Keele, and Tingley (2010). Untreated in green, treated in yellow.\n\n\n\n\n\n\n\n\n\n\n\n\nImai, Kosuke, Luke Keele, and Dustin Tingley. 2010. “A General Approach to Causal Mediation Analysis.” Psychological Methods 15 (4): 309.",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Reminders and Definitions</span>"
    ]
  },
  {
    "objectID": "gaussian-example.html",
    "href": "gaussian-example.html",
    "title": "3  Gaussian Example",
    "section": "",
    "text": "3.1 Data Generating Process\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colGpe1}{RGB}{0, 160, 138}\n\\definecolor{colGpe0}{RGB}{242, 173, 0}\n\\]\nWe want to simulate potential outcomes in a binary treatment setting, with covariate shift between treatment groups.\nLet \\(n=500\\) denote the number of individuals (or unit), and let \\(\\boldsymbol{X}=(X_1,X_2)\\) be drawn from bivariate normal distrubtions whose mean vectors and covariance matrices depend on the treatment assignment \\(A\\in\\{0,1\\}\\).\nFor untreated individuals (\\(A=\\color{colGpe0}0\\)) the covariates \\(\\boldsymbol{X}^{(0)} = (X_1{(0)}, X_2{(0)})\\) are sampled from a \\(\\mathcal{N}(\\mu_0, \\Sigma_0)\\), where \\(\\mu_0 = -1\\), \\(\\Sigma_0 = \\begin{pmatrix} 1 & r_0 \\\\ r_0 & 1 \\end{pmatrix}\\) with \\(r_0 = 0.7\\).\nFor treated individuals (\\(A=\\color{colGpe1}1\\)), covariates \\(\\boldsymbol{X}{(1)} = (X_1{(1)}, X_2{(1)})\\) follow a \\(\\mathcal{N}(\\mu_1, \\Sigma_1)\\), where \\(\\mu_1 = +1\\), \\(\\Sigma_1 = \\begin{pmatrix} 1 & r_1 \\\\ r_1 & 1 \\end{pmatrix}\\) with \\(r_1 = -0.5\\).\nThe treatment assignment \\(A\\) is randomized with probability \\(p_1 = 0.5\\).\nThe potential outcomes are linear functions of the covariates: \\[\n\\begin{aligned}\nY(0) &= a_1 X_1 + a_2 X_2 + \\varepsilon,\\\\\nY(1) &= a_1 X_1 + a_2 X_2 + a_0 + \\varepsilon .\n\\end{aligned}\n\\]\nwhere \\(\\varepsilon \\sim \\mathcal{N}(0, 1)\\) and \\(a_0 = 3\\), \\(a_1 = 2\\), \\(a_2 = -1.5\\).\nThe observed outcome is \\[Y = A \\cdot Y(1) + (1 - A) \\cdot Y(0).\\]\nAs noted by Imai, Keele, and Yamamoto (2010), under treatment status \\(a\\), we only observe \\(X_i{(a)}\\) and we never observe \\(X_i{(1-a)}\\). Using optimal transport, we will build the unobserved value, the counterfactual.\nset.seed(12345)\n# Parameters\nn &lt;- 500\nmu0 &lt;- -1\nmu1 &lt;- +1\nr0 &lt;- +.7\nr1 &lt;- -.5\na &lt;- 1\na0 &lt;-  3\na1 &lt;-  2\na2 &lt;-  -1.5\np1 &lt;- .5\nMu0 &lt;- rep(mu0, 2)\nMu1 &lt;- rep(mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Draw covariates\nX0 &lt;- rmnorm(n, mean = a * Mu0, varcov = Sig0)\nX1 &lt;- rmnorm(n, mean = a * Mu1, varcov = Sig1)\n# Random noise\nE &lt;- rnorm(n)\n# Binary treatment\nA &lt;- sample(0:1, size = n, replace = TRUE, prob = c(1 - p1, p1))\n\nX &lt;- X0\nX[A==1, ] = X1[A==1, ]\n\ndf &lt;- tibble(\n  X1 = X[, 1],\n  X2 = X[, 2],\n  A = A,\n  Y0 = a1 * X1 + a2 * X2 + E,\n  Y1 = a1 * X1 + a2 * X2 + a0 + E,\n  Y = A * Y1 + (1-A) * Y0\n)\nWe define a function to wrap this DGP.\nThe gen_data() function.\n#' @param n Number of units.\n#' @param mu0 Mean of the two covariates in group 0.\n#' @param mu1 Mean of the two covariates in group 1.\n#' @param r0 Covariance of the two covariates in group 0.\n#' @param r1 Covariance of the two covariates in group 1.\n#' @parma a Shift parameter for the mean in both groups\n#'  (default to 1: no shift). Larger values decreases overlapping.\ngen_data &lt;- function(n = 500,\n                     mu0 = -1,\n                     mu1 = +1,\n                     r0 = +.7,\n                     r1 = -.5,\n                     a = 1,\n                     seed = NULL) {\n  \n  if (!is.null(seed)) set.seed(seed)\n  \n  a0 &lt;-  3\n  a1 &lt;-  2\n  a2 &lt;-  -1.5\n  p1 &lt;- .5\n  Mu0 &lt;- rep(mu0, 2)\n  Mu1 &lt;- rep(mu1, 2)\n  Sig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\n  Sig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n  # Draw covariates\n  X0 &lt;- rmnorm(n, mean = a * Mu0, varcov = Sig0)\n  X1 &lt;- rmnorm(n, mean = a * Mu1, varcov = Sig1)\n  # Random noise\n  E &lt;- rnorm(n)\n  # Binary treatment\n  A &lt;- sample(0:1, size = n, replace = TRUE, prob = c(1 - p1, p1))\n  X &lt;- X0\n  X[A==1, ] = X1[A==1, ]\n  df &lt;- tibble(\n    X1 = X[, 1],\n    X2 = X[, 2],\n    A = A,\n    Y0 = a1 * X1 + a2 * X2 + E,\n    Y1 = a1 * X1 + a2 * X2 + a0 + E,\n    Y = A * Y1 + (1-A) * Y0\n  )\n  \n  df\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Gaussian Example</span>"
    ]
  },
  {
    "objectID": "gaussian-example.html#sec-dgp",
    "href": "gaussian-example.html#sec-dgp",
    "title": "3  Gaussian Example",
    "section": "",
    "text": "Causal Mediation Effect (Imai, Keele, and Yamamoto (2010))\n\n\n\nThe causal mediation effect for the \\(i\\)th individual writes:\n\\[\n\\delta_i{(a)} \\equiv Y_i{\\bigl(a, X_i{(1)}\\bigr)} - Y_i{\\bigl(a, X_i{(0)}\\bigr)}, \\quad \\text{for } a={0,1},\n\\] where \\(Y_i{\\bigl(a, X_i{(1)}\\bigr)}\\) is the potential outcome under treatment \\(a\\) with mediator values $ X_i{(1)}$ and \\(Y_i{\\bigl(a, X_i{(0)}\\bigr)}\\) is the potential outcome also under treatment \\(a\\) with mediator values \\(X_i^{(0)}\\).\nPearl (2001) refers to \\(\\delta_i{(a)}\\) as the natural indirect effect.\n\n\n\n\n\n\n\n\n\nHere\n\n\n\nHere, with the current DGP, we have: \\[\n\\begin{cases}\n  \\delta_i(0) = a_1(X_{1,i}(1) - X_{1,i}(0)) + a_2(X_{2,i}(1)-X_{2,i}(0))\\\\\n  \\delta_i(1) = a_1(X_{1,i}(1) - X_{1,i}(0)) + a_2(X_{2,i}(1)-X_{2,i}(0))\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n\nAverage Causal Mediation Effect (ACME) (Imai, Keele, and Yamamoto (2010))\n\n\n\nThe average causal mediation effects writes:\n\\[\n\\begin{align*}\n\\bar{\\delta}{(a)} & \\equiv \\mathbb{E}\\bigl[\\delta_i{(a)}\\bigr]\\\\\n& = \\mathbb{E}\\bigl[ Y_i{(a,X_i{(1)})} - Y_i{(a, X_i{(0)})} \\bigr]\n\\end{align*}\n\\tag{3.1}\\]\n\n\n\n\n\n\n\n\nHere\n\n\n\nHere, we have:\n\\[\n\\begin{cases}\n  \\bar{\\delta}(0) = (a_1+a2)(\\mu_1-\\mu_0)\\\\\n  \\bar{\\delta}(1) = (a_1+a2)(\\mu_1-\\mu_0)\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n\nNatural Direct Effect (Pearl (2001), Imai, Keele, and Yamamoto (2010))\n\n\n\nThe natural direct effect writes: \\[\n\\zeta_i{(a)} = Y_i{(1,X_i{(a)})} - Y_i{(0, X_i{(a)})}, \\quad a=0,1.\n\\tag{3.2}\\]\nHence, it represents the direct effect of the treatment for a given level of the mediator.\n\n\n\n\n\n\n\n\nHere\n\n\n\nHere, we have:\n\\[\n\\begin{cases}\n  \\zeta_i{(0)} = a_0\\\\\n  \\zeta_i{(1)} = a_0\\\\\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n\nTotal Causal Effect (Imai, Keele, and Yamamoto (2010))\n\n\n\nThe total causal effect is given by \\[\n\\tau_i = \\delta_i{(a)} +\\zeta_i^{(a)} (1-a), \\quad a=0,1.\n\\tag{3.3}\\]\n\n\n\n\n\n\n\n\nHere\n\n\n\nHere, we have:\n\\[\n\\tau_i = a_1(X_{1,i}(1) - X_{1,i}(0)) + a_2(X_{2,i}(1)-X_{2,i}(0)) + a_0\n\\] and\n\\[\n\\bar{\\delta}=(a_1+a_2)(\\mu_1-\\mu_0) + a0\n\\]",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Gaussian Example</span>"
    ]
  },
  {
    "objectID": "gaussian-example.html#a-closer-look-at-overlapping",
    "href": "gaussian-example.html#a-closer-look-at-overlapping",
    "title": "3  Gaussian Example",
    "section": "3.2 A Closer Look at Overlapping",
    "text": "3.2 A Closer Look at Overlapping\nLet us consider two examples:\n\nLarge overlap: \\(\\mu_0=-.5\\), \\(\\mu_1=.5\\), the rest of the parameters are the same as those presented above.\nLimited overlap: \\(\\mu_0=-1.5\\), \\(\\mu_1=1.5\\), the rest of the parameters are the same as those presented above.\n\n\n\nCodes to create the Figure.\n# First example\nmu0 &lt;- -.5\nmu1 &lt;- .5\nr0 &lt;- +.7\nr1 &lt;- -.5\na &lt;- 1\np1 &lt;- .5\nMu0 &lt;- rep(mu0, 2)\nMu1 &lt;- rep(mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\nu &lt;- seq(-10, 10, length = 161)\ndxy &lt;- expand_grid(X1 = u, X2 = u)\n\nd0 &lt;- dmnorm(as.matrix(dxy), mean = a * Mu0, varcov = Sig0)\nd1 &lt;- dmnorm(as.matrix(dxy), mean = a * Mu1, varcov = Sig1)\n\nz0 &lt;- matrix(d0, nrow = length(u))\nz1 &lt;- matrix(d1, nrow = length(u))\n\npar(mar = c(2.1, 2.1, 0.1, 0.1), mfrow = c(1,2))\nx_lim &lt;- c(-3, 3)\ny_lim &lt;- c(-4, 4)\n\nplot(NA,NA, \n     xlim = x_lim, ylim = y_lim, \n     xlab = \"\", ylab = \"\", pch = NA,\n     family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\n\n\n\n# posterior probability of class 1 (using Bayes' theorem)\nposterior &lt;- (p1 * d1) / ((1-p1) * d0 + p1 * d1)\n# reshape for plotting\npost_matrix &lt;- matrix(posterior, nrow = length(u), byrow = FALSE)\n\nlvl &lt;- c(.01, .99)\n\n# contour(\n# u, u, post_matrix, levels = lvl, drawlabels = TRUE,\n# col = \"blue\", lty = 3, lwd = 2,\n# xlab = \"X1\", ylab = \"X2\", main = \"Region where 0.01 ≤ P(A|X) ≤ 0.99\"\n# )\n\n# extract contour lines\ncontours &lt;- contourLines(u, u, post_matrix, levels = lvl)\nparam_dens &lt;- 35\ncl &lt;- contours\nfor (i in 1:length(cl)) {\n  if (cl[[i]]$x[2] &lt; cl[[i]]$x[1]) {\n    cl[[i]]$x &lt;- rev(cl[[i]]$x)\n    cl[[i]]$y &lt;- rev(cl[[i]]$y)\n  }\n}\n\n# Bottom-left\npolygon(\n  c(cl[[1]]$x, 10, -10, -10),\n  c(cl[[1]]$y, -10, -10, 10),\n  col=scales::alpha(colGpe0, .9), density = param_dens,\n  border = NA\n)\n# Upper-right\npolygon(\n  c(cl[[2]]$x, 10, 10, -10),\n  c(cl[[2]]$y, -10, 10, 10),\n  col=scales::alpha(colGpe0, .9), density = param_dens,\n  border = NA\n)\n# Upper-left\npolygon(\n  c(cl[[3]]$x, 10, -10, -10),\n  c(cl[[3]]$y, 10, 10, -10),\n  col=scales::alpha(colGpe1, .9), density = param_dens,\n  border = NA\n)\n# Bottom-right\npolygon(\n  c(cl[[4]]$x, 10, 10, -10),\n  c(cl[[4]]$y, 10, -10, -10),\n  col=scales::alpha(colGpe1, .9), density = param_dens,\n  border = NA\n)\n\ncontour_lwr &lt;- cl[sapply(cl, function(x) x$level == lvl[1])]\ncontour_upr &lt;- contours[sapply(cl, function(x) x$level == lvl[2])]\nfor (c in contour_lwr) lines(c$x, c$y, col = \"gray30\", lty = 1)\nfor (c in contour_upr) lines(c$x, c$y, col = \"gray30\", lty = 1)\n\n# Add contour lines\ncontour(u, u, z0, add = TRUE, lwd = 1, col = colGpe0, family = font_family, labcex = 1)\ncontour(u, u, z1, add = TRUE, lwd = 1, col = colGpe1, family = font_family, labcex = 1)\n\n# Second example\nmu0 &lt;- -1.5\nmu1 &lt;- 1.5\nr0 &lt;- +.7\nr1 &lt;- -.5\na &lt;- 1\np1 &lt;- .5\nMu0 &lt;- rep(mu0, 2)\nMu1 &lt;- rep(mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\nu &lt;- seq(-10, 10, length = 161)\ndxy &lt;- expand_grid(X1 = u, X2 = u)\n\nd0 &lt;- dmnorm(as.matrix(dxy), mean = a * Mu0, varcov = Sig0)\nd1 &lt;- dmnorm(as.matrix(dxy), mean = a * Mu1, varcov = Sig1)\n\nz0 &lt;- matrix(d0, nrow = length(u))\nz1 &lt;- matrix(d1, nrow = length(u))\n\n# x_lim &lt;- y_lim &lt;- c(-3.5, 3.5)\nx_lim &lt;- c(-3, 3)\ny_lim &lt;- c(-4, 4)\n\nplot(NA,NA, \n     xlim = x_lim, ylim = y_lim, \n     xlab = \"\", ylab = \"\", pch = NA,\n     family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\n# posterior probability of class 1 (using Bayes' theorem)\nposterior &lt;- (p1 * d1) / ((1-p1) * d0 + p1 * d1)\n# reshape for plotting\npost_matrix &lt;- matrix(posterior, nrow = length(u), byrow = FALSE)\n\nlvl &lt;- c(.01, .99)\n\n# contour(\n# u, u, post_matrix, levels = lvl, drawlabels = TRUE,\n# col = \"blue\", lty = 3, lwd = 2,\n# xlab = \"X1\", ylab = \"X2\", main = \"Region where 0.01 ≤ P(A|X) ≤ 0.99\"\n# )\n\n# extract contour lines\ncontours &lt;- contourLines(u, u, post_matrix, levels = lvl)\n\ncl &lt;- contours\nfor (i in 1:length(cl)) {\n  if (cl[[i]]$x[2] &lt; cl[[i]]$x[1]) {\n    cl[[i]]$x &lt;- rev(cl[[i]]$x)\n    cl[[i]]$y &lt;- rev(cl[[i]]$y)\n  }\n}\n\n# Bottom-left\npolygon(\n  c(cl[[1]]$x, 10, -10, -10),\n  c(cl[[1]]$y, -10, -10, 10),\n  col=scales::alpha(colGpe0, .9), density = param_dens,\n  border = NA\n)\n# Upper-right\npolygon(\n  c(cl[[2]]$x, 10, 10, -10),\n  c(cl[[2]]$y, -10, 10, 10),\n  col=scales::alpha(colGpe0, .9), density = param_dens,\n  border = NA\n)\n# Upper part (wrong but not for the cropped image)\npolygon(\n  c(cl[[3]]$x, 10, 10, -10),\n  c(cl[[3]]$y, -10, 10, 10),\n  col=scales::alpha(colGpe1, .9), density = param_dens,\n  border = NA\n)\n\ncontour_lwr &lt;- cl[sapply(cl, function(x) x$level == lvl[1])]\ncontour_upr &lt;- contours[sapply(cl, function(x) x$level == lvl[2])]\nfor (c in contour_lwr) lines(c$x, c$y, col = \"gray30\", lty = 1)\nfor (c in contour_upr) lines(c$x, c$y, col = \"gray30\", lty = 1)\n\n# Add contour lines\ncontour(u, u, z0, add = TRUE, lwd = 1, col = colGpe0, family = font_family, labcex = 1)\ncontour(u, u, z1, add = TRUE, lwd = 1, col = colGpe1, family = font_family, labcex = 1)\n\np &lt;- recordPlot()\npdf(paste0(path, \"gauss-ex-level-curves-overlap.pdf\"), width = 4.6, height = 4.6/2)\nreplayPlot(p)\ndev.off()\n\n\nquartz_off_screen \n                2 \n\n\n\n\n\nFigure 3.1: Level curves of the two densities of \\(\\boldsymbol{X} \\\\mid A=a\\) in the toy example, and associated propensities. The white area correponds to \\(x\\) where the propensity score is in \\([1\\%,99\\%]\\). The blue area corresponds to \\(P[A=1 \\\\mid \\boldsymbol{X}] &lt; 1\\%\\), the red area corresponds to areas where \\(P[A=1 \\\\mid \\boldsymbol{X}] &gt; 99\\%\\).",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Gaussian Example</span>"
    ]
  },
  {
    "objectID": "gaussian-example.html#counterfactuals",
    "href": "gaussian-example.html#counterfactuals",
    "title": "3  Gaussian Example",
    "section": "3.2 Counterfactuals",
    "text": "3.2 Counterfactuals\nLet us build counterfactuals for individuals from group 0, and for individuals from group 1. We will consider the following methods:\n\nMultivariate Optimal Transport (since we know the parameters of the two Gaussians),\nSequential Optimal Transport.\n\n\n3.2.1 Optimal Transport\n\nlibrary(expm)\n\nThe optimal transport map \\(T(x)\\) from \\(\\mathcal{N}(\\boldsymbol{\\mu}_0, \\boldsymbol{\\Sigma}_0)\\) to \\(\\mathcal{N}(\\boldsymbol{\\mu}_1, \\boldsymbol{\\Sigma}_1)\\) is: \\[T(x) = \\boldsymbol{\\mu}_1 + \\boldsymbol{A}(x - \\boldsymbol{\\mu}_0)\\] where: \\[\n\\boldsymbol{A} = \\boldsymbol{\\Sigma}_0^{1/2}\n       \\left( \\boldsymbol{\\Sigma}_0^{1/2} \\boldsymbol{\\Sigma}_1 \\boldsymbol{\\Sigma}_0^{1/2} \\right)^{-1/2}\n      \\boldsymbol{\\Sigma}_0^{1/2}\n\\]\nWe define the function compute_ot_map() to compute the optimal mapping.\n\n#' Optimal transport mapping between two Gaussian distributions \n#'  (from \\eqn{\\mathcal{N}(\\mu_{\\text{source}}, \\Sigma_{\\text{source}})} to \n#'   \\eqn{\\mathcal{N}(\\mu_{\\text{target}}, \\Sigma_{\\text{target}})})\n#'  \n#' @param mu_source Mean vector of the source Gaussian.\n#' @param sigma_source Covariance matrix of the source Gaussian.\n#' @param mu_target Mean vector of the target Gaussian.\n#' @param sigma_target Covariance matrix of the target Gaussian.\ncompute_ot_map &lt;- function(mu_source, sigma_source, mu_target, sigma_target) {\n  sqrt_sigma_source &lt;- sqrtm(sigma_source)\n  sqrt_sigma_source_inv &lt;- solve(sqrt_sigma_source)\n  \n  inner &lt;- sqrt_sigma_source %*% sigma_target %*% sqrt_sigma_source\n  sqrt_inner &lt;- sqrtm(inner)\n  \n  A &lt;- sqrt_sigma_source_inv %*% sqrt_inner %*% sqrt_sigma_source_inv\n  \n  list(A = A, shift = mu_target - A %*% mu_source)\n}\n\nWe also define the apply_ot_transport() function which uses a transport plan to transport individuals.\n\n#' Function to apply the transport map to simulated data\n#' \n#' @param X Observations to transport.\n#' @param mapping Optimal transport mapping (from `compute_ot_map()`)?\napply_ot_transport &lt;- function(X, mapping) {\n  A &lt;- mapping$A\n  shift &lt;- mapping$shift\n  t(apply(X, 1, function(x) as.vector(shift + A %*% x)))\n}\n\nSince we generated the data, we know the exact transport plan to transport individuals from group 0 to group 1. We also know the exact transport plan to transport individuals from group 1 to group 0.\n\nSigma0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSigma1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\n# Mapping from group 0 to group 1\not_map_0_to_1 &lt;- compute_ot_map(\n  mu_source = Mu0, sigma_source = Sigma0, \n  mu_target = Mu1, sigma_target = Sigma1\n)\n# Mapping from group 1 to group 0\not_map_1_to_0 &lt;- compute_ot_map(\n  mu_source = Mu1, sigma_source = Sigma1, \n  mu_target = Mu0, sigma_target = Sigma0\n)\n\nWe apply the transport map to the untreated units (A = 0).\n\nX0 &lt;- as.matrix(df[df$A == 0, c(\"X1\", \"X2\")])\nX0_t &lt;- apply_ot_transport(X = X0, mapping = ot_map_0_to_1)\ncolnames(X0_t) &lt;- c(c(\"X1\", \"X2\"))\n\nAnd to the transport map to the treated units (A = 1).\n\nX1 &lt;- as.matrix(df[df$A == 1, c(\"X1\", \"X2\")])\nX1_t &lt;- apply_ot_transport(X = X1, mapping = ot_map_1_to_0)\ncolnames(X1_t) &lt;- c(c(\"X1\", \"X2\"))\n\nLet us visualize the transported individuals. First, we define the function draw_ellipse() which will allow us to plot the 95% confidence ellipse in both groups.\n\n\nThe draw_ellipse() function.\ndraw_ellipse &lt;- function(mu, \n                         sigma, \n                         col = \"black\", \n                         lty = 1, \n                         lwd = 1, \n                         level = 0.95, \n                         ...) {\n  \n  angles &lt;- seq(0, 2 * pi, length.out = 100)\n  vals &lt;- sqrt(\n    qchisq(level, df = 2)) * t(chol(sigma)) %*% rbind(cos(angles), sin(angles)\n    )\n  lines(mu[1] + vals[1, ], mu[2] + vals[2, ], col = col, lty = lty, lwd = lwd, ...)\n  \n}\n\n\nWe isolate the observations from group 0 and from group 1.\n\n# Prepare data for the plot\nX0 &lt;- df[df$A == 0, c(\"X1\", \"X2\")]\nX1 &lt;- df[df$A == 1, c(\"X1\", \"X2\")]\n\nThe initial points and the transported values are shown in Figure 3.1\n\n\nCodes to create the Figure.\npar(mar = c(2.1, 2.1, 2.1, 0.1), mfrow = c(1, 2))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\n\n# From 0 to 1\nplot(X0, \n     pch = 16, \n     col = adjustcolor(colGpe0, alpha = .3), \n     xlim = x_lim, ylim = y_lim, \n     xlab = \"\", ylab = \"\",\n     main = \"OT: from A=0 to A=1\",\n     family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X0_t, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0$X1, y0 = X0$X2,\n  x1 = X0_t[, 1], y1 = X0_t[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Covariance of transported points (via OT map)\nSigma0_transport &lt;- ot_map_0_to_1$A %*% Sig0 %*% t(ot_map_0_to_1$A)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\ndraw_ellipse(Mu1, Sigma0_transport, col = colGpet, lty = 2)\n\n# From 1 to 0\nplot(X0, \n     pch = 16, \n     col = adjustcolor(colGpe0, alpha = .3), \n     xlim = x_lim, ylim = y_lim, \n     xlab = \"\", ylab = \"\",\n     main = \"OT: from A=0 to A=1\",\n     family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X1_t, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X1$X1, y0 = X1$X2,\n  x1 = X1_t[, 1], y1 = X1_t[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Covariance of transported points (via OT map)\nSigma0_transport &lt;- ot_map_1_to_0$A %*% Sig1 %*% t(ot_map_1_to_0$A)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\ndraw_ellipse(Mu0, Sigma0_transport, col = colGpet, lty = 2)\n\n\n\n\n\nFigure 3.1: 500 points in each group drawn from bivariates Gaussian distributions and transported values from group 0 to group 1 (left), and from group 1 to group 0 (righr), using optimal transport.\n\n\n\n\n\n\n\n\n\n\n3.2.2 Sequential Transport\nWe will now transport individuals using sequential transport. The results are sensitive to the ordering within the sequence. We will thus consider both ordering here:\n\na first marginal univariate optimal transport along the first dimension (\\(X_1\\)), then a conditional transport for the second dimension (\\(X_2 \\mid X_1)\\): sequential_transport_12(),\na first marginal univariate optimal transport along the second dimension (\\(X_2\\)), then a conditional transport for the first dimension (\\(X_1 \\mid X_2)\\): sequential_transport_21(),\n\n\n\nThe sequential_transport_12() function.\n#' Sequential transport from N(M_source, S_source) to N(M_target, S_target),\n#' along X1, then X2 | X1\n#'\n#' @param X n x 2 matrix of source observations.\n#' @param M_source Mean vector of the source distribution (length 2).\n#' @param S_source Covariance matrix of the source distribution (2x2).\n#' @param M_target Mean vector of the target distribution.\n#' @param S_target Covariance matrix of the target distribution.\nsequential_transport_12 &lt;- function(X, \n                                    M_source, \n                                    S_source, \n                                    M_target, \n                                    S_target) {\n  \n  # marginal univariate transport along the first coordinate (X_1)\n  T1x &lt;- qnorm(\n    pnorm(X[, 1], mean = M_source[1], sd = sqrt(S_source[1, 1])),\n    mean = M_target[1], sd = sqrt(S_target[1, 1])\n  )\n  \n  # conditional parameters for X_2 | X_1\n  m_source &lt;- M_source[2] + S_source[1, 2] / S_source[1, 1] * (X[, 1] - M_source[1])\n  s_source &lt;- S_source[2, 2] - S_source[1, 2]^2 / S_source[1, 1]\n  \n  m_target &lt;- M_target[2] + S_target[1, 2] / S_target[1, 1] * (T1x - M_target[1])\n  s_target &lt;- S_target[2, 2] - S_target[1, 2]^2 / S_target[1, 1]\n  \n  # conditional transport for the second coordinate\n  T2x &lt;- qnorm(\n    pnorm(X[, 2], mean = m_source, sd = sqrt(s_source)),\n    mean = m_target, sd = sqrt(s_target)\n  )\n  \n  cbind(T1x, T2x)\n}\n\n\n\n\nThe sequential_transport_21() function.\n#' Sequential transport from N(M_source, S_source) to N(M_target, S_target),\n#' along X2, then X1 | X2\n#'\n#' @param X n x 2 matrix of source observations.\n#' @param M_source Mean vector of the source distribution (length 2).\n#' @param S_source Covariance matrix of the source distribution (2x2).\n#' @param M_target Mean vector of the target distribution.\n#' @param S_target Covariance matrix of the target distribution.\nsequential_transport_21 &lt;- function(X, M_source, S_source, M_target, S_target) {\n  \n  # marginal univariate transport along X_2\n  T2x &lt;- qnorm(\n    pnorm(X[, 2], mean = M_source[2], sd = sqrt(S_source[2, 2])),\n    mean = M_target[2], sd = sqrt(S_target[2, 2])\n  )\n  \n  # conditional parameters for X_1 | X_2\n  m_source &lt;- M_source[1] + S_source[1, 2] / S_source[2, 2] * (X[, 2] - M_source[2])\n  s_source &lt;- S_source[1, 1] - S_source[1, 2]^2 / S_source[2, 2]\n  \n  m_target &lt;- M_target[1] + S_target[1, 2] / S_target[2, 2] * (T2x - M_target[2])\n  s_target &lt;- S_target[1, 1] - S_target[1, 2]^2 / S_target[2, 2]\n  \n  # conditional transport for X1 | X_2\n  T1x &lt;- qnorm(\n    pnorm(X[, 1], mean = m_source, sd = sqrt(s_source)),\n    mean = m_target, sd = sqrt(s_target)\n  )\n  \n  cbind(T1x, T2x)\n}\n\n\nWe isolate the observations from group 0 and from group 1, and store them as matrices.\n\nX0 &lt;- as.matrix(df[df$A == 0, c(\"X1\", \"X2\")])\nX1 &lt;- as.matrix(df[df$A == 1, c(\"X1\", \"X2\")])\n\nWe then transport from group 0 to group group 1 with sequential transport, first transporting \\(X_1\\) then \\(X_2 | X_1\\).\n\nX0_st_12 &lt;- sequential_transport_12(\n  X = X0, M_source = Mu0, S_source = Sig0, M_target = Mu1, S_target = Sig1\n)\n\nWe do the same but for units in group 1 to group 0.\n\nX1_st_12 &lt;- sequential_transport_12(\n  X = X1, M_source = Mu1, S_source = Sig1, M_target = Mu0, S_target = Sig0\n)\n\nWe also transport from group 0 to group group 1 with sequential transport, first transporting \\(X_1\\) then \\(X_1 | X_2\\).\n\nX0_st_21 &lt;- sequential_transport_21(\n  X = X0, M_source = Mu0, S_source = Sig0, M_target = Mu1, S_target = Sig1\n)\n\nWe do the same but for units in group 1 to group 0.\n\nX1_st_21 &lt;- sequential_transport_21(\n  X = X1, M_source = Mu1, S_source = Sig1, M_target = Mu0, S_target = Sig0\n)\n\nAgain, we can visualize the results on a scatter plot (Figure 3.2).\n\n\nCodes to create the Figure.\n# Prepare data for the plot\nX0 &lt;- df[df$A == 0, c(\"X1\", \"X2\")]\nX1 &lt;- df[df$A == 1, c(\"X1\", \"X2\")]\n\npar(mar = c(2.1, 2.1, 2.1, 0.1), mfrow = c(2,2))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\n\n# From 0 to 1, X1 then X2----\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\ntitle(main = \"A=0 to A=1, X1 then X2\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X0_st_12, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0$X1, y0 = X0$X2,\n  x1 = X0_st_12[, 1], y1 = X0_st_12[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n# From 1 to 0, X1 then X2----\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\ntitle(main = \"A=1 to A=0, X1 then X2\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X1_st_12, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X1$X1, y0 = X1$X2,\n  x1 = X1_st_12[, 1], y1 = X1_st_12[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n# From A=0 to A=1, X2 then X1\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\ntitle(main = \"A=0 to A=1, X2 then X1\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X0_st_21, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0$X1, y0 = X0$X2,\n  x1 = X0_st_21[, 1], y1 = X0_st_21[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n# From A=1 to A=0, X2 then X1\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\ntitle(main = \"A=1 to A=0, X2 then X1\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X1_st_21, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X1$X1, y0 = X1$X2,\n  x1 = X1_st_21[, 1], y1 = X1_st_21[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n\n\n\nFigure 3.2: 500 points in each group drawn from bivariates Gaussian distributions and transported values from group 0 to group 1 (left), and from group 1 to group 0 (right), using sequential optimal transport, first transporting \\(X_1\\), then \\(X_2 \\mid X_1\\) (top), and first transporting \\(X_2\\), then \\(X_1 \\mid X_2\\) (bottom).\n\n\n\n\n\n\n\n\n\n\n3.2.3 Illustration for a Single Unit\n\ncolour_methods &lt;- c(\"OT\" = \"#CC79A7\", \"seq_1\" = \"#009E73\", \"seq_2\" = \"#D55E00\")\n\n# Focus on a unit\ni &lt;- 11\n\nX0 &lt;- df[df$A == 0, c(\"X1\", \"X2\")]\nX1 &lt;- df[df$A == 1, c(\"X1\", \"X2\")]\n\ntikz('figs/gaussian-1-transport.tex', width = 2, height = 2.2)\n\npar(mar = c(2.1, 2.1, 1.8, 0.1))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\n\n# X1 then X2\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\n# title(main = \"X1 then X2\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\n\n# Individual of interest\npoints(X0[i, ], col = adjustcolor(colGpe0, alpha = 1), pch = 15, cex = 1.5)\npoints(X0_t[i, 1], X0_t[i, 2], col = adjustcolor(colour_methods[[\"OT\"]], alpha = 1), pch = 15, cex = 1.5)\npoints(X0_st_12[i, 1], X0_st_12[i, 2], col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = 1), pch = 15, cex = 1.5)\npoints(X0_st_21[i, 1], X0_st_21[i, 2], col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = 1), pch = 15, cex = 1.5)\n\nlength_arrow &lt;- 0.1\nlwd_arrow &lt;- 2\n# OT\narrows(\n  x0 = X0$X1[i], y0 = X0$X2[i],\n  x1 = X0_t[i, 1], y1 = X0_t[i, 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"OT\"]], alpha = 1),\n  lwd = lwd_arrow, lty = 2\n)\n# Seq OT (1): X_1 first\npoints(X0_st_12[i, 1], X0$X2[i], col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5), pch = 16, cex = 1.5)\narrows(\n  x0 = X0$X1[i], y0 = X0$X2[i],\n  x1 = X0_st_12[i, 1], y1 = X0$X2[i],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = 1),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0_st_12[i, 1], y0 = X0$X2[i],\n  x1 = X0_st_12[i, 1], y1 = X0_st_12[i, 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = 1),\n  lwd = lwd_arrow\n)\n\n# Seq OT (2): X_2 first\npoints(X0$X1[i], X0_st_21[i,2], col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5), pch = 16, cex = 1.5)\narrows(\n  x0 = X0$X1[i], y0 = X0$X2[i],\n  x1 = X0$X1[i], y1 = X0_st_21[i,2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = 1),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0$X1[i], y0 = X0_st_21[i,2],\n  x1 = X0_st_21[i, 1], y1 = X0_st_21[i, 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = 1),\n  lwd = lwd_arrow\n)\n\nlegend(\n  \"topleft\", \n  legend = c(\"$x_i$ (Obs.)\", \"OT\", \"Seq. OT (1)\", \"Seq. OT (2)\"), \n  col = c(colGpe0, colour_methods[c(\"OT\", \"seq_1\", \"seq_2\")]), \n  pch = 15, pt.cex = 1.5, cex = 1,\n  bty = \"n\"\n)\n\ndev.off()\n\nquartz_off_screen \n                2 \n\nplot_to_pdf(filename = \"gaussian-1-transport\", path = \"./figs/\", keep_tex = FALSE, crop = TRUE)",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Gaussian Example</span>"
    ]
  },
  {
    "objectID": "gaussian-example.html#causal-effect",
    "href": "gaussian-example.html#causal-effect",
    "title": "3  Gaussian Example",
    "section": "3.3 Causal Effect",
    "text": "3.3 Causal Effect\nWe first generate (again) some data, using the DGP presented in Section 11.1.\n\ndf &lt;- gen_data(\n  n = 500, \n  mu0 = -1, mu1 = +1, \n  r0 = +.7, r1 = -.5, a = 1, \n  seed = 12345\n)\n\n\n3.3.1 With Causal Mediation Analysis\nLet us create a dataset, tb, with only the binary response (Y), the binary treatment (A), and the two covariates.\n\ntb &lt;- df[, c(\"Y\", \"A\", \"X1\", \"X2\")]\nA_name &lt;- \"A\"\nA_untreated &lt;- 0\nY_name &lt;- \"Y\"\n\n\nmed_mod &lt;- mediation::multimed(\n  outcome = \"Y\", \n  med.main = \"X1\", \n  med.alt = \"X2\", \n  treat = \"A\", \n  data = df\n)\n\n\n\n\n\n\n\nWarning\n\n\n\nWe do not load the {mediation} package since it creates multiple conflicts with useful functions from tidyverse (including select()).\n\n\nLet us retrieve \\(\\bar{\\delta}(0)\\) (average causal mediation effect for \\(a=0\\)):\n\n(delta_0_med &lt;- mean((med_mod$d0.lb + med_mod$d0.ub) / 2))\n\n[1] 3.877971\n\n\nThen, let us get \\(\\bar{\\zeta}(1)\\) (average direct effect for \\(a=1\\)):\n\n(zeta_1_med &lt;- mean((med_mod$z1.lb + med_mod$z1.ub) / 2))\n\n[1] 0.06515032\n\n\nWe can then compute the total causal effect:\n\n(tot_effect_med &lt;- delta_0_med + zeta_1_med)\n\n[1] 3.943122\n\n\nLet us also retrieve \\(\\bar{\\delta}(1)\\) (average causal mediation effect for \\(a=1\\)) and \\(\\bar{\\zeta}(0)\\) (average direct effect for \\(a=0\\)):\n\ndelta_1_med &lt;- mean((med_mod$d1.lb + med_mod$d1.ub) / 2)\nzeta_0_med &lt;- mean((med_mod$z0.lb + med_mod$z0.ub) / 2)\nc(delta_1_med, zeta_0_med)\n\n[1] 3.7446202 0.1985014\n\n\n\n\n3.3.2 With Optimal Transport\nWe define a function, causal_effects_cf() to compute the causal effect of \\(A\\) on the outcome \\(Y\\), for the treated individuals.\n\n#' Estimation of total causal effect using counterfactuals.\n#' \n#' @param data_untreated Dataset with the untreated units only.\n#' @param data_treated Dataset with the treated units only.\n#' @param data_cf_untreated Counterfactuals for untreated had they been treated.\n#' @param data_cf_treated Counterfactuals for treated had they been untreated.\n#' @param Y_name Name of the column with the outcome variable.\n#' @param A_name Name of the column with the treatment variable.\n#' @param A_untreated Value of the treatment for the untreated units.\n#' \n#' @returns A list:\n#' - `delta_0_i`: \\eqn{\\delta_(0)}, individual causal mediation effects for \n#'   \\eqn{a=0} (computed on untreated),\n#' - `delta_0`: \\eqn{\\bar{\\delta}(0)}, average causal mediation effect for \n#'   \\eqn{a=0} (computed on untreated),\n#' - `delta_1_i`: \\eqn{\\delta_(1)}, individual causal mediation effects for \n#'   \\eqn{a=1} (computed on treated),\n#' - `delta_1`: \\eqn{\\bar{\\delta}(1)}, average causal mediation effect for \n#'   \\eqn{a=1} (computed on treated),\n#' - `zeta_0_i`: \\eqn{\\zeta_(0)}, individual causal mediation effects for \n#'   \\eqn{a=0} (computed on treaded),\n#' - `zeta_0`: \\eqn{\\bar{\\zeta}(0)}, average causal mediation effect for \n#'   \\eqn{a=0} (computed on treated),\n#' - `zeta_1_i`: \\eqn{\\zeta_(1)}, individual causal mediation effects for \n#'   \\eqn{a=1} (computed on untreaded),\n#' - `zeta_1`: \\eqn{\\bar{\\zeta}(1)}, average causal mediation effect for \n#'   \\eqn{a=1} (computed on untreated),\n#' - `tot_effect`: \\eqb{\\tau}: average total effect (\\eqn{\\bar{\\delta}(0) + \n#'   \\bar{\\zeta}(1)}).\n#'\n#' @importFrom randomForest randomForest\n#' @importFrom dplyr pull select\n#' @importFrom stats predict\n#' @md\ncausal_effects_cf &lt;- function(data_untreated,\n                              data_treated,\n                              data_cf_untreated,\n                              data_cf_treated,\n                              Y_name,\n                              A_name,\n                              A_untreated) {\n  \n  n_untreated &lt;- nrow(data_untreated)\n  n_treated &lt;- nrow(data_treated)\n  \n  # Outcome model for untreated\n  mu_untreated_model &lt;- randomForest(\n    x = data_untreated |&gt; dplyr::select(-!!Y_name, -!!A_name),\n    y = pull(data_untreated, !!Y_name)\n  )\n  \n  # Outcome model for treated\n  mu_treated_model &lt;- randomForest(\n    x = data_treated |&gt; dplyr::select(-!!Y_name, -!!A_name),\n    y = pull(data_treated, !!Y_name)\n  )\n  \n  # Observed outcome\n  y_untreated_obs &lt;- data_untreated |&gt; pull(!!Y_name)\n  y_treated_obs &lt;- data_treated |&gt; pull(!!Y_name)\n  \n  # Natural Indirect Effect, using observed variables\n  delta_0_i &lt;- predict(mu_untreated_model, newdata = data_cf_untreated) - y_untreated_obs\n  delta_0 &lt;- mean(delta_0_i)\n  delta_1_i &lt;- y_treated_obs - predict(mu_treated_model, newdata = data_cf_treated)\n  delta_1 &lt;- mean(delta_1_i)\n  # Natural Indirect Effect, using predictions\n  delta_0_i_p &lt;- predict(mu_untreated_model, newdata = data_cf_untreated) -\n    predict(mu_untreated_model)\n  delta_0_p &lt;- mean(delta_0_i_p)\n  delta_1_i_p &lt;- predict(mu_treated_model) - \n    predict(mu_treated_model, newdata = data_cf_treated)\n  delta_1_p &lt;- mean(delta_1_i_p)\n  \n  # Natural Direct Effect\n  zeta_0_i &lt;- predict(mu_treated_model, newdata = data_cf_treated) -\n    predict(mu_untreated_model, newdata = data_cf_treated)\n  zeta_0 &lt;- mean(zeta_0_i)\n  \n  zeta_1_i &lt;- predict(mu_treated_model, newdata = data_cf_untreated) - \n    predict(mu_untreated_model, newdata = data_cf_untreated)\n  zeta_1 &lt;- mean(zeta_1_i)\n  \n  \n  # Total Causal Effect for treated\n  tot_effect &lt;- delta_0 + zeta_1\n  tot_effect_p &lt;- delta_0_p + zeta_1\n  \n  list(\n    delta_0_i = delta_0_i,\n    delta_0 = delta_0,\n    delta_1_i = delta_1_i,\n    delta_1 = delta_1,\n    zeta_0_i = zeta_0_i,\n    zeta_0 = zeta_0,\n    zeta_1_i = zeta_1_i,\n    zeta_1 = zeta_1,\n    delta_0_i_p = delta_0_i_p,\n    delta_0_p = delta_0_p,\n    delta_1_i_p = delta_1_i_p,\n    delta_1_p = delta_1_p,\n    tot_effect = tot_effect,\n    tot_effect_p = tot_effect_p\n  )\n}\n\nWe use a random forest to estimate the outcome model.\n\nlibrary(randomForest)\n\nWe apply this function to our simulated dataset.\n\ntb_untreated &lt;- tb |&gt; filter(!!sym(A_name) == !!A_untreated)\ntb_treated &lt;- tb |&gt; filter(!!sym(A_name) != !!A_untreated)\n\ncausal_effects_ot &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(X0_t),\n  data_cf_treated = as_tibble(X1_t),\n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated\n)\n\ncbind(\n  delta_0 = causal_effects_ot$delta_0,\n  zeta_1 = causal_effects_ot$zeta_1, \n  delta_1 = causal_effects_ot$delta_1,\n  zeta_0 = causal_effects_ot$zeta_0, \n  tot_effect = causal_effects_ot$tot_effect,\n  tot_effect_p = causal_effects_ot$tot_effect_p\n)\n\n       delta_0   zeta_1   delta_1   zeta_0 tot_effect tot_effect_p\n[1,] 0.9175878 3.170275 0.2363777 3.763413   4.087862     4.100477\n\n\n\n\n3.3.3 With Sequential Optimal Transport\nWe apply the same function as that used with the counterfactuals obtained with optimal transport (causal_effects_cf()). However, here, we feed it with the counterfactuals obtained with sequential transport. For those where we first transport \\(X_1\\) and then \\(X_2 \\mid X_1\\):\n\ncausal_effect_sot_12 &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(X0_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  data_cf_treated = as_tibble(X1_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated\n)\n\nAnd for the counterfactuales obtained by sequential transport where we first transport \\(X_2\\) and then \\(X_1 \\mid X_2\\):\n\ncausal_effect_sot_21 &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(X0_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  data_cf_treated = as_tibble(X1_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated\n)\n\n\n\n3.3.4 Summary\n\ntribble(\n  ~Method, ~Name, ~Value,\n  \"Theoretical\", \"delta(0)\", (a1+a2) * (mu1-mu0),\n  \"Theoretical\", \"delta(1)\", (a1+a2) * (mu1-mu0),\n  \"Theoretical\", \"zeta(0)\", a0,\n  \"Theoretical\", \"zeta(1)\", a0,\n  \"Theoretical\", \"tau\", (a1+a2) * (mu1-mu0) + a0,\n  #\n  \"Mediation\", \"delta(0)\", delta_0_med,\n  \"Mediation\", \"delta(1)\", delta_1_med,\n  \"Mediation\", \"zeta(0)\", zeta_0_med,\n  \"Mediation\", \"zeta(1)\", zeta_1_med,\n  \"Mediation\", \"tau\", tot_effect_med,\n  #\n  \"OT\", \"delta(0)\", causal_effects_ot$delta_0,\n  \"OT\", \"delta(1)\", causal_effects_ot$delta_1,\n  \"OT\", \"zeta(0)\", causal_effects_ot$zeta_0,  \n  \"OT\", \"zeta(1)\", causal_effects_ot$zeta_1,\n  \"OT\", \"tau\", causal_effects_ot$tot_effect,\n  #\n  \"OT (pred)\", \"delta(0)\", causal_effects_ot$delta_0_p,\n  \"OT (pred)\", \"delta(1)\", causal_effects_ot$delta_1_p,\n  \"OT (pred)\", \"tau\", causal_effects_ot$tot_effect_p,\n  #\n  \"SOT (1)\", \"delta(0)\", causal_effect_sot_12$delta_0,\n  \"SOT (1)\", \"delta(1)\", causal_effect_sot_12$delta_1,\n  \"SOT (1)\", \"zeta(0)\", causal_effect_sot_12$zeta_0,  \n  \"SOT (1)\", \"zeta(1)\", causal_effect_sot_12$zeta_1,\n  \"SOT (1)\", \"tau\", causal_effect_sot_12$tot_effect,\n  #\n  \"SOT (1) (pred)\", \"delta(0)\", causal_effect_sot_12$delta_0_p,\n  \"SOT (1) (pred)\", \"delta(1)\", causal_effect_sot_12$delta_1_p,\n  \"SOT (1) (pred)\", \"tau\", causal_effect_sot_12$tot_effect_p,\n  #\n  \"SOT (2)\", \"delta(0)\", causal_effect_sot_21$delta_0,\n  \"SOT (2)\", \"delta(1)\", causal_effect_sot_21$delta_1,\n  \"SOT (2)\", \"zeta(0)\", causal_effect_sot_21$zeta_0,\n  \"SOT (2)\", \"zeta(1)\", causal_effect_sot_21$zeta_1,\n  \"SOT (2)\", \"tau\", causal_effect_sot_21$tot_effect,\n  #\n  \"SOT (2) (pred)\", \"delta(0)\", causal_effect_sot_21$delta_0_p,\n  \"SOT (2) (pred)\", \"delta(1)\", causal_effect_sot_21$delta_1_p,\n  \"SOT (2) (pred)\", \"tau\", causal_effect_sot_21$tot_effect_p\n) |&gt; \n  pivot_wider(names_from = \"Name\", values_from = \"Value\")\n\n# A tibble: 8 × 6\n  Method         `delta(0)` `delta(1)` `zeta(0)` `zeta(1)`   tau\n  &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 Theoretical         1          1         3        3       4   \n2 Mediation           3.88       3.74      0.199    0.0652  3.94\n3 OT                  0.918      0.236     3.76     3.17    4.09\n4 OT (pred)           0.930      0.229    NA       NA       4.10\n5 SOT (1)             1.02       0.119     3.91     3.12    4.15\n6 SOT (1) (pred)      1.03       0.116    NA       NA       4.15\n7 SOT (2)             0.881      0.134     3.94     3.05    3.93\n8 SOT (2) (pred)      0.889      0.117    NA       NA       3.94\n\n\nIn the next page, Chapter 4, we run some simulations using the same DGP, where we make the distance between the two distributions vary.\n\n\n\n\nImai, Kosuke, Luke Keele, and Teppei Yamamoto. 2010. “Identification, Inference and Sensitivity Analysis for Causal Mediation Effects.” Statistical Science 25 (1): 51–71.\n\n\nPearl, Judea. 2001. “Direct and Indirect Effects.” In Proceedings of the Seventeenth Conference on Uncertainty and Artificial Intelligence, 2001, 411–20. Morgan Kaufmann, San Francisco.",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Gaussian Example</span>"
    ]
  },
  {
    "objectID": "gaussian-example-mc.html",
    "href": "gaussian-example-mc.html",
    "title": "4  Gaussian Example - Simulations",
    "section": "",
    "text": "5 Functions\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colA}{RGB}{255, 221, 85}\n\\definecolor{colB}{RGB}{148, 78, 223}\n\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colGpe1}{RGB}{127, 23, 14}\n\\definecolor{colGpe0}{RGB}{27, 149, 224}\n\\]\nLet us redefine the function shown in Chapter 3 that will be used to perform the simulations here.\nFunctions used to generate the data (gen_data()), create counterfactuals with optimal transport (compute_ot_map(), apply_ot_transport()) and sequential transport (sequential_transport_12(), sequential_transport_21()), compute the total causal effect based on (causal_effects_cf())\n## Data----\n\n#' @param n Number of units.\n#' @param mu0 Mean of the two covariates in group 0.\n#' @param mu1 Mean of the two covariates in group 1.\n#' @param r0 Covariance of the two covariates in group 0.\n#' @param r1 Covariance of the two covariates in group 1.\n#' @parma a Shift parameter for the mean in both groups\n#'  (default to 1: no shift). Larger values decreases overlapping.\ngen_data &lt;- function(n = 500,\n                     mu0 = -1,\n                     mu1 = +1,\n                     r0 = +.7,\n                     r1 = -.5,\n                     a = 1,\n                     seed = NULL) {\n  \n  if (!is.null(seed)) set.seed(seed)\n  \n  a0 &lt;-  3\n  a1 &lt;-  2\n  a2 &lt;-  -1.5\n  p1 &lt;- .5\n  Mu0 &lt;- rep(mu0, 2)\n  Mu1 &lt;- rep(mu1, 2)\n  Sig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\n  Sig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n  # Draw covariates\n  X0 &lt;- rmnorm(n, mean = a * Mu0, varcov = Sig0)\n  X1 &lt;- rmnorm(n, mean = a * Mu1, varcov = Sig1)\n  # Random noise\n  E &lt;- rnorm(n)\n  # Binary treatment\n  A &lt;- sample(0:1, size = n, replace = TRUE, prob = c(1 - p1, p1))\n  X &lt;- X0\n  X[A==1, ] = X1[A==1, ]\n  df &lt;- tibble(\n    X1 = X[, 1],\n    X2 = X[, 2],\n    A = A,\n    Y0 = a1 * X1 + a2 * X2 + E,\n    Y1 = a1 * X1 + a2 * X2 + a0 + E,\n    Y = A * Y1 + (1-A) * Y0\n  )\n  \n  df\n}\n\n## Optimal Transport----\n\n#' Optimal transport mapping between two Gaussian distributions \n#'  (from \\eqn{\\mathcal{N}(\\mu_{\\text{source}}, \\Sigma_{\\text{source}})} to \n#'   \\eqn{\\mathcal{N}(\\mu_{\\text{target}}, \\Sigma_{\\text{target}})})\n#'  \n#' @param mu_source Mean vector of the source Gaussian.\n#' @param sigma_source Covariance matrix of the source Gaussian.\n#' @param mu_target Mean vector of the target Gaussian.\n#' @param sigma_target Covariance matrix of the target Gaussian.\ncompute_ot_map &lt;- function(mu_source, sigma_source, mu_target, sigma_target) {\n  sqrt_sigma_source &lt;- sqrtm(sigma_source)\n  sqrt_sigma_source_inv &lt;- solve(sqrt_sigma_source)\n  \n  inner &lt;- sqrt_sigma_source %*% sigma_target %*% sqrt_sigma_source\n  sqrt_inner &lt;- sqrtm(inner)\n  \n  A &lt;- sqrt_sigma_source_inv %*% sqrt_inner %*% sqrt_sigma_source_inv\n  \n  list(A = A, shift = mu_target - A %*% mu_source)\n}\n\n#' Function to apply the transport map to simulated data\n#' \n#' @param X Observations to transport.\n#' @param mapping Optimal transport mapping (from `compute_ot_map()`)?\napply_ot_transport &lt;- function(X, mapping) {\n  A &lt;- mapping$A\n  shift &lt;- mapping$shift\n  t(apply(X, 1, function(x) as.vector(shift + A %*% x)))\n}\n\n## Sequential Optimal Transport----\n\n#' Sequential transport from N(M_source, S_source) to N(M_target, S_target),\n#' along X1, then X2 | X1\n#'\n#' @param X n x 2 matrix of source observations.\n#' @param M_source Mean vector of the source distribution (length 2).\n#' @param S_source Covariance matrix of the source distribution (2x2).\n#' @param M_target Mean vector of the target distribution.\n#' @param S_target Covariance matrix of the target distribution.\nsequential_transport_12 &lt;- function(X, \n                                    M_source, \n                                    S_source, \n                                    M_target, \n                                    S_target) {\n  \n  # marginal univariate transport along the first coordinate (X_1)\n  T1x &lt;- qnorm(\n    pnorm(X[, 1], mean = M_source[1], sd = sqrt(S_source[1, 1])),\n    mean = M_target[1], sd = sqrt(S_target[1, 1])\n  )\n  \n  # conditional parameters for X_2 | X_1\n  m_source &lt;- M_source[2] + S_source[1, 2] / S_source[1, 1] * (X[, 1] - M_source[1])\n  s_source &lt;- S_source[2, 2] - S_source[1, 2]^2 / S_source[1, 1]\n  \n  m_target &lt;- M_target[2] + S_target[1, 2] / S_target[1, 1] * (T1x - M_target[1])\n  s_target &lt;- S_target[2, 2] - S_target[1, 2]^2 / S_target[1, 1]\n  \n  # conditional transport for the second coordinate\n  T2x &lt;- qnorm(\n    pnorm(X[, 2], mean = m_source, sd = sqrt(s_source)),\n    mean = m_target, sd = sqrt(s_target)\n  )\n  \n  cbind(T1x, T2x)\n}\n\n#' Sequential transport from N(M_source, S_source) to N(M_target, S_target),\n#' along X2, then X1 | X2\n#'\n#' @param X n x 2 matrix of source observations.\n#' @param M_source Mean vector of the source distribution (length 2).\n#' @param S_source Covariance matrix of the source distribution (2x2).\n#' @param M_target Mean vector of the target distribution.\n#' @param S_target Covariance matrix of the target distribution.\nsequential_transport_21 &lt;- function(X, M_source, S_source, M_target, S_target) {\n  \n  # marginal univariate transport along X_2\n  T2x &lt;- qnorm(\n    pnorm(X[, 2], mean = M_source[2], sd = sqrt(S_source[2, 2])),\n    mean = M_target[2], sd = sqrt(S_target[2, 2])\n  )\n  \n  # conditional parameters for X_1 | X_2\n  m_source &lt;- M_source[1] + S_source[1, 2] / S_source[2, 2] * (X[, 2] - M_source[2])\n  s_source &lt;- S_source[1, 1] - S_source[1, 2]^2 / S_source[2, 2]\n  \n  m_target &lt;- M_target[1] + S_target[1, 2] / S_target[2, 2] * (T2x - M_target[2])\n  s_target &lt;- S_target[1, 1] - S_target[1, 2]^2 / S_target[2, 2]\n  \n  # conditional transport for X1 | X_2\n  T1x &lt;- qnorm(\n    pnorm(X[, 1], mean = m_source, sd = sqrt(s_source)),\n    mean = m_target, sd = sqrt(s_target)\n  )\n  \n  cbind(T1x, T2x)\n}\n\n## Causal Effect----\n\n#' Estimation of total causal effect using counterfactuals.\n#' \n#' @param data_untreated Dataset with the untreated units only.\n#' @param data_treated Dataset with the treated units only.\n#' @param data_cf_untreated Counterfactuals for untreated had they been treated.\n#' @param data_cf_treated Counterfactuals for treated had they been untreated.\n#' @param Y_name Name of the column with the outcome variable.\n#' @param A_name Name of the column with the treatment variable.\n#' @param A_untreated Value of the treatment for the untreated units.\n#' \n#' @returns A list:\n#' - `delta_0_i`: \\eqn{\\delta_(0)}, individual causal mediation effects for \n#'   \\eqn{a=0} (computed on untreated),\n#' - `delta_0`: \\eqn{\\bar{\\delta}(0)}, average causal mediation effect for \n#'   \\eqn{a=0} (computed on untreated),\n#' - `delta_1_i`: \\eqn{\\delta_(1)}, individual causal mediation effects for \n#'   \\eqn{a=1} (computed on treated),\n#' - `delta_1`: \\eqn{\\bar{\\delta}(1)}, average causal mediation effect for \n#'   \\eqn{a=1} (computed on treated),\n#' - `zeta_0_i`: \\eqn{\\zeta_(0)}, individual causal mediation effects for \n#'   \\eqn{a=0} (computed on treaded),\n#' - `zeta_0`: \\eqn{\\bar{\\zeta}(0)}, average causal mediation effect for \n#'   \\eqn{a=0} (computed on treated),\n#' - `zeta_1_i`: \\eqn{\\zeta_(1)}, individual causal mediation effects for \n#'   \\eqn{a=1} (computed on untreaded),\n#' - `zeta_1`: \\eqn{\\bar{\\zeta}(1)}, average causal mediation effect for \n#'   \\eqn{a=1} (computed on untreated),\n#' - `tot_effect`: \\eqb{\\tau}: average total effect (\\eqn{\\bar{\\delta}(0) + \n#'   \\bar{\\zeta}(1)}).\n#'\n#' @importFrom randomForest randomForest\n#' @importFrom dplyr pull select\n#' @importFrom stats predict\n#' @md\ncausal_effects_cf &lt;- function(data_untreated,\n                              data_treated,\n                              data_cf_untreated,\n                              data_cf_treated,\n                              Y_name,\n                              A_name,\n                              A_untreated) {\n  \n  n_untreated &lt;- nrow(data_untreated)\n  n_treated &lt;- nrow(data_treated)\n  \n  # Outcome model for untreated\n  mu_untreated_model &lt;- randomForest(\n    x = data_untreated |&gt; dplyr::select(-!!Y_name, -!!A_name),\n    y = pull(data_untreated, !!Y_name)\n  )\n  \n  # Outcome model for treated\n  mu_treated_model &lt;- randomForest(\n    x = data_treated |&gt; dplyr::select(-!!Y_name, -!!A_name),\n    y = pull(data_treated, !!Y_name)\n  )\n  \n  # Observed outcome\n  y_untreated_obs &lt;- data_untreated |&gt; pull(!!Y_name)\n  y_treated_obs &lt;- data_treated |&gt; pull(!!Y_name)\n  \n  # Natural Indirect Effect, using observed variables\n  delta_0_i &lt;- predict(mu_untreated_model, newdata = data_cf_untreated) - y_untreated_obs\n  delta_0 &lt;- mean(delta_0_i)\n  delta_1_i &lt;- y_treated_obs - predict(mu_treated_model, newdata = data_cf_treated)\n  delta_1 &lt;- mean(delta_1_i)\n  # Natural Indirect Effect, using predictions\n  delta_0_i_p &lt;- predict(mu_untreated_model, newdata = data_cf_untreated) -\n    predict(mu_untreated_model)\n  delta_0_p &lt;- mean(delta_0_i_p)\n  delta_1_i_p &lt;- predict(mu_treated_model) - \n    predict(mu_treated_model, newdata = data_cf_treated)\n  delta_1_p &lt;- mean(delta_1_i_p)\n  \n  # Natural Direct Effect\n  zeta_0_i &lt;- predict(mu_treated_model, newdata = data_cf_treated) -\n    predict(mu_untreated_model, newdata = data_cf_treated)\n  zeta_0 &lt;- mean(zeta_0_i)\n  \n  zeta_1_i &lt;- predict(mu_treated_model, newdata = data_cf_untreated) - \n    predict(mu_untreated_model, newdata = data_cf_untreated)\n  zeta_1 &lt;- mean(zeta_1_i)\n  \n  \n  # Total Causal Effect for treated\n  tot_effect &lt;- delta_0 + zeta_1\n  tot_effect_p &lt;- delta_0_p + zeta_1\n  \n  list(\n    delta_0_i = delta_0_i,\n    delta_0 = delta_0,\n    delta_1_i = delta_1_i,\n    delta_1 = delta_1,\n    zeta_0_i = zeta_0_i,\n    zeta_0 = zeta_0,\n    zeta_1_i = zeta_1_i,\n    zeta_1 = zeta_1,\n    delta_0_i_p = delta_0_i_p,\n    delta_0_p = delta_0_p,\n    delta_1_i_p = delta_1_i_p,\n    delta_1_p = delta_1_p,\n    tot_effect = tot_effect,\n    tot_effect_p = tot_effect_p\n  )\n}\nWe define the function sim_f() to run a single replication of the Monte-Carlo simulations. This functions proceeds in the following steps:\nsim_f &lt;- function(n = 500,\n                  mu0, \n                  mu1, \n                  r0, \n                  r1, \n                  a, \n                  seed = NULL) {\n  \n  if (!is.null(seed)) set.seed(seed)\n  \n  # 1. Generate data\n  df &lt;- gen_data(\n    n = 500, \n    mu0 = mu0, mu1 = mu1, \n    r0 = r0, r1 = r1, a = a, \n    seed = seed\n  )\n  \n  # 2. Building Counterfactuals\n  \n  ## With Optimal Transport\n  # Transporting map for source: group 1, target: group 0 (careful here)\n  Sigma0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\n  Sigma1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n  Mu0 &lt;- rep(a * mu0, 2)\n  Mu1 &lt;- rep(a * mu1, 2)\n  \n  # Mapping from group 0 to group 1\n  ot_map_0_to_1 &lt;- compute_ot_map(\n    mu_source = Mu0, sigma_source = Sigma0, \n    mu_target = Mu1, sigma_target = Sigma1\n  )\n  # Mapping from group 1 to group 0\n  ot_map_1_to_0 &lt;- compute_ot_map(\n    mu_source = Mu1, sigma_source = Sigma0, \n    mu_target = Mu0, sigma_target = Sigma0\n  )  \n\n  # Apply transport map to treated units (A = 1)\n  X0 &lt;- as.matrix(df[df$A == 0, c(\"X1\", \"X2\")])\n  X1 &lt;- as.matrix(df[df$A == 1, c(\"X1\", \"X2\")])\n  X0_t &lt;- apply_ot_transport(X = X0, mapping = ot_map_0_to_1)\n  colnames(X0_t) &lt;- c(c(\"X1\", \"X2\"))\n  X1_t &lt;- apply_ot_transport(X = X1, mapping = ot_map_1_to_0)\n  colnames(X1_t) &lt;- c(c(\"X1\", \"X2\"))\n  \n  ## With Sequential Transport\n  # Transport from group 0 to group 1: X1 then X2 | X1\n  X0_st_12 &lt;- sequential_transport_12(\n    X = X0, M_source = Mu0, S_source = Sigma0, M_target = Mu1, S_target = Sigma1\n  )\n  # Transport from group 1 to group 0: X1 then X2 | X1\n  X1_st_12 &lt;- sequential_transport_12(\n    X = X1, M_source = Mu1, S_source = Sigma1, M_target = Mu0, S_target = Sigma0\n  )\n  # Transport from group 0 to group 1: X2 then X1 | X2\n  X0_st_21 &lt;- sequential_transport_21(\n    X = X0, M_source = Mu0, S_source = Sigma0, M_target = Mu1, S_target = Sigma1\n  )\n  # Transport from group 1 to group 0: X2 then X1 | X2\n  X1_st_21 &lt;- sequential_transport_21(\n    X = X1, M_source = Mu1, S_source = Sigma1, M_target = Mu0, S_target = Sigma0\n  )\n  \n  # 3. Measuring Total Causal Effect\n  tb &lt;- df[, c(\"Y\", \"A\", \"X1\", \"X2\")]\n  A_name &lt;- \"A\"\n  A_untreated &lt;- 0\n  Y_name &lt;- \"Y\"\n  \n  # Causal Mediation Analysis\n  med_mod &lt;- mediation::multimed(\n    outcome = \"Y\", \n    med.main = \"X1\", \n    med.alt = \"X2\", \n    treat = \"A\", \n    data = tb\n  )\n  delta_0_med &lt;- mean((med_mod$d0.lb + med_mod$d0.ub) / 2)\n  delta_1_med &lt;- mean((med_mod$d1.lb + med_mod$d1.ub) / 2)\n  zeta_0_med &lt;- mean((med_mod$z0.lb + med_mod$z0.ub) / 2)\n  zeta_1_med &lt;- mean((med_mod$z1.lb + med_mod$z1.ub) / 2)\n  tot_effect_med &lt;- delta_0_med + zeta_1_med\n  \n  # With OT counterfactuals\n  tb_untreated &lt;- tb |&gt; filter(!!sym(A_name) == !!A_untreated)\n  tb_treated &lt;- tb |&gt; filter(!!sym(A_name) != !!A_untreated)\n  \n  causal_effects_ot &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_t),\n    data_cf_treated = as_tibble(X1_t),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  # With Sequential Transport counterfactuals\n  causal_effect_sot_12 &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    data_cf_treated = as_tibble(X1_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  causal_effect_sot_21 &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    data_cf_treated = as_tibble(X1_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n\n  tibble(\n    # Mediation\n    delta_0_med = delta_0_med,\n    delta_1_med = delta_1_med,\n    zeta_0_med = zeta_0_med,\n    zeta_1_med = zeta_1_med,\n    tot_effect_med = tot_effect_med,\n    # OT\n    delta_0_ot = causal_effects_ot$delta_0,\n    delta_1_ot = causal_effects_ot$delta_1,\n    delta_0_ot_p = causal_effects_ot$delta_0_p,\n    delta_1_ot_p = causal_effects_ot$delta_1_p,\n    zeta_0_ot = causal_effects_ot$zeta_0,\n    zeta_1_ot = causal_effects_ot$zeta_1,\n    tot_effect_ot = causal_effects_ot$tot_effect,\n    tot_effect_ot_p = causal_effects_ot$tot_effect_p,\n    # SOT 12\n    delta_0_sot_12 = causal_effect_sot_12$delta_0,\n    delta_1_sot_12 = causal_effect_sot_12$delta_1,\n    delta_0_sot_12_p = causal_effect_sot_12$delta_0_p,\n    delta_1_sot_12_p = causal_effect_sot_12$delta_1_p,\n    zeta_0_sot_12 = causal_effect_sot_12$zeta_0,\n    zeta_1_sot_12 = causal_effect_sot_12$zeta_1,\n    tot_effect_sot_12 = causal_effect_sot_12$tot_effect,\n    tot_effect_sot_12_p = causal_effect_sot_12$tot_effect_p,\n    # SOT 21\n    delta_0_sot_21 = causal_effect_sot_21$delta_0,\n    delta_1_sot_21 = causal_effect_sot_21$delta_1,\n    delta_0_sot_21_p = causal_effect_sot_21$delta_0_p,\n    delta_1_sot_21_p = causal_effect_sot_21$delta_1_p,\n    zeta_0_sot_21 = causal_effect_sot_21$zeta_0,\n    zeta_1_sot_21 = causal_effect_sot_21$zeta_1,\n    tot_effect_sot_21 = causal_effect_sot_21$tot_effect,\n    tot_effect_sot_21_p = causal_effect_sot_21$tot_effect_p,\n    n = n,\n    seed = seed,\n    mu0 = mu0,\n    mu1 = mu1,\n    r0 = r0,\n    r1 = r1,\n    a = a\n  )\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Gaussian Example - Simulations</span>"
    ]
  },
  {
    "objectID": "gaussian-example-mc.html#monte-carlo-simulations",
    "href": "gaussian-example-mc.html#monte-carlo-simulations",
    "title": "4  Gaussian Example - Simulations",
    "section": "5.1 Monte-Carlo Simulations",
    "text": "5.1 Monte-Carlo Simulations\nWe make the distance between the means of the Gaussian distributions of the two groups increase. With \\(\\boldsymbol{\\mu}_0 = \\begin{pmatrix}-1\\\\-1\\end{pmatrix}\\) and \\(\\boldsymbol{\\mu}_1 = \\begin{pmatrix}1\\\\1\\end{pmatrix}\\), the distance is equal to \\(1\\). We apply a scalar coefficient \\(a\\geq0\\) to the means to increase that distance: \\(a\\boldsymbol{\\mu}_0\\) and \\(a\\boldsymbol{\\mu}_1\\). We make \\(a\\) vary from 0 to 1 by steps of .1. When \\(a=0\\), the distance is equal to \\(0\\), when \\(a=2\\), the distance is equal to \\(2\\).\nWe define a grid with the different simulations.\n\ngrid_params &lt;- expand_grid(\n  mu0 = -1,\n  mu1 = +1,\n  r0 = +.7,\n  r1 = -.5,\n  a = seq(0, 2, by = .1),\n  seed = seq_len(200) # NEEDS TO BE LARGER AFTER\n)\n\nThe simulations can be run in parallel, as follows.\n\n# This chunk takes about XX minutes to run.\n# We do not evaluate when compiling the document.\n# Instead, we load previously obtained results.\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(tidyverse)\n  library(mnormt)\n  library(expm)\n  library(randomForest)\n}) |&gt;\n  invisible()\n\nclusterExport(\n  cl = cl, c(\n    \"gen_data\", \"compute_ot_map\", \"apply_ot_transport\",\n    \"sequential_transport_12\", \"sequential_transport_21\",\n    \"causal_effects_cf\", \"sim_f\", \"grid_params\"\n  )\n)\n\nres_sim &lt;- pbapply::pblapply(1:nrow(grid_params), function(i) {\n  \n  grid_params_current &lt;- grid_params[i, ]\n  \n  mu0 &lt;- grid_params_current$mu0\n  mu1 &lt;- grid_params_current$mu1\n  r0 &lt;- grid_params_current$r0\n  r1 &lt;- grid_params_current$r1\n  a &lt;- grid_params_current$a\n  seed &lt;- grid_params_current$seed\n  \n  sim_f(n = 500, mu0 = mu0, mu1 = mu1, r0 = r0, r1 = r1, a = a, seed = seed)\n}, cl = cl)\n\nstopCluster(cl)\nres_sim &lt;- list_rbind(res_sim)\n\nsave(res_sim, file = \"../output/res_sim-gaussian-mc.rda\")\n\nWe load previously obtained results:\n\nload(\"../output/res_sim-gaussian-mc.rda\")\n\n\nTotal Causal EffectNatural Indirect Effect (\\(\\delta(0)\\))Natural Indirect Effect (\\(\\delta(1)\\))Natural Direct Effect (\\(\\zeta(0)\\))Natural Direct Effect (\\(\\zeta(1)\\))\n\n\n\n\nCodes to create the Figure.\ndata_plot &lt;- res_sim |&gt; \n  dplyr::select(\n    n, seed, a,\n    tot_effect_med, tot_effect_ot, tot_effect_sot_12, tot_effect_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(tot_effect_med, tot_effect_ot, tot_effect_sot_12, tot_effect_sot_21), \n    names_to = \"type\", values_to = \"tau\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"tot_effect_med\", \"tot_effect_ot\", \n        \"tot_effect_sot_12\", \"tot_effect_sot_21\"\n      ),\n      labels = c(\"CausalMed\", \"OT\", \"Seq OT (1)\", \"Seq OT (2)\")\n    ),\n    dist_to_causal_effect = (3+a) - tau\n  )\nggplot(\n  data = data_plot,\n  mapping = aes(x = factor(a), y = dist_to_causal_effect)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"AIPW\" = \"#56B4E9\", \n      \"IPW\" = \"gray\",\n      \"CausalMed\" = \"#E69F00\",\n      \"OT\" = \"#CC79A7\", \n      \"Seq OT (1)\" = \"#009E73\", \n      \"Seq OT (2)\" = \"#D55E00\"\n    )\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = latex2exp::TeX(\"Distance $\\\\alpha$\"),\n    y = \"Distance to theoretical total causal effect\",\n  ) +\n  scale_x_discrete(\n    labels = ifelse(unique(data_plot$a) %% .5 == 0, unique(data_plot$a), \"\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\ndata_plot &lt;- res_sim |&gt; \n  dplyr::select(\n    n, seed, a, mu0, mu1,\n    delta_0_med, delta_0_ot, delta_0_sot_12, delta_0_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(delta_0_med, delta_0_ot, delta_0_sot_12, delta_0_sot_21), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"delta_0_med\", \"delta_0_ot\", \"delta_0_sot_12\", \"delta_0_sot_21\"\n      ),\n      labels = c(\"CausalMed\", \"OT\", \"Seq OT (1)\", \"Seq OT (2)\")\n    ),\n    dist_to_theo_val = 2 * (a*mu1 - a*mu0) + (-1.5) * (a*mu1 - a*mu0) - val\n  )\nggplot(\n  data = data_plot,\n  mapping = aes(x = factor(a), y = dist_to_theo_val)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"AIPW\" = \"#56B4E9\", \n      \"IPW\" = \"gray\",\n      \"CausalMed\" = \"#E69F00\",\n      \"OT\" = \"#CC79A7\", \n      \"Seq OT (1)\" = \"#009E73\", \n      \"Seq OT (2)\" = \"#D55E00\"\n    )\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = latex2exp::TeX(\"Distance $\\\\alpha$\"),\n    y = \"Distance to theoretical natural indirect effect\",\n  ) +\n  scale_x_discrete(\n    labels = ifelse(unique(data_plot$a) %% .5 == 0, unique(data_plot$a), \"\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\ndata_plot &lt;- res_sim |&gt; \n  dplyr::select(\n    n, seed, a, mu0, mu1,\n    delta_1_med, delta_1_ot, delta_1_sot_12, delta_1_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(delta_1_med, delta_1_ot, delta_1_sot_12, delta_1_sot_21), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"delta_1_med\", \"delta_1_ot\", \"delta_1_sot_12\", \"delta_1_sot_21\"\n      ),\n      labels = c(\"CausalMed\", \"OT\", \"Seq OT (1)\", \"Seq OT (2)\")\n    ),\n    dist_to_theo_val = 2 * (a*mu1 - a*mu0) + (-1.5) * (a*mu1 - a*mu0) - val\n  )\nggplot(\n  data = data_plot,\n  mapping = aes(x = factor(a), y = dist_to_theo_val)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"AIPW\" = \"#56B4E9\", \n      \"IPW\" = \"gray\",\n      \"CausalMed\" = \"#E69F00\",\n      \"OT\" = \"#CC79A7\", \n      \"Seq OT (1)\" = \"#009E73\", \n      \"Seq OT (2)\" = \"#D55E00\"\n    )\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = latex2exp::TeX(\"Distance $\\\\alpha$\"),\n    y = \"Distance to theoretical natural indirect effect\",\n  ) +\n  scale_x_discrete(\n    labels = ifelse(unique(data_plot$a) %% .5 == 0, unique(data_plot$a), \"\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\ndata_plot &lt;- res_sim |&gt; \n  dplyr::select(\n    n, seed, a, mu0, mu1,\n    zeta_0_med, zeta_0_ot, zeta_0_sot_12, zeta_0_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(zeta_0_med, zeta_0_ot, zeta_0_sot_12, zeta_0_sot_21), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"zeta_0_med\", \"zeta_0_ot\", \"zeta_0_sot_12\", \"zeta_0_sot_21\"\n      ),\n      labels = c(\"CausalMed\", \"OT\", \"Seq OT (1)\", \"Seq OT (2)\")\n    ),\n    dist_to_theo_val = 3 - val\n  )\nggplot(\n  data = data_plot,\n  mapping = aes(x = factor(a), y = dist_to_theo_val)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"AIPW\" = \"#56B4E9\", \n      \"IPW\" = \"gray\",\n      \"CausalMed\" = \"#E69F00\",\n      \"OT\" = \"#CC79A7\", \n      \"Seq OT (1)\" = \"#009E73\", \n      \"Seq OT (2)\" = \"#D55E00\"\n    )\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = latex2exp::TeX(\"Distance $\\\\alpha$\"),\n    y = \"Distance to theoretical natural direct effect\",\n  ) +\n  scale_x_discrete(\n    labels = ifelse(unique(data_plot$a) %% .5 == 0, unique(data_plot$a), \"\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\ndata_plot &lt;- res_sim |&gt; \n  dplyr::select(\n    n, seed, a, mu0, mu1,\n    zeta_1_med, zeta_1_ot, zeta_1_sot_12, zeta_1_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(zeta_1_med, zeta_1_ot, zeta_1_sot_12, zeta_1_sot_21), \n    names_to = \"type\", values_to = \"val\"\n  ) |&gt; \n  mutate(\n    type = factor(\n      type,\n      levels = c(\n        \"zeta_1_med\", \"zeta_1_ot\", \"zeta_1_sot_12\", \"zeta_1_sot_21\"\n      ),\n      labels = c(\"CausalMed\", \"OT\", \"Seq OT (1)\", \"Seq OT (2)\")\n    ),\n    dist_to_theo_val = 3 - val\n  )\nggplot(\n  data = data_plot,\n  mapping = aes(x = factor(a), y = dist_to_theo_val)\n) +\n  geom_violin(\n    mapping = aes(fill = type)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(~type, scales = \"free_x\", ncol = 2) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"AIPW\" = \"#56B4E9\", \n      \"IPW\" = \"gray\",\n      \"CausalMed\" = \"#E69F00\",\n      \"OT\" = \"#CC79A7\", \n      \"Seq OT (1)\" = \"#009E73\", \n      \"Seq OT (2)\" = \"#D55E00\"\n    )\n  ) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    x = latex2exp::TeX(\"Distance $\\\\alpha$\"),\n    y = \"Distance to theoretical natural direct effect\",\n  ) +\n  scale_x_discrete(\n    labels = ifelse(unique(data_plot$a) %% .5 == 0, unique(data_plot$a), \"\")\n  )",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Gaussian Example - Simulations</span>"
    ]
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "5  Miscellaneous functions",
    "section": "",
    "text": "Objectives\n\n\n\nThis page shows some functions used later on with the exercises. They are written in the following script file: ../scripts/utils.R.\n\n\n\ncolours &lt;- c(\n  # `0` = \"#5BBCD6\", \n  # `1` = \"#FF0000\", \n  # `0` = \"#1b95e0\",\n  # `1` = \"#7F170E\",\n  `0` = \"#00A08A\", \n  `1` = \"#F2AD00\", \n  with = \"#046C9A\", \n  without = \"#C93312\", \n  `2` = \"#0B775E\"\n)\n# Colour scale from colour of class 0 to class 1\ncolfunc &lt;- colorRampPalette(c(colours[\"0\"], colours[\"1\"]))\nscl &lt;- scales::alpha(colfunc(9),.9)\n\n\nfont_size &lt;- 20\nfont_family &lt;- \"CMU Serif\"\n\n#' Theme for ggplot2\n#'\n#' @param ... Arguments passed to the theme function.\n#' @export\n#' @importFrom ggplot2 element_rect element_text element_blank element_line unit\n#'   rel theme\n#'\ntheme_paper &lt;- function (...) {\n  theme(\n    text = element_text(family = font_family),\n    plot.background = element_rect(fill = \"transparent\", color = NA),\n    panel.background = element_rect(fill = \"transparent\", color = NA),\n    # panel.border = element_rect(fill = NA, colour = \"black\", linewidth = 1),\n    panel.border = element_blank(),\n    axis.line = element_line(color = \"black\"),\n    axis.text = element_text(color = \"black\"),\n    legend.text = element_text(size = rel(1)),\n    legend.title = element_text(size = rel(1)),\n    legend.background = element_rect(fill = \"transparent\", color = NULL),\n    # legend.position = \"bottom\",\n    # legend.direction = \"horizontal\",\n    # legend.box = \"vertical\",\n    legend.key = element_blank(),\n    panel.spacing = unit(1, \"lines\"),\n    panel.grid.major = element_line(colour = \"grey90\"),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0, size = rel(1), face = \"bold\"),\n    plot.title.position = \"plot\",\n    plot.margin = unit(c(1, 1, 1, 1), \"lines\"),\n    strip.background = element_rect(fill = NA, colour = NA),\n    strip.text = element_text(size = rel(1))\n  )\n}\n\ntheme_ggtern_paper &lt;- function(...) {\n  font_family &lt;- \"CMU Serif\"\n  font_size &lt;- 20\n  theme(\n    strip.background = element_rect(colour = \"black\", fill = NA),\n    strip.text.x = element_text(colour = \"black\"),\n    strip.text = ggtext::element_markdown(),\n    text = element_text(family = font_family, size = unit(font_size, \"pt\")),\n    axis.title = element_text(size = rel(.8)),\n    tern.axis.arrow.show = TRUE,\n    tern.axis.arrow.sep = .13,\n    tern.axis.vshift = .05,\n    panel.border = element_rect(colour = NA)\n  )\n}\n\n\n#' From plot created with {tikzDevice}, create a standalone latex document\n#' and compile it with pdflatex to save the plot as pdf\n#' \n#' @param filename Name of the tex file (WITHOUT THE EXTENSION) that contains \n#'  the tikzpicture.\n#' @param path_to_latex Path to LaTeX engine (Defaults to\n#'   `/Library/TeX/texbin/`).\n#' @param interpreter By default, use pdflatex (`pdflatex`).\n#' @param path Path to the destination folder.\n#' @param keep_tex should the tex file (only the one from the standalone doc) \n#'  be kept after compilation? Defaults to `FALSE`.\n#' @param verbose A logical value indicating whether diagnostic messages are\n#'   printed when measuring dimensions of strings. Defaults to `FALSE`.\n#' @param ignore.stdout A logical (not NA) indicating whether messages written\n#'   to ‘stdout’  should be ignored. Defaults to `TRUE`.\n#' @param crop If `TRUE` (default to `FALSE`), the PDF is cropped using pdfcrop.\n#' \nplot_to_pdf &lt;- function(filename,\n                        path_to_latex = \"/Library/TeX/texbin/\",\n                        interpreter = \"pdflatex\",\n                        path = \"./\",\n                        keep_tex = FALSE,\n                        verbose = FALSE,\n                        ignore.stdout = TRUE,\n                        crop = FALSE) {\n  content &lt;- paste0(\n    \"\\\\documentclass{standalone}\n      \\\\usepackage{amsmath,amssymb,amsthm,mathtools,graphicx}\n      \\\\usepackage{array,dcolumn}\n      %\\\\usepackage{dsfont}\n      %\\\\usepackage{fontspec}\n      \\\\renewcommand{\\\\rmdefault}{ptm}\n      \\\\renewcommand{\\\\sfdefault}{phv}\n      %\\\\setmainfont{Noto Sans}\n      %\n      \\\\usepackage{nicefrac}\n      \\\\usepackage{times}\n      %\\\\usepackage{natbib}\n      \\\\usepackage{microtype}\n      %\\\\usepackage{newtxtext,newtxmath}\n      %\\\\usepackage{times,mathpazo}\n      \\\\usepackage{pgfplots}\n      \\\\usetikzlibrary{pgfplots.groupplots}\n      \\\\usepackage{xcolor}\n      \\\\usepackage{mathptmx}\n      \\\\begin{document}\n\n      \\\\input{\",\n    path, filename,\n    \".tex}\n\n      \\\\end{document}\"\n  )\n  \n  # The file which will import the graph in tex format\n  fileConn &lt;- file(paste0(path, filename, \"_tmp.tex\"))\n  writeLines(content, fileConn)\n  close(fileConn)\n  \n  # Process tex file to get the PDF\n  system(\n    paste0(\n      path_to_latex,\n      interpreter, \" -shell-escape -synctex=1 -interaction=nonstopmode  \",\n      path,\n      filename, \"_tmp.tex\"),\n    ignore.stdout = TRUE\n  )\n  if (crop == TRUE) {\n    system(\n      paste0(\n        \"pdfcrop \", filename, \"_tmp.pdf \", filename, \"_tmp.pdf\"\n      )\n    )\n  }\n  if(!path %in%  c(\".\", \"./\", \"/\")) \n    system(paste0(\"mv \", filename, \"_tmp.pdf \", path))\n  system(paste0(\"rm \", filename, \"_tmp.aux\"))\n  system(paste0(\"rm \", filename, \"_tmp.log\"))\n  system(paste0(\"rm \", filename, \"_tmp.synctex.gz\"))\n  if (!keep_tex) {\n    system(paste0(\"rm \", path, filename, \"_tmp.tex\"))\n  }\n  system(paste0(\"mv \", path, filename, \"_tmp.pdf \", path, filename, \".pdf\"))\n}\n\n\n#' Save a ggplot2 plot as PDF, using LaTeX tikz\n#'\n#' @param plot A ggplot2 object.\n#' @param path_to_latex Path to LaTeX engine (Defaults to\n#'   `/Library/TeX/texbin/`).\n#' @param interpreter By default, use pdflatex (`pdflatex`).\n#' @param path Path to the destination folder.\n#' @param filename File name (without the extension).\n#' @param keep_tex should the tex file be kept after compilation? Defaults to\n#'   `FALSE`.\n#' @param width Width in inches (default to 15).\n#' @param height Height in inches (default to 15).\n#' @param verbose A logical value indicating whether diagnostic messages are\n#'   printed when measuring dimensions of strings. Defaults to `FALSE`.\n#' @param ignore.stdout A logical (not NA) indicating whether messages written\n#'   to ‘stdout’  should be ignored. Defaults to `TRUE`.\n#' @param crop If `TRUE` (default to `FALSE`), the PDF is cropped using pdfcrop.\n#'\n#' @importFrom tikzDevice tikz\n#' @importFrom grDevices dev.off\n#' @export\n#' @md\n#'\nggplot2_to_pdf &lt;- function(plot,\n                           path_to_latex = \"/Library/TeX/texbin/\",\n                           interpreter = \"pdflatex\",\n                           path = \"./\",\n                           filename,\n                           keep_tex = FALSE,\n                           width = 15,\n                           height = 15,\n                           verbose = FALSE,\n                           ignore.stdout = TRUE,\n                           crop = FALSE) {\n  content &lt;- paste0(\n    \"\\\\documentclass{standalone}\n      \\\\usepackage{amsmath,amssymb,amsthm,mathtools,graphicx}\n      \\\\usepackage{array,dcolumn}\n      %\\\\usepackage{dsfont}\n      %\\\\usepackage{fontspec}\n      \\\\renewcommand{\\\\rmdefault}{ptm}\n      \\\\renewcommand{\\\\sfdefault}{phv}\n      %\\\\setmainfont{Noto Sans}\n      %\n      \\\\usepackage{nicefrac}\n      \\\\usepackage{times}\n      %\\\\usepackage{natbib}\n      \\\\usepackage{microtype}\n      %\\\\usepackage{newtxtext,newtxmath}\n      %\\\\usepackage{times,mathpazo}\n      \\\\usepackage{pgfplots}\n      \\\\usetikzlibrary{pgfplots.groupplots}\n      \\\\usepackage{xcolor}\n      \\\\usepackage{mathptmx}\n      \\\\begin{document}\n\n      \\\\input{\",\n    path, filename,\n    \"_content.tex}\n\n      \\\\end{document}\"\n  )\n\n  # The file which will import the graph in tex format\n  fileConn &lt;- file(paste0(path, filename, \".tex\"))\n  writeLines(content, fileConn)\n  close(fileConn)\n\n  # Export graph to tex\n  tikz(file = paste0(\n    path,\n    filename, \"_content.tex\"),\n    width = width,\n    height = height,\n    verbose = verbose\n  )\n  print(plot)\n  dev.off()\n\n  # Move the scale from ggplot, if any\n  name_scale &lt;- paste0(filename, \"_content_ras1.png\")\n  scale_exists &lt;- file.exists(name_scale)\n  if (scale_exists & ! path %in% c(\".\", \"./\", \"/\")) {\n    system(paste0(\"mv \", name_scale, \" \", path))\n  }\n\n  # Process tex file to get the PDF\n  system(\n    paste0(\n      path_to_latex,\n      interpreter, \" -shell-escape -synctex=1 -interaction=nonstopmode  \",\n      path,\n      filename, \".tex\"),\n    ignore.stdout = TRUE\n  )\n  if (crop == TRUE) {\n    system(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\n  }\n  if(!path %in%  c(\".\", \"./\", \"/\")) system(paste0(\"mv \", filename, \".pdf \", path))\n  system(paste0(\"rm \", filename, \".aux\"))\n  system(paste0(\"rm \", filename, \".log\"))\n  system(paste0(\"rm \", filename, \".synctex.gz\"))\n  if (!keep_tex) {\n    system(paste0(\"rm \", path, filename, \".tex\"))\n    system(paste0(\"rm \", path, filename, \"_content.tex\"))\n  }\n  if (scale_exists) system(paste0(\"rm \", path, \"/\", name_scale))\n}",
    "crumbs": [
      "II. Functions for Illustrations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Miscellaneous functions</span>"
    ]
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "6  Functions for Sequential Transport",
    "section": "",
    "text": "6.1 compute_counterfactual_probs()\n#' Compute counterfactual predicted probabilities for a single observation\n#'\n#' @param i Index of the observation from group 0.\n#' @param pred_probs_0 Matrix of predicted probabilities (group 0).\n#' @param pred_probs_1 Matrix of predicted probabilities (group 1).\n#' @param weights_0 Matrix of intra-group distances for group 0.\n#' @param weights_1 Matrix of inter-group distances from group 0 to group 1.\n#' @param num_neighbors_q Number of neighbors to use.\n#'\n#' @return A vector of counterfactual predicted probabilities.\ncompute_counterfactual_probs &lt;- function(i,\n                                         pred_probs_0,\n                                         pred_probs_1,\n                                         weights_0,\n                                         weights_1,\n                                         num_neighbors_q) {\n  # Identify closest neighbours within the same group\n  dist_neigh_0 &lt;- weights_0[i, , drop = FALSE]\n  # and among the other group\n  dist_neigh_1 &lt;- weights_1[i, , drop = FALSE]\n  \n  ranks_weights_0 &lt;- order(dist_neigh_0, decreasing = TRUE)[1:num_neighbors_q]\n  ranks_weights_1 &lt;- order(dist_neigh_1, decreasing = TRUE)[1:num_neighbors_q]\n  i_rank &lt;- which(ranks_weights_0 == i)\n  \n  W_i &lt;- wasserstein_simplex(\n    X = pred_probs_0[ranks_weights_0, ],\n    Y = pred_probs_1[ranks_weights_1, ],\n    wx = dist_neigh_0[ranks_weights_0],\n    wy = dist_neigh_1[ranks_weights_1]\n  )\n  \n  # Most likely match under the transport plan\n  pred_probs_1[ranks_weights_1, ][which.max(W_i$plan[i_rank, ]), ]\n}",
    "crumbs": [
      "II. Functions for Illustrations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#ot_simplex_probs",
    "href": "functions.html#ot_simplex_probs",
    "title": "6  Functions for Sequential Transport",
    "section": "6.2 ot_simplex_probs()",
    "text": "6.2 ot_simplex_probs()\n\n#' @param pred_probs_0 Matrix with predicted probabilities to belong the each \n#'  class of the categorical variable, in group 0 (source).\n#' @param pred_probs_1 Matrix with predicted probabilities to belong the each \n#'  class of the categorical variable, in group 1 (target).\n#' @param weights_0 Weights corresponding to the distance between observations \n#'  within source group.\n#' @param weights_1 Weights corresponding to the distance between observations \n#'  within target group.\n#' @param num_neighbors_q Number of neigbors to use for categorical variables.\n#'  Default to the min between 50 and the number of observations in the data.\n#' @param cl A cluster object, created by package parallel. If `NULL` (default), \n#'   no parallel computing is used to transport categorical data.\n#'  \n#' @importFrom transportsimplex wasserstein_simplex\not_simplex_probs &lt;- function(pred_probs_0,\n                             pred_probs_1,\n                             weights_0,\n                             weights_1,\n                             num_neighbors_q = NULL,\n                             cl = NULL) {\n  \n  if (is.null(num_neighbors_q)) {\n    num_neighbors_q &lt;- min(nrow(pred_probs_0), nrow(pred_probs_1), 50)\n  } else {\n    num_neighbors_q &lt;- min(nrow(pred_probs_0), nrow(pred_probs_1), num_neighbors_q)\n  }\n  \n  mat_counter_categ &lt;- matrix(\n    NA, ncol = ncol(pred_probs_0), nrow = nrow(pred_probs_0)\n  )\n  \n  indices &lt;- seq_len(nrow(pred_probs_0))\n  \n  if (!is.null(cl)) {\n    parallel::clusterExport(\n      cl, varlist = c(\n        \"pred_probs_0\", \"pred_probs_1\", \n        \"weights_0\", \"weights_1\", \n        \"num_neighbors_q\", \"compute_counterfactual_probs\"\n      ),\n      envir = environment()\n    )\n    res &lt;- pbapply::pblapply(\n      indices, \n      compute_counterfactual_probs,\n      pred_probs_0 = pred_probs_0,\n      pred_probs_1 = pred_probs_1,\n      weights_0 = weights_0,\n      weights_1 = weights_1,\n      num_neighbors_q = num_neighbors_q,\n      cl = cl\n    )\n  } else {\n    res &lt;- pbapply::pblapply(\n      indices, compute_counterfactual_probs,\n      pred_probs_0 = pred_probs_0,\n      pred_probs_1 = pred_probs_1,\n      weights_0 = weights_0,\n      weights_1 = weights_1,\n      num_neighbors_q = num_neighbors_q\n    )\n    \n  }\n  \n  do.call(rbind, res)\n}",
    "crumbs": [
      "II. Functions for Illustrations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#get_assignment",
    "href": "functions.html#get_assignment",
    "title": "6  Functions for Sequential Transport",
    "section": "6.3 get_assignment()",
    "text": "6.3 get_assignment()\n\n#' OT for categorical variable, from source distribution to target \n#' probabilities.\n#' \n#' @param probs Propensities from the source distribution (individuals in rows,\n#'  classes in columns).\n#' @param labels Levels (labels) of the classes.\n#' @param p Vector of target probabilities. If omitted, uniform weights are \n#'  used.\n#' \nget_assignment &lt;- function(probs,\n                           labels,\n                           p = NULL) {\n  \n  n_labels &lt;- ncol(probs)\n  n &lt;- nrow(probs)\n  if (is.null(p)) p &lt;- rep(1, n_labels) / n_labels # Uniform weights\n  \n  # Unit vectors\n  vertices &lt;- diag(n_labels)\n  # colnames(vertices) &lt;- colnames()\n  # source weights\n  mass_source &lt;- rep(1 / n, n)\n  # target weights\n  mass_target &lt;- as.numeric(p)\n  \n  # Cost matrix (squared Euclidean distance)\n  cost_matrix &lt;- as.matrix(dist(rbind(probs, vertices))^2)\n  cost_matrix &lt;- cost_matrix[1:n, (n + 1):(n + n_labels)]\n  \n  # Assign each observation to one vertex\n  # by minimizing the global transport cost, while matching marginals\n  \n  # Solve the optimal transport plan\n  ot_plan &lt;- transport::transport(\n    a = mass_source, b = mass_target, costm = cost_matrix, \n    method = \"shortsimplex\"\n  )\n  \n  # Assign each sample to a category based on OT plan\n  assignment &lt;- rep(NA, n)\n  # mass each source sends to each target\n  mass_matrix &lt;- matrix(0, nrow = n, ncol = n_labels)\n  \n  for (j in 1:nrow(ot_plan)) {\n    from &lt;- ot_plan$from[j]\n    to &lt;- ot_plan$to[j]\n    mass &lt;- ot_plan$mass[j]\n    mass_matrix[from, to] &lt;- mass_matrix[from, to] + mass\n  }\n  \n  # Assign each source point to the target it contributes the most mass to\n  assignments &lt;- max.col(mass_matrix, ties.method = \"random\")\n  #factor(c(1, 2, 4), levels = 1:4, labels = c(\"A\", \"B\", \"C\", \"D\"))\n  \n  factor(assignments, levels = 1:length(labels), labels = labels)\n}",
    "crumbs": [
      "II. Functions for Illustrations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#seq_trans",
    "href": "functions.html#seq_trans",
    "title": "6  Functions for Sequential Transport",
    "section": "6.4 seq_trans()",
    "text": "6.4 seq_trans()\n\n#' Sequential Transport Using a Pre-Defined Causal Graph\n#'\n#' The sensitive attribute, S, is assumed to be a binary variable with value\n#' $S_0$ in the source distribution and $S_1$ in the target distribution.\n#'\n#' @param data Data frame with the observations.\n#' @param adj Adjacency matrix for the causal graph.\n#' @param s Name of the sensitive attribute column in the data.\n#' @param S_0 Label of the sensitive attribute in the source distribution.\n#' @param y Name of the outcome variable in the data.\n#' @param num_neighbors Number of neighbors to use in the weighted quantile\n#'        estimation. Default to 5.\n#' @param num_neighbors_q Number of neigbors to use for categorical variables.\n#'  Default to the min between 50 and the number of observations in the data.\n#' @param silent If `TRUE`, the messages showing progress in the estimation are\n#'        not shown. Default to `silent=FALSE`.\n#' @param cl A cluster object, created by package parallel. If `NULL` (default), \n#'   no parallel computing is used to transport categorical data. Otherwise, \n#'   only used to transport categorical data.\n#'\n#' @returns An element of class `\"sequential_transport\"` (a list):\n#' * `transported`: A named list with the transported values. The names are those of the variables.\n#' * `weights`: A list with the weights of each observation in the two groups.\n#' * `ecdf`: A list with empirical distribution functions for numerical variables.\n#' * `ecdf_values`: A list with the values of the ecdf evaluated for each observation in the source distribution.\n#' * `fit_for_categ`: A list with the estimated multinomial models to predict categories using parents characteristics\n#' * `params`: A list with some parameters used to transport observations:\n#'     * `adj`: Adjacency matrix.\n#'     * `top_order`: Topological ordering.\n#'     * `s`: Name of the sensitive attribute.\n#'     * `S_0`: Label of the sensitive attribute in the source distribution.\n#'     * `S_1`: Label of the sensitive attribute in the target distribution.\n#'     * `y`: Name of the outcome variable in the data.\n#'     * `num_neighbors`: Number of neighbors used when computing quantiles.\n#' @md\n#' @export\n#'\n#' @examples\n#' # Data with two groups: S=0, S=1, an outcome Y and two covariates X1 and X2\n#' sim_dat &lt;- simul_dataset()\n#' # Causal graph:\n#' variables &lt;- c(\"S\", \"X1\", \"X2\", \"Y\")\n#' adj &lt;- matrix(\n#'   # S  X1 X2 Y\n#'   c(0, 1, 1, 1,# S\n#'     0, 0, 1, 1,# X1\n#'     0, 0, 0, 1,# X2\n#'     0, 0, 0, 0  # Y\n#'   ),\n#'   ncol = length(variables),\n#'   dimnames = rep(list(variables), 2),\n#'   byrow = TRUE\n#' )\n#' # To visualize the causal graph:\n#' # causal_graph &lt;- fairadapt::graphModel(adj)\n#' # plot(causal_graph)\n#'\n#' # Sequential transport according to the causal graph\n#' transported &lt;- seq_trans(data = sim_dat, adj = adj, s = \"S\", S_0 = 0, y = \"Y\")\n#' transported\n#' # Transported values from S=0 to S=1, using the causal graph.\n#' transported_val &lt;- as.data.frame(transported$transported)\n#' head(transported_val)\n#' @importFrom stats predict ecdf quantile\n#' @importFrom dplyr across filter mutate pull select\n#' @importFrom tidyselect where\n#' @importFrom rlang sym !! := is_character\n#' @importFrom cluster daisy\n#' @importFrom Hmisc wtd.quantile\n#' @importFrom nnet multinom\n#' @importFrom purrr map_chr\n#' @seealso [seq_trans_new()], [simul_dataset()]\nseq_trans &lt;- function(data,\n                      adj,\n                      s,\n                      S_0,\n                      y,\n                      num_neighbors = 5,\n                      num_neighbors_q = NULL,\n                      silent = FALSE,\n                      cl = NULL) {\n  # Make sure character variables are encoded as factors\n  data &lt;-\n    data |&gt;\n    mutate(across(where(is_character), ~as.factor(.x)))\n  \n  s_unique &lt;- unique(data[[s]])\n  S_1 &lt;- s_unique[s_unique != S_0]\n  \n  # Topological ordering\n  top_order &lt;- seqtransfairness::topological_ordering(adj)\n  variables &lt;- top_order[!top_order %in% c(s, y)]\n  # Observations in group S_0\n  data_0 &lt;- data |&gt; filter(!!sym(s) == !!S_0)\n  data_1 &lt;- data |&gt; filter(!!sym(s) != !!S_0)\n  \n  # Lists where results will be stored\n  list_transported &lt;- list()  # Transported values\n  list_transported_prob &lt;- list()  # Transported prob. for categ. variables\n  list_weights &lt;- list()      # Weights\n  list_ecdf &lt;- list()         # Empirical dist. function\n  list_ecdf_values &lt;- list()  # Evaluated values of the ecdf\n  fit_for_categ &lt;- list()     # Fitted multinomial models for categ. variables\n  gower_matrix_all &lt;- NULL    # Distance between observations\n  \n  for (x_name in variables) {\n    if (silent == FALSE) cat(\"Transporting \", x_name, \"\\n\")\n    # Names of the parent variables\n    parents &lt;- colnames(adj)[adj[, x_name] == 1]\n    # values of current x in each group\n    x_S0 &lt;- data_0 |&gt; pull(!!x_name)\n    x_S1 &lt;- data_1 |&gt; pull(!!x_name)\n    # Check whether X is numeric\n    is_x_num &lt;- is.numeric(x_S0)\n    # Characteristics of the parent variables (if any)\n    parents_characteristics &lt;- data_0 |&gt; select(!!parents, -!!s)\n    \n    if (length(parents_characteristics) &gt; 0) {\n      \n      data_0_parents &lt;- data_0 |&gt; select(!!parents) |&gt; select(-!!s)\n      data_1_parents &lt;- data_1 |&gt; select(!!parents) |&gt; select(-!!s)\n      # Weights in S_0\n      weights_S0 &lt;- as.matrix(daisy(data_0_parents, metric = \"gower\"))\n      tot_weights_S0 &lt;- apply(weights_S0, MARGIN = 1, sum)\n      # Weights in S_1\n      # First, we need to get the transported values for the parents, if necessary\n      data_0_parents_t &lt;- data_0_parents #init\n      for (parent in parents) {\n        # does the parent depend on the sensitive variable\n        if (parent %in% names(list_transported)) {\n          data_0_parents_t &lt;-\n            data_0_parents_t |&gt;\n            mutate(!!sym(parent) := list_transported[[parent]])\n        }\n      }\n      # Unfortunately, we will compute a lot of distances not needed\n      combined &lt;- rbind(data_0_parents_t, data_1_parents)\n      gower_dist &lt;- daisy(combined, metric = \"gower\")\n      gower_matrix &lt;- as.matrix(gower_dist)\n      n_0 &lt;- nrow(data_0_parents_t)\n      n_1 &lt;- nrow(data_1_parents)\n      weights_S1 &lt;- gower_matrix[1:n_0, (n_0 + 1):(n_0 + n_1), drop = FALSE]\n      weights_S1 &lt;- weights_S1 + 1e-8\n      weights_S1 &lt;- 1 / (weights_S1)^2\n      tot_weights_S1 &lt;- apply(weights_S1, MARGIN = 1, sum)\n      \n      if (is_x_num == TRUE) {\n        # Numerical variable to transport\n        \n        # Empirical distribution function\n        f &lt;- rep(NA, length(x_S0))\n        for (i in 1:length(x_S0)) {\n          f[i] &lt;- weights_S0[i, ] %*% (x_S0 &lt;= x_S0[i]) / tot_weights_S0[i]\n        }\n        list_ecdf_values[[x_name]] &lt;- f\n        f[f==1] &lt;- 1-(1e-8)\n        \n        # Transported values\n        transported &lt;- rep(NA, length(x_S0))\n        for (i in 1:length(x_S0)) {\n          wts &lt;- weights_S1[i, ]\n          wts[-order(wts, decreasing = TRUE)[1:num_neighbors]] &lt;- 0\n          transported[i] &lt;- Hmisc::wtd.quantile(\n            x = x_S1, weights = weights_S1[i, ], probs = f[i]\n          ) |&gt; suppressWarnings()\n        }\n      } else {\n        # X is non numeric and has parents\n        x_labels &lt;- data |&gt; pull(!!x_name) |&gt; levels()\n        # Estimation of propensity in source group\n        fit_categ_0 &lt;- nnet::multinom(\n          paste(x_name, \"~ .\"),\n          data = data_0 |&gt; select(-!!y),\n          trace = FALSE\n        )\n        # Estimation of propensity in target group\n        fit_categ_1 &lt;- nnet::multinom(\n          paste(x_name, \"~ .\"),\n          data = data_1 |&gt; select(-!!y),\n          trace = FALSE\n        )\n        \n        # Predictions with these models:\n        pred_probs_0 &lt;- predict(fit_categ_0, type = \"probs\")\n        pred_probs_1 &lt;- predict(fit_categ_1, type = \"probs\")\n        \n        if (length(x_labels) == 2) {\n          # Binary\n          # Empirical distribution function\n          f &lt;- rep(NA, length(pred_probs_0))\n          for (i in 1:length(pred_probs_0)) {\n            f[i] &lt;- weights_S0[i, ] %*% (pred_probs_0 &lt;= pred_probs_0[i]) / tot_weights_S0[i]\n          }\n          list_ecdf_values[[x_name]] &lt;- f\n          f[f==1] &lt;- 1-(1e-8)\n          \n          # Transported values\n          pred_probs_0_t &lt;- rep(NA, length(pred_probs_0))\n          for (i in 1:length(pred_probs_0)) {\n            wts &lt;- weights_S1[i, ]\n            wts[-order(wts, decreasing = TRUE)[1:num_neighbors]] &lt;- 0\n            pred_probs_0_t[i] &lt;- Hmisc::wtd.quantile(\n              x = pred_probs_1, weights = weights_S1[i, ], probs = f[i]\n            ) |&gt; suppressWarnings()\n          }\n          pred_probs_0_t &lt;- cbind(pred_probs_0_t, 1-pred_probs_0_t)\n          transported &lt;- get_assignment(\n            probs = pred_probs_0_t, \n            labels = x_labels, \n            p = table(data_1 |&gt; pull(!!x_name)) / nrow(data_1)\n          )\n        } else {\n          # Categorical with more than two classes\n          \n          # If some classes are in a group but not in the other\n          if (!all(x_labels %in% colnames(pred_probs_0))) {\n            small_prob &lt;- min(pred_probs_0/2, 1e-8)\n            # Identify missing columns\n            x_labels_missing_0 &lt;- \n              x_labels[which(! x_labels %in% colnames(pred_probs_0))]\n            # set those to a tiny value\n            pred_probs_0_missing &lt;- matrix(\n              rep(small_prob, n_0 * length(x_labels_missing_0)), \n              ncol = length(x_labels_missing_0)\n            )\n            colnames(pred_probs_0_missing) &lt;- x_labels_missing_0\n            # Add column(s) to the prediction matrix\n            pred_probs_0 &lt;- cbind(pred_probs_0, pred_probs_0_missing)\n            # Normalize the probabilities\n            pred_probs_0 &lt;- pred_probs_0 / rowSums(pred_probs_0)\n          }\n          \n          # Same for other group\n          if (!all(x_labels %in% colnames(pred_probs_1))) {\n            small_prob &lt;- min(pred_probs_1/2, 1e-8)\n            # Identify missing columns\n            x_labels_missing_1 &lt;- \n              x_labels[which(! x_labels %in% colnames(pred_probs_1))]\n            # set those to a tiny value\n            pred_probs_1_missing &lt;- matrix(\n              rep(small_prob, n_1 * length(x_labels_missing_1)), \n              ncol = length(x_labels_missing_1)\n            )\n            colnames(pred_probs_1_missing) &lt;- x_labels_missing_1\n            # Add column(s) to the prediction matrix\n            pred_probs_1 &lt;- cbind(pred_probs_1, pred_probs_1_missing)\n            # Normalize the probabilities\n            pred_probs_1 &lt;- pred_probs_1 / rowSums(pred_probs_1)\n          }\n          \n          pred_probs_0_t &lt;- ot_simplex_probs(\n            pred_probs_0 = pred_probs_0, \n            pred_probs_1 = pred_probs_1, \n            weights_0 = 1 / (weights_S0 + 1e-8)^2, \n            weights_1 = weights_S1, \n            num_neighbors_q = num_neighbors_q,\n            cl = cl\n          )\n          \n          # Target prob\n          target_prob &lt;- table(data_1 |&gt; pull(!!x_name)) / nrow(data_1)\n          \n          transported &lt;- get_assignment(\n            probs = pred_probs_0_t, \n            labels = x_labels, \n            p = target_prob\n          )\n        }\n        \n        fit_for_categ[[x_name]] &lt;- list(\n          \"source\" = fit_categ_0,\n          \"target\" = fit_categ_1\n        )\n        colnames(pred_probs_0_t) &lt;- x_labels\n        list_transported_prob[[x_name]] &lt;- pred_probs_0_t\n      }\n      list_transported[[x_name]] &lt;- transported\n      \n      # Store weights for possible later use\n      list_weights[[x_name]] &lt;- list(\n        w_S0 = list(weights = weights_S0, tot_weights = tot_weights_S0),\n        w_S1 = list(weights = weights_S1, tot_weights = tot_weights_S1)\n      )\n    } else {\n      # No parents\n      if (is_x_num == TRUE) {\n        # X is numerical and has no parents\n        F_X_S0 &lt;- ecdf(x_S0)\n        list_ecdf[[x_name]] &lt;- F_X_S0\n        f &lt;- F_X_S0(x_S0)\n        list_ecdf_values[[x_name]] &lt;- f\n        transported &lt;- as.numeric(quantile(x_S1, probs = f))\n      } else {\n        # X is not numerical and has no parents\n        x_labels &lt;- data |&gt; pull(!!x_name) |&gt; levels()\n        # Estimation of propensity in source group\n        fit_categ_0 &lt;- nnet::multinom(\n          paste(x_name, \"~ .\"),\n          data = data_0 |&gt; select(-!!y),\n          trace = FALSE\n        )\n        # Estimation of propensity in target group\n        fit_categ_1 &lt;- nnet::multinom(\n          paste(x_name, \"~ .\"),\n          data = data_1 |&gt; select(-!!y),\n          trace = FALSE\n        )\n        # Predictions with these models:\n        pred_probs_0 &lt;- predict(fit_categ_0, type = \"probs\")\n        pred_probs_1 &lt;- predict(fit_categ_1, type = \"probs\")\n        \n        if (length(x_labels) == 2) {\n          # Binary variable\n          F_pred_probs_S0 &lt;- ecdf(pred_probs_0)\n          list_ecdf[[x_name]] &lt;- F_pred_probs_S0\n          f &lt;- F_pred_probs_S0(pred_probs_0)\n          list_ecdf_values[[x_name]] &lt;- f\n          pred_probs_0_t &lt;- as.numeric(quantile(pred_probs_1, probs = f))\n          pred_probs_0_t &lt;- cbind(pred_probs_0_t, 1-pred_probs_0_t)\n          transported &lt;- get_assignment(\n            probs = pred_probs_0_t, \n            labels = x_labels, \n            p = table(data_1 |&gt; pull(!!x_name)) / nrow(data_1)\n          )\n          colnames(pred_probs_0_t) &lt;- x_labels\n        } else {\n          # More than two classes\n          \n          # If some classes are in a group but not in the other\n          if (!all(x_labels %in% colnames(pred_probs_0))) {\n            small_prob &lt;- min(pred_probs_0/2, 1e-8)\n            # Identify missing columns\n            x_labels_missing_0 &lt;- \n              x_labels[which(! x_labels %in% colnames(pred_probs_0))]\n            # set those to a tiny value\n            pred_probs_0_missing &lt;- matrix(\n              rep(small_prob, n_0 * length(x_labels_missing_0)), \n              ncol = length(x_labels_missing_0)\n            )\n            colnames(pred_probs_0_missing) &lt;- x_labels_missing_0\n            # Add column(s) to the prediction matrix\n            pred_probs_0 &lt;- cbind(pred_probs_0, pred_probs_0_missing)\n            # Normalize the probabilities\n            pred_probs_0 &lt;- pred_probs_0 / rowSums(pred_probs_0)\n          }\n          \n          # Same for other group\n          if (!all(x_labels %in% colnames(pred_probs_1))) {\n            small_prob &lt;- min(pred_probs_1/2, 1e-8)\n            # Identify missing columns\n            x_labels_missing_1 &lt;- \n              x_labels[which(! x_labels %in% colnames(pred_probs_1))]\n            # set those to a tiny value\n            pred_probs_1_missing &lt;- matrix(\n              rep(small_prob, n_1 * length(x_labels_missing_1)), \n              ncol = length(x_labels_missing_1)\n            )\n            colnames(pred_probs_1_missing) &lt;- x_labels_missing_1\n            # Add column(s) to the prediction matrix\n            pred_probs_1 &lt;- cbind(pred_probs_1, pred_probs_1_missing)\n            # Normalize the probabilities\n            pred_probs_1 &lt;- pred_probs_1 / rowSums(pred_probs_1)\n          }\n          \n          mapping &lt;- wasserstein_simplex(\n            X = pred_probs_0, Y = pred_probs_1\n          )\n          pred_probs_0_t &lt;- counterfactual_w(\n            mapping = mapping, X0 = pred_probs_0, X1 = pred_probs_1\n          )\n          transported &lt;- get_assignment(\n            probs = pred_probs_0_t, \n            labels = x_labels, \n            p = table(data_1 |&gt; pull(!!x_name)) / nrow(data_1)\n          )\n          colnames(pred_probs_0_t) &lt;- x_labels\n        }\n        list_transported_prob[[x_name]] &lt;- pred_probs_0_t\n      }\n      list_transported[[x_name]] &lt;- transported\n    }\n  }\n  \n  structure(\n    list(\n      transported = list_transported,\n      transported_prob = list_transported_prob,\n      weights = list_weights,\n      ecdf = list_ecdf,\n      ecdf_values = list_ecdf_values,\n      fit_for_categ = fit_for_categ,\n      params = list(\n        adj = adj,\n        top_order = top_order,\n        s = s,\n        S_0 = S_0,\n        S_1 = S_1,\n        y = y,\n        num_neighbors = num_neighbors\n      )\n    ),\n    class = \"sequential_transport\"\n  )\n}",
    "crumbs": [
      "II. Functions for Illustrations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#compute_pdist_simplex_fast",
    "href": "functions.html#compute_pdist_simplex_fast",
    "title": "6  Functions for Sequential Transport",
    "section": "6.5 compute_pdist_simplex_fast()",
    "text": "6.5 compute_pdist_simplex_fast()\n\n#' Pairwise distance matrix on the simplex\n#'\n#' @description\n#' Computes the pairwise distance matrix of observations in the simplex, using\n#' the cost function for optimal transport on the unit simplex as the distance\n#' metric.\n#'\n#' @param X Matrix of observations (one observation per row).\n#' @param Y Matrix of observations (one observation per row).\n#'\n#' @returns A matrix of size n x m, where n is the number of observation in X,\n#'  and m is the number of observations in Y, containing the distances between\n#'  observations in X and Y.\n#' @noRd\ncompute_pdist_simplex_fast &lt;- function(X, Y) {\n  p &lt;- ncol(X)\n  invX &lt;- 1 / X\n  \n  # R[j,i] = sum_k Y[j,k] * invX[i,k]\n  R &lt;- Y %*% t(invX)\n  \n  logXmean &lt;- rowMeans(log(X))\n  logYmean &lt;- rowMeans(log(Y))\n  \n  # M[i,j] = log(R[j,i]) - log(p) - logYmean[j] + logXmean[i]\n  M_t &lt;- log(R) - log(p) -\n    outer(logYmean, rep(1, length(logXmean))) +\n    outer(rep(1, length(logYmean)), logXmean)\n  \n  t(M_t)\n}",
    "crumbs": [
      "II. Functions for Illustrations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#wass_lp",
    "href": "functions.html#wass_lp",
    "title": "6  Functions for Sequential Transport",
    "section": "6.6 wass_lp()",
    "text": "6.6 wass_lp()\n\n#' Solving the Optimal Transport Problem\n#'\n#' @description\n#' Finds the optimal transport plan using linear programming.\n#' In a first attempts, it uses `CVXR::solve` with the OSQP solver.\n#' If this fails, it uses `lpSolve::lp` instead.\n#' The function minimizes the transport cost while ensuring:\n#' * Mass conservation (row and column sums match the marginals).\n#' * Nonnegative transport flows.\n#'\n#' @param dxy Cost matrix of transport distances between points in X and Y.\n#' @param wx Weights (marginal distribution) for X.\n#' @param wy Weights (marginal distribution) for Y.\n#' @param p Order of the Wassterstein distance. (If p=2: squared Euclidean\n#'  cost).\n#'\n#' @importFrom CVXR Variable Minimize matrix_trace Problem solve\n#' @importFrom lpSolve lp\n#'\n#' @noRd\nwass_lp &lt;- function(dxy,\n                    wx,\n                    wy,\n                    p) {\n  cxy    &lt;- dxy\n  m      &lt;- length(wx)\n  ww_m   &lt;- matrix(wx, ncol = 1)\n  n      &lt;- length(wy)\n  ww_n   &lt;- matrix(wy, nrow = 1)\n  ones_m &lt;- matrix(rep(1, n), ncol = 1)\n  ones_n &lt;- matrix(rep(1, m), nrow = 1)\n  plan   &lt;- CVXR::Variable(m, n)\n  \n  wd.obj    &lt;- CVXR::Minimize(CVXR::matrix_trace(t(cxy) %*% plan))\n  wd.const1 &lt;- list(plan &gt;= 0)\n  wd.const2 &lt;- list(plan %*% ones_m == ww_m, ones_n %*% plan == ww_n)\n  wd.prob   &lt;- CVXR::Problem(wd.obj, c(wd.const1, wd.const2))\n  wd.solve  &lt;- CVXR::solve(wd.prob, solver = \"OSQP\")\n  \n  if (all(wd.solve$status==\"optimal\")) {\n    # successful\n    gamma &lt;- wd.solve$getValue(plan)\n    value &lt;- (base::sum(gamma * cxy))\n  } else {\n    # failed : use lpsolve\n    cxy &lt;- (dxy)\n    m   &lt;- nrow(cxy)\n    n   &lt;- ncol(cxy)\n    \n    c  &lt;- as.vector(cxy)\n    A1 &lt;- base::kronecker(matrix(1, nrow = 1, ncol = n), diag(m))\n    A2 &lt;- base::kronecker(diag(n), matrix(1, nrow = 1, ncol = m))\n    A  &lt;- rbind(A1, A2)\n    \n    f.obj &lt;- c\n    f.con &lt;- A\n    f.dir &lt;- rep(\"==\", nrow(A))\n    f.rhs &lt;- c(rep(1 / m, m), rep(1 / n, n))\n    f.sol &lt;- (lpSolve::lp(\"min\", f.obj, f.con, f.dir, f.rhs))\n    \n    gamma &lt;- matrix(f.sol$solution, nrow = m)\n    value &lt;- (sum(gamma*cxy)^(1 / p))\n  }\n  list(distance = value, plan = gamma)\n}",
    "crumbs": [
      "II. Functions for Illustrations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#valid_single_marginal",
    "href": "functions.html#valid_single_marginal",
    "title": "6  Functions for Sequential Transport",
    "section": "6.7 valid_single_marginal()",
    "text": "6.7 valid_single_marginal()\n\n#' Ensures that a weight vector (marginal distribution) is valid\n#'\n#' @description\n#' Returns a uniform weight if the provided vector if NULL. Otherwise, checks\n#' if the vector has length M and nonnegative entries, and if so, normalizes\n#' the vector of weights to sum to 1.\n#'\n#' @param mvec (Optional) Vector of weights.\n#' @param M Length of the weight vector.\n#' @param fname Name of the distance used (string).\n#' @noRd\nvalid_single_marginal &lt;- function(mvec, M, fname) {\n  dname &lt;- paste0(\"'\", deparse(substitute(mvec)), \"'\")\n  if ((length(mvec) == 0) && is.null(mvec)) {\n    return(rep(1 / M, M))\n  } else {\n    mvec &lt;- as.vector(mvec)\n    if ((length(mvec) != M) || (any(mvec &lt; 0))) {\n      stop(\n        paste0(\n          \"* \", fname, \" : \", dname,\n          \" should be a nonnegative vector of length \",M,\".\"\n        )\n      )\n    }\n    return(mvec / base::sum(mvec))\n  }\n}",
    "crumbs": [
      "II. Functions for Illustrations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "functions.html#wasserstein_simplex",
    "href": "functions.html#wasserstein_simplex",
    "title": "6  Functions for Sequential Transport",
    "section": "6.8 wasserstein_simplex()",
    "text": "6.8 wasserstein_simplex()\n\n#' Wasserstein distance between two sets of probability vectors X and Y\n#'\n#' @param X Matrix of probability vectors in a first group.\n#' @param Y Matrix of probability vectors in a second group.\n#' @param wx Weights (marginal distribution) for X. Default to `NULL` (uniform\n#' weights will be used).\n#' @param wy Weights (marginal distribution) for Y. Default to `NULL` (uniform\n#' weights will be used).\n#'\n#' @returns A list with two elements:\n#' * `distance`: the Wassterstein distance\n#' * `plan`: the optimal transport plan describing how mass is transported\n#'   between X and Y.\n#' @export\nwasserstein_simplex &lt;- function(X,\n                                Y,\n                                wx = NULL,\n                                wy = NULL) {\n  ## CHECK INPUTS\n  if (is.vector(X)) {\n    X &lt;- matrix(X, ncol = 1)\n  }\n  if (is.vector(Y)) {\n    Y &lt;- matrix(Y, ncol = 1)\n  }\n  if (!is.matrix(X)) { stop(\"* wasserstein : input 'X' should be a matrix.\") }\n  if (!is.matrix(Y)) { stop(\"* wasserstein : input 'Y' should be a matrix.\") }\n  if (base::ncol(X) != base::ncol(Y)){\n    stop(\"* wasserstein : input 'X' and 'Y' should be of same dimension.\")\n  }\n  \n  # Number of observation in each matrix\n  m &lt;- base::nrow(X)\n  n &lt;- base::nrow(Y)\n  \n  wxname &lt;-  paste0(\"'\",deparse(substitute(wx)),\"'\")\n  wyname &lt;- paste0(\"'\",deparse(substitute(wy)),\"'\")\n  fname  &lt;- \"wasserstein\"\n  \n  # Weight normalization\n  par_wx &lt;- valid_single_marginal(wx, m, fname)\n  par_wy &lt;- valid_single_marginal(wy, n, fname)\n  \n  # Cost matrix\n  dist_mat  &lt;- compute_pdist_simplex_fast(X, Y)\n  \n  # Solve the optimal transport problem\n  wass_lp(dxy = dist_mat, wx = par_wx, wy = par_wy, p = 2)\n}\n\n\n\n\n\nFernandes Machado, Agathe, Arthur Charpentier, and Ewen Gallic. 2025a. “Optimal Transport on Categorical Data for Counterfactuals Using Compositional Data and Dirichlet Transport.” https://arxiv.org/abs/2501.15549.\n\n\n———. 2025b. “Sequential Conditional Transport on Probabilistic Graphs for Interpretable Counterfactual Fairness.” Proceedings of the AAAI Conference on Artificial Intelligence 39 (18): 19358–66. https://doi.org/10.1609/aaai.v39i18.34131.",
    "crumbs": [
      "II. Functions for Illustrations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Functions for Sequential Transport</span>"
    ]
  },
  {
    "objectID": "transp-categ.html",
    "href": "transp-categ.html",
    "title": "7  Counterfactuals for Categorical Features",
    "section": "",
    "text": "7.1 1-to-1 Matching\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colA}{RGB}{255, 221, 85}\n\\definecolor{colB}{RGB}{148, 78, 223}\n\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colGpeZero}{RGB}{127, 23, 14}\n\\definecolor{colGpeUn}{RGB}{27, 149, 224}\n\\]\nConsider a categorical variables \\(x \\in \\{{\\color{colA}A}, {\\color{colB}B}, {\\color{colC}C}\\}\\), with group-specific distributions. The categorical variable could be, for example, the treatment administered for a disease: A=surgery, B=medication, C=no treatment. We consider two groups (this could non-Black/Black, for example). We want to build a counterfactual category for each individual from a group to the other.\nLet Group 1 and Group 0 represent two subpopulations in which the distribution of \\(x\\) differs:\nGroup 1 could be, for example, Black individuals, whereas Group 0 could be individuals who are not Black.\nAssume that the objective is to define, for each individual in Group 1, a counterfactual category that reflects the distributional characteristics of Group 0. That is, we want to know what would be the medical treatment of a Black individuals with a given treatment (e.g., “C=no treatment) had they been non-Black.\nLet us generate a dummy data set with 100 individuals in both Group 0 and Group 1.\nA way to obtain the counterfactual for the categorical variable is to implement a 1-to-1 matching procedure.\nEach category is assigned an arbitrary numeric value (e.g., \\(A = 1\\), \\(B = 2\\), \\(C = 3\\)), allowing us to define a cost matrix based on the absolute difference between encoded categories. That is, the cost of matching an individual from Group 1 with category \\(x_{j1}\\) to an individual from Group 0 with category \\(x_{i0}\\) is given by \\(C_{ij} = |x_{i0} - x_{j1}|\\).\nA linear sum assignment problem can then be used to find the matching that minimizes the total cost across pairs.\nThe matched category from Group 0 is interpreted as the counterfactual category for the corresponding Group 1 individual.\nWe can compute the distance between the observations from Group 0 to Group 1, by setting numeric values to each category: A=1, B=2, C=3:\nx0_index &lt;- match(x0, cat_levels)\nx1_index &lt;- match(x1, cat_levels)\ncost_matrix &lt;- outer(x0_index, x1_index, function(i, j) abs(i - j))\nThe linear sum assignment problem is tackled with solve_LSAP() from {clue}.\nlibrary(clue)\nassignment &lt;- solve_LSAP(cost_matrix)\nThe mapping can be stored in a tibble.\ntb_coupling &lt;- tibble(\n  x0 = x0,\n  x1 = x1[assignment]\n) |&gt; \n  mutate(\n    cost = abs(match(x0, cat_levels) - match(x1, cat_levels))\n  )\nWe compute the number of observations from Group 1 matched with observations from Group 0 per category.\ntb_coupling |&gt; \n  group_by(x1, x0) |&gt; \n  count() |&gt; \n  group_by(x1) |&gt; \n  mutate(prop = 100 * n / sum(n))\n\n# A tibble: 5 × 4\n# Groups:   x1 [3]\n  x1    x0        n  prop\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n1 A     A        10   100\n2 B     A        20    40\n3 B     B        30    60\n4 C     A        20    50\n5 C     C        20    50\nThen, we can visualize the results, using an alluvial plot (Figure 7.1). All individuals in Group 1 with label A are matched directly to individuals in Group 0 with the same label. The remaining 40% of individuals in Group 0 labeled A are then matched to Group 1 individuals who originally had label B or C. This matching is performed probabilistically: among Group 1 individuals with label B, 60% retain their original label, and 40% are reclassified as A; among those with label C, 50% remain C, and 50% are reclassified as A.\nCodes to create the Figure.\nflow &lt;- data.frame(\n  depart = rep(LETTERS[1:3], 3),\n  category = rep(LETTERS[1:3], each = 3),\n  freq = as.vector(table(tb_coupling$x1, tb_coupling$x0))\n)\np_1 &lt;- ggplot(\n  data = flow,\n  mapping = aes(axis1 = depart, axis2 = category, y = freq)\n) +\n  geom_alluvium(aes(fill = category)) +\n  geom_stratum() +\n  scale_fill_manual(values = col_categ) +\n  geom_text(\n    stat = \"stratum\",\n    mapping = aes(label = after_stat(stratum)),\n    family = font_family\n  ) +\n  # scale_x_discrete(\n  #   limits = c(\"Group 1\", \"Group 0\"),\n  #   expand = c(0.15, 0.05)\n  # ) +\n  scale_x_discrete(\n    limits = c(\"Group 1\", \"Group 0\"),\n    labels = c(\n      \"Group 1\" = str_c(\"&lt;span style='color:\", col_group[2], \";'&gt;Group 1&lt;/span&gt;\"),\n      \"Group 0\" = str_c(\"&lt;span style='color:\", col_group[1], \";'&gt;Group 0&lt;/span&gt;\")\n    ),\n    expand = c(0.15, 0.05)\n  ) +\n  ylab(\"proportions\") + \n  scale_y_continuous(transform = ) +\n  # theme_minimal(base_size = font_size, base_family = font_family) +\n  theme_paper() +\n  theme(\n    axis.text.x = ggtext::element_markdown()\n  )\np_1\n\n\n\n\n\nFigure 7.1: Matching individuals given a categorical variable.\nThis can also be visualized on a ternary plot (Figure 7.2).\nCodes to create the Figure.\n# Create interpolated values using McCann (1997) displacement\nf_line_simplex &lt;- function(x, \n                           y, \n                           lgt = 601) {\n  \n  zx &lt;- as.numeric(clr(x))[1:2]\n  zy &lt;- as.numeric(clr(y))[1:2]\n  t &lt;- seq(0, 1, length = lgt)\n  \n  tx &lt;- cbind(\n    (1 - t) * zx[1] + t * zy[1], \n    (1 - t) * zx[2] + t * zy[2]\n  )\n  tx &lt;- cbind(tx, -(tx[, 1] + tx[, 2]))\n  df &lt;- as.data.frame(matrix(as.numeric(clrInv(tx)), lgt, 3))\n  names(df) &lt;- c(\"A\",\"B\",\"C\")\n  \n  df\n                           }\n\n# dummy dataset to create an empty ternary plot\nSB &lt;- tibble(\n  A = c(0.2, 0.3, 0.5, 0.6),\n  B = c(0.3, 0.4, 0.2, 0.1),\n  C = 1 - c(0.2, 0.3, 0.5, 0.6) - c(0.3, 0.4, 0.2, 0.1),\n  group = c(\"1\", \"1\", \"0\", \"0\")\n)\n\np_2 &lt;- ggtern(data = SB, aes(x = A, y = B, z = C)) +\n  # fake (invisible) points\n  # geom_point(size = 0.01, alpha = 0, aes(color = group)) +\n  # fake (invisible) lines\n  # geom_path(aes(color = group), data = SB, alpha = 0, show.legend = TRUE) +\n  scale_colour_manual(name = \"group\", values = col_group) +\n  guides(\n    colour = guide_legend(\n      override.aes = list(\n        linetype = \"solid\",\n        shape = NA,\n        size = 1.5,\n        alpha = 1\n      )\n    )\n  ) +\n  theme_light(base_size = font_size, base_family = font_family) +\n  theme_ggtern_paper() +\n  theme(\n    legend.title = element_text(size = font_size),\n    legend.text = element_text(size = font_size)\n    # tern.axis.hshift = .10\n  ) +\n  theme_latex(TRUE) +\n  theme_hidetitles()\n\n\np_2 &lt;- p_2 + \n  geom_text(mapping = aes(x = 0.9, y = 0.06, z = 0.08), label = p0[1], color = col_group[1], family = font_family, size = font_size-3, size.unit = \"pt\") +\n  geom_text(mapping = aes(x = 0.09, y = 0.9, z = 0.09), label = p0[2], color = col_group[1], family = font_family, size = font_size-3, size.unit = \"pt\") +\n  geom_text(mapping = aes(x = 0.08, y = 0.06, z = 0.9), label = p0[3], color = col_group[1], family = font_family, size = font_size-3, size.unit = \"pt\") + \n  geom_text(mapping = aes(x = 0.3, y = 0.1, z = 0.11), label = p1[1], color = col_group[2], family = font_family, size = font_size-3, size.unit = \"pt\") +\n  geom_text(mapping = aes(x = 0.15, y = 0.65, z = 0.25), label = p1[2], color = col_group[2], family = font_family, size = font_size-3, size.unit = \"pt\") +\n  geom_text(mapping = aes(x = 0.1, y = 0.2, z = 0.8), label = p1[3], color = col_group[2], family = font_family, size = font_size-3, size.unit = \"pt\") \n\n\nLi1 &lt;- f_line_simplex(x = c(.75, .125, .125), y = c(.125, .125, .75), lgt = 2)\nLi2 &lt;- f_line_simplex(x = c(.75, .125, .125), y = c(.125, .75, .125), lgt = 2)\np_2 &lt;- p_2 + \n  geom_line(\n    data = Li2, aes(x = A, y = B, z = C), \n    color = col_group[2], linwidth = .6,\n    arrow = arrow(length=unit(0.20,\"cm\"))\n  ) + \n  geom_line(\n    data = Li1, aes(x = A, y = B, z = C), \n    color = col_group[2], linwidth = .6,\n    arrow = arrow(length=unit(0.20,\"cm\"))\n  ) \np_2\n\n\n\n\n\nFigure 7.2: Matching individuals given a categorical variable, on a Ternary plot.\nCodes to export the figures in PDF.\np_matching_indiv &lt;- cowplot::plot_grid(\n  ggplotGrob(\n    p_1 +\n      # Remove top/bottom margin\n      theme(\n        plot.margin = ggplot2::margin(t = 0, r = 0, b = 0, l = 0)\n      )\n  ),\n  # table_grob,\n  ggplotGrob(\n    p_2 +\n      # Remove top/bottom margin\n      theme(\n        plot.background = element_rect(fill = \"transparent\", color = NA),\n        plot.margin = ggplot2::margin(t = 0, r = 0, b = 0, l = 0)\n      )\n  ),\n  rel_widths = c(1.4,1),\n  ncol = 2\n)\n\np_matching_indiv\n\nfilename &lt;- \"ternary-categ-matching-indiv\"\nggsave(\n  p_matching_indiv, file = str_c(path, filename, \".pdf\"),\n  height = 2*1.75, width = 3.75*1.75,\n  family = font_family,\n  device = cairo_pdf\n)\n# Crop PDF\nsystem(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))",
    "crumbs": [
      "III. Sequential Transport for General Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Counterfactuals for Categorical Features</span>"
    ]
  },
  {
    "objectID": "transp-categ.html#categorical-data-in-the-simplex",
    "href": "transp-categ.html#categorical-data-in-the-simplex",
    "title": "7  Counterfactuals for Categorical Features",
    "section": "7.2 Categorical Data in the Simplex",
    "text": "7.2 Categorical Data in the Simplex\nIn our example, for each observation, there exists a probability of belonging to each of the categories of the categorical variable, which is group-specific: \\(\\boldsymbol{p}_1 = (0.1, 0.5, 0.4)\\) and \\(\\boldsymbol{p}_0 = (0.5, 0.3, 0.2)\\).\nLet us generate again some observation in both groups, using the same vectors of probabilities as in Section 7.1:\n\nset.seed(1234)\nn &lt;- 100\nn0 &lt;- n1 &lt;- n\np0 &lt;- c(0.5, 0.3, 0.2)\np1 &lt;- c(0.1, 0.5, 0.4)\n# Sample category\nx0 &lt;- sample(c(\"A\", \"B\", \"C\"), size = n0, replace = TRUE, prob = p0)\nx1 &lt;- sample(c(\"A\", \"B\", \"C\"), size = n1, replace = TRUE, prob = p1)\ncat_levels &lt;- c(\"A\", \"B\", \"C\")\n\nNow, assume we were able to estimate the propensities of belonging to each category, using a classifier. Instead of really training a classifier here, we will simply draw the values from a Dirichlet distribution, using rdirichlet() from {MCMCpack}. We consider two different situations, with more or less concentration around the mean.\n\nlibrary(MCMCpack)\n\n\nFirst situation: lower concentrationSecond situation: higher concentration\n\n\n\nset.seed(12345)\nalpha_A &lt;- c(9, 3, 2)\nZ_A &lt;- as.data.frame(rdirichlet(n0 + n1, alpha_A))\nalpha_B &lt;- c(3, 11, 4)\nZ_B &lt;- as.data.frame(rdirichlet(n0 + n1, alpha_B))\nalpha_C &lt;- c(2, 3, 9)\nZ_C &lt;- as.data.frame(rdirichlet(n0 + n1, alpha_C))\n# For each observation from group 0 and matched obs from group 1, we have\n# drawn a category (A, B, or C).\n# We add drawn propensities, depending on the category\nZ &lt;- Z_A\ncategory &lt;- c(x0, x1)\nZ[category == \"B\", ] &lt;- Z_B[category == \"B\", ]\nZ[category == \"C\", ] &lt;- Z_C[category == \"C\", ]\ntb_sample_z &lt;- as_tibble(Z)\nnames(tb_sample_z) &lt;- c(\"A\", \"B\", \"C\")\ntb_sample_z$group &lt;- factor(c(rep(0, n0), rep(1, n1)), levels = c(0, 1))\n\ntb_sample_z_1 &lt;- tb_sample_z\ntb_sample_z_1\n\n# A tibble: 200 × 4\n        A     B      C group\n    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;\n 1 0.668  0.243 0.0888 0    \n 2 0.112  0.618 0.270  0    \n 3 0.214  0.571 0.215  0    \n 4 0.286  0.566 0.148  0    \n 5 0.0988 0.204 0.697  0    \n 6 0.224  0.495 0.281  0    \n 7 0.373  0.542 0.0851 0    \n 8 0.735  0.195 0.0703 0    \n 9 0.257  0.517 0.227  0    \n10 0.104  0.758 0.138  0    \n# ℹ 190 more rows\n\n\n\n\n\nset.seed(1234)\nalpha_A &lt;- c(19, 3, 2)\nZ_A &lt;- as.data.frame(rdirichlet(n0 + n1, alpha_A))\nalpha_B &lt;- c(3, 17, 2)\nZ_B &lt;- as.data.frame(rdirichlet(n0 + n1, alpha_B))\nalpha_C &lt;- c(2, 3, 17)\nZ_C &lt;- as.data.frame(rdirichlet(n0 + n1, alpha_C))\n# For each observation from group 0 and matched obs from group 1, we have\n# drawn a category (A, B, or C).\n# We add drawn propensities, depending on the category\nZ &lt;- Z_A\ncategory &lt;- c(x0, x1)\nZ[category == \"B\", ] &lt;- Z_B[category == \"B\", ]\nZ[category == \"C\", ] &lt;- Z_C[category == \"C\", ]\ntb_sample_z &lt;- as_tibble(Z)\nnames(tb_sample_z) &lt;- c(\"A\", \"B\", \"C\")\ntb_sample_z$group &lt;- factor(c(rep(0, n0), rep(1, n1)), levels = c(0, 1))\n\ntb_sample_z_2 &lt;- tb_sample_z\ntb_sample_z_2\n\n# A tibble: 200 × 4\n        A     B      C group\n    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;\n 1 0.732  0.162 0.106  0    \n 2 0.0438 0.910 0.0462 0    \n 3 0.144  0.772 0.0841 0    \n 4 0.208  0.638 0.153  0    \n 5 0.0477 0.414 0.538  0    \n 6 0.0319 0.847 0.121  0    \n 7 0.873  0.115 0.0118 0    \n 8 0.789  0.107 0.104  0    \n 9 0.265  0.627 0.108  0    \n10 0.0946 0.803 0.102  0    \n# ℹ 190 more rows\n\n\n\n\n\nThe categorical variable in the simplex, using the simulated propensity scores, can be visualized on a ternary plot, as in Figure 7.3.\n\n\nCodes to create the Figure.\np &lt;- ggtern(\n  data = tb_sample_z_1 |&gt; mutate(type = \"(1)\") |&gt; \n    bind_rows(\n      tb_sample_z_2 |&gt; mutate(type = \"(2)\")\n    ), \n  mapping = aes(x = A, y = B, z = C)) +\n  geom_point(size = 1, alpha = 0.7, mapping = aes(color = group)) +\n  scale_colour_manual(name = \"group\",values = col_group) +\n  facet_wrap(~ type) +\n  theme_light(base_size = font_size, base_family = font_family) +\n  theme_ggtern_paper() +\n  theme(\n    legend.title = element_text(size = .8 * font_size),\n    legend.text = element_text(size = .8 * font_size),\n    tern.axis.vshift = .08,\n    tern.axis.arrow.sep = .16,\n  ) +\n  # theme_latex(TRUE)\n  theme_hidetitles()\np\n\n\n\n\n\nFigure 7.3: Using propensity scores, we have of points \\(\\boldsymbol{x}_{0,i}\\)’s and \\(\\boldsymbol{x}_{1,i}\\)’s in the simplex \\(\\mathcal{S}_3\\).\n\n\n\n\n\n\n\n\n\n\nCodes to export the figures in PDF.\nfilename &lt;- \"ternary-categ-drawn\"\nggsave(\n  p, file = str_c(path, filename, \".pdf\"),\n  height = 2*1.75, width = 3.75*1.75,\n  family = font_family,\n  device = cairo_pdf\n)\n# Crop PDF\nsystem(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\n\n\nLet us apply 1-to-1 matching exactly as in Section 7.1, setting numeric values to each category: A=1, B=2, C=3.\n\nx0_index &lt;- match(x0, cat_levels)\nx1_index &lt;- match(x1, cat_levels)\ncost_matrix &lt;- outer(x0_index, x1_index, function(i, j) abs(i - j))\n# 1-1 matching\nassignment &lt;- solve_LSAP(cost_matrix)\n# Store this in a tibble\ntb_coupling &lt;- tibble(\n  x0 = x0,\n  x1 = x1[assignment]\n) |&gt; \n  mutate(\n    cost = abs(match(x0, cat_levels) - match(x1, cat_levels))\n  )\n\nThe matching can be visualized on a ternary plot (Figure 7.4).\n\nidx &lt;- which(tb_coupling$cost != 0)\n\n# Ise the plot from previous figure as a baseline\np_matching &lt;- p\n\n# Draw a line joining the matched observations.\nfor (i in idx) {\n  lines_1 &lt;- f_line_simplex(\n    x = tb_sample_z_1[i, 1:3], \n    y = tb_sample_z_1[n + assignment[i], 1:3], \n    lgt = 101\n  )\n  lines_2 &lt;- f_line_simplex(\n    x = tb_sample_z_2[i, 1:3], \n    y = tb_sample_z_2[n + assignment[i], 1:3], \n    lgt = 101\n  )\n  lines_both &lt;- as_tibble(lines_1) |&gt; mutate(type = \"(1)\") |&gt; \n    bind_rows(\n      as_tibble(lines_2) |&gt; mutate(type = \"(2)\")\n    )\n  \n  p_matching &lt;- p_matching + \n    geom_line(\n      data = lines_both, \n      mapping = aes(x = A, y = B, z = C), \n      color = col_group[2], linewidth = .2,, alpha = .5,\n      arrow = arrow(length = unit(0.20, \"cm\"))\n    )\n}\n\np_matching\n\n\n\n\nFigure 7.4: Optimal matching of \\(\\boldsymbol{p}_{0,i}\\)’s and \\(\\boldsymbol{p}_{1,i}\\)’s in the simplex \\(\\mathcal{S}_3\\).\n\n\n\n\n\n\n\n\n\n\nCodes to export the figures in PDF.\nfilename &lt;- \"ternary-categ-ot\"\nggsave(\n  p_matching, file = str_c(path, filename, \".pdf\"),\n  height = 2*1.75, width = 3.75*1.75,\n  family = font_family,\n  device = cairo_pdf\n)\n# Crop PDF\nsystem(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))",
    "crumbs": [
      "III. Sequential Transport for General Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Counterfactuals for Categorical Features</span>"
    ]
  },
  {
    "objectID": "barycentric.html",
    "href": "barycentric.html",
    "title": "8  Barycentric Centroid of Balance",
    "section": "",
    "text": "8.1 Varying \\(\\alpha\\) and \\(\\boldsymbol{p}\\).\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colA}{RGB}{255, 221, 85}\n\\definecolor{colB}{RGB}{148, 78, 223}\n\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colGpeZero}{RGB}{127, 23, 14}\n\\definecolor{colGpeUn}{RGB}{27, 149, 224}\n\\]\nLet us consider, as in Chapter 7, a categorical variable \\(x \\in \\{{\\color{colA}A}, {\\color{colB}B}, {\\color{colC}C}\\}\\), with group-specific distributions. We draw random samples from a Dirichlet distribution. Let us start with a concentration parameter \\(\\alpha=(2, 5, 3)\\). Each sample lies in the 3-dimensional simplex \\(\\mathcal{S}_3\\), and the resulting distribution has density \\(f\\) with respect to Lebesgue measure on \\(\\mathcal{S}_3\\).\nWe want to find a partition \\(R_A,R_B,R_C\\) of \\(\\mathcal{S}_3\\) such that \\[\n\\int_{R_i}f(\\boldsymbol{x})\\mathrm{d}\\boldsymbol{x}=p_i,~i\\in\\{A,B,C\\}.\n\\] We can use (classical) optimal transport theory to find partitions of the simplex that map probability mass from the Dirichlet to the discrete distribution \\(\\boldsymbol{p}=(p_A,p_B,p_C)\\), in each vertex of the simplex, \\[\n\\int_{T^{-1}(\\boldsymbol{u}_i)}f(\\boldsymbol{x})\\mathrm{d}\\boldsymbol{x}=p_i,~i\\in\\{A,B,C\\},\n\\] where \\(\\{\\boldsymbol{u}_A,\\boldsymbol{u}_B,\\boldsymbol{u}_C\\}\\) are unit vectors, vertices of the \\(\\mathcal{S}_3\\) (i.e., \\((1,0,0)\\), \\((0,1,0)\\) and \\((0,0,1)\\)).\nLet us consider for now that \\(\\boldsymbol{p}=(1/2,1/3,1/6))\\).\nEach region \\(R_i\\) corresponds to the set of points \\(\\boldsymbol{x}\\in\\mathcal{S}_3\\) such that \\(\\boldsymbol{u}_i\\) minimizes \\(\\|\\boldsymbol{x}-\\boldsymbol{u}_i\\|^2-\\phi_i\\) where \\(\\phi_i\\in\\mathbb{R}\\) is a potential offset (weight, determined via dual optimization). This structure defines a power diagram, also known as a Laguerre–Voronoi diagram (or additively weighted Voronoi diagram). These subsets form a weighted Voronoi tessellation (in barycentric space), as shown in (simplex-baryc-centr-bal-example?).\nWe can, in addition, identify the intersection, i.e., the point where the minimum of the class-wise kernel density estimates is maximized. We do it by considering a grid over which we estimate the density. We create a function, generate_simplex_grid(), to generate a grid on \\(\\mathcal{S}_3\\).\nWe create a function, get_category_density_2D(), to estimate the kernel density estumation for a given category.\nLet us create a triangular grid over (A,B,C) constrained to S_3:\nWe evaluate the KDE for data from the source distribution:\nThen, we can find the point where min(densities) is maximal.\nLet us now make \\(\\alpha\\) and \\(\\boldsymbol{p}\\) vary. We will consider \\(\\boldsymbol{\\alpha} = (1,1,1)\\) (uniform distribution), and \\(\\boldsymbol{\\alpha} = (2, 5, 3)\\); and \\(\\boldsymbol{p} = (1/3,1/3,1/3)\\), and \\(\\boldsymbol{p} = (1/2,1/3,1/6)\\).\nFor convenience, let us wrap the previous code in a function, get_data_assignment().\nCode for the get_data_assignment function\n#' @param n Number of observations to sample from the Dirichlet Distribution.\n#' @param Vector of shape parameters, or matrix of shape parameters \n#'  corresponding to the number of draw. Default to \\eqn{(1,1,1)}.\n#' @param p Vector of target probabilities. Default to \\eqn{(1/3, 1/3, 1/3)}.\n#' \nget_data_assignment &lt;- function(n,\n                                alpha = c(1, 1, 1),\n                                p = c(1, 1, 1) / 3,\n                                intersection_point = TRUE) {\n  \n  # Draw n samples\n  samples &lt;- rdirichlet(n, alpha = alpha)\n  \n  # Unit vectors of S_3\n  vertices &lt;- matrix(c(\n    1, 0, 0,  # A\n    0, 1, 0,  # B\n    0, 0, 1   # C\n  ), byrow = TRUE, ncol = 3)\n  \n  # source weights\n  mass_source &lt;- rep(1 / n, n)\n  # target weights\n  mass_target &lt;- p\n  \n  # Cost matrix (squared Euclidean distance)\n  cost_matrix &lt;- as.matrix(dist(rbind(samples, vertices))^2)\n  cost_matrix &lt;- cost_matrix[1:n, (n + 1):(n + 3)]\n  \n  # We assign eah observation to one vertex\n  # by minimizing the global transport cost, while matching marginals\n  \n  # Solve the optimal transport plan\n  ot_plan &lt;- transport::transport(\n    a = mass_source, b = mass_target, costm = cost_matrix, \n    method = \"shortsimplex\"\n  )\n  \n  # Assign each sample to a category based on OT plan\n  assignment &lt;- rep(NA, n)\n  # mass each source sends to each target\n  mass_matrix &lt;- matrix(0, nrow = n, ncol = 3)\n  \n  for (j in 1:nrow(ot_plan)) {\n    from &lt;- ot_plan$from[j]\n    to &lt;- ot_plan$to[j]\n    mass &lt;- ot_plan$mass[j]\n    mass_matrix[from, to] &lt;- mass_matrix[from, to] + mass\n  }\n  \n  # Assign each source point to the target it contributes the most mass to\n  assignment &lt;- max.col(mass_matrix, ties.method = \"first\")\n  \n  colnames(samples) &lt;- c(\"A\", \"B\", \"C\")\n  samples &lt;- \n    as_tibble(samples) |&gt; \n    mutate(category = colnames(samples)[assignment])\n  \n  #\n  # Intersection point\n  #\n  if (intersection_point == TRUE) {\n    # Create a triangular grid over (A,B,C) constrained to S_3\n    grid_points &lt;- generate_simplex_grid(resolution = 100)\n    \n    # Evaluation of KDE for data from the source distribution\n    dens_A &lt;- get_category_density_2D(\n      samples = samples, grid_points = grid_points, category_label = \"A\"\n    )\n    dens_B &lt;- get_category_density_2D(\n      samples = samples, grid_points = grid_points, category_label = \"B\"\n    )\n    dens_C &lt;- get_category_density_2D(\n      samples = samples, grid_points = grid_points, category_label = \"C\"\n    )\n    # Find point where min(densities) is maximal\n    min_dens &lt;- pmin(dens_A, dens_B, dens_C)\n    max_idx &lt;- which.max(min_dens)\n    \n    intersection_point &lt;- grid_points[max_idx, ]\n    \n    tb_intersection &lt;- as_tibble(intersection_point)\n  } else {\n    tb_intersection &lt;- NULL\n  }\n  \n  list(\n    samples = samples,\n    tb_intersection = tb_intersection\n  )\n}\nUsing get_data_assignment(), we draw samples according to \\(\\boldsymbol{\\alpha}\\) and then we find partitions of the simplex that map probability mass from the Dirichlet to the discrete distribution \\(\\boldsymbol{p}\\), in each vertex of the simplex.\nsamples_unif_unif &lt;- get_data_assignment(\n  n = n, \n  alpha = c(1, 1, 1), \n  p = c(1, 1, 1) / 3\n)\n\nsamples_unif_p &lt;- get_data_assignment(\n  n = n, \n  alpha = c(1, 1, 1), \n  p = c(3, 2, 1) / 6\n)\n\nsamples_dirichlet_unif &lt;- get_data_assignment(\n  n = n, \n  alpha = c(2, 5, 3), \n  p = c(1, 1, 1) / 3\n)\n\nsamples_dirichlet_p &lt;- get_data_assignment(\n  n = n, \n  alpha = c(2, 5, 3), \n  p = c(3, 2, 1) / 6\n)\nThe results can be visualized in simplex-baryc-centr-bal-example-full, when \\(\\mathcal{D}(\\boldsymbol{\\alpha})\\) with \\(\\boldsymbol{\\alpha}=(1, 1, 1)\\) (left) and \\(\\boldsymbol{\\alpha}=(2, 5, 3)\\) (right), when \\(\\boldsymbol{p}=(1,1,1)/3\\) (top) and \\(\\boldsymbol{p}=(3,2,1)/6\\) (bottom).\nCodes to create the Figure.\np &lt;- ggtern(\n  data = samples_unif_unif$samples |&gt; \n    mutate(distrib = \"Uniform\", p = \"(1,1,1)/3\") |&gt; \n    bind_rows(\n      samples_unif_p$samples |&gt; \n        mutate(distrib = \"Uniform\", p = \"(3,2,1)/6\")\n    ) |&gt; \n    bind_rows(\n      samples_dirichlet_unif$samples |&gt; \n        mutate(distrib = \"2_5_3\", p = \"(1,1,1)/3\")\n    ) |&gt; \n    bind_rows(\n      samples_dirichlet_p$samples |&gt; \n        mutate(distrib = \"2_5_3\", p = \"(3,2,1)/6\")\n    ) |&gt;\n    mutate(\n      distrib = factor(\n        distrib,\n        labels = c(\n          \"Uniform\" = parse(text = latex2exp::TeX(\"D(1,1,1)\")),\n          \"2_5_3\" = parse(text = latex2exp::TeX(\"$D(2,5,3)$\"))\n        )\n      ),\n      p = factor(\n        p,\n        labels = c(\n          \"(1,1,1)/3\" = parse(text = latex2exp::TeX(\"$p=(1,1,1)/3$\")),\n          \"(3,2,1)/6\" = parse(text = latex2exp::TeX(\"$p=(3,2,1)/6$\"))\n        )\n      )\n    ),\n  mapping = aes(x = A, y = B, z = C)\n) +\n  geom_point(alpha = .8, size = .5, mapping = aes(color = category)) +\n  geom_point(\n    data = samples_unif_unif$tb_intersection |&gt; \n      mutate(distrib = \"Uniform\", p = \"(1,1,1)/3\") |&gt; \n      bind_rows(\n        samples_unif_p$tb_intersection |&gt; \n          mutate(distrib = \"Uniform\", p = \"(3,2,1)/6\")\n      ) |&gt; \n      bind_rows(\n        samples_dirichlet_unif$tb_intersection |&gt; \n          mutate(distrib = \"2_5_3\", p = \"(1,1,1)/3\")\n      ) |&gt; \n      bind_rows(\n        samples_dirichlet_p$tb_intersection |&gt; \n          mutate(distrib = \"2_5_3\", p = \"(3,2,1)/6\")\n      ) |&gt;\n      mutate(\n        distrib = factor(\n          distrib,\n          labels = c(\n            \"Uniform\" = parse(text = latex2exp::TeX(\"D(1,1,1)\")),\n            \"2_5_3\" = parse(text = latex2exp::TeX(\"$D(2,5,3)$\"))\n          )\n        ),\n        p = factor(\n          p,\n          labels = c(\n            \"(1,1,1)/3\" = parse(text = latex2exp::TeX(\"$p=(1,1,1)/3$\")),\n            \"(3,2,1)/6\" = parse(text = latex2exp::TeX(\"$p=(3,2,1)/6$\"))\n          )\n        )\n      )\n  ) +\n  scale_colour_manual(values = col_categ) +\n  facet_grid(p ~ distrib, labeller = label_parsed, switch = \"y\") +\n  theme_light(base_size = font_size, base_family = font_family) +\n  theme(\n    strip.background = element_rect(colour = \"black\", fill = NA),\n    strip.text.x = element_text(colour = \"black\"),\n    strip.text.y = element_text(colour = \"black\"),\n    text = element_text(family = font_family, size = unit(font_size, \"pt\")),\n    axis.title = element_text(size = rel(.8)),\n    tern.axis.arrow.show = TRUE,\n    tern.axis.arrow.sep = .16,\n    tern.axis.vshift = .09,\n    legend.position = \"bottom\",\n    legend.title = element_text(size = .8 * font_size),\n    legend.text = element_text(size = .8 * font_size),\n    panel.border = element_rect(colour = NA)\n  ) +\n  theme_hidetitles() +\n  guides(colour = guide_legend(override.aes = list(size = 2)))\n\np\n\n\n\n\n\nFigure 8.2: Barycentric centroid of balance, when \\(\\mathcal{D}(\\boldsymbol{\\alpha})\\) with \\(\\boldsymbol{\\alpha}=(1, 1, 1)\\) (left) and \\(\\boldsymbol{\\alpha}=(2, 5, 3)\\) (right), when \\(\\boldsymbol{p}=(1,1,1)/3\\) (top) and \\(\\boldsymbol{p}=(3,2,1)/6\\) (bottom). Black dot: intersection (point where the minimum of the class-wise kernel density estimates is maximized).\nCodes to export the figure in PDF.\nfilename &lt;- \"baryc-centr-bal\"\nggsave(\n  p, file = str_c(path, filename, \".pdf\"),\n  height = 3.3*1.75, width = 3.25*1.75,\n  family = font_family,\n  device = cairo_pdf\n)\n# Crop PDF\nsystem(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))",
    "crumbs": [
      "III. Sequential Transport for General Data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Barycentric Centroid of Balance</span>"
    ]
  },
  {
    "objectID": "transport-categ-toy.html",
    "href": "transport-categ-toy.html",
    "title": "9  Transporting a Categorical Variable",
    "section": "",
    "text": "9.1 Setup\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colA}{RGB}{255, 221, 85}\n\\definecolor{colB}{RGB}{148, 78, 223}\n\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colGpeZero}{RGB}{127, 23, 14}\n\\definecolor{colGpeUn}{RGB}{27, 149, 224}\n\\]\nAs in the previous pages, assume two groups: 0 and 1. In the first group, there are \\(n_0=6\\) individuals indexed 1, 2, 3, 4, 5, 6; and in group 1, there are \\(n_1=6\\) individuals indexed 7, 8, 9, 10, 11, 12. Let \\(Y\\) denote a response variable that takes values in \\(\\mathbb{R}\\), and let \\(X\\) be a categorical variable taking values \\(\\{A,B,C\\}\\).\nLet us assume that we obtained the estimated probabilities of being in each class using a multinomial regression model. This allows to convert categorical observations \\(\\{x_{1,1},\\cdots,x_{1,n_1}\\}\\) and \\(\\{x_{0,1},\\cdots,x_{0,n_0}\\}\\) into estimated probabilities, \\(\\{\\boldsymbol{p}_{1,1},\\cdots,\\boldsymbol{p}_{1,n_1}\\}\\) and \\(\\{\\boldsymbol{p}_{0,1},\\cdots,\\boldsymbol{p}_{0,n_0}\\}\\).\nLet us create a toy example:\ngroup_0 &lt;- tribble(\n  ~i, ~x, ~p_A, ~p_B, ~p_C, ~y,\n  1, \"A\", .8,   .1,   .1,   1,\n  2, \"A\", .7,   .2,   .1,   2,\n  3, \"A\", .6,   .1,   .3,   3,\n  4, \"B\", .2,   .7,   .1,   4,\n  5, \"B\", .3,   .6,   .1,   5,\n  6, \"C\", .1,   .2,   .7,   6\n)\n\ngroup_1 &lt;- tribble(\n  ~i, ~x, ~p_A, ~p_B, ~p_C, ~y,\n  7,  \"A\", .7,  .2,   .1,   3,\n  8,  \"B\", .1,  .7,   .2,   4,\n  9,  \"B\", .6,  .2,   .2,   5,\n  10, \"B\", .2,  .5,   .3,   6,\n  11, \"C\", .3,  .1,   .6,   7,\n  12, \"C\", .1,  .3,   .6,   8\n)",
    "crumbs": [
      "III. Sequential Transport for General Data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transporting a Categorical Variable</span>"
    ]
  },
  {
    "objectID": "transport-categ-toy.html#random-matching",
    "href": "transport-categ-toy.html#random-matching",
    "title": "9  Transporting a Categorical Variable",
    "section": "9.2 Random Matching",
    "text": "9.2 Random Matching\nThere are \\(6!=720\\) different random matching that can be done. We will show two of them below.\n\n9.2.1 First Random Matching\nLet us first consider a random matching in which the individuals matched are 1 (group 0) and 12 (group 1), 2 and 9, 3 and 7, 4 and 10, 5 and 8, 6 and 12. We can compute the difference \\(y(1) - y(0)\\) for each pair of matched individuals (column diff in the table below).\n\nmatched_ex_1 &lt;- tribble(\n  ~i_0, ~i_1,\n  1, 12,\n  2, 9,\n  3, 7,\n  4, 10,\n  5, 8,\n  6, 11\n) |&gt;\n  left_join(\n    group_0 |&gt;\n      rename_with(~str_c(.x, \"_0\")),\n    by = \"i_0\"\n  ) |&gt;\n  left_join(\n    group_1 |&gt;\n      rename_with(~str_c(.x, \"_1\")),\n    by = \"i_1\"\n  )\n\ntb_att_1 &lt;- \n  matched_ex_1 |&gt;\n  mutate(diff = y_1 - y_0) |&gt;\n  select(i_0, i_1, diff, x_0, x_1)\ntb_att_1\n\n# A tibble: 6 × 5\n    i_0   i_1  diff x_0   x_1  \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1     1    12     7 A     C    \n2     2     9     3 A     B    \n3     3     7     0 A     A    \n4     4    10     2 B     B    \n5     5     8    -1 B     B    \n6     6    11     1 C     C    \n\n\nThe average treatment on the treated is thus, in that case:\n\nmean(tb_att_1$diff)\n\n[1] 2\n\n\nAnd if we compute the ATT by category of \\(X\\):\n\ntb_att_1 |&gt; group_by(x_1) |&gt; summarise(ATT = mean(diff))\n\n# A tibble: 3 × 2\n  x_1     ATT\n  &lt;chr&gt; &lt;dbl&gt;\n1 A      0   \n2 B      1.33\n3 C      4   \n\n\n\n\n9.2.2 Second Random Matching\nWe can consider, for the sake of illustration, a second random matching, where the individuals matched are 1 and 8, 2 and 7, 3 and 11, 4 and 10, 5 and 9, 6 and 12. Again, we can compute the difference in outcomes \\(y(1)-y(0)\\) for each pair of matched individuals.\n\nmatched_ex_2 &lt;- tribble(\n  ~i_0, ~i_1,\n  1, 8,\n  2, 7,\n  3, 11,\n  4, 10,\n  5, 9,\n  6, 12\n) |&gt;\n  left_join(\n    group_0 |&gt;\n      rename_with(~str_c(.x, \"_0\")),\n    by = \"i_0\"\n  ) |&gt;\n  left_join(\n    group_1 |&gt;\n      rename_with(~str_c(.x, \"_1\")),\n    by = \"i_1\"\n  )\n\ntb_att_2 &lt;- matched_ex_2 |&gt;\n  mutate(diff = y_1 - y_0) |&gt;\n  select(i_0, i_1, diff, x_0, x_1)\ntb_att_2\n\n# A tibble: 6 × 5\n    i_0   i_1  diff x_0   x_1  \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1     1     8     3 A     B    \n2     2     7     1 A     A    \n3     3    11     4 A     C    \n4     4    10     2 B     B    \n5     5     9     0 B     B    \n6     6    12     2 C     C    \n\n\nThe average treatment on the treated is thus, in that case:\n\nmean(tb_att_2$diff)\n\n[1] 2\n\n\nAnd if we compute the ATT by category of \\(X\\):\n\ntb_att_2 |&gt; group_by(x_1) |&gt; summarise(ATT = mean(diff))\n\n# A tibble: 3 × 2\n  x_1     ATT\n  &lt;chr&gt; &lt;dbl&gt;\n1 A      1   \n2 B      1.67\n3 C      3",
    "crumbs": [
      "III. Sequential Transport for General Data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transporting a Categorical Variable</span>"
    ]
  },
  {
    "objectID": "transport-categ-toy.html#sec-matching-euclidean",
    "href": "transport-categ-toy.html#sec-matching-euclidean",
    "title": "9  Transporting a Categorical Variable",
    "section": "9.3 Matching Using the Euclidean Distances Cost Matrix",
    "text": "9.3 Matching Using the Euclidean Distances Cost Matrix\nLet us nw perform optimal matching between individuals from the two groups using Euclidean distances. These distances are computed in the space of centered log-ratio (clr) transformed probability vectors associated with each individual’s membership in one of the classes.\nLet us first extract the probability vectors (\\(p_A, p_B, p_C\\)) from both groups and apply the clr transformation to make them suitable for Euclidean geometry in the compositional space.\n\nlibrary(compositions)\nall_coords &lt;- rbind(\n  as.matrix(group_0[, c(\"p_A\", \"p_B\", \"p_C\")]),\n  as.matrix(group_1[, c(\"p_A\", \"p_B\", \"p_C\")])\n) |&gt; \n  clr()\n\nThen, we can compute the pairwise Euclidean distances between individuals in group 1 and those in group 0, based on their clr-transformed probability vectors.\n\nrow.names(all_coords) &lt;- c(group_0$i, group_1$i)\n# Euclidean distances between the clr transform of the propensities\nD &lt;- as.matrix(dist(all_coords, method = \"euclidean\"))\nn0 &lt;- nrow(group_0)\nn1 &lt;- nrow(group_1)\nbetween_distances &lt;- D[(n0 + 1):(n0 + n1), 1:n0]\nround(between_distances, 2)\n\n      1    2    3    4    5    6\n7  0.63 0.00 1.30 1.77 1.38 2.75\n8  2.91 2.42 2.67 0.98 1.30 1.77\n9  0.80 0.64 0.79 1.78 1.46 2.16\n10 2.27 1.85 1.93 1.06 1.15 1.36\n11 1.99 2.09 0.98 2.67 2.53 1.30\n12 2.92 2.67 2.21 2.09 2.21 0.41\n\n\nWe aim to find the optimal matching between the individuals in group 1 and group 0 based on these distances. Formally, we want to solve the following optimal transport problem: \\[\n\\min_{P\\in\\mathcal{U}(\\boldsymbol{1}_{n_1},\\boldsymbol{1}_{n_0})}\n\\langle P,\\,C\\rangle,\n\\] where \\(C:=[C_{i,j}]\\) is the cost matrix, with \\(C_{ij}\\) measuring the cost of matching individual \\(i\\) from group 1 to individual \\(j\\) from group 0. Here, we use the Euclidean distance that we juste computed. The total cost is given by \\(\\langle P, C\\rangle=\\sum_{i=1}^{n_1}\\sum_{j=1}^{n_0}P_{ij}\\,C_{ij}\\). The set of admissible transport plans is defined as follows: \\[\n\\left\\{\\,P\\in\\mathbb{R}_+^{n_1\\times n_0}:\nP\\,\\mathbf{1}_{n_0}=\\frac{\\mathbf{1}_{n_1}}{n_1},\\\nP^\\top\\mathbf{1}_{n_1}=\\frac{\\mathbf{1}_{n_0}}{n_0}\n\\right\\}.\n\\] We thus have a uniform mass distribution across both groups.\n\n\n\n\n\n\nNote\n\n\n\nAn alternative cost function (which is not used here) is the cross-entropy between two compositional vectors: \\[\n\\begin{equation*}\nc(\\mathbf{x},\\mathbf{y})=\\log\\left(\\frac{1}{d}\\sum_{i=1}^d\\frac{y_i}{x_i}\\right)-\\frac{1}{d}\\sum_{i=1}^d\\log\\left(\\frac{y_i}{x_i}\\right),\n\\end{equation*}.\n\\] This corresponds to the “Dirichlet transport” (Baxendale and Wong (2022)). This alternative is considered below, in Section 9.4.\n\n\nWe solve the optimal transport problem using the transport() function from the {transport} package. This function computes the optimal matching plan based on the cost matrix.\n\n# source weights\nmass_source &lt;- rep(1 / n1, n1)\n# target weights\nmass_target &lt;- rep(1 / n0, n0)\n\n# Solve the optimal transport plan\not_plan &lt;- transport::transport(\n  a = mass_source, b = mass_target, costm = between_distances, \n  method = \"networkflow\"\n)\not_plan$i_0 &lt;- group_0$i[ot_plan$to]\not_plan$i_1 &lt;- group_1$i[ot_plan$from]\not_plan\n\n  from to      mass i_0 i_1\n1    1  2 0.1666667   2   7\n2    2  4 0.1666667   4   8\n3    3  1 0.1666667   1   9\n4    4  5 0.1666667   5  10\n5    5  3 0.1666667   3  11\n6    6  6 0.1666667   6  12\n\n\nWe can visualize the results in a ternary plot (Figure 9.1). The lines depict the matched individuals (shown by dots and their index).\n\n\nCodes to create the Figure.\nall_data &lt;- \n  bind_rows(group_0 |&gt; mutate(group = \"0\"), group_1 |&gt; mutate(group = \"1\"))\n\nlibrary(ggtern)\n\np &lt;- ggtern(\n  data = all_data |&gt; \n    left_join(\n      ot_plan |&gt; \n        mutate(\n          i_0 = as.numeric(i_0),\n          i_1 = as.numeric(i_1),\n          id_match = as.character(row_number())\n        ) |&gt; \n        dplyr::select(i_0, i_1, id_match) |&gt; \n        pivot_longer(cols = c(i_0, i_1), values_to = \"i\") |&gt; \n        dplyr::select(-name)\n    ),\n  mapping = aes(x = p_A, y = p_B, z = p_C, group = id_match)\n) +\n  geom_point(mapping = aes(shape = group, colour = x), size = 4) +\n  geom_text(\n    mapping = aes(\n      label = i, \n      x = p_A + ifelse(group == 0, -1, 1) * 0.05\n    ),\n    size = .3*font_size\n  ) +\n  labs(x = \"$p_A$\", y = \"$p_B$\", z = \"$p_C\") +\n  geom_line(\n    colour = \"gray40\", \n    # mapping = aes(linetype = id_match)\n  ) +\n  scale_colour_manual(name = \"category\", values = col_categ) +\n  scale_shape_discrete(name = \"group\") +\n  theme_light(base_size = font_size, base_family = font_family) +\n  # theme_paper() +\n  theme_ggtern() +\n  theme(\n    legend.title = element_text(size = .8*font_size),\n    legend.text = element_text(size = .8*font_size)\n  ) +\n  theme_latex(TRUE) +\n  theme_hidetitles()\n\np\n\n\n\n\n\nFigure 9.1: 1-to-1 Matching with optimal transport based on the distances between the individuals with respect to their estimated probabilities of being in each class.\n\n\n\n\n\n\n\n\n\n\nCodes to export the figure in PDF.\nfilename &lt;- \"ternary-toy\"\nggsave(\n  p, file = str_c(path, filename, \".pdf\"),\n  height = 2.2*1.75, width = 4*1.75,\n  family = font_family,\n  device = cairo_pdf\n)\n# Crop PDF\nsystem(paste0(\"pdfcrop \", path, filename, \".pdf \", path, filename, \".pdf\"))\n\n\nWe can compute the differences \\(y(1)-y(0)\\) for each matched individuals.\n\not_plan_diff &lt;- \n  ot_plan |&gt; \n  left_join(group_0 |&gt; select(i_0 = i, y_0 = y, x_0 = x), by = \"i_0\") |&gt; \n  left_join(group_1 |&gt; select(i_1 = i, y_1 = y, x_1 = x), by = \"i_1\") |&gt; \n  mutate(diff = y_1 - y_0) |&gt;\n  select(i_0, i_1, diff, x_0, x_1)\not_plan_diff\n\n  i_0 i_1 diff x_0 x_1\n1   2   7    1   A   A\n2   4   8    0   B   B\n3   1   9    4   A   B\n4   5  10    1   B   B\n5   3  11    4   A   C\n6   6  12    2   C   C\n\n\nResulting in an ATT of:\n\nmean(ot_plan_diff$diff)\n\n[1] 2\n\n\nAnd if we compute the ATT by category of \\(X\\):\n\not_plan_diff |&gt; group_by(x_1) |&gt; summarise(ATT = mean(diff))\n\n# A tibble: 3 × 2\n  x_1     ATT\n  &lt;chr&gt; &lt;dbl&gt;\n1 A      1   \n2 B      1.67\n3 C      3",
    "crumbs": [
      "III. Sequential Transport for General Data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transporting a Categorical Variable</span>"
    ]
  },
  {
    "objectID": "transport-categ-toy.html#sec-matching-ce",
    "href": "transport-categ-toy.html#sec-matching-ce",
    "title": "9  Transporting a Categorical Variable",
    "section": "9.4 Matching Using the Cross-Entropy Cost Matrix",
    "text": "9.4 Matching Using the Cross-Entropy Cost Matrix\nIn Section 9.3, we used the Euclidean distance of the clr-transformed vector of probabilities as the cost function to solve the optimal transport problem. Here, we consider an alternative cost function, the cross-entreopy: \\[\nc(\\mathbf{x}, \\mathbf{y}) = \\log\\left(\\frac{1}{d} \\sum_{i=1}^d \\frac{y_i}{x_i}\\right) - \\frac{1}{d} \\sum_{i=1}^d \\log\\left(\\frac{y_i}{x_i}\\right).\n\\]\nWe first extract the probability vectors for the individuals from both groups (without clr transform), and we make sure there is no probability equal to 0.\n\np0 &lt;- as.matrix(group_0[, c(\"p_A\", \"p_B\", \"p_C\")])\np1 &lt;- as.matrix(group_1[, c(\"p_A\", \"p_B\", \"p_C\")])\np0 &lt;- pmax(p0, 1e-10)\np1 &lt;- pmax(p1, 1e-10)\n\nLet us define the cross-entropy cost function:\n\ncross_entropy_cost &lt;- function(x, y) {\n  d &lt;- length(x)\n  log(mean(y / x)) - mean(log(y / x))\n}\n\nWe can then compute the pairwise cost matrix (group1 rows vs group0 columns).\n\nbetween_distances_ce &lt;- outer(\n  1:nrow(p1), 1:nrow(p0),\n  Vectorize(function(i, j) cross_entropy_cost(p1[i, ], p0[j, ]))\n)\nround(between_distances_ce, 4)\n\n       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]\n[1,] 0.0598 0.0000 0.2894 0.4670 0.3057 0.9985\n[2,] 1.2447 0.9537 0.8514 0.1542 0.2894 0.4670\n[3,] 0.1149 0.0619 0.0959 0.5474 0.3836 0.6215\n[4,] 0.8534 0.5984 0.5067 0.1610 0.1813 0.3289\n[5,] 0.5154 0.4892 0.1542 1.0435 0.8708 0.2379\n[6,] 1.3118 1.0435 0.8232 0.4892 0.5436 0.0266\n\n\nThen, we can solde the optimal transport problem.\n\not_plan_ce &lt;- transport::transport(\n  a = mass_source,\n  b = mass_target,\n  costm = between_distances_ce,\n  method = \"networkflow\"\n)\not_plan_ce$i_0 &lt;- group_0$i[ot_plan_ce$to]\not_plan_ce$i_1 &lt;- group_1$i[ot_plan_ce$from]\not_plan_ce\n\n  from to      mass i_0 i_1\n1    1  2 0.1666667   2   7\n2    2  4 0.1666667   4   8\n3    3  1 0.1666667   1   9\n4    4  5 0.1666667   5  10\n5    5  3 0.1666667   3  11\n6    6  6 0.1666667   6  12\n\n\nWe can compute the differences \\(y(1)-y(0)\\) for each matched individuals.\n\not_plan_ce_diff &lt;- \n  ot_plan_ce |&gt; \n  left_join(group_0 |&gt; select(i_0 = i, y_0 = y, x_0 = x), by = \"i_0\") |&gt; \n  left_join(group_1 |&gt; select(i_1 = i, y_1 = y, x_1 = x), by = \"i_1\") |&gt; \n  mutate(diff = y_1 - y_0) |&gt;\n  select(i_0, i_1, diff, x_0, x_1)\not_plan_ce_diff\n\n  i_0 i_1 diff x_0 x_1\n1   2   7    1   A   A\n2   4   8    0   B   B\n3   1   9    4   A   B\n4   5  10    1   B   B\n5   3  11    4   A   C\n6   6  12    2   C   C\n\n\nResulting in an ATT of:\n\nmean(ot_plan_ce_diff$diff)\n\n[1] 2\n\n\nAnd if we compute the ATT by category of \\(X\\):\n\not_plan_ce_diff |&gt; group_by(x_1) |&gt; summarise(ATT = mean(diff))\n\n# A tibble: 3 × 2\n  x_1     ATT\n  &lt;chr&gt; &lt;dbl&gt;\n1 A      1   \n2 B      1.67\n3 C      3   \n\n\n\n\n\n\nBaxendale, Peter, and Ting-Kam Leonard Wong. 2022. “Random Concave Functions.” The Annals of Applied Probability 32 (2): 812–52.",
    "crumbs": [
      "III. Sequential Transport for General Data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Transporting a Categorical Variable</span>"
    ]
  },
  {
    "objectID": "transport-gaussian-local-weights.html",
    "href": "transport-gaussian-local-weights.html",
    "title": "10  Gaussian Conditional Univariate Transport with Local Weights",
    "section": "",
    "text": "10.1 Sequential Optimal Transport\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colA}{RGB}{255, 221, 85}\n\\definecolor{colB}{RGB}{148, 78, 223}\n\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colGpeZero}{RGB}{127, 23, 14}\n\\definecolor{colGpeUn}{RGB}{27, 149, 224}\n\\]\nLet \\(A=\\{0,1\\}\\) be a binary treatment. Individuals for which \\(A=0\\) are in group 0, those for which \\(A=1\\) are in group 1. Let \\(\\boldsymbol{X}=(X_1, X_2) | A=a\\) follow a multivariate Normal distribution. We set the following means for group 0 and group 1, \\(\\boldsymbol{\\mu}_0\\) and \\(\\boldsymbol{\\mu}_1\\), respectively:\nM0 &lt;- c(-1, -1)\nM1 &lt;- c(1.5, 1.5)\nand the following variance-covariance matrices, \\(\\boldsymbol{\\Sigma}_0\\) and \\(\\boldsymbol{\\Sigma}_1\\):\nS0 &lt;- 4 * matrix(c(1, .5, .5, 1) * 1.2^2, 2, 2)\nS1 &lt;- 4 * matrix(c(1, -.4, -.4, 1) * .9^2, 2, 2)\nSet the seed for reproducibility:\nset.seed(1234)\nWe will first focus on the point \\((x_{1,0} = 0, x_{2,0} =1)\\) from group 0 that we want to transport in group 1.\nx0 &lt;- c(0, 0)\nWe will proceed in a sequential way, assuming the following topological order: \\(A \\rightarrow X_1 \\rightarrow X_2\\).\nFirst, transport \\(x_{1,0}\\) from group 0 to group 1. To do so, simply estimate the cumulative distribution function on the individuals in group 0 \\(\\widehat{F}_{1,a=0}\\) and the quantile function on the individuals in group 1 \\(\\widehat{Q}_{1,t=1}\\). The transport map is \\(T_1^\\star = \\widehat{Q}_{1,t=1}\\circ\\widehat{F}_{1,t=0}\\) so that the counterfactual of \\(x_{1,0}\\) in group 1 is \\(x_{1,1}^\\star=T_1^\\star(x_{1,0})\\).\nT1x0 &lt;- qnorm(\n  p = pnorm(q = x0[1], mean = M0[1], sd = sqrt(S0[1, 1])), \n  mean = M1[1], sd = sqrt(S1[1,1])\n)\nThen, transport \\(x_{2,0}\\) conditional on \\(x_{1,0}\\). To do so, estimate the cumulative distribution function on individuals from group 0 \\(\\widehat{F}_{2,a=0}\\) conditional on \\(X_1=x_{1,0}\\), for \\(X_2\\); and the quantile function on the individuals from group 1 \\(\\widehat{Q}_{2,t=1}\\), conditional on \\(X_2=x^\\star_{1,0}\\), for \\(X_2\\). The transport map is \\(T_2^\\star = \\widehat{Q}_{2,t=1}\\circ\\widehat{F}_{2,t=0}\\) so that the counterfactual of \\(x_{2,0}\\) in group 1 is \\(x_{2,1}^\\star=T_{2\\mid1}^\\star(x_{2,0})\\).\nm10 &lt;- M0[2] + S0[1, 2] / S0[1, 1] * (x0[1] - M0[1])\ns10 &lt;- S0[2, 2] - S0[1, 2]^2 / S0[1, 1]\nm11 &lt;- M1[2] + S1[1, 2] / S1[1, 1] * (T1x0[1] - M1[1])\ns11 &lt;- S1[2, 2] - S1[1, 2]^2 / S1[1, 1]\n\nT2x0 &lt;- qnorm(\n  p = pnorm(q = x0[2], mean = m10, sd = sqrt(s10)), \n  mean = m11, \n  sd = sqrt(s11)\n)\nThe coordinates of the transported point are:\nc(round(T1x0,4), round(T2x0,4))\n\n[1] 2.2500 1.5969\nWe define a wraper function, transp_ot() for the previous codes, to transport an observation from group 0 to group 1 with that framework.\nThe transp_ot(){.R} function.\ntransp_ot &lt;- function(x0) {\n  # First, transport X_1 from group 0 to group 1\n  T1x0 &lt;- qnorm(\n    p = pnorm(q = x0[1], mean = M0[1], sd = sqrt(S0[1, 1])), \n    mean = M1[1], sd = sqrt(S1[1,1])\n  )\n  \n  # Then, transport X_2 conditional on X_1\n  m10 &lt;- M0[2] + S0[1, 2] / S0[1, 1] * (x0[1] - M0[1])\n  s10 &lt;- S0[2, 2] - S0[1, 2]^2 / S0[1, 1]\n  m11 &lt;- M1[2] + S1[1, 2] / S1[1, 1] * (T1x0[1] - M1[1])\n  s11 &lt;- S1[2, 2] - S1[1, 2]^2 / S1[1, 1]\n  \n  T2x0 &lt;- qnorm(\n    p = pnorm(q = x0[2], mean = m10, sd = sqrt(s10)), \n    mean = m11, \n    sd = sqrt(s11)\n  )\n  \n  T2x0\n}\nLet us visualize the initial point and is transported version on a plot.\nCodes to create the Figure.\n# Let us display the 50% confidence ellipses for both groups\nZ0 &lt;- as.data.frame(ellipse::ellipse(S0, level = .5))\nZ0 &lt;- Z0 + rep(M0, each = nrow(Z0))\nZ1 &lt;- as.data.frame(ellipse::ellipse(S1, level = .5))\nZ1 &lt;- Z1 + rep(M1, each = nrow(Z1))\nplot(\n  Z0, type = \"l\", col = colours[1],\n  xlim = range(c(Z0[, 1], Z1[, 1])),\n  ylim = range(c(Z0[, 2], Z1[, 2])),\n  xlab = \"\", ylab = \"\"\n)\nlines(Z1, type = \"l\", col = colours[2])\n# The starting point\npoints(x0[1], x0[2], pch = 19, col = \"black\", cex = 2)\n# Transport of the first component (x_1): intermediate point\nsegments(x0[1], x0[2], T1x0, x0[2], col = colours[3])\npoints(T1x0, x0[2], pch = 19, col = \"gray\", cex = 1)\n# Transport of the second component (x_2), conditional on x_1\n# The resulting point in the transported individual from group 0 to group 1.\nsegments(T1x0, T2x0, T1x0, x0[2], col = colours[3])\npoints(T1x0, T2x0, pch = 19, col = colours[3], cex = 2)\n\n\n\n\nPoint \\((x_{1,0} = 0, x_{2,0} =1)\\) in group 0 transported in group 1. The intermediate point from the sequential transport is shown in gray.",
    "crumbs": [
      "III. Sequential Transport for General Data",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Gaussian Conditional Univariate Transport with Local Weights</span>"
    ]
  },
  {
    "objectID": "transport-gaussian-local-weights.html#sequential-transport-using-kernel-method",
    "href": "transport-gaussian-local-weights.html#sequential-transport-using-kernel-method",
    "title": "10  Gaussian Conditional Univariate Transport with Local Weights",
    "section": "10.2 Sequential Transport using Kernel Method",
    "text": "10.2 Sequential Transport using Kernel Method\nLet us now transport the point using local weights.\nAgain, we will proceed in two steps. In a first step, we transport \\(x_{1,t=0}\\) from group 0 to group 1. The transport map is \\(T_1^\\star=\\widehat{Q}_{1,t=1}\\circ \\widehat{F}_{1,t=0}(x)\\) where \\[\n\\widehat{F}_{1,t}(x)=\\frac{1}{n_t}\\sum_{i=1}^{n_t}\\boldsymbol{1}(x_{1,i,t}\\leq x)\\text{ and }\\widehat{Q}_{1,t}=\\widehat{F}_{1,t}^{-1}.\n\\]\nThen, we proceed to the transport of \\(x_{2,0}\\) conditional on \\(x_{1,0}\\). The transport map is \\(T_2^\\star=\\widehat{Q}_{2|1,t=1}\\circ \\widehat{F}_{2|1,t=0}(x)\\) where \\[\n\\widehat{F}_{2|1,t}(x)=\\sum_{i=1}^{n_t}\\omega_{i,t}\\boldsymbol{1}(x_{1,i,t}\\leq x)\\text{ and }\\widehat{Q}_{2|1,t}=\\widehat{F}_{2|1,t}^{-1}.\n\\] with \\[\n\\omega_{i,t=0} \\propto k_h(x_{1,i,t=0}-x_{1,0})\n\\text{ and }\n\\omega_{i,t=1} \\propto k_h(x_{1,i,t=1}-x^\\star_{1,0})\n\\] for some kernel \\(k_h\\).\n\nlibrary(mvtnorm)\nlibrary(Hmisc)\n\n\nAttaching package: 'Hmisc'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    src, summarize\n\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\n\nWe set the seed for reproducibility:\n\nset.seed(12345)\n\nWe define a function, Transp2x0(), to transport an observation under this Gaussian framework, using either a Gaussian or a Uniform (retangular) kernel.\n\n#' @param x0 Point to transport\n#' @param n Number of observations to draw\n#' @param kernel Type of kernel to use: \"gaussian\" for Gaussian kernel, or \n#'  \"uniform\" for rectangular (uniform) kernel.\nTransp2x0 &lt;- function(x0,\n                      n, \n                      kernel = c(\"gaussian\", \"uniform\"),\n                      seed = NULL) {\n  \n  if (!is.null(seed)) set.seed(seed)\n  kernel &lt;- match.arg(kernel)\n  \n  # Parameters of the multivariate Gaussian distributions in the\n  # two groups\n  M0 &lt;- c(-1, -1)\n  M1 &lt;- c(1.5, 1.5)\n  S0 &lt;- 4 * matrix(c(1, .5, .5, 1) * 1.2^2, 2, 2)\n  S1 &lt;- 4 * matrix(c(1, -.4, -.4, 1) * .9^2, 2, 2)\n  \n  # Bandwidth for smoothing (to be used in the Gaussian kernel weights)\n  h &lt;- .0001 + runif(1)\n  \n  # Drawing individuals in both groups\n  X0 &lt;- mnormt::rmnorm(n, M0, S0)\n  X1 &lt;- mnormt::rmnorm(n, M1, S1)\n  \n  # Transport of the first coordinate\n  # cdf value of starting point in group 0\n  u &lt;- mean(X0[, 1] &lt;= x0[1])\n  # corresponding quantile level in group 1\n  T1x0 &lt;- as.numeric(quantile(X1[, 1], u))\n  \n  if (kernel == \"gaussian\") {\n    # Transport of the second coordinate, conditional on the first\n    # using kernel smoothing\n    # Weights based on the proximity in the first dimension\n    w0x0 &lt;- dnorm(X0[, 1], x0[1], sd = h)\n    w0x0 &lt;- w0x0 / sum(w0x0)\n    w1x0 &lt;- dnorm(X1[, 1], T1x0, sd = h)\n    w1x0 &lt;- w1x0 / sum(w1x0)\n    # conditional distribution of the second coordinate in group 0\n    # weighted by proximity in the first coordinate\n  } else {\n    # uniform (or rectangular) kernel\n    w0x0 &lt;- (abs(X0[, 1] - x0[1]) &lt; (h)) * 1\n    w0x0 &lt;- w0x0 / sum(w0x0)\n    w1x0 &lt;- (abs(X1[, 1] - T1x0) &lt; h) * 1\n    w1x0 &lt;- w1x0 / sum(w1x0)\n  }\n  u &lt;- weighted.mean(X0[, 2] &lt;= x0[2], w0x0)\n  \n  # u-th weighted quantile of the second coordinate, where the weights\n  # reflect the closeness to T1x0\n  T2x0 &lt;- Hmisc::wtd.quantile(\n    x = X1[, 2], weights = w1x0, probs = u, normwt = TRUE) |&gt; \n    as.numeric()\n  \n  c(x = h, y = T2x0)\n}\n\n\n10.2.1 Simulations\nLet us now run some simulations. We will consider two different kernels: a Gaussian, and a Uniform. We will tranpsport two points: \\((x_{1,0} = 0, x_{2,0} =1)\\) and \\((x_{1,0} = -2, x_{2,0} = -1)\\). For each case, we generate 5,000 samples from the DGP shown in Section 10.1.\n\n# This chunk is not evaluated here. Each simulation takes about 4 minutes.\n# The results of previously run simulations are loaded in this notebook.\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(mvtnorm)\n}) |&gt;\n  invisible()\n\nn &lt;- 1e5\nn_repl &lt;- 5000\n\nclusterExport(cl, c(\"Transp2x0\", \"n\", \"n_repl\"))\n\n# Starting point: (0,0) and Gaussian kernel\nres_sim_gaussian_1 &lt;- pbapply::pblapply(\n  seq_len(n_repl), \n  function(x) Transp2x0(x0 = c(0, 0), n = n, kernel = \"gaussian\", seed = x),\n  cl = cl\n)\nres_sim_gaussian_1 &lt;- do.call(\"rbind\", res_sim_gaussian_1)\n\n# Starting point: (0,0) and uniform kernel\nres_sim_uniform_1 &lt;- pbapply::pblapply(\n  seq_len(n_repl), \n  function(x) Transp2x0(x0 = c(0, 0), n = n, kernel = \"uniform\", seed = x),\n  cl = cl\n)\nres_sim_uniform_1 &lt;- do.call(\"rbind\", res_sim_uniform_1)\n\n# Starting point: (-2,1) and Gaussian kernel\nres_sim_gaussian_2 &lt;- pbapply::pblapply(\n  seq_len(n_repl), \n  function(x) Transp2x0(x0 = c(-2, -1), n = n, kernel = \"gaussian\", seed = x),\n  cl = cl\n)\n\nres_sim_gaussian_2 &lt;- do.call(\"rbind\", res_sim_gaussian_2)\n\n# Starting point: (-2,1) and uniform kernel\nres_sim_uniform_2 &lt;- pbapply::pblapply(\n  seq_len(n_repl), \n  function(x) Transp2x0(x0 = c(-2, -1), n = n, kernel = \"uniform\", seed = x),\n  cl = cl\n)\nres_sim_uniform_2 &lt;- do.call(\"rbind\", res_sim_uniform_2)\n\nstopCluster(cl)\n\nsave(\n  res_sim_gaussian_1,\n  res_sim_gaussian_2,\n  res_sim_uniform_1,\n  res_sim_uniform_2,\n  file = \"../output/simyot-loc-weights.rda\"\n)\n\nWe load the results:\n\nload(\"../output/simyot-loc-weights.rda\")\n\n\n10.2.1.1 Results\nWe can visualize the results. In Figure 10.1 we can visualize \\(x_{2|1,0}^\\star\\) (on the \\(y\\)-axis) when \\((x_{1,0},x_{2,0})=(0,0)\\) (on top) and when \\((x_{1,0},x_{2,0})=(-2,-1)\\) (below) using simulated Gaussian samples, for two choices of kernels (Gaussian on the left, uniform on the right). The horizontal dashed line indicates the transported value from standard optimal transport (as in Section 10.1).\n\n\nCodes to create the Figure\nlibrary(mgcv)\nf_plot &lt;- function(res_sim, kernel, x0, ylim = NULL) {\n  plot(\n    res_sim[, 1], res_sim[, 2],\n    # V[1,], V[2,],\n    cex = .5, col = scales::alpha(colours[3], .2),\n    xlab = \"\",\n    ylab = \"\",\n    main = \"\",\n    ylim = ylim,\n    family = font_family\n  )\n  title(\n    main = paste(kernel, \"kernel\"),\n    family = font_family,\n    adj = 0,\n    line = 2\n  )\n  title(\n    main =  latex2exp::TeX(\n      paste(\n        \"$(x_{1,0}, x_{2,0}) = (\", \n        paste(x0, collapse = \", \"), \")$\"\n      )\n    ),\n    family = font_family,\n    adj = 0,\n    line = 1\n  )\n  title(\n    xlab = \"Size of neighborhood (bandwidth)\", \n    ylab = \"Transported value\", \n    line = 2,\n    family = font_family\n  )\n  \n  T2x0 &lt;- transp_ot(x0)\n  # Result obtained sequential transport\n  abline(h = T2x0, lty=2, col=\"darkred\")\n  # Smooth line of the transported values obtained with the kernel approach\n  base &lt;- data.frame(x = res_sim[, 1], y = res_sim[, 2])\n  reg &lt;- mgcv::gam(y ~ s(x), data = base)\n  nbase &lt;- data.frame(x = (1:100) / 100)\n  p &lt;- predict(reg, newdata = nbase, type = \"link\", se.fit = TRUE)\n  lines(nbase$x, p$fit, col = colours[4], lwd = 3)\n}\n\npar(mfrow = c(2,2), mar = c(3.1, 3.1, 3.1, 2.1))\nf_plot(res_sim_gaussian_1, kernel = \"Gaussian\", x0 = c(0, 0), ylim = c(1.4, 1.8))\nf_plot(res_sim_uniform_1, kernel = \"Uniform\", x0 = c(0, 0), ylim = c(1.4, 1.8))\nf_plot(res_sim_gaussian_2, kernel = \"Gaussian\", x0 = c(-2, -1), ylim = c(2, 2.5))\nf_plot(res_sim_uniform_2, kernel = \"Uniform\", x0 = c(-2, -1), ylim = c(2, 2.5))\n\npath &lt;- \"./figs/\"\np &lt;- recordPlot()\npdf(paste0(path, \"gaussian-ot-local-weights.pdf\"), \n    width = 4.6, height = 4.6)\nreplayPlot(p)\ndev.off()\n\n\nquartz_off_screen \n                2 \n\n\n\n\n\nFigure 10.1: Conditional Optimal Transport using local weights. Value of \\(x_{2|1,0}^\\star\\) on the \\(y\\)-axis when \\((x_{1,0}, x_{2,0}) = (0,0)\\) (top) and \\((-2, -1)\\) (bottom), based on 5,000 simulated Gaussian samples. The left panel uses Gaussian kernels; the right panel uses rectangular (uniform) kernels. The horizontal dashed line indicates the transported value from standard optimal transport.",
    "crumbs": [
      "III. Sequential Transport for General Data",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Gaussian Conditional Univariate Transport with Local Weights</span>"
    ]
  },
  {
    "objectID": "xp-simulated.html",
    "href": "xp-simulated.html",
    "title": "11  Simulated Data",
    "section": "",
    "text": "11.1 Data Generating Process\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colA}{RGB}{255, 221, 85}\n\\definecolor{colB}{RGB}{148, 78, 223}\n\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colGpeZero}{RGB}{127, 23, 14}\n\\definecolor{colGpeUn}{RGB}{27, 149, 224}\n\\]\nWe load the functions that will allow us to build the counterfactuals (see Chapter 6), and some graphical themes for the plots (see [Chapter 5):\nWe simulate a dataset comprising a binary treatment indicator \\(A \\in \\{0,1\\}\\), a binary outcome \\(Y \\in \\{0,1\\}\\), and three covariates: two continuous variables \\(X_1, X_2 \\in \\mathbb{R}\\) and one categorical variable \\(X_3 \\in \\{\\text{A}, \\text{B}, \\text{C}\\}\\). For individuals with \\(A = 0\\), the vector \\((X_1, X_2)\\) is drawn from a bivariate normal distribution with mean vector \\(\\mu_0 = (-1, -1)\\) and covariance matrix \\(\\Sigma_0 = 1.2^2 \\begin{bmatrix} 1 & 0.5 \\\\ 0.5 & 1 \\end{bmatrix}\\). For those with \\(A = 1\\), the distribution shifts to mean \\(\\mu_1 = (1.5, 1.5)\\) and covariance \\(\\Sigma_1 = 0.9^2 \\begin{bmatrix} 1 & -0.4 \\\\ -0.4 & 1 \\end{bmatrix}\\). This leads to distinct location and dependence structures across treatment groups.\nThe categorical variable \\(X_3\\) is generated conditionally on \\(X_1, X_2\\), and \\(A\\) via a multinomial logistic model. Letting \\(p_{\\text{A}}, p_{\\text{B}}, p_{\\text{C}}\\) denote the unnormalized logit scores for each level of \\(X_3\\), we set:\n\\[\n\\begin{aligned}\np_{\\text{A}} &= 0.5 + 0.3 X_1 - 0.4 X_2 + 0.2 A, \\\\\np_{\\text{B}} &= -0.3 + 0.5 X_2 - 0.2 X_1 - 0.1 A, \\\\\np_{\\text{C}} &= 0,\n\\end{aligned}\n\\]\nwith the associated probabilities obtained via softmax normalization:\n\\[\nP(X_3 = k) = \\frac{\\exp(p_k)}{\\exp(p_{\\text{A}}) + \\exp(p_{\\text{B}}) + \\exp(p_{\\text{C}})}, \\quad \\text{for } k \\in \\{\\text{A}, \\text{B}, \\text{C}\\}.\n\\]\nThe binary outcome \\(Y\\) is modeled using a logistic regression, with functional forms differing across treatment groups. For \\(A = 0\\), the log-odds is defined as:\n\\[\n\\eta_0 = -0.2 + 0.6 X_1 - 0.6 X_2 + \\gamma(X_3),\n\\]\nand for \\(A = 1\\):\n\\[\n\\eta_1 = 0.1 - 0.2 X_1 + 0.8 X_2 + \\gamma(X_3),\n\\]\nwhere the contribution of \\(X_3\\) is encoded as:\n\\[\n\\gamma(X_3) =\n\\begin{cases}\n0.2 & \\text{if } X_3 = \\text{B}, \\\\\n-0.3 & \\text{if } X_3 = \\text{C}, \\\\\n0 & \\text{if } X_3 = \\text{A},\n\\end{cases}\n\\quad \\text{(for } A = 0\\text{)},\n\\]\nand similarly, for \\(A = 1\\):\n\\[\n\\gamma(X_3) =\n\\begin{cases}\n-0.2 & \\text{if } X_3 = \\text{B}, \\\\\n-0.1 & \\text{if } X_3 = \\text{C}, \\\\\n0 & \\text{if } X_3 = \\text{A}.\n\\end{cases}\n\\]\nThe outcome \\(Y\\) is then drawn from a Bernoulli distribution with success probability \\(P[Y = 1] = \\mathrm{logit}^{-1}(\\eta_A)\\).\nFor each observation, we additionally simulate a counterfactual covariate vector and outcome under the opposite treatment status. This includes drawing \\((X_1^{\\text{cf}}, X_2^{\\text{cf}})\\) from the treatment-specific bivariate normal distribution of the opposite group, computing the corresponding \\(X_3^{\\text{cf}}\\) using the same multinomial model (with \\(A\\) flipped), and evaluating \\(Y^{\\text{cf}}\\) via the appropriate counterfactual logit model.\nWe draw \\(n_0=400\\) observations in group 0 and \\(n_1=200\\) observations in group 1. We generate a function, gen_data() to generate data from this data generating process.\nThe gen_data() function.\ngen_data &lt;- function(seed) {\n  set.seed(seed)\n  n_0 &lt;- 400\n  n_1 &lt;- 200\n  \n  # X1 and X2 in both groups from sensitive-specific multivariate normal \n  # distributions\n  M_0 &lt;- c(-1, -1)\n  S_0 &lt;- matrix(c(1, .5, .5, 1) * 1.2^2, 2, 2)\n  M_1 &lt;- c(1.5, 1.5)\n  S_1 &lt;- matrix(c(1, -.4, -.4, 1) * 0.9^2, 2, 2)\n  X_0 &lt;- MASS::mvrnorm(n = n_0, mu = M_0, Sigma = S_0)\n  X_1 &lt;- MASS::mvrnorm(n = n_1, mu = M_1, Sigma = S_1)\n  \n  # Counterfactuals\n  X_0_cf &lt;- MASS::mvrnorm(n = n_0, mu = M_1, Sigma = S_1)\n  X_1_cf &lt;- MASS::mvrnorm(n = n_1, mu = M_0, Sigma = S_0)\n  \n  # X3: categorical, depends on S, X1, X3\n  scores &lt;- function(x1, x2, a) {\n    p_A &lt;- 0.5 + 0.3 * x1 - 0.4 * x2 + 0.2 * a\n    p_B &lt;- -0.3 + 0.5 * x2 - 0.2*x1 - 0.1 * a\n    p_C &lt;- 0\n    exps &lt;- exp(cbind(p_A, p_B, p_C))\n    prob &lt;- exps / rowSums(exps)\n    prob\n  }\n  \n  prob_X3_0 &lt;- scores(x1 = X_0[, 1], x2 = X_0[, 2], a = 0)\n  prob_X3_1 &lt;- scores(x1 = X_1[, 1], x2 = X_1[, 2], a = 1)\n  X3_0 &lt;- apply(prob_X3_0, 1, function(p) sample(c(\"A\", \"B\", \"C\"), 1, prob = p))\n  X3_1 &lt;- apply(prob_X3_1, 1, function(p) sample(c(\"A\", \"B\", \"C\"), 1, prob = p))\n  \n  # Counterfactuals\n  prob_X3_0_cf &lt;- scores(x1 = X_0_cf[, 1], x2 = X_0_cf[, 2], a = 1)\n  prob_X3_1_cf &lt;- scores(x1 = X_1_cf[, 1], x2 = X_1_cf[, 2], a = 0)\n  X3_0_cf &lt;- apply(prob_X3_0_cf, 1, function(p) sample(c(\"A\", \"B\", \"C\"), 1, prob = p))\n  X3_1_cf &lt;- apply(prob_X3_1_cf, 1, function(p) sample(c(\"A\", \"B\", \"C\"), 1, prob = p))\n  \n  \n  # Predictor for Y:\n  eta_0 &lt;- -0.2 + 0.6 * X_0[, 1] - 0.6 * X_0[, 2] + \n    ifelse(X3_0 == \"B\", 0.2, ifelse(X3_0 == \"C\", -0.3, 0))\n  eta_1 &lt;- 0.1 - 0.2 * X_1[, 1] + 0.8 * X_1[, 2] + \n    ifelse(X3_1 == \"B\", -0.2, ifelse(X3_1 == \"C\", -0.1, 0))\n  \n  p_0 &lt;- exp(eta_0) / (1 + exp(eta_0))\n  p_1 &lt;- exp(eta_1) / (1 + exp(eta_1))\n  \n  # Predictor for Y, counterfactuals\n  eta_0_cf &lt;- 0.1 - 0.2 * X_0_cf[, 1] + 0.8 * X_0_cf[, 2] + \n    ifelse(X3_0_cf == \"B\", -0.2, ifelse(X3_0_cf == \"C\", -0.1, 0))\n  \n  eta_1_cf &lt;- -0.2 + 0.6 * X_1_cf[, 1] - 0.6 * X_1_cf[, 2] + \n    ifelse(X3_1_cf == \"B\", 0.2, ifelse(X3_1_cf == \"C\", -0.3, 0))\n  \n  p_0_cf &lt;- exp(eta_0_cf) / (1 + exp(eta_0_cf))\n  p_1_cf &lt;- exp(eta_1_cf) / (1 + exp(eta_1_cf))\n  \n  \n  Y_0 &lt;- rbinom(n_0, size = 1, prob = p_0)\n  Y_1 &lt;- rbinom(n_1, size = 1, prob = p_1)\n  \n  Y_0_cf &lt;- rbinom(n_0, size = 1, prob = p_0_cf)\n  Y_1_cf &lt;- rbinom(n_1, size = 1, prob = p_1_cf)\n  \n  # Dataset with individuals in group 0 only\n  data_0 &lt;- tibble(\n    A = 0, \n    X1 = X_0[, 1], X2 = X_0[, 2], X3 = X3_0, Y = Y_0,\n    X1_cf = X_0_cf[, 1], X2_cf = X_0_cf[, 2], X3_cf = X3_0_cf, Y_cf = Y_0_cf,\n    eta = eta_0, p = p_0,\n    eta_cf = eta_0_cf, p_cf = p_0_cf\n  ) |&gt; \n    bind_cols(as_tibble(prob_X3_0) |&gt; rename_with(~ str_c(\"X3_\", .))) |&gt; \n    bind_cols(as_tibble(prob_X3_0_cf) |&gt; rename_with(~ str_c(\"X3_cf_\", .)))\n  # Dataset with individuals in group 1 only\n  data_1 &lt;- tibble(\n    A = 1, \n    X1 = X_1[, 1], X2 = X_1[, 2], X3 = X3_1, Y = Y_1,\n    X1_cf = X_1_cf[, 1], X2_cf = X_1_cf[, 2], X3_cf = X3_1_cf, Y_cf = Y_1_cf,\n    eta = eta_1,  p = p_1,\n    eta_cf = eta_1_cf, p_cf = p_1_cf\n  ) |&gt; \n    bind_cols(as_tibble(prob_X3_1) |&gt; rename_with(~ str_c(\"X3_\", .))) |&gt; \n    bind_cols(as_tibble(prob_X3_1_cf) |&gt; rename_with(~ str_c(\"X3_cf_\", .)))\n  # # Combine final dataset\n  data_all &lt;- rbind(data_0, data_1)\n  \n  data_all\n}\nLet us generate a dataset:\ntb &lt;- gen_data(2) |&gt; \n  mutate(across(where(is.character), ~as.factor(.x)))\nCodes to create the Figure\n#| label: fig-dist-true-prob\n#| message: false\n#| warning: false\nggplot(\n  data = tb |&gt; mutate(A = factor(A)) |&gt; select(A, p, p_cf) |&gt; \n    pivot_longer(cols = c(p, p_cf), names_to = \"type\", values_to = \"p\") |&gt; \n    mutate(\n      type = factor(type, levels = c(\"p\", \"p_cf\"), labels = c(\"Obs.\", \"Counterfactual\")\n      )\n    ),\n  mapping = aes(x = p)\n) +\n  geom_histogram(\n    mapping = aes(fill = A), alpha = .5, colour = \"black\",\n    position = \"identity\", bins = 30\n  ) +\n  facet_wrap(~type) +\n  scale_fill_manual(values = c(\"0\" = colours[[\"0\"]], \"1\" = colours[[\"1\"]])) +\n  theme_paper()\n\n\n\n\nDistribution of the true probability of the outcome across groups for the untreated and the treated, for observed values (left) and unobserved values (right).",
    "crumbs": [
      "IV. Experiments",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Simulated Data</span>"
    ]
  },
  {
    "objectID": "xp-simulated.html#counterfactuals",
    "href": "xp-simulated.html#counterfactuals",
    "title": "11  Simulated Data",
    "section": "11.2 Counterfactuals",
    "text": "11.2 Counterfactuals\nWe assume a structural model as shown in Figure 11.1.\n\nvariables &lt;- c(\"A\", \"X1\", \"X2\", \"X3\", \"Y\")\n\nadj &lt;- matrix(\n  # A  X1 X2 X3 Y\n  c(0, 1, 1, 1, 1,# A\n    0, 0, 1, 1, 1,# X1\n    0, 0, 0, 1, 1,# X2\n    0, 0, 0, 0, 1,# X3\n    0, 0, 0, 0, 0  # Y\n  ),\n  ncol = length(variables),\n  dimnames = rep(list(variables), 2),\n  byrow = TRUE\n)\n\ncausal_graph &lt;- fairadapt::graphModel(adj)\nplot(causal_graph)\n\n\n\n\nFigure 11.1: Asumed Causal Structure\n\n\n\n\n\n\n\n\nLet us follow this DAG and build the counterfactuals of untreated: we thus transport individuals from \\(A=0\\) to \\(A=1\\). Let us set a seed for reproducibility.\n\nseed &lt;- 1234\nset.seed(seed)\n\nWe call the seq_trans() function (see Chapter 6) function to build the counterfactuals of untreated individuals. The estimations are done using parallel computation.\n\nA_name &lt;- \"A\" # treatment name\nY_name &lt;- \"Y\" # outcome name\nA_untreated &lt;- 0\n\n\n# The estimation takes about 16 secondes to run.\n# We do not run it here, it was previously estimated.\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(transportsimplex)\n  source(\"../scripts/functions.R\")\n}) |&gt;\n  invisible()\n\nsequential_transport &lt;- seq_trans(\n  data = tb, \n  adj = adj, \n  s = A_name, \n  S_0 = 0, # source: untreated\n  y = Y_name, \n  num_neighbors = 50, \n  num_neighbors_q = NULL,\n  silent = FALSE,\n  method = \"shortsimplex\",\n  cl = cl\n)\n\nsave(sequential_transport, file = \"../output/res_simul-seq-t.rda\")\n\nstopCluster(cl)\n\nLet us load the results of the estimation:\n\nload(\"../output/res_simul-seq-t.rda\")",
    "crumbs": [
      "IV. Experiments",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Simulated Data</span>"
    ]
  },
  {
    "objectID": "xp-simulated.html#measuring-the-causal-effect",
    "href": "xp-simulated.html#measuring-the-causal-effect",
    "title": "11  Simulated Data",
    "section": "11.3 Measuring the Causal Effect",
    "text": "11.3 Measuring the Causal Effect\n\ntb_estim &lt;- tb |&gt; select(Y, A, X1, X2, X3)\nA_name &lt;- \"A\"\nA_untreated &lt;- 0\nY_name &lt;- \"Y\"\n\n\n11.3.1 With Causal Mediation Analysis\nLet us use the multimed() function from {mediation} to estimate:\n\n\\(\\bar{\\delta}(0)\\): the average causal mediation effect for \\(a=0\\),\n\\(\\bar{\\zeta}(1)\\): the average direct effect for \\(a=1\\),\n\\(\\bar{\\tau} = \\bar{\\delta}(0) + \\bar{\\zeta}(1)\\): the total causal effect.\n\n\n# library(mediation) # we do not load it\n#  otherwise it masks a lot of useful functions\nmed_mod &lt;- mediation::multimed(\n  outcome = \"Y\", \n  med.main = \"X1\", \n  med.alt = c(\"X2\", \"X3\"),\n  treat = \"A\", \n  data = tb_estim\n)\n\ndelta_0_med &lt;- mean((med_mod$d0.lb + med_mod$d0.ub) / 2)\nzeta_1_med &lt;- mean((med_mod$z1.lb + med_mod$z1.ub) / 2)\ntot_effect_med &lt;- delta_0_med + zeta_1_med\n\nThe estimated values:\n\ncbind(delta_0 = delta_0_med, zeta_1 = zeta_1_med, tot_effect = tot_effect_med)\n\n     delta_0 zeta_1 tot_effect\n[1,]      NA     NA         NA\n\n\n\n\n11.3.2 With Sequential Optimal Transport\n\nlibrary(randomForest)\n\nWe use a random forest to estimate the outcome model (see causal_effects_cf() in Chapter 6).\n\ntb_untreated &lt;- tb_estim |&gt; filter(!!sym(A_name) == !!A_untreated)\ntb_treated &lt;- tb_estim |&gt; filter(!!sym(A_name) != !!A_untreated)\n\ncausal_effects_sot &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf = as_tibble(sequential_transport$transported), \n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated\n)\n\ncbind(\n  delta_0 = causal_effects_sot$delta_0,\n  zeta_1 = causal_effects_sot$zeta_1, \n  tot_effect = causal_effects_sot$tot_effect\n)\n\n        delta_0    zeta_1 tot_effect\n[1,] 0.09955393 0.1995481   0.299102",
    "crumbs": [
      "IV. Experiments",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Simulated Data</span>"
    ]
  },
  {
    "objectID": "xp-compas.html",
    "href": "xp-compas.html",
    "title": "12  Compas",
    "section": "",
    "text": "12.1 Data\n\\[\n\\definecolor{wongBlack}{RGB}{0,0,0}\n\\definecolor{wongGold}{RGB}{230, 159, 0}\n\\definecolor{wongLightBlue}{RGB}{86, 180, 233}\n\\definecolor{wongGreen}{RGB}{0, 158, 115}\n\\definecolor{wongYellow}{RGB}{240, 228, 66}\n\\definecolor{wongBlue}{RGB}{0, 114, 178}\n\\definecolor{wongOrange}{RGB}{213, 94, 0}\n\\definecolor{wongPurple}{RGB}{204, 121, 167}\n\\definecolor{colA}{RGB}{255, 221, 85}\n\\definecolor{colB}{RGB}{148, 78, 223}\n\\definecolor{colC}{RGB}{63, 179, 178}\n\\definecolor{colGpeZero}{RGB}{127, 23, 14}\n\\definecolor{colGpeUn}{RGB}{27, 149, 224}\n\\]\nWe load the functions that will allow us to build the counterfactuals (see Chapter 6):\nWe load the COMPAS dataset that is available in the {mlr3fairness} package.\ndata(compas, package = \"mlr3fairness\")\nThe outcome variable is binary here: whether the defendant is rearrested at any time. The “treatment” \\(A\\) will be the sensitive attribute, race. We will consider a binary version of the race: Caucasian (whites, \\(A=0\\)) and African-American (Blacks, \\(A=1\\)). The idea is to build counterfactuals for Black people to ask questions such as “had this Black individual been white, what whould the prediction of an algorithm modeling recidivism be?”.\nTo train the predictive model of recidivism, we will use the following covariates: the age, the prior criminal records of defendants, and the charge degree (felony or misdemeanor).\ntb &lt;- compas |&gt; \n  as_tibble() |&gt; \n  filter(race %in% c(\"Caucasian\", \"African-American\")) |&gt;\n  select(\n    race, # sensitive\n    age, \n    priors_count, # The prior criminal records of defendants. \n    c_charge_degree, # F: Felony M: Misdemeanor\n    is_recid # outcome\n  ) |&gt; \n  mutate(\n   race = ifelse(race == \"African-American\", 1, 0), # African-American as \"treated\"\n   is_recid = ifelse(is_recid == 0, 0, 1)\n  )\n  # working with a fraction of observations here (40%)\ndim(tb)\n\n[1] 5278    5\n\nsummary(tb)\n\n      race             age         priors_count    c_charge_degree\n Min.   :0.0000   Min.   :18.00   Min.   : 0.000   F:3440         \n 1st Qu.:0.0000   1st Qu.:25.00   1st Qu.: 0.000   M:1838         \n Median :1.0000   Median :31.00   Median : 2.000                  \n Mean   :0.6016   Mean   :34.45   Mean   : 3.462                  \n 3rd Qu.:1.0000   3rd Qu.:42.00   3rd Qu.: 5.000                  \n Max.   :1.0000   Max.   :80.00   Max.   :38.000                  \n    is_recid     \n Min.   :0.0000  \n 1st Qu.:0.0000  \n Median :1.0000  \n Mean   :0.5015  \n 3rd Qu.:1.0000  \n Max.   :1.0000\nWe assume the DAG shown in Figure 12.1.\nvariables &lt;- c(\"race\", \n               \"age\", \"priors_count\", \"c_charge_degree\", \n               \"is_recid\")\n# Row: outgoing arrow\nadj &lt;- matrix(\n  # S  1  2  3  Y\n  c(0, 1, 1, 1, 1,# S\n    0, 0, 1, 2, 1,# 1 (age)\n    0, 0, 0, 0, 1,# 2 (priors_count)\n    0, 0, 0, 0, 1,# 3 (c_charge_degree)\n    0, 0, 0, 0, 0 # Y\n  ),\n  ncol = length(variables),\n  dimnames = rep(list(variables), 2),\n  byrow = TRUE\n)\n\ncausal_graph &lt;- fairadapt::graphModel(adj)\nplot(causal_graph)\n\n\n\n\nFigure 12.1: Assumed structural model for the probability of recidivism.",
    "crumbs": [
      "IV. Experiments",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Compas</span>"
    ]
  },
  {
    "objectID": "xp-compas.html#counterfactuals",
    "href": "xp-compas.html#counterfactuals",
    "title": "12  Compas",
    "section": "12.2 Counterfactuals",
    "text": "12.2 Counterfactuals\nLet us follow the DAG from Figure 12.1 and build the counterfactuals of Black individuals: we thus transport individuals from \\(A=1\\) to \\(A=0\\). Let us set a seed for reproducibility.\n\nseed &lt;- 1234\nset.seed(seed)\n\nWe call the seq_trans() function (see Chapter 6) function to build the counterfactuals of Black individuals. The estimations are done using parallel computation.\n\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nsocket cluster with 9 nodes on host 'localhost'\n\nclusterEvalQ(cl, {\n  library(transportsimplex)\n}) |&gt;\n  invisible()\n\n\nA_name &lt;- \"race\" # treatment name\nY_name &lt;- \"is_recid\" # outcome name\n\nsequential_transport &lt;- seq_trans(\n  data = tb, \n  adj = adj, \n  s = A_name, \n  S_0 = 1, # source: treated\n  y = Y_name, \n  num_neighbors = 50, \n  num_neighbors_q = NULL,\n  silent = FALSE,\n  cl = cl\n)\n\nTransporting  age \nTransporting  priors_count \nTransporting  c_charge_degree \n\nstopCluster(cl)",
    "crumbs": [
      "IV. Experiments",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Compas</span>"
    ]
  },
  {
    "objectID": "xp-compas.html#measuring-the-causal-effect",
    "href": "xp-compas.html#measuring-the-causal-effect",
    "title": "12  Compas",
    "section": "12.3 Measuring the Causal Effect",
    "text": "12.3 Measuring the Causal Effect\n\n12.3.1 ATT with the Conditional Optimal Transport Approach\nRecall that the average treatment on the treated writes \\[\n\\text{ATT} = \\mathbb{E}\\bigl[Y(1) - Y(0) \\mid A=1\\bigr]\n\\]\nFor a treated unit \\(i\\) (Black individual), \\(Y_i(1)\\) corresponds to the observed value and \\(Y_i(0)\\) to its counterfactual, i.e. \\(Y_i(0)\\mid A=1 = x_{1,i}^\\star\\).\n\\[\n\\widehat{\\text{ATT}}^{\\text{COT}} = \\frac{1}{n_1} \\sum_{i:A_i=1}\\bigl[ Y_i -  \\hat{\\mu}_0(x_{1,i}^\\star)\\bigr],\n\\tag{12.1}\\] where \\(\\hat{\\mu}_0()\\) is the predictive outcome model trained on the untreated (white individuals), i.e., an estimation of \\(\\mu_0(\\boldsymbol{X}_i) = \\mathbb{E}[Y_i \\mid \\boldsymbol{X}_i, A_i = 0]\\)\n\nA_untreated &lt;- 0 # transport from 1 to 0\n\nLet us split the data between treated (Black individuas) and untreated (white individuals).\n\ntb_untreated &lt;- tb |&gt; filter(!!sym(A_name) == !!A_untreated)\ntb_treated &lt;- tb |&gt; filter(!!sym(A_name) != !!A_untreated)\n\nn_untreated &lt;- nrow(tb_untreated)\nn_treated &lt;- nrow(tb_treated)\n\nWe train a random forest to predict recidivism, among the untreated only (white individuals): \\(\\hat{\\mu}_0()\\).\n\nmu_untreated_model &lt;- randomForest(\n  x = tb_untreated |&gt; select(-!!Y_name, -!!A_name),\n  y = factor(pull(tb_untreated, !!Y_name), levels = c(0,1))\n)\n\nThe transported values for age, prior counts and charge degrees of all treated (Black individuals): \\(x_{1,i}^\\star\\)\n\ntb_treated_t &lt;- sequential_transport$transported |&gt; \n  as_tibble() |&gt;\n  unnest_wider(where(is.list))\n\nThe prediction of the algorithm on those transported individuals, i.e., \\(\\hat{\\mu}_0(x_{1,i}^\\star)\\)\n\npred_treated_t &lt;- predict(mu_untreated_model, newdata = tb_treated_t)\n\nWe can then compute the ATT (Equation 12.1).\n\n# ATT with the counterfactuals\nY_treated_obs &lt;- tb |&gt; filter(!!sym(A_name) != !!A_untreated) |&gt; pull(!!Y_name)\nATT_cot &lt;- mean(Y_treated_obs - ifelse(pred_treated_t == 0, 0, 1))\nATT_cot\n\n[1] 0.448189\n\n\n\n\n12.3.2 ATT with the AIPW Estimator\nWe use cross-fitting to estimate the average treatment on the treated using the AIPW estimator: \\[\n\\widehat{\\text{ATT}}_{\\text{AIPW}} = \\frac{1}{n_1} \\sum_{i: A_i = 1} \\left[ Y_i - \\hat{\\mu}_0(X_i) \\right] + \\frac{1}{n_1} \\sum_{i: A_i = 0} \\frac{\\hat{e}(X_i)}{1 - \\hat{e}(X_i)} \\left[ Y_i - \\hat{\\mu}_0(X_i) \\right]\n\\]\nwhere \\(\\hat{e}\\bigl(\\boldsymbol{X}_i\\bigr)\\) is the estimation of the propensity score \\(e(X_i) = \\mathbb{P}(A_i = 1 \\mid \\boldsymbol{X}_i)\\).\n\nset.seed(seed)\nn &lt;- n_untreated + n_treated\nn_folds &lt;- 5 # 5-fold cross-fitting\nfolds &lt;- sample(rep(1:n_folds, length.out = n))\n# Init results\n## outcomes\nmu_untreated_hat &lt;- rep(NA, n)\nmu_treated_hat &lt;- rep(NA, n)\n## propensity scores\ne_hat  &lt;- rep(NA, n)\n\nfor (k in 1:n_folds) {\n  idx_valid &lt;- which(folds == k)\n  idx_train &lt;- setdiff(1:n, idx_valid)\n  tb_train &lt;- tb |&gt; slice(idx_train)\n  tb_valid &lt;- tb |&gt; slice(-idx_train)\n  # Outcome models\n  mu_untreated_model &lt;- randomForest(\n    x = tb_train |&gt; filter(!!sym(A_name) == !!A_untreated) |&gt; \n      select(-!!Y_name, -!!A_name),\n    y = tb_train |&gt; filter(!!sym(A_name) == !!A_untreated) |&gt; \n      pull(!!Y_name) |&gt; factor(levels = c(0, 1))\n  )\n  mu_treated_model &lt;- randomForest(\n    x = tb_train |&gt; \n      filter(!!sym(A_name) != !!A_untreated) |&gt; select(-!!Y_name, -!!A_name),\n    y = tb_train |&gt; filter(!!sym(A_name) != !!A_untreated) |&gt; \n      pull(!!Y_name) |&gt; factor(levels = c(0, 1))\n  )\n  \n  mu_untreated_hat[idx_valid] &lt;- predict(\n    mu_untreated_model, newdata = tb_valid |&gt; select(-!!Y_name, -!!A_name)\n  ) |&gt; as.character() |&gt; as.numeric()\n  mu_treated_hat[idx_valid] &lt;- predict(\n    mu_treated_model, newdata = tb_valid |&gt; select(-!!Y_name, -!!A_name)\n  ) |&gt; as.character() |&gt; as.numeric()\n  \n  # Propensity model\n  ps_model &lt;- glm(\n    paste(A_name, \" ~ .\"), data = tb_train |&gt; select(-!!Y_name),\n    family = binomial()\n  )\n  # Propensity scores\n  e_hat[idx_valid] &lt;- predict(\n    ps_model, newdata = tb_valid, type = \"response\"\n  )\n}\n\nFor convenience, let us extract the treatment and the outcome:\n\nA &lt;- pull(tb, !!A_name)\nY &lt;- pull(tb, !!Y_name)\n# Index of treated\ntreated_idx &lt;- which(A != A_untreated)\n\nLastly, we can compute the ATT with the AIPW estimator:\n\naipw_terms &lt;- A * (Y - mu_untreated_hat) +\n  (1 - A) * (e_hat / (1 - e_hat)) * (Y - mu_untreated_hat)\nATT_aipw &lt;- sum(aipw_terms[treated_idx]) / sum(A == 1)\nATT_aipw\n\n[1] 0.143937\n\n\n\n\n12.3.3 ATT with a Causal Forest\nLet us apply a causal forest to estimate the ATT.\nFirst, we need to perform 1-hot encoding for categorical variables to comply with the requirements of the causal_forest(){R} from {grf}.\n\n# 1-hot-encoding\nX_mat &lt;- tb |&gt; select(-!!Y_name, -!!A_name)\nX_mat &lt;- model.matrix(~ . - 1, data = X_mat)\n\nWe train the causal forest:\n\nfit_cf &lt;- causal_forest(\n  X = X_mat, \n  Y = Y, \n  W = A\n)\n\n\n# the individual treatment effects\ntau_hat &lt;- predict(fit_cf)$predictions\n# the ATT\nATT_dml &lt;- mean(tau_hat[treated_idx])\nATT_dlm_se &lt;- sqrt(var(tau_hat[treated_idx]) / n_treated)\n\n# This can also be obtained as follows:\n# average_treatment_effect(fit_cf, target.sample = \"treated\")\n\n# The ATT:\nATT_dml\n\n[1] 0.02585502\n\n\n\n\n12.3.4 Summary\n\ntibble(ATT_cot = ATT_cot, ATT_aipw = ATT_aipw, ATT_dml = ATT_dml)\n\n# A tibble: 1 × 3\n  ATT_cot ATT_aipw ATT_dml\n    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1   0.448    0.144  0.0259",
    "crumbs": [
      "IV. Experiments",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Compas</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Baxendale, Peter, and Ting-Kam Leonard Wong. 2022. “Random Concave\nFunctions.” The Annals of Applied Probability 32 (2):\n812–52.\n\n\nFernandes Machado, Agathe, Arthur Charpentier, and Ewen Gallic. 2025a.\n“Optimal Transport on Categorical Data for Counterfactuals Using\nCompositional Data and Dirichlet Transport.” https://arxiv.org/abs/2501.15549.\n\n\n———. 2025b. “Sequential Conditional Transport on Probabilistic\nGraphs for Interpretable Counterfactual Fairness.”\nProceedings of the AAAI Conference on Artificial Intelligence\n39 (18): 19358–66. https://doi.org/10.1609/aaai.v39i18.34131.\n\n\nImai, Kosuke, Luke Keele, and Dustin Tingley. 2010. “A General\nApproach to Causal Mediation Analysis.” Psychological\nMethods 15 (4): 309.\n\n\nImai, Kosuke, Luke Keele, and Teppei Yamamoto. 2010.\n“Identification, Inference and Sensitivity Analysis for Causal\nMediation Effects.” Statistical Science 25 (1): 51–71.\n\n\nPearl, Judea. 2001. “Direct and Indirect Effects.” In\nProceedings of the Seventeenth Conference on Uncertainty and\nArtificial Intelligence, 2001, 411–20. Morgan Kaufmann, San\nFrancisco.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "xp-simulated.html#monte-carlo-experiment",
    "href": "xp-simulated.html#monte-carlo-experiment",
    "title": "11  Simulated Data",
    "section": "11.4 Monte-Carlo Experiment",
    "text": "11.4 Monte-Carlo Experiment\nWe run Monte-Carlo simulations to reproduce the previous steps. In each of the 200 iteration, we draw some data according to the DGP presented in Section 11.1. Then, we use the seq_trans() function (see Chapter 6) to perform sequential conditional transport to transport individuals from the untreated group (\\(A=0\\)) to the treated group (\\(A=1\\)).\nWe set the seeds for each replication and we define placeholders.\n\nseeds &lt;- 1:200\nres_simul_transp &lt;- vector(mode = \"list\", length = length(seeds))\nres_simul_effects &lt;- vector(mode = \"list\", length = length(seeds))\n\n\n# This chunk is not evaluated.\n# Each of the 200 replications takes about 16 seconds to run\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(transportsimplex)\n  source(\"../scripts/functions.R\")\n}) |&gt;\n  invisible()\n\nfor (i in 1:length(seeds)) {\n  cat(paste0(\"Simulation \", i, \"/\", length(seeds), \"\\n\"))\n  seed &lt;- seeds[i]\n  tb_all &lt;- gen_data(seed)\n  tb &lt;- tb_all |&gt; select(A, X1, X2, X3, Y) |&gt; \n    mutate(across(where(is.character), ~as.factor(.x)))\n  \n  A_name &lt;- \"A\"\n  A_untreated &lt;- 0\n  Y_name &lt;- \"Y\"\n  \n  sequential_transport &lt;- seq_trans(\n    data = tb, \n    adj = adj, \n    s = A_name, \n    S_0 = 0, # source: untreated\n    y = Y_name, \n    num_neighbors = 50, \n    num_neighbors_q = NULL,\n    silent = FALSE,\n    cl = cl\n  )\n  res_simul_transp[[i]] &lt;- sequential_transport\n  \n  tb_untreated &lt;- tb |&gt; filter(!!sym(A_name) == !!A_untreated)\n  tb_treated &lt;- tb |&gt; filter(!!sym(A_name) != !!A_untreated)\n  \n  n_untreated &lt;- nrow(tb_untreated)\n  n_treated &lt;- nrow(tb_treated)\n  \n  ## Measuring Causal Effect----\n  \n  # With Causal Mediation Analysis\n  med_mod &lt;- mediation::multimed(\n    outcome = \"Y\", \n    med.main = \"X1\", \n    med.alt = c(\"X2\", \"X3\"),\n    treat = \"A\", \n    data = tb |&gt; mutate(X3 = as.numeric(X3))\n  )\n  \n  delta_0_med &lt;- mean((med_mod$d0.lb + med_mod$d0.ub) / 2)\n  zeta_1_med &lt;- mean((med_mod$z1.lb + med_mod$z1.ub) / 2)\n  tot_effect_med &lt;- delta_0_med + zeta_1_med\n \n  # With Counterfactual Values\n  causal_effects_sot &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf = as_tibble(sequential_transport$transported), \n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  \n  res_simul_effects[[i]] &lt;- tibble(\n    seed = seed,\n    delta_0_med = delta_0_med, \n    zeta_1_med = zeta_1_med, \n    tot_effect_med = tot_effect_med,\n    delta_0_sot = causal_effects_sot$delta_0,\n    zeta_1_sot = causal_effects_sot$zeta_1, \n    tot_effect_sot = causal_effects_sot$tot_effect\n    )\n}\n\n\nsave(res_simul_transp, res_simul_effects, file = \"../output/res_simul.rda\")\n\nstopCluster(cl)\n\nWe load previously run simulations:\n\nload(\"../output/res_simul.rda\")\n\nWe can have a look at the transported values for variable \\(X_3\\) (from group 0 to group 1) of the first run, on a ternary plot (Figure 11.2).\n\n\nCodes to create the Figure.\nlibrary(ggtern)\ni &lt;- 1\nggtern(\n  data = gen_data(i) |&gt; select(A, X3_p_A,X3_p_B, X3_p_C) |&gt; \n    mutate(A = as.character(A)) |&gt; \n    bind_rows(\n      as_tibble(res_simul_transp[[i]]$transported_prob$X3) |&gt; \n        rename_with(.fn = ~str_c(\"X3_p_\", .)) |&gt; \n        mutate(A = \"1 to 0\")\n    ) |&gt; \n    mutate(A = factor(A, levels = c(\"0\", \"1\", \"1 to 0\"))),\n  mapping = aes(x = X3_p_A, y = X3_p_B, z = X3_p_C)\n) +\n  geom_point(\n    mapping = aes(colour = A), size = .5, alpha = .2\n  ) +\n  labs(x = \"A\", y = \"B\", z = \"C\") +\n  scale_colour_manual(\n    values = c(\"0\" = colours[[\"0\"]], \"1\" = colours[[\"1\"]], \"1 to 0\" = colours[[\"B\"]])\n  ) +\n  theme_light(base_size = font_size, base_family = font_family) +\n  theme_ggtern_paper() +\n  theme(\n    legend.title = element_text(size = .8 * font_size),\n    legend.text = element_text(size = .8 * font_size),\n    tern.axis.vshift = .08,\n    tern.axis.arrow.sep = .16,\n  ) +\n  theme_hidetitles() +\n  guides(\n    colour = guide_legend(\n      override.aes = list(\n        size = 1.5,\n        alpha = 1\n      )\n    )\n  )\n\n\n\n\n\nFigure 11.2: \\(X_3\\) values for individuals from group 0, those from group 1, and those transported from group 0 to group 1 using sequential transport.\n\n\n\n\n\n\n\n\nThen, we can look at the measures of causal effects.\n\ncausal_effects &lt;- list_rbind(res_simul_effects)\n\n\n\nCodes to create the Figure.\ndata_plot &lt;- causal_effects |&gt; \n  pivot_longer(\n    cols = -seed, \n    names_to = \"name\", values_to = \"tau\"\n  ) |&gt; \n  mutate(\n    type = case_when(\n      str_detect(name, \"^delta\") ~ \"delta\",\n      str_detect(name, \"^zeta\") ~ \"zeta\",\n      str_detect(name, \"^tot_effect\") ~ \"tot_effect\",\n      TRUE ~ NA_character_\n    ),\n    type = factor(\n      type, \n      levels = c(\"delta\", \"zeta\", \"tot_effect\"),\n      labels = c(\n        \"$\\\\bar{\\\\delta}(0)$\",\n        \"$\\\\bar{\\\\zeta}(1)$\",\n        \"$\\\\bar{\\\\tau}$\"\n      )),\n    Method = case_when(\n      str_detect(name, \"_med$\") ~ \"causal_med\",\n      str_detect(name, \"_sot$\") ~ \"seq_ot\",\n      TRUE ~ NA_character_\n    ),\n    Method = factor(\n      Method,\n      levels = c(\n        \"causal_med\", \"seq_ot\"\n      ),\n      labels = c(\"Causal Med.\", \"Seq. OT\")\n    )\n  )\nggplot(\n  data = data_plot,\n  mapping = aes(x = tau, y = Method)\n) +\n  geom_violin(\n    mapping = aes(fill = Method),\n    draw_quantiles = c(0.25, 0.5, 0.75)\n  ) +\n  geom_hline(yintercept = 0, colour = \"darkred\", linetype = \"dashed\") +\n  theme_paper() +\n  facet_wrap(\n    ~type, nrow = 1,\n    labeller = as_labeller(latex2exp::TeX, default = label_parsed)\n  ) +\n  scale_fill_manual(\n    NULL,\n    values = c(\n      \"Causal Med.\" = \"#E69F00\",\n      \"Seq. OT\" = \"#009E73\"\n    )\n  ) +\n  labs(y = NULL, x = latex2exp::TeX(\"$\\\\tau$\")) +\n  theme(legend.position = \"bottom\") # axis.text.y = element_blank()\n\n\n\n\n\nFigure 11.3: Causal effects, 200 replications.",
    "crumbs": [
      "IV. Experiments",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Simulated Data</span>"
    ]
  },
  {
    "objectID": "gaussian-example.html#sec-cf",
    "href": "gaussian-example.html#sec-cf",
    "title": "3  Gaussian Example",
    "section": "3.2 Counterfactuals",
    "text": "3.2 Counterfactuals\nLet us build counterfactuals for individuals from group 0, and for individuals from group 1. We will consider the following methods:\n\nMultivariate Optimal Transport (since we know the parameters of the two Gaussians),\nSequential Optimal Transport.\n\n\n3.2.1 Optimal Transport\n\nlibrary(expm)\n\nThe optimal transport map \\(T(x)\\) from \\(\\mathcal{N}(\\boldsymbol{\\mu}_0, \\boldsymbol{\\Sigma}_0)\\) to \\(\\mathcal{N}(\\boldsymbol{\\mu}_1, \\boldsymbol{\\Sigma}_1)\\) is: \\[T(x) = \\boldsymbol{\\mu}_1 + \\boldsymbol{A}(x - \\boldsymbol{\\mu}_0)\\] where: \\[\n\\boldsymbol{A} = \\boldsymbol{\\Sigma}_0^{1/2}\n       \\left( \\boldsymbol{\\Sigma}_0^{1/2} \\boldsymbol{\\Sigma}_1 \\boldsymbol{\\Sigma}_0^{1/2} \\right)^{-1/2}\n      \\boldsymbol{\\Sigma}_0^{1/2}\n\\]\nWe define the function compute_ot_map() to compute the optimal mapping.\n\n#' Optimal transport mapping between two Gaussian distributions \n#'  (from \\eqn{\\mathcal{N}(\\mu_{\\text{source}}, \\Sigma_{\\text{source}})} to \n#'   \\eqn{\\mathcal{N}(\\mu_{\\text{target}}, \\Sigma_{\\text{target}})})\n#'  \n#' @param mu_source Mean vector of the source Gaussian.\n#' @param sigma_source Covariance matrix of the source Gaussian.\n#' @param mu_target Mean vector of the target Gaussian.\n#' @param sigma_target Covariance matrix of the target Gaussian.\ncompute_ot_map &lt;- function(mu_source, sigma_source, mu_target, sigma_target) {\n  sqrt_sigma_source &lt;- sqrtm(sigma_source)\n  sqrt_sigma_source_inv &lt;- solve(sqrt_sigma_source)\n  \n  inner &lt;- sqrt_sigma_source %*% sigma_target %*% sqrt_sigma_source\n  sqrt_inner &lt;- sqrtm(inner)\n  \n  A &lt;- sqrt_sigma_source_inv %*% sqrt_inner %*% sqrt_sigma_source_inv\n  \n  list(A = A, shift = mu_target - A %*% mu_source)\n}\n\nWe also define the apply_ot_transport() function which uses a transport plan to transport individuals.\n\n#' Function to apply the transport map to simulated data\n#' \n#' @param X Observations to transport.\n#' @param mapping Optimal transport mapping (from `compute_ot_map()`)?\napply_ot_transport &lt;- function(X, mapping) {\n  A &lt;- mapping$A\n  shift &lt;- mapping$shift\n  t(apply(X, 1, function(x) as.vector(shift + A %*% x)))\n}\n\nSince we generated the data, we know the exact transport plan to transport individuals from group 0 to group 1. We also know the exact transport plan to transport individuals from group 1 to group 0.\n\nSigma0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSigma1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\n# Mapping from group 0 to group 1\not_map_0_to_1 &lt;- compute_ot_map(\n  mu_source = Mu0, sigma_source = Sigma0, \n  mu_target = Mu1, sigma_target = Sigma1\n)\n# Mapping from group 1 to group 0\not_map_1_to_0 &lt;- compute_ot_map(\n  mu_source = Mu1, sigma_source = Sigma1, \n  mu_target = Mu0, sigma_target = Sigma0\n)\n\nWe apply the transport map to the untreated units (A = 0).\n\nX0 &lt;- as.matrix(df[df$A == 0, c(\"X1\", \"X2\")])\nX0_t &lt;- apply_ot_transport(X = X0, mapping = ot_map_0_to_1)\ncolnames(X0_t) &lt;- c(c(\"X1\", \"X2\"))\n\nAnd to the transport map to the treated units (A = 1).\n\nX1 &lt;- as.matrix(df[df$A == 1, c(\"X1\", \"X2\")])\nX1_t &lt;- apply_ot_transport(X = X1, mapping = ot_map_1_to_0)\ncolnames(X1_t) &lt;- c(c(\"X1\", \"X2\"))\n\nLet us visualize the transported individuals. First, we define the function draw_ellipse() which will allow us to plot the 95% confidence ellipse in both groups.\n\n\nThe draw_ellipse() function.\ndraw_ellipse &lt;- function(mu, \n                         sigma, \n                         col = \"black\", \n                         lty = 1, \n                         lwd = 1, \n                         level = 0.95, \n                         ...) {\n  \n  angles &lt;- seq(0, 2 * pi, length.out = 100)\n  vals &lt;- sqrt(\n    qchisq(level, df = 2)) * t(chol(sigma)) %*% rbind(cos(angles), sin(angles)\n    )\n  lines(mu[1] + vals[1, ], mu[2] + vals[2, ], col = col, lty = lty, lwd = lwd, ...)\n  \n}\n\n\nWe isolate the observations from group 0 and from group 1.\n\n# Prepare data for the plot\nX0 &lt;- df[df$A == 0, c(\"X1\", \"X2\")]\nX1 &lt;- df[df$A == 1, c(\"X1\", \"X2\")]\n\nThe initial points and the transported values are shown in Figure 3.1\n\n\nCodes to create the Figure.\npar(mar = c(2.1, 2.1, 2.1, 0.1), mfrow = c(1, 2))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\n\n# From 0 to 1\nplot(X0, \n     pch = 16, \n     col = adjustcolor(colGpe0, alpha = .3), \n     xlim = x_lim, ylim = y_lim, \n     xlab = \"\", ylab = \"\",\n     main = \"OT: from A=0 to A=1\",\n     family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X0_t, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0$X1, y0 = X0$X2,\n  x1 = X0_t[, 1], y1 = X0_t[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Covariance of transported points (via OT map)\nSigma0_transport &lt;- ot_map_0_to_1$A %*% Sig0 %*% t(ot_map_0_to_1$A)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\ndraw_ellipse(Mu1, Sigma0_transport, col = colGpet, lty = 2)\n\n# From 1 to 0\nplot(X0, \n     pch = 16, \n     col = adjustcolor(colGpe0, alpha = .3), \n     xlim = x_lim, ylim = y_lim, \n     xlab = \"\", ylab = \"\",\n     main = \"OT: from A=0 to A=1\",\n     family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X1_t, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X1$X1, y0 = X1$X2,\n  x1 = X1_t[, 1], y1 = X1_t[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Covariance of transported points (via OT map)\nSigma0_transport &lt;- ot_map_1_to_0$A %*% Sig1 %*% t(ot_map_1_to_0$A)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\ndraw_ellipse(Mu0, Sigma0_transport, col = colGpet, lty = 2)\n\n\n\n\n\nFigure 3.1: 500 points in each group drawn from bivariates Gaussian distributions and transported values from group 0 to group 1 (left), and from group 1 to group 0 (righr), using optimal transport.\n\n\n\n\n\n\n\n\n\n\n3.2.2 Sequential Transport\nWe will now transport individuals using sequential transport. The results are sensitive to the ordering within the sequence. We will thus consider both ordering here:\n\na first marginal univariate optimal transport along the first dimension (\\(X_1\\)), then a conditional transport for the second dimension (\\(X_2 \\mid X_1)\\): sequential_transport_12(),\na first marginal univariate optimal transport along the second dimension (\\(X_2\\)), then a conditional transport for the first dimension (\\(X_1 \\mid X_2)\\): sequential_transport_21(),\n\n\n\nThe sequential_transport_12() function.\n#' Sequential transport from N(M_source, S_source) to N(M_target, S_target),\n#' along X1, then X2 | X1\n#'\n#' @param X n x 2 matrix of source observations.\n#' @param M_source Mean vector of the source distribution (length 2).\n#' @param S_source Covariance matrix of the source distribution (2x2).\n#' @param M_target Mean vector of the target distribution.\n#' @param S_target Covariance matrix of the target distribution.\nsequential_transport_12 &lt;- function(X, \n                                    M_source, \n                                    S_source, \n                                    M_target, \n                                    S_target) {\n  \n  # marginal univariate transport along the first coordinate (X_1)\n  T1x &lt;- qnorm(\n    pnorm(X[, 1], mean = M_source[1], sd = sqrt(S_source[1, 1])),\n    mean = M_target[1], sd = sqrt(S_target[1, 1])\n  )\n  \n  # conditional parameters for X_2 | X_1\n  m_source &lt;- M_source[2] + S_source[1, 2] / S_source[1, 1] * (X[, 1] - M_source[1])\n  s_source &lt;- S_source[2, 2] - S_source[1, 2]^2 / S_source[1, 1]\n  \n  m_target &lt;- M_target[2] + S_target[1, 2] / S_target[1, 1] * (T1x - M_target[1])\n  s_target &lt;- S_target[2, 2] - S_target[1, 2]^2 / S_target[1, 1]\n  \n  # conditional transport for the second coordinate\n  T2x &lt;- qnorm(\n    pnorm(X[, 2], mean = m_source, sd = sqrt(s_source)),\n    mean = m_target, sd = sqrt(s_target)\n  )\n  \n  cbind(T1x, T2x)\n}\n\n\n\n\nThe sequential_transport_21() function.\n#' Sequential transport from N(M_source, S_source) to N(M_target, S_target),\n#' along X2, then X1 | X2\n#'\n#' @param X n x 2 matrix of source observations.\n#' @param M_source Mean vector of the source distribution (length 2).\n#' @param S_source Covariance matrix of the source distribution (2x2).\n#' @param M_target Mean vector of the target distribution.\n#' @param S_target Covariance matrix of the target distribution.\nsequential_transport_21 &lt;- function(X, M_source, S_source, M_target, S_target) {\n  \n  # marginal univariate transport along X_2\n  T2x &lt;- qnorm(\n    pnorm(X[, 2], mean = M_source[2], sd = sqrt(S_source[2, 2])),\n    mean = M_target[2], sd = sqrt(S_target[2, 2])\n  )\n  \n  # conditional parameters for X_1 | X_2\n  m_source &lt;- M_source[1] + S_source[1, 2] / S_source[2, 2] * (X[, 2] - M_source[2])\n  s_source &lt;- S_source[1, 1] - S_source[1, 2]^2 / S_source[2, 2]\n  \n  m_target &lt;- M_target[1] + S_target[1, 2] / S_target[2, 2] * (T2x - M_target[2])\n  s_target &lt;- S_target[1, 1] - S_target[1, 2]^2 / S_target[2, 2]\n  \n  # conditional transport for X1 | X_2\n  T1x &lt;- qnorm(\n    pnorm(X[, 1], mean = m_source, sd = sqrt(s_source)),\n    mean = m_target, sd = sqrt(s_target)\n  )\n  \n  cbind(T1x, T2x)\n}\n\n\nWe isolate the observations from group 0 and from group 1, and store them as matrices.\n\nX0 &lt;- as.matrix(df[df$A == 0, c(\"X1\", \"X2\")])\nX1 &lt;- as.matrix(df[df$A == 1, c(\"X1\", \"X2\")])\n\nWe then transport from group 0 to group group 1 with sequential transport, first transporting \\(X_1\\) then \\(X_2 | X_1\\).\n\nX0_st_12 &lt;- sequential_transport_12(\n  X = X0, M_source = Mu0, S_source = Sig0, M_target = Mu1, S_target = Sig1\n)\n\nWe do the same but for units in group 1 to group 0.\n\nX1_st_12 &lt;- sequential_transport_12(\n  X = X1, M_source = Mu1, S_source = Sig1, M_target = Mu0, S_target = Sig0\n)\n\nWe also transport from group 0 to group group 1 with sequential transport, first transporting \\(X_1\\) then \\(X_1 | X_2\\).\n\nX0_st_21 &lt;- sequential_transport_21(\n  X = X0, M_source = Mu0, S_source = Sig0, M_target = Mu1, S_target = Sig1\n)\n\nWe do the same but for units in group 1 to group 0.\n\nX1_st_21 &lt;- sequential_transport_21(\n  X = X1, M_source = Mu1, S_source = Sig1, M_target = Mu0, S_target = Sig0\n)\n\nAgain, we can visualize the results on a scatter plot (Figure 3.2).\n\n\nCodes to create the Figure.\n# Prepare data for the plot\nX0 &lt;- df[df$A == 0, c(\"X1\", \"X2\")]\nX1 &lt;- df[df$A == 1, c(\"X1\", \"X2\")]\n\npar(mar = c(2.1, 2.1, 2.1, 0.1), mfrow = c(2,2))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\n\n# From 0 to 1, X1 then X2----\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\ntitle(main = \"A=0 to A=1, X1 then X2\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X0_st_12, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0$X1, y0 = X0$X2,\n  x1 = X0_st_12[, 1], y1 = X0_st_12[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# True mean and covariance (scaled by 'a')\nMu0 &lt;- rep(a * mu0, 2)\nMu1 &lt;- rep(a * mu1, 2)\nSig0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\nSig1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n# From 1 to 0, X1 then X2----\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\ntitle(main = \"A=1 to A=0, X1 then X2\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X1_st_12, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X1$X1, y0 = X1$X2,\n  x1 = X1_st_12[, 1], y1 = X1_st_12[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n# From A=0 to A=1, X2 then X1\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\ntitle(main = \"A=0 to A=1, X2 then X1\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X0_st_21, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X0$X1, y0 = X0$X2,\n  x1 = X0_st_21[, 1], y1 = X0_st_21[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n# From A=1 to A=0, X2 then X1\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\ntitle(main = \"A=1 to A=0, X2 then X1\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\npoints(X1_st_21, col = adjustcolor(colGpet, alpha = .3), pch = 17)\n\n# Add arrows from original to transported\narrows(\n  x0 = X1$X1, y0 = X1$X2,\n  x1 = X1_st_21[, 1], y1 = X1_st_21[, 2],\n  length = 0.05, col = adjustcolor(\"gray\", alpha = .3)\n)\n\n# Add ellipses\ndraw_ellipse(Mu0, Sig0, col = colGpe0, lty = 2)\ndraw_ellipse(Mu1, Sig1, col = colGpe1, lty = 2)\n\n\n\n\n\nFigure 3.2: 500 points in each group drawn from bivariates Gaussian distributions and transported values from group 0 to group 1 (left), and from group 1 to group 0 (right), using sequential optimal transport, first transporting \\(X_1\\), then \\(X_2 \\mid X_1\\) (top), and first transporting \\(X_2\\), then \\(X_1 \\mid X_2\\) (bottom).\n\n\n\n\n\n\n\n\n\n\n3.2.3 Illustration for a Single Unit\n\ncolour_methods &lt;- c(\"OT\" = \"#CC79A7\", \"seq_1\" = \"#009E73\", \"seq_2\" = \"#D55E00\")\n\n# Focus on a unit\ni &lt;- 11\n\nX0 &lt;- df[df$A == 0, c(\"X1\", \"X2\")]\nX1 &lt;- df[df$A == 1, c(\"X1\", \"X2\")]\n\ntikz('figs/gaussian-1-transport.tex', width = 2, height = 2.2)\n\npar(mar = c(2.1, 2.1, 1.8, 0.1))\nx_lim &lt;- c(-4, 4)\ny_lim &lt;- c(-4, 4)\n\n# X1 then X2\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family\n)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\n# title(main = \"X1 then X2\", line=.5, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\n\n# Individual of interest\npoints(X0[i, ], col = adjustcolor(colGpe0, alpha = 1), pch = 15, cex = 1.5)\npoints(X0_t[i, 1], X0_t[i, 2], col = adjustcolor(colour_methods[[\"OT\"]], alpha = 1), pch = 15, cex = 1.5)\npoints(X0_st_12[i, 1], X0_st_12[i, 2], col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = 1), pch = 15, cex = 1.5)\npoints(X0_st_21[i, 1], X0_st_21[i, 2], col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = 1), pch = 15, cex = 1.5)\n\nlength_arrow &lt;- 0.1\nlwd_arrow &lt;- 2\n# OT\narrows(\n  x0 = X0$X1[i], y0 = X0$X2[i],\n  x1 = X0_t[i, 1], y1 = X0_t[i, 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"OT\"]], alpha = 1),\n  lwd = lwd_arrow, lty = 2\n)\n# Seq OT (1): X_1 first\npoints(X0_st_12[i, 1], X0$X2[i], col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5), pch = 16, cex = 1.5)\narrows(\n  x0 = X0$X1[i], y0 = X0$X2[i],\n  x1 = X0_st_12[i, 1], y1 = X0$X2[i],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = 1),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0_st_12[i, 1], y0 = X0$X2[i],\n  x1 = X0_st_12[i, 1], y1 = X0_st_12[i, 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = 1),\n  lwd = lwd_arrow\n)\n\n# Seq OT (2): X_2 first\npoints(X0$X1[i], X0_st_21[i,2], col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5), pch = 16, cex = 1.5)\narrows(\n  x0 = X0$X1[i], y0 = X0$X2[i],\n  x1 = X0$X1[i], y1 = X0_st_21[i,2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = 1),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0$X1[i], y0 = X0_st_21[i,2],\n  x1 = X0_st_21[i, 1], y1 = X0_st_21[i, 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = 1),\n  lwd = lwd_arrow\n)\n\nlegend(\n  \"topleft\", \n  legend = c(\"$x_i$ (Obs.)\", \"OT\", \"Seq. OT (1)\", \"Seq. OT (2)\"), \n  col = c(colGpe0, colour_methods[c(\"OT\", \"seq_1\", \"seq_2\")]), \n  pch = 15, pt.cex = 1.5, cex = 1,\n  bty = \"n\"\n)\n\ndev.off()\n\nquartz_off_screen \n                2 \n\nplot_to_pdf(filename = \"gaussian-1-transport\", path = \"./figs/\", keep_tex = FALSE, crop = TRUE)",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Gaussian Example</span>"
    ]
  },
  {
    "objectID": "gaussian-example.html#sec-causal-effects",
    "href": "gaussian-example.html#sec-causal-effects",
    "title": "3  Gaussian Example",
    "section": "3.3 Causal Effect",
    "text": "3.3 Causal Effect\nWe first generate (again) some data, using the DGP presented in Section 11.1.\n\ndf &lt;- gen_data(\n  n = 500, \n  mu0 = -1, mu1 = +1, \n  r0 = +.7, r1 = -.5, a = 1, \n  seed = 12345\n)\n\n\n3.3.1 With Causal Mediation Analysis\nLet us create a dataset, tb, with only the binary response (Y), the binary treatment (A), and the two covariates.\n\ntb &lt;- df[, c(\"Y\", \"A\", \"X1\", \"X2\")]\nA_name &lt;- \"A\"\nA_untreated &lt;- 0\nY_name &lt;- \"Y\"\n\n\nmed_mod &lt;- mediation::multimed(\n  outcome = \"Y\", \n  med.main = \"X1\", \n  med.alt = \"X2\", \n  treat = \"A\", \n  data = df\n)\n\n\n\n\n\n\n\nWarning\n\n\n\nWe do not load the {mediation} package since it creates multiple conflicts with useful functions from tidyverse (including select()).\n\n\nLet us retrieve \\(\\bar{\\delta}(0)\\) (average causal mediation effect for \\(a=0\\)):\n\n(delta_0_med &lt;- mean((med_mod$d0.lb + med_mod$d0.ub) / 2))\n\n[1] 3.877971\n\n\nThen, let us get \\(\\bar{\\zeta}(1)\\) (average direct effect for \\(a=1\\)):\n\n(zeta_1_med &lt;- mean((med_mod$z1.lb + med_mod$z1.ub) / 2))\n\n[1] 0.06515032\n\n\nWe can then compute the total causal effect:\n\n(tot_effect_med &lt;- delta_0_med + zeta_1_med)\n\n[1] 3.943122\n\n\nLet us also retrieve \\(\\bar{\\delta}(1)\\) (average causal mediation effect for \\(a=1\\)) and \\(\\bar{\\zeta}(0)\\) (average direct effect for \\(a=0\\)):\n\ndelta_1_med &lt;- mean((med_mod$d1.lb + med_mod$d1.ub) / 2)\nzeta_0_med &lt;- mean((med_mod$z0.lb + med_mod$z0.ub) / 2)\nc(delta_1_med, zeta_0_med)\n\n[1] 3.7446202 0.1985014\n\n\n\n\n3.3.2 With Optimal Transport\nWe define a function, causal_effects_cf() to compute the causal effect of \\(A\\) on the outcome \\(Y\\), for the treated individuals.\n\n#' Estimation of total causal effect using counterfactuals.\n#' \n#' @param data_untreated Dataset with the untreated units only.\n#' @param data_treated Dataset with the treated units only.\n#' @param data_cf_untreated Counterfactuals for untreated had they been treated.\n#' @param data_cf_treated Counterfactuals for treated had they been untreated.\n#' @param Y_name Name of the column with the outcome variable.\n#' @param A_name Name of the column with the treatment variable.\n#' @param A_untreated Value of the treatment for the untreated units.\n#' \n#' @returns A list:\n#' - `delta_0_i`: \\eqn{\\delta_(0)}, individual causal mediation effects for \n#'   \\eqn{a=0} (computed on untreated),\n#' - `delta_0`: \\eqn{\\bar{\\delta}(0)}, average causal mediation effect for \n#'   \\eqn{a=0} (computed on untreated),\n#' - `delta_1_i`: \\eqn{\\delta_(1)}, individual causal mediation effects for \n#'   \\eqn{a=1} (computed on treated),\n#' - `delta_1`: \\eqn{\\bar{\\delta}(1)}, average causal mediation effect for \n#'   \\eqn{a=1} (computed on treated),\n#' - `zeta_0_i`: \\eqn{\\zeta_(0)}, individual causal mediation effects for \n#'   \\eqn{a=0} (computed on treaded),\n#' - `zeta_0`: \\eqn{\\bar{\\zeta}(0)}, average causal mediation effect for \n#'   \\eqn{a=0} (computed on treated),\n#' - `zeta_1_i`: \\eqn{\\zeta_(1)}, individual causal mediation effects for \n#'   \\eqn{a=1} (computed on untreaded),\n#' - `zeta_1`: \\eqn{\\bar{\\zeta}(1)}, average causal mediation effect for \n#'   \\eqn{a=1} (computed on untreated),\n#' - `tot_effect`: \\eqb{\\tau}: average total effect (\\eqn{\\bar{\\delta}(0) + \n#'   \\bar{\\zeta}(1)}).\n#'\n#' @importFrom randomForest randomForest\n#' @importFrom dplyr pull select\n#' @importFrom stats predict\n#' @md\ncausal_effects_cf &lt;- function(data_untreated,\n                              data_treated,\n                              data_cf_untreated,\n                              data_cf_treated,\n                              Y_name,\n                              A_name,\n                              A_untreated) {\n  \n  n_untreated &lt;- nrow(data_untreated)\n  n_treated &lt;- nrow(data_treated)\n  \n  # Outcome model for untreated\n  mu_untreated_model &lt;- randomForest(\n    x = data_untreated |&gt; dplyr::select(-!!Y_name, -!!A_name),\n    y = pull(data_untreated, !!Y_name)\n  )\n  \n  # Outcome model for treated\n  mu_treated_model &lt;- randomForest(\n    x = data_treated |&gt; dplyr::select(-!!Y_name, -!!A_name),\n    y = pull(data_treated, !!Y_name)\n  )\n  \n  # Observed outcome\n  y_untreated_obs &lt;- data_untreated |&gt; pull(!!Y_name)\n  y_treated_obs &lt;- data_treated |&gt; pull(!!Y_name)\n  \n  # Natural Indirect Effect, using predictions\n  delta_0_i &lt;- predict(mu_untreated_model, newdata = data_cf_untreated) -\n    predict(mu_untreated_model)\n  delta_0 &lt;- mean(delta_0_i)\n  delta_1_i &lt;- predict(mu_treated_model) - \n    predict(mu_treated_model, newdata = data_cf_treated)\n  delta_1 &lt;- mean(delta_1_i)\n\n  # Natural Indirect Effect, using observed variables\n  delta_0_i_obs &lt;- predict(mu_untreated_model, newdata = data_cf_untreated) - \n    y_untreated_obs\n  delta_0_obs &lt;- mean(delta_0_i_obs)\n  delta_1_i_obs &lt;- y_treated_obs - \n    predict(mu_treated_model, newdata = data_cf_treated)\n  delta_1_obs &lt;- mean(delta_1_i_obs)\n  \n  # Natural Direct Effect (only predictions)\n  zeta_0_i &lt;- predict(mu_treated_model, newdata = data_cf_treated) -\n    predict(mu_untreated_model, newdata = data_cf_treated)\n  zeta_0 &lt;- mean(zeta_0_i)\n  \n  zeta_1_i &lt;- predict(mu_treated_model, newdata = data_cf_untreated) - \n    predict(mu_untreated_model, newdata = data_cf_untreated)\n  zeta_1 &lt;- mean(zeta_1_i)\n  \n  # Total Causal Effect for treated\n  tot_effect &lt;- delta_0 + zeta_1  \n  tot_effect_obs &lt;- delta_0_obs + zeta_1\n  \n  \n  list(\n    delta_0_i = delta_0_i,\n    delta_1_i = delta_1_i,\n    zeta_0_i = zeta_0_i,\n    zeta_1_i = zeta_1_i,\n    delta_0_i_obs = delta_0_i_obs,\n    delta_1_i_obs = delta_1_i_obs,\n    delta_0 = delta_0,\n    delta_1 = delta_1,\n    zeta_0 = zeta_0,\n    zeta_1 = zeta_1,\n    delta_0_obs = delta_0_obs,\n    delta_1_obs = delta_1_obs,\n    tot_effect = tot_effect,\n    tot_effect_obs = tot_effect_obs\n  )\n}\n\nWe use a random forest to estimate the outcome model.\n\nlibrary(randomForest)\n\nWe apply this function to our simulated dataset.\n\ntb_untreated &lt;- tb |&gt; filter(!!sym(A_name) == !!A_untreated)\ntb_treated &lt;- tb |&gt; filter(!!sym(A_name) != !!A_untreated)\n\ncausal_effects_ot &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(X0_t),\n  data_cf_treated = as_tibble(X1_t),\n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated\n)\n\ncbind(\n  delta_0 = causal_effects_ot$delta_0,\n  zeta_1 = causal_effects_ot$zeta_1,\n  delta_1 = causal_effects_ot$delta_1,\n  zeta_0 = causal_effects_ot$zeta_0,\n  tot_effect = causal_effects_ot$tot_effect,\n  tot_effect_obs = causal_effects_ot$tot_effect_obs\n)\n\n       delta_0   zeta_1   delta_1   zeta_0 tot_effect tot_effect_obs\n[1,] 0.9302024 3.170275 0.2286476 3.763413   4.100477       4.087862\n\n\n\n\n3.3.3 With Sequential Optimal Transport\nWe apply the same function as that used with the counterfactuals obtained with optimal transport (causal_effects_cf()). However, here, we feed it with the counterfactuals obtained with sequential transport. For those where we first transport \\(X_1\\) and then \\(X_2 \\mid X_1\\):\n\ncausal_effect_sot_12 &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(X0_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  data_cf_treated = as_tibble(X1_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated\n)\n\nAnd for the counterfactuales obtained by sequential transport where we first transport \\(X_2\\) and then \\(X_1 \\mid X_2\\):\n\ncausal_effect_sot_21 &lt;- causal_effects_cf(\n  data_untreated = tb_untreated, \n  data_treated = tb_treated,\n  data_cf_untreated = as_tibble(X0_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  data_cf_treated = as_tibble(X1_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n  Y_name = Y_name, \n  A_name = A_name, \n  A_untreated = A_untreated\n)\n\n\n\n3.3.4 Summary\n\ntribble(\n  ~Method, ~Name, ~Value,\n  \"Theoretical\", \"delta(0)\", (a1+a2) * (mu1-mu0),\n  \"Theoretical\", \"delta(1)\", (a1+a2) * (mu1-mu0),\n  \"Theoretical\", \"zeta(0)\", a0,\n  \"Theoretical\", \"zeta(1)\", a0,\n  \"Theoretical\", \"tau\", (a1+a2) * (mu1-mu0) + a0,\n  #\n  \"Mediation\", \"delta(0)\", delta_0_med,\n  \"Mediation\", \"delta(1)\", delta_1_med,\n  \"Mediation\", \"zeta(0)\", zeta_0_med,\n  \"Mediation\", \"zeta(1)\", zeta_1_med,\n  \"Mediation\", \"tau\", tot_effect_med,\n  #\n  \"OT\", \"delta(0)\", causal_effects_ot$delta_0,\n  \"OT\", \"delta(1)\", causal_effects_ot$delta_1,\n  \"OT\", \"zeta(0)\", causal_effects_ot$zeta_0,  \n  \"OT\", \"zeta(1)\", causal_effects_ot$zeta_1,\n  \"OT\", \"tau\", causal_effects_ot$tot_effect,\n  #\n  \"OT (Obs)\", \"delta(0)\", causal_effects_ot$delta_0_obs,\n  \"OT (Obs)\", \"delta(1)\", causal_effects_ot$delta_1_obs,\n  \"OT (Obs)\", \"tau\", causal_effects_ot$tot_effect_obs,\n  #\n  \"SOT (1)\", \"delta(0)\", causal_effect_sot_12$delta_0,\n  \"SOT (1)\", \"delta(1)\", causal_effect_sot_12$delta_1,\n  \"SOT (1)\", \"zeta(0)\", causal_effect_sot_12$zeta_0,  \n  \"SOT (1)\", \"zeta(1)\", causal_effect_sot_12$zeta_1,\n  \"SOT (1)\", \"tau\", causal_effect_sot_12$tot_effect,\n  #\n  \"SOT (1) (Obs)\", \"delta(0)\", causal_effect_sot_12$delta_0_obs,\n  \"SOT (1) (Obs)\", \"delta(1)\", causal_effect_sot_12$delta_1_obs,\n  \"SOT (1) (Obs)\", \"tau\", causal_effect_sot_12$tot_effect_obs,\n  #\n  \"SOT (2)\", \"delta(0)\", causal_effect_sot_21$delta_0,\n  \"SOT (2)\", \"delta(1)\", causal_effect_sot_21$delta_1,\n  \"SOT (2)\", \"zeta(0)\", causal_effect_sot_21$zeta_0,\n  \"SOT (2)\", \"zeta(1)\", causal_effect_sot_21$zeta_1,\n  \"SOT (2)\", \"tau\", causal_effect_sot_21$tot_effect,\n  #\n  \"SOT (2) (Obs)\", \"delta(0)\", causal_effect_sot_21$delta_0_obs,\n  \"SOT (2) (Obs)\", \"delta(1)\", causal_effect_sot_21$delta_1_obs,\n  \"SOT (2) (Obs)\", \"tau\", causal_effect_sot_21$tot_effect_obs\n) |&gt; \n  pivot_wider(names_from = \"Name\", values_from = \"Value\")\n\n# A tibble: 8 × 6\n  Method        `delta(0)` `delta(1)` `zeta(0)` `zeta(1)`   tau\n  &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 Theoretical        1          1         3        3       4   \n2 Mediation          3.88       3.74      0.199    0.0652  3.94\n3 OT                 0.930      0.229     3.76     3.17    4.10\n4 OT (Obs)           0.918      0.236    NA       NA       4.09\n5 SOT (1)            1.03       0.116     3.91     3.12    4.15\n6 SOT (1) (Obs)      1.02       0.119    NA       NA       4.15\n7 SOT (2)            0.889      0.117     3.94     3.05    3.94\n8 SOT (2) (Obs)      0.881      0.134    NA       NA       3.93\n\n\n\n\n3.3.5 Some Individuals\nLet us have a look at some individuals. We focus on the one with the predicted \\(\\tau_i\\) estimated using Optimal Transport which is the closest to the theoretical value, and the one that is the farthest. Let us get the theoretical values:\n\n(tau_theo &lt;- (a1 + a2) * (mu1 - mu0) + a0)\n\n[1] 4\n\n(tau_med &lt;- tot_effect_med)\n\n[1] 3.943122\n\n(tau_ot &lt;- causal_effects_ot$tot_effect)\n\n[1] 4.100477\n\n(tau_sot_12 &lt;- causal_effect_sot_12$tot_effect)\n\n[1] 4.153104\n\n(tau_sot_21 &lt;- causal_effect_sot_21$tot_effect)\n\n[1] 3.942041\n\n\nWe create a table that contains the coordinates of individuals from group 0), their transported coordinates (using OT, and sequential transport), and their estimated values for \\(\\delta_i(0)\\), \\(\\zeta_i(1)\\), and \\(\\tau_i\\), obtained with OT and with sequential transport.\n\ntb_indiv_0 &lt;- \n  tibble(\n    X1 = X0$X1,\n    X2 = X0$X2,\n    X1_t = X0_t[, 1], # with OT\n    X2_t = X0_t[, 2], # idem\n    X1_sot_12 = X0_st_12[, 1], # with Seq T (1)\n    X2_sot_12 = X0_st_12[, 2], # idem\n    X1_sot_21 = X0_st_21[, 1], # with Seq T (2)\n    X2_sot_21 = X0_st_21[, 2], # idem\n    # OT\n    delta_0_i_ot = causal_effects_ot$delta_0_i,\n    zeta_1_i_ot = causal_effects_ot$zeta_1_i,\n    # ST (1)\n    delta_0_i_sot_12 = causal_effect_sot_12$delta_0_i,\n    zeta_1_i_sot_12 = causal_effect_sot_12$zeta_1_i,\n    # ST (2)\n    delta_0_i_sot_21 = causal_effect_sot_21$delta_0_i,\n    zeta_1_i_sot_21 = causal_effect_sot_21$zeta_1_i\n  ) |&gt; \n  # Total causal effect\n  mutate(\n    tau_i_ot = delta_0_i_ot + zeta_1_i_ot,\n    tau_i_sot_12 = delta_0_i_sot_12 + zeta_1_i_sot_12,\n    tau_i_sot_21 = delta_0_i_ot + zeta_1_i_sot_21\n  ) |&gt; \n  # Distance to the theoretical value\n  mutate(\n    tau_i_ot_dist = abs(tau_i_ot - tau_theo),\n    tau_i_sot_12_dist = abs(tau_i_sot_12 - tau_theo),\n    tau_i_sot_21_dist = abs(tau_i_sot_21 - tau_theo)\n  )\n\nIn that table, we identify the two untreated units of interest.\n\nind_closest &lt;- order(tb_indiv_0$tau_i_ot_dist)[1]\nind_farthest &lt;- rev(order(tb_indiv_0$tau_i_ot_dist))[1]\n\n\n\nCodes to create the Table.\nformat_num &lt;- function(x) scales::number(x, accuracy = 0.1)\n\ntb_indiv_0_short &lt;- \n  tb_indiv_0 |&gt; \n  select(-ends_with(\"dist\")) |&gt; \n  mutate(\n    across(where(is.numeric),\n           ~format_num(.x)\n    )\n  ) |&gt; \n  mutate(\n    obs_type = case_when(\n      row_number() == ind_closest ~ \"Closest\",\n      row_number() == ind_farthest ~ \"Farthest\",\n      TRUE ~ \"Other\"\n    )\n  ) |&gt; \n  filter(obs_type != \"Other\") |&gt; \n  mutate(\n    coord = str_c(\"(\", X1, \", \", X2, \")\"),\n    coord_OT = str_c(\"(\", X1_t, \", \", X2_t, \")\"),\n    coord_ST1 = str_c(\"(\", X1_sot_12, \", \", X2_sot_12, \")\"),\n    coord_ST2 = str_c(\"(\", X1_sot_21, \", \", X2_sot_21, \")\")\n  ) |&gt; \n  select(\n    -X1, -X2, -X1_t, -X2_t, -X1_sot_12, -X2_sot_12, -X1_sot_21, -X2_sot_21\n  ) |&gt; \n  pivot_longer(\n    cols = c(\n      -obs_type, -coord, -coord_OT, -coord_ST1, -coord_ST2\n    )\n  ) |&gt; \n  mutate(\n    type = case_when(\n      str_detect(name, \"^delta\") ~ \"delta\",\n      str_detect(name, \"^zeta\") ~ \"zeta\",\n      str_detect(name, \"^tau\") ~ \"tau\",\n      TRUE ~ NA_character_\n    ),\n    type = factor(\n      type, \n      levels = c(\"delta\", \"zeta\", \"tau\")\n    ),\n    method = case_when(\n      str_detect(name, \"_med$\") ~ \"CM\",\n      str_detect(name, \"_ot$\") ~ \"OT\",\n      str_detect(name, \"_sot_12$\") ~ \"ST(1)\",\n      str_detect(name, \"sot_21$\") ~ \"ST(2)\",\n      TRUE ~ \"\"\n    )\n  ) |&gt; \n  select(-name) |&gt; \n  pivot_wider(\n    names_from = type, values_from = value\n  )\ntb_indiv_0_short |&gt; \n  group_by(obs_type) |&gt; \n  slice_head(n=1) |&gt; \n  select(coord, coord_OT, coord_ST1, coord_ST2) |&gt; \n  kableExtra::kbl(booktabs = TRUE)\n\n\n\nCoordinates of two untreated units before and after transport.\n\n\nobs_type\ncoord\ncoord_OT\ncoord_ST1\ncoord_ST2\n\n\n\n\nClosest\n(-1.5, -1.4)\n(0.6, 0.9)\n(0.5, 1.2)\n(0.9, 0.6)\n\n\nFarthest\n(-2.4, -3.8)\n(1.4, -1.6)\n(-0.4, -0.4)\n(3.0, -1.8)\n\n\n\n\n\n\n\n\n\nCodes to create the Table.\ntb_indiv_0_short |&gt; \n  select(method, delta, zeta, tau) |&gt; \n  kableExtra::kbl(booktabs = TRUE)\n\n\n\nEstimated values of \\(\\delta_i(0)\\), \\(\\zeta_i(1)\\), and \\(\\tau_i\\) for the two individuals, depending on the transport method.\n\n\nmethod\ndelta\nzeta\ntau\n\n\n\n\nOT\n4.0\n4.9\n9.0\n\n\nST(1)\n1.3\n3.4\n4.6\n\n\nST(2)\n3.9\n7.6\n11.7\n\n\nOT\n1.4\n2.6\n4.0\n\n\nST(1)\n-0.3\n3.5\n3.2\n\n\nST(2)\n1.6\n3.5\n4.9\n\n\n\n\n\n\n\n\n\nCodes to create the Figure\nexport_tikz &lt;- FALSE\nfile_name &lt;- \"gaussian-tau-two-indiv\"\n\nif (export_tikz == TRUE)\n  tikz(paste0(\"figs/\", file_name, \".tex\"), width = 3.2, height = 1.5)\n\n# par(mar = c(2.1, 2.1, .1, .1), mfrow = c(1, 2))\nlayout(matrix(c(1, 2), nrow = 1, byrow = TRUE), widths = c(10,8.1))\npar(mar = c(2.1, 2.1, .1, .1))\n## Closest----\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family,\n  axes = FALSE\n)\naxis(1, at = -3:3, labels = TRUE)\naxis(2, at = -3:3, labels = TRUE)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\n\n# Individuals of interest\n# Arrows to OT\narrows(\n  x0 = X0$X1[c(ind_closest)],\n  y0 = X0$X2[c(ind_closest)],\n  x1 = X0_t[c(ind_closest), \"X1\"], \n  y1 = X0_t[c(ind_closest), \"X2\"],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"OT\"]], alpha = 1),\n  lwd = lwd_arrow, lty = 2\n)\n# Seq OT (1): X_1 first\n# points(\n#   X0_st_12[c(ind_closest), 1], \n#   X0$X2[c(ind_closest)], \n#   col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5), pch = 16, cex = 1\n# )\narrows(\n  x0 = X0$X1[c(ind_closest)], \n  y0 = X0$X2[c(ind_closest)],\n  x1 = X0_st_12[c(ind_closest), 1], \n  y1 = X0$X2[c(ind_closest)],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0_st_12[c(ind_closest), 1], \n  y0 = X0$X2[c(ind_closest)],\n  x1 = X0_st_12[c(ind_closest), 1], \n  y1 = X0_st_12[c(ind_closest), 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5),\n  lwd = lwd_arrow\n)\n# Seq OT (2): X_2 first\n# points(\n#   X0$X1[c(ind_closest)], \n#   X0_st_21[c(ind_closest),2], \n#   col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5), pch = 16, cex = 1\n# )\narrows(\n  x0 = X0$X1[c(ind_closest)], \n  y0 = X0$X2[c(ind_closest)],\n  x1 = X0$X1[c(ind_closest)], \n  y1 = X0_st_21[c(ind_closest),2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0$X1[c(ind_closest)], \n  y0 = X0_st_21[c(ind_closest),2],\n  x1 = X0_st_21[c(ind_closest), 1], \n  y1 = X0_st_21[c(ind_closest), 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5),\n  lwd = lwd_arrow\n)\n\n# Individuals\npoints(\n  tb_indiv_0$X1[c(ind_closest)], \n  tb_indiv_0$X2[c(ind_closest)], \n  col = \"black\", pch = c(15), cex = 1\n)\n# Transported values for those individuals (OT)\npoints(\n  X0_t[c(ind_closest), \"X1\"], \n  X0_t[c(ind_closest), \"X2\"], \n  col = colour_methods[[\"OT\"]], pch = c(15), cex = 1\n)\n# With Sequential transport (1)\npoints(\n  X0_st_12[c(ind_closest), 1], \n  X0_st_12[c(ind_closest), 2], \n  col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = 1), pch = 15, cex = 1\n)\n# With Sequential transport (2)\npoints(\n  X0_st_21[c(ind_closest), 1], \n  X0_st_21[c(ind_closest), 2], \n  col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = 1), pch = 15, cex = 1\n)\n\n\nif (export_tikz == FALSE) {\n  lab_points_ot &lt;- latex2exp::TeX(\n    paste0(\n      \"$\\\\tau_i^{OT}=\", \n      round(tb_indiv_0$tau_i_ot[c(ind_closest)], 2), \"$\"\n    )\n  )\n  lab_points_sot_12 &lt;- latex2exp::TeX(\n    paste0(\n      \"$\\\\tau_i^{ST(1)}=\", \n      round(tb_indiv_0$tau_i_sot_12[c(ind_closest)], 2), \"$\"\n    )\n  )\n  lab_points_sot_21 &lt;- latex2exp::TeX(\n    paste0(\n      \"$\\\\tau_i^{ST(2)}=\", \n      round(tb_indiv_0$tau_i_sot_21[c(ind_closest)], 2), \"$\"\n    )\n  )\n} else {\n  lab_points_ot &lt;- paste0(\n    \"$\\\\tau_i^{\\\\textnormal{OT}}=\", \n    round(tb_indiv_0$tau_i_ot[c(ind_closest)], 2), \"$\"\n  )\n  lab_points_sot_12 &lt;- paste0(\n    \"$\\\\tau_i^{\\\\textnormal{ST}(1)}=\", \n    round(tb_indiv_0$tau_i_sot_12[c(ind_closest)], 2), \"$\"\n  )\n  lab_points_sot_21 &lt;- paste0(\n    \"$\\\\tau_i^{\\\\textnormal{ST}(2)}=\", \n    round(tb_indiv_0$tau_i_sot_21[c(ind_closest)], 2), \"$\"\n  )\n}\n# Initial point\ntext(\n  x = X0_t[c(ind_closest), \"X1\"], \n  y = X0_t[c(ind_closest), \"X2\"] + .5, \n  labels = lab_points_ot,\n  col = colour_methods[[\"OT\"]]\n)\ntext(\n  x = X0_st_12[c(ind_closest), 1], \n  y = X0_st_12[c(ind_closest), 2] + 1, \n  labels = lab_points_sot_12,\n  col = colour_methods[[\"seq_1\"]]\n)\ntext(\n  x = X0_st_21[c(ind_closest), 1], \n  y = X0_st_21[c(ind_closest), 2] - 1, \n  labels = lab_points_sot_21,\n  col = colour_methods[[\"seq_2\"]]\n)\n\n## Farthest----\npar(mar = c(2.1, .1, .1, .1))\nplot(\n  X0, \n  pch = 16, \n  col = adjustcolor(colGpe0, alpha = .3), \n  xlim = x_lim, ylim = y_lim, \n  xlab = \"\", ylab = \"\",\n  main = \"\",\n  family = font_family,\n  axes = FALSE\n)\naxis(1, at = -3:3, labels = TRUE)\n# axis(2, at = -3:3, labels = TRUE)\ntitle(xlab = \"X1\", ylab=\"X2\", line=2, cex.lab=1.2, family = font_family)\npoints(X1, col = adjustcolor(colGpe1, alpha = .3), pch = 16)\n\n# Individuals of interest\n# Arrows to OT\narrows(\n  x0 = X0$X1[c(ind_farthest)],\n  y0 = X0$X2[c(ind_farthest)],\n  x1 = X0_t[c(ind_farthest), \"X1\"], \n  y1 = X0_t[c(ind_farthest), \"X2\"],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"OT\"]], alpha = 1),\n  lwd = lwd_arrow, lty = 2\n)\n# Seq OT (1): X_1 first\n# points(\n#   X0_st_12[c(ind_farthest), 1], \n#   X0$X2[c(ind_farthest)], \n#   col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5), pch = 16, cex = 1\n# )\narrows(\n  x0 = X0$X1[c(ind_farthest)], \n  y0 = X0$X2[c(ind_farthest)],\n  x1 = X0_st_12[c(ind_farthest), 1], \n  y1 = X0$X2[c(ind_farthest)],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0_st_12[c(ind_farthest), 1], \n  y0 = X0$X2[c(ind_farthest)],\n  x1 = X0_st_12[c(ind_farthest), 1], \n  y1 = X0_st_12[c(ind_farthest), 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = .5),\n  lwd = lwd_arrow\n)\n# Seq OT (2): X_2 first\n# points(\n#   X0$X1[c(ind_farthest)], \n#   X0_st_21[c(ind_farthest),2], \n#   col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5), pch = 16, cex = 1\n# )\narrows(\n  x0 = X0$X1[c(ind_farthest)], \n  y0 = X0$X2[c(ind_farthest)],\n  x1 = X0$X1[c(ind_farthest)], \n  y1 = X0_st_21[c(ind_farthest),2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5),\n  lwd = lwd_arrow\n)\narrows(\n  x0 = X0$X1[c(ind_farthest)], \n  y0 = X0_st_21[c(ind_farthest),2],\n  x1 = X0_st_21[c(ind_farthest), 1], \n  y1 = X0_st_21[c(ind_farthest), 2],\n  length = length_arrow, col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = .5),\n  lwd = lwd_arrow\n)\n\n# Individuals\npoints(\n  tb_indiv_0$X1[c(ind_farthest)], \n  tb_indiv_0$X2[c(ind_farthest)], \n  col = \"black\", pch = c(15), cex = 1\n)\n# Transported values for those individuals (OT)\npoints(\n  X0_t[c(ind_farthest), \"X1\"], \n  X0_t[c(ind_farthest), \"X2\"], \n  col = colour_methods[[\"OT\"]], pch = c(15), cex = 1\n)\n# With Sequential transport (1)\npoints(\n  X0_st_12[c(ind_farthest), 1], \n  X0_st_12[c(ind_farthest), 2], \n  col = adjustcolor(colour_methods[[\"seq_1\"]], alpha = 1), pch = 15, cex = 1\n)\n# With Sequential transport (2)\npoints(\n  X0_st_21[c(ind_farthest), 1], \n  X0_st_21[c(ind_farthest), 2], \n  col = adjustcolor(colour_methods[[\"seq_2\"]], alpha = 1), pch = 15, cex = 1\n)\n\n\nif (export_tikz == FALSE) {\n  lab_points_ot &lt;- latex2exp::TeX(\n    paste0(\n      \"$\\\\tau_i^{OT}=\", \n      round(tb_indiv_0$tau_i_ot[c(ind_farthest)], 2), \"$\"\n    )\n  )\n  lab_points_sot_12 &lt;- latex2exp::TeX(\n    paste0(\n      \"$\\\\tau_i^{ST(1)}=\", \n      round(tb_indiv_0$tau_i_sot_12[c(ind_farthest)], 2), \"$\"\n    )\n  )\n  lab_points_sot_21 &lt;- latex2exp::TeX(\n    paste0(\n      \"$\\\\tau_i^{ST(2)}=\", \n      round(tb_indiv_0$tau_i_sot_21[c(ind_farthest)], 2), \"$\"\n    )\n  )\n} else {\n  lab_points_ot &lt;- paste0(\n    \"$\\\\tau_i^{\\\\textnormal{OT}}=\", \n    round(tb_indiv_0$tau_i_ot[c(ind_farthest)], 2), \"$\"\n  )\n  lab_points_sot_12 &lt;- paste0(\n    \"$\\\\tau_i^{\\\\textnormal{ST}(1)}=\", \n    round(tb_indiv_0$tau_i_sot_12[c(ind_farthest)], 2), \"$\"\n  )\n  lab_points_sot_21 &lt;- paste0(\n    \"$\\\\tau_i^{\\\\textnormal{ST}(2)}=\", \n    round(tb_indiv_0$tau_i_sot_21[c(ind_farthest)], 2), \"$\"\n  )\n}\n# Initial point\ntext(\n  x = X0_t[c(ind_farthest), \"X1\"], \n  y = X0_t[c(ind_farthest), \"X2\"] + .5, \n  labels = lab_points_ot,\n  col = colour_methods[[\"OT\"]]\n)\ntext(\n  x = X0_st_12[c(ind_farthest), 1], \n  y = X0_st_12[c(ind_farthest), 2] + .5, \n  labels = lab_points_sot_12,\n  col = colour_methods[[\"seq_1\"]]\n)\ntext(\n  x = X0_st_21[c(ind_farthest), 1] - 1.5, \n  y = X0_st_21[c(ind_farthest), 2] - 1, \n  labels = lab_points_sot_21,\n  col = colour_methods[[\"seq_2\"]]\n)\n\n\n\n\n\n\n\n\n\nCodes to create the Figure\nif (export_tikz == TRUE) {\n  dev.off()\n  plot_to_pdf(filename = file_name, path = \"./figs/\", keep_tex = FALSE, crop = FALSE)\n}",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Gaussian Example</span>"
    ]
  },
  {
    "objectID": "gaussian-example.html#monte-carlo-simulations",
    "href": "gaussian-example.html#monte-carlo-simulations",
    "title": "3  Gaussian Example",
    "section": "3.4 Monte-Carlo Simulations",
    "text": "3.4 Monte-Carlo Simulations\nLet us perform Monte-Carlo simulations to observe the stability of the previous estimations. We define a function, sim_f(), to perform three steps:\n\nGenerate a sample from the DGP shown in Section 11.1,\nBuild the counterfactuals using OT and Sequential transport as in Section 3.2,\nCompute the causal effects as in Section 3.3.\n\n\n\nThe sim_f() function.\nsim_f &lt;- function(n = 500,\n                  mu0, \n                  mu1, \n                  r0, \n                  r1, \n                  a, \n                  seed = NULL) {\n  \n  if (!is.null(seed)) set.seed(seed)\n  \n  # 1. Generate data\n  df &lt;- gen_data(\n    n = 500, \n    mu0 = mu0, mu1 = mu1, \n    r0 = r0, r1 = r1, a = a, \n    seed = seed\n  )\n  \n  # 2. Building Counterfactuals\n  \n  ## With Optimal Transport\n  # Transporting map for source: group 1, target: group 0 (careful here)\n  Sigma0 &lt;- matrix(c(1, r0, r0, 1), 2, 2)\n  Sigma1 &lt;- matrix(c(1, r1, r1, 1), 2, 2)\n  Mu0 &lt;- rep(a * mu0, 2)\n  Mu1 &lt;- rep(a * mu1, 2)\n  \n  # Mapping from group 0 to group 1\n  ot_map_0_to_1 &lt;- compute_ot_map(\n    mu_source = Mu0, sigma_source = Sigma0, \n    mu_target = Mu1, sigma_target = Sigma1\n  )\n  # Mapping from group 1 to group 0\n  ot_map_1_to_0 &lt;- compute_ot_map(\n    mu_source = Mu1, sigma_source = Sigma0, \n    mu_target = Mu0, sigma_target = Sigma0\n  )  \n\n  # Apply transport map to treated units (A = 1)\n  X0 &lt;- as.matrix(df[df$A == 0, c(\"X1\", \"X2\")])\n  X1 &lt;- as.matrix(df[df$A == 1, c(\"X1\", \"X2\")])\n  X0_t &lt;- apply_ot_transport(X = X0, mapping = ot_map_0_to_1)\n  colnames(X0_t) &lt;- c(c(\"X1\", \"X2\"))\n  X1_t &lt;- apply_ot_transport(X = X1, mapping = ot_map_1_to_0)\n  colnames(X1_t) &lt;- c(c(\"X1\", \"X2\"))\n  \n  ## With Sequential Transport\n  # Transport from group 0 to group 1: X1 then X2 | X1\n  X0_st_12 &lt;- sequential_transport_12(\n    X = X0, M_source = Mu0, S_source = Sigma0, M_target = Mu1, S_target = Sigma1\n  )\n  # Transport from group 1 to group 0: X1 then X2 | X1\n  X1_st_12 &lt;- sequential_transport_12(\n    X = X1, M_source = Mu1, S_source = Sigma1, M_target = Mu0, S_target = Sigma0\n  )\n  # Transport from group 0 to group 1: X2 then X1 | X2\n  X0_st_21 &lt;- sequential_transport_21(\n    X = X0, M_source = Mu0, S_source = Sigma0, M_target = Mu1, S_target = Sigma1\n  )\n  # Transport from group 1 to group 0: X2 then X1 | X2\n  X1_st_21 &lt;- sequential_transport_21(\n    X = X1, M_source = Mu1, S_source = Sigma1, M_target = Mu0, S_target = Sigma0\n  )\n  \n  # 3. Measuring Total Causal Effect\n  tb &lt;- df[, c(\"Y\", \"A\", \"X1\", \"X2\")]\n  A_name &lt;- \"A\"\n  A_untreated &lt;- 0\n  Y_name &lt;- \"Y\"\n  \n  # Causal Mediation Analysis\n  med_mod &lt;- mediation::multimed(\n    outcome = \"Y\", \n    med.main = \"X1\", \n    med.alt = \"X2\", \n    treat = \"A\", \n    data = tb\n  )\n  delta_0_med &lt;- mean((med_mod$d0.lb + med_mod$d0.ub) / 2)\n  delta_1_med &lt;- mean((med_mod$d1.lb + med_mod$d1.ub) / 2)\n  zeta_0_med &lt;- mean((med_mod$z0.lb + med_mod$z0.ub) / 2)\n  zeta_1_med &lt;- mean((med_mod$z1.lb + med_mod$z1.ub) / 2)\n  tot_effect_med &lt;- delta_0_med + zeta_1_med\n  \n  # With OT counterfactuals\n  tb_untreated &lt;- tb |&gt; filter(!!sym(A_name) == !!A_untreated)\n  tb_treated &lt;- tb |&gt; filter(!!sym(A_name) != !!A_untreated)\n  \n  causal_effects_ot &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_t),\n    data_cf_treated = as_tibble(X1_t),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  # With Sequential Transport counterfactuals\n  causal_effect_sot_12 &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    data_cf_treated = as_tibble(X1_st_12) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n  causal_effect_sot_21 &lt;- causal_effects_cf(\n    data_untreated = tb_untreated, \n    data_treated = tb_treated,\n    data_cf_untreated = as_tibble(X0_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    data_cf_treated = as_tibble(X1_st_21) |&gt; magrittr::set_colnames(c(\"X1\", \"X2\")),\n    Y_name = Y_name, \n    A_name = A_name, \n    A_untreated = A_untreated\n  )\n\n  tibble(\n    # Mediation\n    delta_0_med = delta_0_med,\n    delta_1_med = delta_1_med,\n    zeta_0_med = zeta_0_med,\n    zeta_1_med = zeta_1_med,\n    tot_effect_med = tot_effect_med,\n    # OT\n    delta_0_ot = causal_effects_ot$delta_0,\n    delta_1_ot = causal_effects_ot$delta_1,\n    delta_0_ot_obs = causal_effects_ot$delta_0_obs,\n    delta_1_ot_obs = causal_effects_ot$delta_1_obs,\n    zeta_0_ot = causal_effects_ot$zeta_0,\n    zeta_1_ot = causal_effects_ot$zeta_1,\n    tot_effect_ot = causal_effects_ot$tot_effect,\n    tot_effect_ot_obs = causal_effects_ot$tot_effect_obs,\n    # SOT 12\n    delta_0_sot_12 = causal_effect_sot_12$delta_0,\n    delta_1_sot_12 = causal_effect_sot_12$delta_1,\n    delta_0_sot_12_obs = causal_effect_sot_12$delta_0_obs,\n    delta_1_sot_12_obs = causal_effect_sot_12$delta_1_obs,\n    zeta_0_sot_12 = causal_effect_sot_12$zeta_0,\n    zeta_1_sot_12 = causal_effect_sot_12$zeta_1,\n    tot_effect_sot_12 = causal_effect_sot_12$tot_effect,\n    tot_effect_sot_12_obs = causal_effect_sot_12$tot_effect_obs,\n    # SOT 21\n    delta_0_sot_21 = causal_effect_sot_21$delta_0,\n    delta_1_sot_21 = causal_effect_sot_21$delta_1,\n    delta_0_sot_21_obs = causal_effect_sot_21$delta_0_obs,\n    delta_1_sot_21_obs = causal_effect_sot_21$delta_1_obs,\n    zeta_0_sot_21 = causal_effect_sot_21$zeta_0,\n    zeta_1_sot_21 = causal_effect_sot_21$zeta_1,\n    tot_effect_sot_21 = causal_effect_sot_21$tot_effect,\n    tot_effect_sot_21_obs = causal_effect_sot_21$tot_effect_obs,\n    n = n,\n    seed = seed,\n    mu0 = mu0,\n    mu1 = mu1,\n    r0 = r0,\n    r1 = r1,\n    a = a\n  )\n}\n\n\nThe simulations can be run in parallel, as follows.\n\n# This chunk takes about XX minutes to run.\n# We do not evaluate when compiling the document.\n# Instead, we load previously obtained results.\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(tidyverse)\n  library(mnormt)\n  library(expm)\n  library(randomForest)\n}) |&gt;\n  invisible()\n\nclusterExport(\n  cl = cl, c(\n    \"gen_data\", \"compute_ot_map\", \"apply_ot_transport\",\n    \"sequential_transport_12\", \"sequential_transport_21\",\n    \"causal_effects_cf\", \"sim_f\"\n  )\n)\n\nres_sim &lt;- pbapply::pblapply(1:200, function(seed) {\n  sim_f(n = 500, mu0 = -1, mu1 = +1, r0 = +.7, r1 = -.5, a = 1, seed = seed)\n}, cl = cl)\n\nstopCluster(cl)\nres_sim &lt;- list_rbind(res_sim)\n\nsave(res_sim, file = \"../output/res_sim-gaussian-mc-a1.rda\")\n\nWe load previously obtained results:\n\nload(\"../output/res_sim-gaussian-mc-a1.rda\")\n\n\n\nCodes to create the Figure.\n#' @parma metric_name Name of the metric (e.g., \"tot_effect_ot\")\n#' @param method_label Label of the method (for title, e.g., \"OT\")\nplot_hist_sim &lt;- function(metric_name, \n                          method_label,\n                          x_lim = NULL,\n                          y_axis = TRUE,\n                          export_tikz = FALSE) {\n  # type &lt;- match.arg(type)\n  type &lt;- case_when(\n    str_detect(metric_name, \"^delta\") ~ \"delta\",\n    str_detect(metric_name, \"^zeta\") ~ \"zeta\",\n    str_detect(metric_name, \"^tot_effect\") & !str_detect(metric_name, \"obs$\") ~ \"tau\",\n    str_detect(metric_name, \"^tot_effect\") & str_detect(metric_name, \"obs$\") ~ \"theta\",\n    TRUE ~ NA_character_\n  )\n  group &lt;- case_when(\n    str_detect(metric_name, \"_0_\") ~ \"0\",\n    str_detect(metric_name, \"_1_\") ~ \"1\",\n    TRUE ~ \"\"\n  )\n  \n  if (type == \"delta\") {\n    title_lab &lt;- paste0(\"$\\\\bar{\\\\delta}_\", group, \"$, \", method_label)\n  } else if (type == \"zeta\") {\n    title_lab &lt;- paste0(\"$\\\\bar{\\\\zeta}_\", group, \"$, \", method_label)\n  } else if (type == \"tau\") {\n    title_lab &lt;- paste0(\"$\\\\bar{\\\\tau}$, \", method_label)\n  } else {\n    title_lab &lt;- paste0(\"$\\\\bar{\\\\theta}$, \", method_label)\n  }\n  \n  if (export_tikz == FALSE) {\n    title_lab &lt;- latex2exp::TeX(title_lab)\n  }\n  \n  if (group == \"0\") {\n    fill_col &lt;- colGpe0\n  } else if (group == \"1\") {\n    fill_col &lt;- colGpe1\n  } else {\n    fill_col &lt;- \"gray\"\n  }\n  \n  if (is.null(x_lim)) x_lim &lt;- range(res_sim |&gt; pull(!!metric_name))\n  \n  hist(\n    res_sim |&gt; pull(!!metric_name), \n    main = title_lab,\n    xlab = \"\",\n    col = adjustcolor(fill_col, alpha = .5),\n    xlim = x_lim,\n    axes = FALSE\n  )\n  axis(1)\n  if (y_axis == TRUE) axis(2)\n  if (type == \"delta\") {\n    abline(v = (a1+a2)*(mu1-mu0), col = \"darkred\", lty = 2, lwd = 2)\n  } else if (type == \"zeta\") {\n    abline(v = a0, col = \"darkred\", lty = 2, lwd = 2)\n  } else if (type %in% c(\"tau\", \"theta\")) {\n    abline(v = (a1+a2)*(mu1-mu0) + a0, col = \"darkred\", lty = 2, lwd = 2)\n  }\n}\n\n\n\n\nexport_tikz &lt;- FALSE\nfile_name &lt;- \"gaussian-hist-mc\"\n\nif (export_tikz == TRUE)\n  tikz(paste0(\"figs/\", file_name, \".tex\"), width = 2.8, height = 2.8)\npar(mar = c(2.1, 2.1, 2.1, .5), mfrow = c(3,4))\nx_lim &lt;- c(0,5)\nplot_hist_sim(metric_name = \"delta_0_med\", method_label = \"CM\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"delta_0_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"delta_0_sot_12\", method_label = \"ST (1)\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"delta_0_sot_21\", method_label = \"ST (2)\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5)\nplot_hist_sim(metric_name = \"zeta_1_med\", method_label = \"CM\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"zeta_1_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"zeta_1_sot_12\", method_label = \"ST (1)\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"zeta_1_sot_21\", method_label = \"ST (2)\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5)\nplot_hist_sim(metric_name = \"tot_effect_med\", method_label = \"CM\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_sot_12\", method_label = \"ST (1)\", x_lim= x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_sot_21\", method_label = \"ST (2)\", x_lim= x_lim, export_tikz = export_tikz)\nif (export_tikz == TRUE) {\n  dev.off()\n  plot_to_pdf(filename = file_name, path = \"./figs/\", keep_tex = FALSE, crop = TRUE)\n}\n\n\n\n\n\nFigure 3.3: Estimated values of \\(\\bar{\\delta}(0)\\), \\(\\bar{\\zeta}(1)\\), and \\(\\bar{\\tau}\\) across 200 Monte Carlo simulations using Causal Mediation (CM), Optimal Transport (OT), and Sequential Transport ST (1) (moving \\(X_1\\) first) and ST (2) (moving \\(X_2\\) first). The red vertical bar denotes the theoretical value.\n\n\n\n\n\n\n\n\n\n\nCodes to create the Figure.\npar(mar = c(2.1, 2.1, 2.1, .5), mfrow = c(3,4))\nx_lim &lt;- c(0,5)\nplot_hist_sim(metric_name = \"delta_1_med\", method_label = \"CM\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"delta_1_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"delta_1_sot_12\", method_label = \"ST (1)\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"delta_1_sot_21\", method_label = \"ST (2)\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(-1,5)\nplot_hist_sim(metric_name = \"zeta_0_med\", method_label = \"CM\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"zeta_0_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"zeta_0_sot_12\", method_label = \"ST (1)\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"zeta_0_sot_21\", method_label = \"ST (2)\", x_lim = x_lim, export_tikz = export_tikz)\nx_lim &lt;- c(3,5)\nplot_hist_sim(metric_name = \"tot_effect_med\", method_label = \"CM\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_sot_12\", method_label = \"ST (1)\", x_lim= x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_sot_21\", method_label = \"ST (2)\", x_lim= x_lim, export_tikz = export_tikz)\n\n\n\n\n\nFigure 3.4: Estimated values of \\(\\bar{\\delta}(1)\\), \\(\\bar{\\zeta}(0)\\), and \\(\\bar{\\tau}\\) across 200 Monte Carlo simulations using Causal Mediation (CM), Optimal Transport (OT), and Sequential Transport ST (1) (moving \\(X_1\\) first) and ST (2) (moving \\(X_2\\) first). The red vertical bar denotes the theoretical value.\n\n\n\n\n\n\n\n\nThe comparison of the estimates made using observed values for \\(y\\) (whenever observed) is shown in Figure 3.5.\n\n\nCodes to create the Figure.\npar(mar = c(2.1, 2.1, 2.1, .5), mfrow = c(2,3))\nplot_hist_sim(metric_name = \"tot_effect_ot\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_sot_12\", method_label = \"ST (1)\", x_lim= x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_sot_21\", method_label = \"ST (2)\", x_lim= x_lim, export_tikz = export_tikz)\n\nplot_hist_sim(metric_name = \"tot_effect_ot_obs\", method_label = \"OT\", x_lim = x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_sot_12_obs\", method_label = \"ST (1)\", x_lim= x_lim, export_tikz = export_tikz)\nplot_hist_sim(metric_name = \"tot_effect_sot_21_obs\", method_label = \"ST (2)\", x_lim= x_lim, export_tikz = export_tikz)\n\n\n\n\n\nFigure 3.5: Estimated values of \\(\\bar{\\tau}\\) and \\(\\bar{\\theta}\\) across 200 Monte Carlo simulations using ptimal Transport (OT), and Sequential Transport ST (1) (moving \\(X_1\\) first) and ST (2) (moving \\(X_2\\) first). The red vertical bar denotes the theoretical value.\n\n\n\n\n\n\n\n\nWe also use violin plots, since exporting these histograms in a two-column format paper is not a good idea.\n\n\nCodes to create the Figure.\nexport_pdf &lt;- FALSE\n\n\n\np &lt;- ggplot(\n  data = res_sim |&gt; \n    select(\n      delta_0_med, delta_0_ot, delta_0_sot_12, delta_0_sot_21,\n      zeta_1_med, zeta_1_ot, zeta_1_sot_12, zeta_1_sot_21,\n      tot_effect_med, tot_effect_ot, tot_effect_sot_12, tot_effect_sot_21\n    ) |&gt; \n    mutate(row = row_number()) |&gt; \n    pivot_longer(cols = -row) |&gt; \n    mutate(\n      type = case_when(\n        str_detect(name, \"^delta\") ~ \"delta\",\n        str_detect(name, \"^zeta\") ~ \"zeta\",\n        str_detect(name, \"^tot_effect\") & !str_detect(name, \"obs$\") ~ \"tau\",\n        TRUE ~ NA_character_\n      ),\n      type = factor(\n        type, \n        levels = c(\"delta\", \"zeta\", \"tau\"),\n        labels = c(\"$\\\\bar{\\\\delta}(0)$\", \"$\\\\bar{\\\\zeta}(1)$\", \n                   \"$\\\\bar{\\\\tau}$\")\n      ),\n      method = case_when(\n        str_detect(name, \"_med$\") ~ \"CM\",\n        str_detect(name, \"_ot$\") ~ \"OT\",\n        str_detect(name, \"_sot_12$\") ~ \"ST(1)\",\n        str_detect(name, \"sot_21$\") ~ \"ST(2)\",\n        TRUE ~ \"\"\n      ),\n      method = factor(method, levels = rev(c(\"CM\", \"OT\", \"ST(1)\", \"ST(2)\")))\n    )\n) +\n  geom_violin(\n    mapping = aes(x = value, y = method, fill = method),\n    draw_quantiles = c(.25, .5, .75)) +\n  labs(x = NULL, y = NULL)\n\nif (export_pdf == TRUE) {\n  p &lt;- p + \n    facet_wrap(\n    ~ type, scales = \"free_x\",\n  )\n} else {\n  p &lt;- p +\n    facet_wrap(\n      ~ type, scales = \"free_x\",\n      labeller = as_labeller(latex2exp::TeX, default = label_parsed)\n    )\n}\n\np &lt;- p +\n  geom_vline(\n    data = tibble(\n      type = c(\"$\\\\bar{\\\\delta}(0)$\", \"$\\\\bar{\\\\zeta}(1)$\", \n               \"$\\\\bar{\\\\tau}$\"), \n      val_theo = c(\n        (a1+a2)*(mu1-mu0),\n        a0,\n        (a1+a2)*(mu1-mu0) + a0\n      )\n    ) |&gt; \n      mutate(\n        type = factor(\n          type, \n          levels = c(\"$\\\\bar{\\\\delta}(0)$\", \"$\\\\bar{\\\\zeta}(1)$\", \n                     \"$\\\\bar{\\\\tau}$\")\n        )\n      ),\n    mapping = aes(xintercept = val_theo),\n    colour = \"darkred\", linetype = \"dashed\", linewidth = 1\n  ) +\n  scale_fill_manual(\n    NULL, \n    values = c(\n      \"CM\" = \"gray\",\n      \"OT\" = colour_methods[[\"OT\"]], \n      \"ST(1)\" =  colour_methods[[\"seq_1\"]],\n      \"ST(2)\" =  colour_methods[[\"seq_2\"]]\n    ),\n    guide = \"none\"\n  ) +\n  theme_paper()\n\np\n\nif (export_pdf == TRUE) {\n  ggplot2_to_pdf(\n    plot = p, \n    filename = \"gaussian-violin-mc\", path = \"figs/\", \n    width = 3.3, height = 1.5,\n    crop = TRUE\n  )\n  \n  system(paste0(\"pdfcrop figs/gaussian-violin-mc.pdf figs/gaussian-violin-mc.pdf\"))\n}\n\n\n\n\n\nFigure 3.6: Estimated values of \\(\\bar{\\delta}(0)\\), \\(\\bar{\\zeta}(1)\\), and \\(\\bar{\\tau}\\) across 200 Monte Carlo simulations using Causal Mediation (CM), Optimal Transport (OT), and Sequential Transport ST (1) (moving \\(X_1\\) first) and ST (2) (moving \\(X_2\\) first). The red vertical bar denotes the theoretical value.\n\n\n\n\n\n\n\n\n\n\n\n\nImai, Kosuke, Luke Keele, and Teppei Yamamoto. 2010. “Identification, Inference and Sensitivity Analysis for Causal Mediation Effects.” Statistical Science 25 (1): 51–71.\n\n\nPearl, Judea. 2001. “Direct and Indirect Effects.” In Proceedings of the Seventeenth Conference on Uncertainty and Artificial Intelligence, 2001, 411–20. Morgan Kaufmann, San Francisco.",
    "crumbs": [
      "I. Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Gaussian Example</span>"
    ]
  }
]